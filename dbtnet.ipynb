{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "#!pip install monai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "import csv\n",
    "from scipy import ndimage, misc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skimage.measure import label\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "\n",
    "import functools\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "#from ipywidgets import IProgress\n",
    "# [STAR] All imports for DBT\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from duke_dbt_data import dcmread_image, read_boxes, draw_box, evaluate\n",
    "np.random.seed(0)\n",
    "#torch.manual_seed(0)!pip install monai\n",
    "\n",
    "# [STAR] All the Imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     11,
     28,
     48,
     82,
     99,
     114,
     125,
     136,
     163,
     190,
     198,
     206,
     269,
     332,
     393,
     429,
     517,
     650,
     773,
     836,
     934,
     939,
     1021
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Pytorch Models for training\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block \n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(Attention_block, self).__init__()\n",
    "\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        out = x * psi\n",
    "        return out\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class DoubleConv_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Down_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            DoubleConv_3D(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class Up_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up   = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv_3D(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv_3D, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.dp2 = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "        #x3 = self.dp1(x3)\n",
    "        \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "        #x4 = self.dp2(x4)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_3D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc   = DoubleConv_3D(n_channels, 16)\n",
    "        self.down1 = Down_3D(16, 32)\n",
    "        self.down2 = Down_3D(32, 64)\n",
    "        self.down3 = Down_3D(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down_3D(128, 256 // factor)\n",
    "        self.up1 = Up_3D(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up_3D(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up_3D(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up_3D(32, 16, bilinear)\n",
    "        self.outc = OutConv_3D(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.dp2 = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "        #x3 = self.dp1(x3)\n",
    "        \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "        #x4 = self.dp2(x4)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_with_BN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_with_BN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.BatchNorm2d(16)\n",
    "        self.gn2 = nn.BatchNorm2d(32)\n",
    "        self.gn3 = nn.BatchNorm2d(64)\n",
    "        self.gn4 = nn.BatchNorm2d(128)\n",
    "        self.gn5 = nn.BatchNorm2d(64)\n",
    "        self.gn6 = nn.BatchNorm2d(32)\n",
    "        self.gn7 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.4)\n",
    "        self.dp2 = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_without_GN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_without_GN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x  = self.up1(x5, x4)\n",
    "        x  = self.up2(x, x3)\n",
    "        x  = self.up3(x, x2)\n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN_old(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=256, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.bilinear = bilinear\n",
    "        self.n_classes = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        self.lsgn_a = nn.GroupNorm(128,256)\n",
    "    \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h = torch.unsqueeze(hidden,0)\n",
    "        \n",
    "        embedded = input\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        hidden_bilstm = h[0]\n",
    "        \n",
    "        \n",
    "        hidden_bilinn =  hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "    \n",
    "        hidden_bilinn = self.lsgn_a(hidden_bilinn)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden_bilinn), 1)), dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        attn_weights  = self.lsgn_a(attn_weights)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "   #     print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "  #      print('The output shape is : ',output.shape)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    " #      print('The output shape after is : ',output.shape)\n",
    "        \n",
    "    \n",
    "        hidden_bi = hidden_bilinn.unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #print(\"output and hidden before lstm \",output.shape,hidden_bi.shape)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        output = self.lsgn_a(output)\n",
    "        \n",
    "       #output = self.lsgn_a(output)\n",
    "    \n",
    "        return output,hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "\n",
    "############### MAIN MODEL ##############\n",
    "class UNetDoubleSmallGroupNormdifferent_old(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(128,256)\n",
    "        \n",
    "        self.lsgn2 = nn.GroupNorm(64,256)\n",
    "        \n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        #print('x5 shape is :',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,256,256])\n",
    "\n",
    "        lstm = nn.LSTM(256,256,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "                \n",
    "        #print('xlst',xlst.shape)    \n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        \n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        \n",
    "        #print(hidden)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        \n",
    "        \n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,256,256))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "    \n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,256,16,16])\n",
    "        \n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    " \n",
    "        \n",
    "        \n",
    "        x5 = self.lsgn2(x5)\n",
    "        \n",
    "        ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallGroupNormdifferent(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc     = DoubleConv(n_channels, 16)\n",
    "        self.down1   = Down(16, 32)\n",
    "        self.downnew = Down(16,16)\n",
    "        self.down2   = Down(32, 64)\n",
    "        self.down3   = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4   = Down(128, 256 // factor) \n",
    "        self.upsam   = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        self.ups3  = nn.ConvTranspose2d(1 , 1, kernel_size=2, stride=2)\n",
    "        self.ups4  = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(64,128)\n",
    "        self.lsgn2 = nn.GroupNorm(64,1024)\n",
    "        self.lsgn3 = nn.GroupNorm(64,1024)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        self.gn8 = nn.GroupNorm(4,8)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        #x = self.upsam()\n",
    "        \n",
    "        x1 = self.inc(x)\n",
    "        #x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "        #x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "        #x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        #x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        #x5 = self.gn\n",
    "        #x5 = torch.squeeze(x5)\n",
    "        #x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        #print('x5:',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,128,1024])\n",
    "        \n",
    "\n",
    "        lstm = nn.LSTM(1024,1024,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,128,1024))\n",
    "        #a = ndarray((4,128,1024))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo   = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,128,32,32])\n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    "        #x5 = self.lsgn3(x5)\n",
    "        \n",
    "        #x5 = self.ups4(x5)\n",
    "    \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "        #x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        #x = self.gn7(x)\n",
    "\n",
    "        #x = self.downnew(x)\n",
    "        \n",
    "        #out    = self.out_softmax(logits)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallWithoutGN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallWithoutGN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc   = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        ups4     = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=128, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p   = dropout_p\n",
    "        self.max_length  = max_length\n",
    "        self.bilinear    = bilinear\n",
    "        self.n_classes   = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn      = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.attn2   = nn.Linear(1024, 128)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(3072, 1024)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru     = nn.GRU(1024, 1024)\n",
    "        self.out     = nn.Linear(1024, 1024)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        #self.lsgn_a = nn.GroupNorm(512,1024)\n",
    "        self.lsbn_a1 = nn.BatchNorm1d(1024)\n",
    "        #self.lsgn_a2 = nn.GroupNorm(512,1024)\n",
    "        \n",
    "        #self.lsgn_in = nn.GroupNorm(64,128)\n",
    "        self.lsbn_in1 = nn.BatchNorm1d(2048)\n",
    "        self.lsbn_in2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        \n",
    "        self.lsbn_in3 = nn.BatchNorm1d(128)#nn.GroupNorm(64,   128)\n",
    "        self.lsbn_in4 = nn.BatchNorm1d(128)#nn.GroupNorm(64,   128)\n",
    "        self.lsbn_in5 = nn.BatchNorm1d(1024)#nn.GroupNorm(512,  1024)\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4     = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h        = torch.unsqueeze(hidden, 0)\n",
    "        embedded = input\n",
    "        #embedded = self.lsgn_in1(embedded)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        hidden_bilstm = h[0]\n",
    "        hidden_bilinn = hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "        hidden_bilinn = self.lsbn_a1(hidden_bilinn)\n",
    "        \n",
    "        hidden_bi     = hidden_bilinn.unsqueeze(0)\n",
    "        \n",
    "        #print(hidden_bilinn.shape)\n",
    "        \n",
    "        attn_weights  = torch.cat((embedded[0], hidden_bilinn), 1)\n",
    "        attn_weights  = self.lsbn_in1(attn_weights)\n",
    "        \n",
    "        attn_weights  = self.attn(attn_weights)\n",
    "        attn_weights  = self.lsbn_in2(attn_weights)\n",
    "        \n",
    "        attn_weights  = F.softmax(attn_weights, dim=1)\n",
    "        \n",
    "        attn_weights  = self.attn2(attn_weights)\n",
    "        attn_weights  = self.lsbn_in3(attn_weights)\n",
    "        \n",
    "        #print(attn_weights.unsqueeze(0).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        #print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output = self.lsbn_in4(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = self.out(output[0])\n",
    "        output = self.lsbn_in5(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "\n",
    "class AttU_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Unet implementation\n",
    "    Paper: https://arxiv.org/abs/1804.03999\n",
    "    \"\"\"\n",
    "    def __init__(self, img_ch=1, output_ch=1):\n",
    "        super(AttU_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(img_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        #self.active = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "\n",
    "        #print(x5.shape)\n",
    "        d5 = self.Up5(e5)\n",
    "        #print(d5.shape)\n",
    "        x4 = self.Att5(g=d5, x=e4)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4, x=e3)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3, x=e2)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2, x=e1)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "      #  out = self.active(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class UNetNormal(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNetNormal, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        my_factor = 1\n",
    "        factor    = 1\n",
    "        \n",
    "        self.inc   = DoubleConv(n_channels, 32*my_factor)\n",
    "        self.down1 = Down(32*my_factor, 64*my_factor)\n",
    "        self.down2 = Down(64*my_factor, 128*my_factor)\n",
    "        self.down3 = Down(128*my_factor, 256*my_factor)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(256*my_factor, 512*my_factor // factor)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(256,512)\n",
    "        self.lsgn2 = nn.GroupNorm(512,1024)\n",
    "        \n",
    "        self.up1 = Up(512*my_factor, 256*my_factor // factor, bilinear)\n",
    "        self.up2 = Up(256*my_factor, 128*my_factor // factor, bilinear)\n",
    "        self.up3 = Up(128*my_factor, 64*my_factor // factor, bilinear)\n",
    "        self.up4 = Up(64*my_factor, 32*my_factor, bilinear)\n",
    "        self.outc = OutConv(32*my_factor, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        #self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "#model = SUNet_3D(1, 1)\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Read all the slices in training set without augmentation\n",
    "\n",
    "basepath = '/home/drilnvm/DBTex/'\n",
    "df = read_boxes(boxes_fp=basepath+\"BCS-DBT-boxes-train.csv\", filepaths_fp=basepath+\"BCS-DBT-file-paths-train.csv\")\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr = []\n",
    "height_arr = []\n",
    "\n",
    "for i in tqdm(range(224)):\n",
    "    box_series  = df.iloc[i]\n",
    "    view        = box_series[\"View\"]\n",
    "    slice_index = box_series[\"Slice\"]\n",
    "    image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    image       = dcmread_image(fp=image_path, view=view, index=slice_index-1)\n",
    "    \n",
    "    #trainx.append(image[slice_index-1:slice_index+1])\n",
    "    #trainx.append(image[slice_index])\n",
    "    trainx.append(image)\n",
    "    trainy.append(box_series[\"Class\"])\n",
    "    #image = image[slice_index]\n",
    "    \n",
    "    x, y, width, height = box_series[[\"X\", \"Y\", \"Width\", \"Height\"]]\n",
    "    #image               = draw_box(image=image, x=x, y=y, width=width, height=height, lw=10)\n",
    "    #boximage.append(image)\n",
    "    coordx.append(x)\n",
    "    coordy.append(y)\n",
    "    width_arr.append(width)\n",
    "    height_arr.append(height)\n",
    "\n",
    "print(len(trainx), len(trainy), len(boximage))\n",
    "\n",
    "# mx = 0\n",
    "# my = 0\n",
    "# for i in range(len(trainx)):\n",
    "#     if trainx[i].shape[0] > mx:\n",
    "#         mx = trainx[i].shape[0]\n",
    "#     if trainx[i].shape[1] > my:\n",
    "#         my = trainx[i].shape[1]\n",
    "# print(mx, my)\n",
    "\n",
    "if(1):\n",
    "    np.save('coordx.npy', coordx)\n",
    "    np.save('coordy.npy', coordy)\n",
    "\n",
    "    newtrainx  = np.zeros([len(trainx), 1, 3000, 2000], 'float16')\n",
    "    newtrainy  = np.zeros([len(trainx), 1], 'float16')\n",
    "    for i in range(len(trainx)):\n",
    "        newtrainx[i, 0, :trainx[i].shape[0], :trainx[i].shape[1]] = trainx[i]\n",
    "        if trainy[i] == 'benign':\n",
    "            newtrainy[i, 0] = 0\n",
    "        else:\n",
    "            newtrainy[i, 0] = 1\n",
    "\n",
    "    np.save('trainx.npy', newtrainx)\n",
    "    np.save('trainy.npy', newtrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     63,
     121,
     161,
     209,
     215,
     220
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] DBT classes for data loader\n",
    "\n",
    "class DBTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_set = 1, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        suffix_str  = ''#random.choice(['_m2', '_m1', '_p1', '_p2', ''])\n",
    "        print('READING NEW FILE >> ', suffix_str, ' <<')\n",
    "        \n",
    "        #shuffle_index = np.arange(224)\n",
    "        #np.random.shuffle(shuffle_index)\n",
    "        #np.save('shuffle_array.npy', shuffle_index)\n",
    "        #shuffle_index = np.load('shuffle_array.npy')\n",
    "        \n",
    "        trainx = np.load('trainx'+suffix_str+'.npy')\n",
    "        trainy = np.load('trainy'+suffix_str+'.npy')\n",
    "        coordx = np.load('coordx'+suffix_str+'.npy')\n",
    "        coordy = np.load('coordy'+suffix_str+'.npy')\n",
    "        width_arr  = np.load('width_arr'+suffix_str+'.npy')\n",
    "        height_arr = np.load('height_arr'+suffix_str+'.npy')\n",
    "        \n",
    "        #trainx = trainx[shuffle_index]\n",
    "        #trainy = trainy[shuffle_index]\n",
    "        #coordx = coordx[shuffle_index]\n",
    "        #coordy = coordy[shuffle_index]\n",
    "        #width_arr  = width_arr[shuffle_index]\n",
    "        #height_arr = height_arr[shuffle_index]\n",
    "        \n",
    "        self.counter = 0\n",
    "        if train_set == 1:\n",
    "            self.train_start  = 0\n",
    "            self.train_end    = 175\n",
    "        else:\n",
    "            self.train_start  = 175\n",
    "            self.train_end    = 220\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        #t1 = np.load('trainx_m1.npy')[self.train_start:self.train_end]\n",
    "        #t2 = np.load('trainx.npy')[self.train_start:self.train_end]\n",
    "        #t3 = np.load('trainx_p1.npy')[self.train_start:self.train_end]\n",
    "        #self.trainx  =  np.concatenate([t2, t1, t3], axis=1)\n",
    "        \n",
    "        self.trainx = trainx[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "        self.trainy = trainy[self.train_start:self.train_end]\n",
    "        self.coordx = coordx[self.train_start:self.train_end]\n",
    "        self.coordy = coordy[self.train_start:self.train_end]\n",
    "        self.width_arr  = width_arr[self.train_start:self.train_end]\n",
    "        self.height_arr = height_arr[self.train_start:self.train_end]\n",
    "        \n",
    "        print('Total size of dataset ', len(np.load('width_arr'+suffix_str+'.npy')))\n",
    "#         self.trainx = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainx.npy')[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "#         self.trainy = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainy.npy')[self.train_start:self.train_end]\n",
    "#         self.coordx = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordx.npy')[self.train_start:self.train_end]\n",
    "#         self.coordy = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordy.npy')[self.train_start:self.train_end]\n",
    "#         self.width_arr  = np.load('/media/yu-hao/WindowsData/DBT_numpy/width_arr.npy')[self.train_start:self.train_end]\n",
    "#         self.height_arr = np.load('/media/yu-hao/WindowsData/DBT_numpy/height_arr.npy')[self.train_start:self.train_end]\n",
    "        \n",
    "        self.transforms1 = A.Compose(\n",
    "                                    [A.HorizontalFlip(p=0.5),  A.VerticalFlip(p=0.5), ],\n",
    "                                     #A.Downscale(scale_min=0.95, scale_max=0.98, p=0.25, interpolation=3),],\n",
    "                                    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']),\n",
    "                                   )\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        self.counter = self.counter+1\n",
    "        #if self.counter % 10 == 0:\n",
    "        #    print('Counter is ', self.counter)\n",
    "        \n",
    "#         if self.train_set == 1 and self.counter % 150 == 0 and random.random() < 0.2:\n",
    "#             suffix_str  = random.choice([ '_m1', '_p1', ''])\n",
    "#             print('READING NEW FILE >> ', suffix_str, ' <<')\n",
    "#             self.trainx = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainx'+suffix_str+'.npy')[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "#             self.trainy = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainy'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.coordx = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordx'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.coordy = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordy'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.width_arr  = np.load('/media/yu-hao/WindowsData/DBT_numpy/width_arr'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.height_arr = np.load('/media/yu-hao/WindowsData/DBT_numpy/height_arr'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "                \n",
    "        #img = self.trainx[idx].astype('float32')/60000.0\n",
    "        img = self.trainx[idx, 0].astype('float32')/60000.0\n",
    "        img[img > 1] = 1\n",
    "        img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        if(self.train_set == 1):\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        \n",
    "        boxes = np.array([self.coordx[idx]/4, self.coordy[idx]/4, self.width_arr[idx]/4, self.height_arr[idx]/4])#records[['x', 'y', 'w', 'h']].values\n",
    "        boxes = np.expand_dims(boxes, axis=0)\n",
    "        boxes[:, 2] = boxes[:, 0]+boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1]+boxes[:, 3]\n",
    "        \n",
    "        area = self.width_arr[idx] * self.height_arr[idx]\n",
    "        area = torch.Tensor(area)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels =  torch.ones((1,)).type(torch.int64)\n",
    "        \n",
    "        if(self.train_set == 1):\n",
    "        #if(0):\n",
    "            transformed = self.transforms1(image=img, bboxes=boxes, labels=labels)\n",
    "            image    = transformed['image']\n",
    "            boxes    = np.array(transformed['bboxes'])\n",
    "            img      = np.moveaxis(image, 2, 0)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.Tensor(np.array([0])).type(torch.int64)\n",
    "        \n",
    "        target              = {}\n",
    "        target['boxes']     = torch.Tensor(boxes)\n",
    "        target['labels']    = labels\n",
    "        target['image_id']  = torch.tensor([idx])\n",
    "        target['area']      = area\n",
    "        target['iscrowd']   = iscrowd\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.trainx.shape[0]\n",
    "\n",
    "class DBTDatasetValidation(torch.utils.data.Dataset):\n",
    "    def __init__(self, val_index = 0, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.basepath  = '/home/drilnvm/DBTex/'\n",
    "        self.counter   = 0\n",
    "        self.val_index = val_index\n",
    "        self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-train.csv')\n",
    "        #self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "        \n",
    "        box_series       = self.df.iloc[self.val_index]\n",
    "        self.PatientID   = box_series[\"PatientID\"]\n",
    "        self.StudyUID    = box_series[\"StudyUID\"]\n",
    "        self.view        = box_series[\"View\"]\n",
    "        \n",
    "        image_path      = os.path.join(self.basepath, box_series[\"descriptive_path\"])\n",
    "        self.vol        = dcmread_image(fp=image_path, view=self.view)\n",
    "        self.newtrainx  = np.zeros([len(self.vol), 1, 3000, 2000], 'float16')\n",
    "        for i in range(len(self.vol)):\n",
    "            self.newtrainx[i, 0, :self.vol[i].shape[0], :self.vol[i].shape[1]] = self.vol[i]\n",
    "        \n",
    "        print('File reading done ', self.vol.shape, image_path)\n",
    "        #print()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img          = self.newtrainx[idx, 0].astype('float32')/60000.0\n",
    "        img[img > 1] = 1\n",
    "        img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        target              = {}\n",
    "        target['image_id']  = torch.tensor([idx])\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vol.shape[0]\n",
    "\n",
    "class DBTDatasetValidationTrain(torch.utils.data.Dataset):\n",
    "    def __init__(self, val_index = 0, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.basepath  = '/home/drilnvm/DBTex/'\n",
    "        self.counter   = 0\n",
    "        self.val_index = val_index\n",
    "        self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv')\n",
    "        #self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "        \n",
    "        box_series       = self.df.iloc[self.val_index]\n",
    "        self.PatientID   = box_series[\"PatientID\"]\n",
    "        self.StudyUID    = box_series[\"StudyUID\"]\n",
    "        self.view        = box_series[\"View\"]\n",
    "        self.slice_index = box_series[\"Slice\"]\n",
    "        self.X           = box_series[\"X\"]\n",
    "        self.Y           = box_series[\"Y\"]\n",
    "        self.Width       = box_series[\"Width\"]\n",
    "        self.Height      = box_series[\"Height\"]\n",
    "        #Slice,X,Y,Width,Height\n",
    "        \n",
    "        #image_path      = os.path.join(self.basepath, box_series[\"descriptive_path\"])\n",
    "        self.vol = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy/'+self.PatientID+'_'+self.StudyUID+'_'+self.view+'.npy')\n",
    "        #self.vol        = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy1/val_vol_'+str(val_index)+'.npy')#dcmread_image(fp=image_path, view=self.view)\n",
    "        self.newtrainx  = np.expand_dims(self.vol, 1)#np.zeros([len(self.vol), 1, 750, 500], 'float16')\n",
    "        #for i in range(len(self.vol)):\n",
    "        #    self.newtrainx[i, 0, :self.vol[i].shape[0], :self.vol[i].shape[1]] = self.vol[i]\n",
    "        print('File reading done ',            self.vol.shape)\n",
    "        #print('Inside DBTDatasetValidationTrain ', box_series)\n",
    "        \n",
    "        #print(box_series[\"descriptive_path\"])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img          = self.newtrainx[idx, 0].astype('float32')#/60000.0\n",
    "        img[img > 1] = 1\n",
    "        #img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        target              = {}\n",
    "        if idx == self.slice_index:\n",
    "            target['boxes']  = torch.tensor([self.X, self.Y, self.X+self.Width, self.Y+self.Height])\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vol.shape[0]\n",
    "\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n",
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n"
     ]
    }
   ],
   "source": [
    "# [STAR] DBT Dataset and Model Creation\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataset     = DBTDataset(train_set=1)\n",
    "valid_dataset     = DBTDataset(train_set=0)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=1, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "#model       = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "params       = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer    = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0001)\n",
    "lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     7,
     13
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Train loss: 0.24805516038428654\n",
      "Epoch #0 Val   loss: 0.20107608354753917\n",
      "Saving the model  1000 0.20107608354753917\n",
      "Epoch #1 Train loss: 0.19063299995931712\n",
      "Epoch #1 Val   loss: 0.1944615145524343\n",
      "Saving the model  0.20107608354753917 0.1944615145524343\n",
      "Epoch #2 Train loss: 0.17734958468513054\n",
      "Epoch #2 Val   loss: 0.18896096445344113\n",
      "Saving the model  0.1944615145524343 0.18896096445344113\n",
      "Epoch #3 Train loss: 0.16284725290130486\n",
      "Epoch #3 Val   loss: 0.18728316101349063\n",
      "Saving the model  0.18896096445344113 0.18728316101349063\n"
     ]
    }
   ],
   "source": [
    "# [STAR] Training loop for DBT dataset\n",
    "\n",
    "loss_hist     = Averager()\n",
    "val_loss_hist = Averager()\n",
    "\n",
    "prev_min   = 1000\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    loss_hist.reset()\n",
    "    \n",
    "    model.train()\n",
    "    itr = 1\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "        \n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses     = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if itr % 50 == 0:\n",
    "        #    print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in valid_data_loader:\n",
    "            new_images  = []\n",
    "            for img in images:\n",
    "                new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "            images    = new_images\n",
    "            targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            #print(loss_dict)\n",
    "\n",
    "            losses     = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            val_loss_hist.send(loss_value)\n",
    "\n",
    "            #if itr % 50 == 0:\n",
    "            #    print(f\"Validation Iteration #{itr} loss: {loss_value}\")\n",
    "            itr = itr+1\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    if val_loss_hist.value < prev_min:\n",
    "        print(f\"Epoch #{epoch} Train loss: {loss_hist.value}\")\n",
    "        print(f\"Epoch #{epoch} Val   loss: {val_loss_hist.value}\")\n",
    "        print('Saving the model ', prev_min, val_loss_hist.value)\n",
    "        torch.save(model.state_dict(), 'fasterrcnn_resnet50_dbt25.pth')\n",
    "        prev_min = val_loss_hist.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Iteration #10 loss: 0.15957418084144592\n",
      "Validation Iteration #20 loss: 0.2850976288318634\n",
      "Validation Iteration #30 loss: 0.21906031668186188\n",
      "Validation Iteration #40 loss: 0.2091214954853058\n",
      "0.18152466780609555\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For printing the loss of the trained model\n",
    "\n",
    "# fasterrcnn_resnet50_dbt7.pth  0.24080992616713048\n",
    "# fasterrcnn_resnet50_dbt8.pth  0.1653416310250759\n",
    "# fasterrcnn_resnet50_dbt9.pth  0.17630461007356643\n",
    "# fasterrcnn_resnet50_dbt10.pth 0.17438715264201166\n",
    "# fasterrcnn_resnet50_dbt11.pth 0.16590506657958032\n",
    "# fasterrcnn_resnet50_dbt14.pth 0.1608045955002308\n",
    "# fasterrcnn_resnet50_dbt21.pth 0.15965028703212739\n",
    "# fasterrcnn_resnet50_dbt15.pth (3 adjacent channel)\n",
    "\n",
    "all_target    = []\n",
    "all_scores    = []\n",
    "val_loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt25.pth'))\n",
    "model.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        #print(loss_dict)\n",
    "\n",
    "        losses     = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        val_loss_hist.send(loss_value)\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(f\"Validation Iteration #{itr} loss: {loss_value}\")\n",
    "        itr = itr+1\n",
    "\n",
    "print(val_loss_hist.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  175 DBT-P03658 DBT-S05241 rmlo\n",
      "File reading done  (78, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/49 [00:04<03:38,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  176 DBT-P03677 DBT-S00709 lcc\n",
      "File reading done  (78, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/49 [00:09<03:33,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  177 DBT-P03677 DBT-S00709 lmlo\n",
      "File reading done  (73, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/49 [00:13<03:24,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  178 DBT-P03677 DBT-S00709 rcc\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/49 [00:17<03:19,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  179 DBT-P03677 DBT-S00709 rcc\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/49 [00:22<03:14,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  180 DBT-P03677 DBT-S00709 rmlo\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/49 [00:26<03:09,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  181 DBT-P03677 DBT-S00709 rmlo\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/49 [00:30<03:04,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  182 DBT-P03748 DBT-S02094 lcc\n",
      "File reading done  (78, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 8/49 [00:35<03:01,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  183 DBT-P03748 DBT-S02094 lmlo\n",
      "File reading done  (74, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/49 [00:39<02:55,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  184 DBT-P03816 DBT-S03888 rcc\n",
      "File reading done  (70, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/49 [00:43<02:47,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  185 DBT-P03816 DBT-S03888 rmlo\n",
      "File reading done  (85, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/49 [00:48<02:50,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  186 DBT-P03915 DBT-S05004 lcc\n",
      "File reading done  (72, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/49 [00:52<02:42,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  187 DBT-P03978 DBT-S00442 rcc\n",
      "File reading done  (50, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 13/49 [00:55<02:22,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  188 DBT-P03978 DBT-S00442 rmlo\n",
      "File reading done  (45, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 14/49 [00:58<02:04,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  189 DBT-P04026 DBT-S01650 rcc1\n",
      "File reading done  (65, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 15/49 [01:02<02:03,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  190 DBT-P04026 DBT-S01650 rmlo\n",
      "File reading done  (58, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 16/49 [01:05<01:57,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  191 DBT-P04090 DBT-S01718 rcc\n",
      "File reading done  (87, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 17/49 [01:10<02:08,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  192 DBT-P04090 DBT-S01718 rmlo\n",
      "File reading done  (80, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 18/49 [01:15<02:10,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  193 DBT-P04116 DBT-S03961 rcc\n",
      "File reading done  (80, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 19/49 [01:19<02:10,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  194 DBT-P04116 DBT-S03961 rmlo\n",
      "File reading done  (83, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 20/49 [01:24<02:10,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  195 DBT-P04326 DBT-S03750 lcc\n",
      "File reading done  (79, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 21/49 [01:29<02:06,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  196 DBT-P04326 DBT-S03750 lmlo\n",
      "File reading done  (93, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 22/49 [01:34<02:09,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  197 DBT-P04372 DBT-S04281 lcc\n",
      "File reading done  (72, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 23/49 [01:39<01:59,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  198 DBT-P04372 DBT-S04281 lmlo\n",
      "File reading done  (81, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 24/49 [01:43<01:56,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  199 DBT-P04429 DBT-S00568 lcc\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 25/49 [01:48<01:50,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  200 DBT-P04429 DBT-S00568 lmlo\n",
      "File reading done  (74, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 26/49 [01:52<01:43,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  201 DBT-P04631 DBT-S05515 lcc\n",
      "File reading done  (70, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 27/49 [01:56<01:36,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  202 DBT-P04631 DBT-S05515 lmlo\n",
      "File reading done  (83, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 28/49 [02:01<01:34,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  203 DBT-P04710 DBT-S03227 rcc\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 29/49 [02:05<01:30,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  204 DBT-P04710 DBT-S03227 rmlo\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 30/49 [02:10<01:25,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  205 DBT-P04721 DBT-S01833 lcc\n",
      "File reading done  (67, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 31/49 [02:14<01:18,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  206 DBT-P04721 DBT-S01833 lmlo\n",
      "File reading done  (63, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 32/49 [02:18<01:10,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  207 DBT-P04750 DBT-S00052 rcc\n",
      "File reading done  (63, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 33/49 [02:21<01:04,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  208 DBT-P04818 DBT-S02975 rcc\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 34/49 [02:26<01:02,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  209 DBT-P04818 DBT-S02975 rmlo\n",
      "File reading done  (79, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 35/49 [02:30<00:59,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  210 DBT-P04858 DBT-S04555 lmlo\n",
      "File reading done  (66, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 36/49 [02:34<00:54,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  211 DBT-P04858 DBT-S04555 rcc\n",
      "File reading done  (61, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 37/49 [02:38<00:47,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  212 DBT-P04901 DBT-S05032 rcc\n",
      "File reading done  (60, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 38/49 [02:41<00:42,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  213 DBT-P04901 DBT-S05032 rmlo\n",
      "File reading done  (64, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 39/49 [02:45<00:38,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  214 DBT-P05014 DBT-S04931 rcc\n",
      "File reading done  (80, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 40/49 [02:50<00:36,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  215 DBT-P05014 DBT-S04931 rmlo\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 41/49 [02:54<00:33,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  216 DBT-P05022 DBT-S05195 rcc\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 42/49 [02:58<00:29,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  217 DBT-P05022 DBT-S05195 rmlo\n",
      "File reading done  (72, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 43/49 [03:03<00:25,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  218 DBT-P05030 DBT-S05569 rcc\n",
      "File reading done  (75, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 44/49 [03:07<00:21,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  219 DBT-P05030 DBT-S05569 rmlo\n",
      "File reading done  (74, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 45/49 [03:11<00:17,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  220 DBT-P05047 DBT-S05588 rcc\n",
      "File reading done  (78, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 46/49 [03:16<00:13,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  221 DBT-P05047 DBT-S05588 rmlo\n",
      "File reading done  (76, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 47/49 [03:20<00:08,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  222 DBT-P05056 DBT-S01839 rcc\n",
      "File reading done  (72, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 48/49 [03:25<00:04,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  223 DBT-P05056 DBT-S01839 rmlo\n",
      "File reading done  (65, 750, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [03:28<00:00,  4.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For Obtaining the result on Validation set of the Challenge\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt25.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr  = []\n",
    "height_arr = []\n",
    "\n",
    "PatientID_arr = []\n",
    "StudyUID_arr  = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "        \n",
    "basepath = '/home/drilnvm/DBTex/'\n",
    "df = read_boxes(boxes_fp=basepath+\"BCS-DBT-boxes-train.csv\", filepaths_fp=basepath+\"BCS-DBT-file-paths-train.csv\")\n",
    "\n",
    "    \n",
    "for i in tqdm(range(175, 224)):\n",
    "    #if i in shuffle_index:\n",
    "    \n",
    "    #else:\n",
    "    #    continue\n",
    "    box_series  = df.iloc[i]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view        = box_series[\"View\"]\n",
    "    \n",
    "    print('Processing ', i, PatientID, StudyUID, view)\n",
    "    \n",
    "    #slice_index = box_series[\"Slice\"]\n",
    "    #image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #print(box_series)\n",
    "    \n",
    "    valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "    #valid_dataset     = DBTDataset(train_set=0)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "        \n",
    "    all_target = []\n",
    "    all_scores = []\n",
    "    all_images = []\n",
    "    \n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        #print(targets)\n",
    "        all_images.append(images[0][0].astype('float16'))\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        #targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images)\n",
    "        #print(loss_dict)\n",
    "        \n",
    "        all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "        all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_results25/'+PatientID+'_'+StudyUID+'_'+view+'_score_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_scores, filehandle)\n",
    "        \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_results25/'+PatientID+'_'+StudyUID+'_'+view+'_target_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_target, filehandle)\n",
    "    \n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_vol_'+str(i), np.array(all_images).astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total validation length  224\n",
      "DBT-P03658,DBT-S05241,rmlo,1763,213,96,182,22,8,0.81263536\n",
      "DBT-P03658,DBT-S05241,rmlo,1044,214,1612,214,63,8,0.5722631\n",
      "DBT-P03677,DBT-S00709,lcc,285,221,1032,463,42,8,0.6317786\n",
      "DBT-P03677,DBT-S00709,lcc,220,285,1006,283,53,8,0.73361546\n",
      "DBT-P03677,DBT-S00709,lmlo,0,116,85,122,17,8,0.5756018\n",
      "DBT-P03677,DBT-S00709,lmlo,0,114,91,117,22,8,0.7432487\n",
      "DBT-P03677,DBT-S00709,lmlo,397,246,1195,392,29,8,0.5984555\n",
      "DBT-P03677,DBT-S00709,lmlo,311,236,1360,335,45,8,0.7659871\n",
      "DBT-P03677,DBT-S00709,lmlo,262,301,1381,337,50,8,0.72628415\n",
      "DBT-P03677,DBT-S00709,lmlo,303,271,1326,307,60,8,0.54247487\n",
      "DBT-P03677,DBT-S00709,rcc,1579,335,1388,714,7,8,0.56710875\n",
      "DBT-P03677,DBT-S00709,rcc,1529,426,1589,468,19,8,0.8489964\n",
      "DBT-P03677,DBT-S00709,rcc,1565,310,1535,294,31,8,0.74650955\n",
      "DBT-P03677,DBT-S00709,rcc,1598,226,1395,374,39,8,0.77168953\n",
      "DBT-P03677,DBT-S00709,rcc,1740,156,769,292,52,8,0.6725952\n",
      "DBT-P03677,DBT-S00709,rcc,1735,160,774,299,62,8,0.6883447\n",
      "DBT-P03677,DBT-S00709,rcc,1579,335,1388,714,7,8,0.56710875\n",
      "DBT-P03677,DBT-S00709,rcc,1529,426,1589,468,19,8,0.8489964\n",
      "DBT-P03677,DBT-S00709,rcc,1565,310,1535,294,31,8,0.74650955\n",
      "DBT-P03677,DBT-S00709,rcc,1598,226,1395,374,39,8,0.77168953\n",
      "DBT-P03677,DBT-S00709,rcc,1740,156,769,292,52,8,0.6725952\n",
      "DBT-P03677,DBT-S00709,rcc,1735,160,774,299,62,8,0.6883447\n",
      "DBT-P03677,DBT-S00709,rmlo,1653,231,111,208,23,8,0.7617154\n",
      "DBT-P03677,DBT-S00709,rmlo,1410,280,1113,330,48,8,0.8700382\n",
      "DBT-P03677,DBT-S00709,rmlo,1653,231,111,208,23,8,0.7617154\n",
      "DBT-P03677,DBT-S00709,rmlo,1410,280,1113,330,48,8,0.8700382\n",
      "DBT-P03748,DBT-S02094,lcc,128,152,1650,229,29,8,0.71194226\n",
      "DBT-P03748,DBT-S02094,lcc,129,155,1667,187,45,8,0.9382397\n",
      "DBT-P03748,DBT-S02094,lcc,133,153,1666,192,59,8,0.86541307\n",
      "DBT-P03748,DBT-S02094,lmlo,36,160,964,205,36,8,0.88773626\n",
      "DBT-P03748,DBT-S02094,lmlo,32,166,962,181,44,8,0.9207852\n",
      "DBT-P03748,DBT-S02094,lmlo,331,151,912,130,59,8,0.60202754\n",
      "DBT-P03816,DBT-S03888,rcc,1200,350,648,329,2,8,0.6325456\n",
      "DBT-P03816,DBT-S03888,rcc,1102,266,1412,280,16,8,0.785483\n",
      "DBT-P03816,DBT-S03888,rcc,1555,133,1916,130,25,8,0.7058866\n",
      "DBT-P03816,DBT-S03888,rcc,1147,400,651,460,34,8,0.8278733\n",
      "DBT-P03816,DBT-S03888,rcc,1796,173,1302,219,45,8,0.83256197\n",
      "DBT-P03816,DBT-S03888,rcc,1077,429,585,608,59,8,0.6462489\n",
      "DBT-P03816,DBT-S03888,rmlo,1599,202,223,163,23,8,0.85870314\n",
      "DBT-P03816,DBT-S03888,rmlo,1586,210,224,160,34,8,0.85529995\n",
      "DBT-P03816,DBT-S03888,rmlo,1369,125,905,94,61,8,0.858621\n",
      "DBT-P03816,DBT-S03888,rmlo,667,430,1078,780,68,8,0.6004817\n",
      "DBT-P03816,DBT-S03888,rmlo,681,443,1049,823,72,8,0.57398105\n",
      "DBT-P03915,DBT-S05004,lcc,180,113,1618,112,28,8,0.8488949\n",
      "DBT-P03915,DBT-S05004,lcc,182,109,1626,102,41,8,0.8755586\n",
      "DBT-P03915,DBT-S05004,lcc,176,122,1624,103,50,8,0.7834502\n",
      "DBT-P03915,DBT-S05004,lcc,176,118,1615,106,58,8,0.67142266\n",
      "DBT-P03978,DBT-S00442,rcc,1507,370,659,446,25,8,0.75627905\n",
      "DBT-P03978,DBT-S00442,rcc,1567,284,627,295,42,8,0.7518619\n",
      "DBT-P03978,DBT-S00442,rmlo,1361,272,796,390,6,8,0.8295865\n",
      "DBT-P03978,DBT-S00442,rmlo,1332,329,802,329,23,8,0.7329317\n",
      "DBT-P03978,DBT-S00442,rmlo,1345,271,776,335,40,8,0.5857271\n",
      "DBT-P04026,DBT-S01650,rcc1,1274,256,998,339,6,8,0.81838\n",
      "DBT-P04026,DBT-S01650,rcc1,1628,217,1036,176,13,8,0.7757227\n",
      "DBT-P04026,DBT-S01650,rcc1,1619,211,1049,203,25,8,0.75956064\n",
      "DBT-P04026,DBT-S01650,rmlo,1510,211,1354,193,30,8,0.66497684\n",
      "DBT-P04090,DBT-S01718,rcc,1497,128,729,100,12,8,0.77336556\n",
      "DBT-P04090,DBT-S01718,rcc,1842,139,1270,118,24,8,0.8122721\n",
      "DBT-P04090,DBT-S01718,rcc,1842,136,1265,124,31,8,0.72717726\n",
      "DBT-P04090,DBT-S01718,rcc,1435,206,683,192,39,8,0.79617226\n",
      "DBT-P04090,DBT-S01718,rcc,1331,185,1326,163,54,8,0.8760392\n",
      "DBT-P04090,DBT-S01718,rcc,1340,169,1321,166,64,8,0.9225028\n",
      "DBT-P04090,DBT-S01718,rcc,1337,173,1322,168,70,8,0.8780984\n",
      "DBT-P04090,DBT-S01718,rcc,1325,186,1332,155,74,8,0.86428195\n",
      "DBT-P04090,DBT-S01718,rmlo,1044,259,1199,223,18,8,0.7516836\n",
      "DBT-P04090,DBT-S01718,rmlo,1516,195,1550,185,34,8,0.79500234\n",
      "DBT-P04090,DBT-S01718,rmlo,1018,315,777,242,47,8,0.72904366\n",
      "DBT-P04090,DBT-S01718,rmlo,1193,168,800,162,60,8,0.93142384\n",
      "DBT-P04090,DBT-S01718,rmlo,1197,170,803,161,69,8,0.8688547\n",
      "DBT-P04116,DBT-S03961,rcc,1376,125,974,116,3,8,0.5699148\n",
      "DBT-P04116,DBT-S03961,rcc,1374,136,974,117,10,8,0.76964027\n",
      "DBT-P04116,DBT-S03961,rcc,1483,263,477,300,23,8,0.6316628\n",
      "DBT-P04116,DBT-S03961,rcc,1504,248,566,203,27,8,0.8150322\n",
      "DBT-P04116,DBT-S03961,rcc,1359,259,897,273,39,8,0.83886594\n",
      "DBT-P04116,DBT-S03961,rcc,1363,255,884,290,50,8,0.7889598\n",
      "DBT-P04116,DBT-S03961,rmlo,1604,241,1761,328,26,8,0.84216785\n",
      "DBT-P04116,DBT-S03961,rmlo,1605,245,1720,341,33,8,0.79060435\n",
      "DBT-P04116,DBT-S03961,rmlo,1609,239,1733,337,37,8,0.81189585\n",
      "DBT-P04326,DBT-S03750,lmlo,0,255,1583,378,13,8,0.6324411\n",
      "DBT-P04326,DBT-S03750,lmlo,0,277,1562,450,23,8,0.77948004\n",
      "DBT-P04326,DBT-S03750,lmlo,0,327,1603,403,40,8,0.7644348\n",
      "DBT-P04326,DBT-S03750,lmlo,99,144,1913,99,57,8,0.5497321\n",
      "DBT-P04372,DBT-S04281,lcc,913,173,1268,147,32,8,0.7728775\n",
      "DBT-P04372,DBT-S04281,lcc,916,168,1276,147,36,8,0.81759536\n",
      "DBT-P04372,DBT-S04281,lcc,121,81,599,64,44,8,0.8003853\n",
      "DBT-P04372,DBT-S04281,lcc,121,79,598,65,49,8,0.77672064\n",
      "DBT-P04372,DBT-S04281,lcc,786,206,823,354,63,8,0.53218174\n",
      "DBT-P04372,DBT-S04281,lmlo,860,198,1717,232,11,8,0.5718083\n",
      "DBT-P04372,DBT-S04281,lmlo,838,93,592,86,31,8,0.7721237\n",
      "DBT-P04372,DBT-S04281,lmlo,1145,318,1362,226,43,8,0.6218364\n",
      "DBT-P04372,DBT-S04281,lmlo,1175,287,819,293,47,8,0.74004734\n",
      "DBT-P04372,DBT-S04281,lmlo,1180,287,829,274,52,8,0.76929057\n",
      "DBT-P04372,DBT-S04281,lmlo,889,223,1425,252,66,8,0.63825077\n",
      "DBT-P04429,DBT-S00568,lcc,391,237,544,216,11,8,0.7382803\n",
      "DBT-P04429,DBT-S00568,lcc,593,189,764,160,15,8,0.7922646\n",
      "DBT-P04429,DBT-S00568,lcc,237,341,845,369,28,8,0.76606464\n",
      "DBT-P04429,DBT-S00568,lcc,290,281,879,301,43,8,0.8190098\n",
      "DBT-P04429,DBT-S00568,lcc,255,310,896,281,51,8,0.91807187\n",
      "DBT-P04429,DBT-S00568,lcc,251,296,901,279,55,8,0.9387297\n",
      "DBT-P04429,DBT-S00568,lcc,276,277,873,327,63,8,0.80014074\n",
      "DBT-P04429,DBT-S00568,lmlo,691,236,713,293,29,8,0.8675703\n",
      "DBT-P04429,DBT-S00568,lmlo,688,236,725,271,38,8,0.925349\n",
      "DBT-P04429,DBT-S00568,lmlo,685,265,705,280,52,8,0.609543\n",
      "DBT-P04631,DBT-S05515,lcc,805,120,1113,135,5,8,0.90005\n",
      "DBT-P04631,DBT-S05515,lcc,291,253,784,289,51,8,0.5306098\n",
      "DBT-P04631,DBT-S05515,lmlo,631,180,1709,188,13,8,0.6134759\n",
      "DBT-P04631,DBT-S05515,lmlo,628,167,1725,154,21,8,0.78836036\n",
      "DBT-P04631,DBT-S05515,lmlo,612,193,1710,180,27,8,0.80484587\n",
      "DBT-P04631,DBT-S05515,lmlo,373,339,1364,222,55,8,0.6747225\n",
      "DBT-P04631,DBT-S05515,lmlo,436,190,555,186,68,8,0.6948451\n",
      "DBT-P04710,DBT-S03227,rcc,1533,246,1430,310,14,8,0.85028625\n",
      "DBT-P04710,DBT-S03227,rcc,1534,233,1395,349,39,8,0.8751754\n",
      "DBT-P04710,DBT-S03227,rcc,1505,270,1399,327,58,8,0.77922225\n",
      "DBT-P04710,DBT-S03227,rmlo,1428,365,1676,245,13,8,0.5842331\n",
      "DBT-P04710,DBT-S03227,rmlo,1545,271,1518,292,32,8,0.879516\n",
      "DBT-P04710,DBT-S03227,rmlo,1568,254,1515,320,56,8,0.7471028\n",
      "DBT-P04721,DBT-S01833,lcc,0,228,687,248,15,8,0.8221922\n",
      "DBT-P04721,DBT-S01833,lcc,0,224,669,258,19,8,0.7953485\n",
      "DBT-P04721,DBT-S01833,lcc,200,225,1181,264,30,8,0.8038972\n",
      "DBT-P04721,DBT-S01833,lcc,81,218,773,178,35,8,0.8256553\n",
      "DBT-P04721,DBT-S01833,lcc,80,211,742,190,40,8,0.70471233\n",
      "DBT-P04721,DBT-S01833,lcc,182,271,1342,335,60,8,0.6023471\n",
      "DBT-P04721,DBT-S01833,lmlo,457,203,771,180,9,8,0.67604357\n",
      "DBT-P04721,DBT-S01833,lmlo,235,93,180,93,17,8,0.7409431\n",
      "DBT-P04721,DBT-S01833,lmlo,404,261,1140,212,40,8,0.61225444\n",
      "DBT-P04721,DBT-S01833,lmlo,491,234,972,243,47,8,0.7171689\n",
      "DBT-P04750,DBT-S00052,rcc,1314,195,667,233,1,8,0.5066774\n",
      "DBT-P04750,DBT-S00052,rcc,1027,210,1110,125,18,8,0.6952315\n",
      "DBT-P04750,DBT-S00052,rcc,1296,206,659,214,31,8,0.70348877\n",
      "DBT-P04818,DBT-S02975,rcc,1586,198,1281,202,15,8,0.67751974\n",
      "DBT-P04818,DBT-S02975,rcc,1342,183,1440,225,20,8,0.8209006\n",
      "DBT-P04818,DBT-S02975,rcc,1096,378,1680,297,51,8,0.52006763\n",
      "DBT-P04818,DBT-S02975,rmlo,1490,85,586,88,25,8,0.55424464\n",
      "DBT-P04818,DBT-S02975,rmlo,1490,227,1263,150,47,8,0.6652827\n",
      "DBT-P04858,DBT-S04555,lmlo,440,166,1235,135,10,8,0.84140927\n",
      "DBT-P04858,DBT-S04555,lmlo,448,155,1243,134,16,8,0.87189245\n",
      "DBT-P04858,DBT-S04555,lmlo,0,148,515,161,22,8,0.8911252\n",
      "DBT-P04858,DBT-S04555,lmlo,634,213,1330,207,50,8,0.7216089\n",
      "DBT-P04858,DBT-S04555,rcc,1068,130,1573,98,3,8,0.5965962\n",
      "DBT-P04858,DBT-S04555,rcc,906,220,1252,209,16,8,0.7052124\n",
      "DBT-P04858,DBT-S04555,rcc,947,209,1242,205,38,8,0.747969\n",
      "DBT-P04901,DBT-S05032,rcc,1561,208,1043,361,25,8,0.8248993\n",
      "DBT-P04901,DBT-S05032,rcc,1554,209,955,450,31,8,0.8063941\n",
      "DBT-P04901,DBT-S05032,rmlo,1370,266,1034,339,6,8,0.5503078\n",
      "DBT-P04901,DBT-S05032,rmlo,1366,278,1035,325,19,8,0.8166643\n",
      "DBT-P04901,DBT-S05032,rmlo,1300,361,889,668,39,8,0.7362199\n",
      "DBT-P04901,DBT-S05032,rmlo,1266,375,947,693,51,8,0.55377483\n",
      "DBT-P05014,DBT-S04931,rcc,1325,203,1738,195,6,8,0.78237927\n",
      "DBT-P05014,DBT-S04931,rcc,1333,199,1742,185,10,8,0.8176629\n",
      "DBT-P05014,DBT-S04931,rcc,1436,393,697,234,15,8,0.74768174\n",
      "DBT-P05014,DBT-S04931,rcc,1241,255,706,199,29,8,0.8217828\n",
      "DBT-P05014,DBT-S04931,rmlo,1230,219,1161,192,17,8,0.8540602\n",
      "DBT-P05014,DBT-S04931,rmlo,1849,141,277,220,35,8,0.68476796\n",
      "DBT-P05014,DBT-S04931,rmlo,1049,240,865,269,44,8,0.8011773\n",
      "DBT-P05014,DBT-S04931,rmlo,910,299,1090,362,60,8,0.63916016\n",
      "DBT-P05022,DBT-S05195,rcc,1180,258,1026,293,5,8,0.71044445\n",
      "DBT-P05022,DBT-S05195,rcc,1670,210,1454,183,32,8,0.8771102\n",
      "DBT-P05022,DBT-S05195,rcc,1141,292,966,362,39,8,0.8013039\n",
      "DBT-P05022,DBT-S05195,rcc,1837,162,337,275,46,8,0.8295091\n",
      "DBT-P05022,DBT-S05195,rcc,1146,279,1008,325,51,8,0.75300324\n",
      "DBT-P05022,DBT-S05195,rcc,1119,258,970,326,57,8,0.70144314\n",
      "DBT-P05022,DBT-S05195,rmlo,1026,318,972,216,18,8,0.7444894\n",
      "DBT-P05022,DBT-S05195,rmlo,1615,224,1253,230,36,8,0.86899215\n",
      "DBT-P05022,DBT-S05195,rmlo,1018,234,911,288,47,8,0.76972973\n",
      "DBT-P05022,DBT-S05195,rmlo,1045,301,963,253,59,8,0.8787168\n",
      "DBT-P05022,DBT-S05195,rmlo,1015,306,924,318,67,8,0.7408064\n",
      "DBT-P05030,DBT-S05569,rcc,1390,298,793,321,3,8,0.62592983\n",
      "DBT-P05030,DBT-S05569,rcc,1259,307,923,278,20,8,0.82462424\n",
      "DBT-P05030,DBT-S05569,rcc,1644,265,672,199,30,8,0.89782655\n",
      "DBT-P05030,DBT-S05569,rcc,1028,230,1461,206,42,8,0.77218705\n",
      "DBT-P05030,DBT-S05569,rcc,1050,295,1486,312,58,8,0.72961736\n",
      "DBT-P05030,DBT-S05569,rmlo,1144,298,1612,323,7,8,0.8179512\n",
      "DBT-P05030,DBT-S05569,rmlo,1409,179,583,203,23,8,0.9143416\n",
      "DBT-P05030,DBT-S05569,rmlo,1091,318,982,215,40,8,0.71060646\n",
      "DBT-P05047,DBT-S05588,rcc,1442,190,936,152,4,8,0.6747335\n",
      "DBT-P05047,DBT-S05588,rcc,1383,223,1188,344,27,8,0.8008626\n",
      "DBT-P05047,DBT-S05588,rcc,1378,231,1158,358,35,8,0.91245526\n",
      "DBT-P05047,DBT-S05588,rcc,1390,250,1156,397,39,8,0.8836249\n",
      "DBT-P05047,DBT-S05588,rcc,1390,256,1135,426,43,8,0.8930925\n",
      "DBT-P05047,DBT-S05588,rcc,1383,246,1142,395,57,8,0.80910563\n",
      "DBT-P05047,DBT-S05588,rmlo,1244,245,1109,399,35,8,0.84357417\n",
      "DBT-P05047,DBT-S05588,rmlo,1255,277,1129,366,42,8,0.8776585\n",
      "DBT-P05056,DBT-S01839,rcc,967,450,1156,671,5,8,0.8070925\n",
      "DBT-P05056,DBT-S01839,rcc,953,479,1187,564,9,8,0.8120497\n",
      "DBT-P05056,DBT-S01839,rcc,985,309,1378,370,27,8,0.5506297\n",
      "DBT-P05056,DBT-S01839,rcc,974,348,1049,717,48,8,0.5584232\n",
      "DBT-P05056,DBT-S01839,rmlo,1165,137,1285,106,8,8,0.8067334\n",
      "DBT-P05056,DBT-S01839,rmlo,1251,210,375,139,26,8,0.7564354\n",
      "Total Prediction  189\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For writing the csv file for submission\n",
    "\n",
    "# 0.25 -> output3 -> score_2 0.648, score_3 0.68\n",
    "# 0.50 -> output2 -> score_2 0.646, score_3 0.65\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "total_prediction = [\"PatientID,StudyUID,View,X,Width,Y,Height,Z,Depth,Score\"]\n",
    "prediction_lines = []\n",
    "\n",
    "#df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "#df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-train.csv')\n",
    "df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv')\n",
    "print('Total validation length ', len(df))\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "\n",
    "\n",
    "#for case_index in range(175, 224):\n",
    "for case_index in range(175, 224):\n",
    "    #if case_index not in shuffle_index:\n",
    "    #    continue\n",
    "    \n",
    "    box_series  = df.iloc[case_index]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view_name   = box_series[\"View\"]\n",
    "    \n",
    "    \n",
    "    #img        = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy1/val_vol_'+str(case_index)+'.npy')\n",
    "    all_target = pickle.load(open('/media/drilnvm/ubuntudata2/DBTEx_results25/'+PatientID+'_'+StudyUID+'_'+view_name+'_target_'+str(case_index)+'.data', 'rb'))\n",
    "    all_scores = pickle.load(open('/media/drilnvm/ubuntudata2/DBTEx_results25/'+PatientID+'_'+StudyUID+'_'+view_name+'_score_'+str(case_index)+'.data', 'rb'))\n",
    "    \n",
    "    #print(PatientID, StudyUID, view_name,  len(all_target), len(all_scores))\n",
    "    \n",
    "    d_init_x = -1\n",
    "    d_init_y = -1\n",
    "    d_init_z = -1\n",
    "    all1     = []\n",
    "    \n",
    "    for i, t in enumerate(all_scores):\n",
    "        if len(t) > 0 and t[0] > 0.5:\n",
    "            if d_init_x == -1:\n",
    "                d_init_x = all_target[i][0][0]\n",
    "                d_init_y = all_target[i][0][1]\n",
    "                d_init_z = i\n",
    "        \n",
    "            temp_dist = np.min([100, np.linalg.norm([all_target[i][0][0]-d_init_x, all_target[i][0][1]-d_init_y, i-d_init_z])])\n",
    "            all1.append(temp_dist)\n",
    "            \n",
    "            # update previous coordinate\n",
    "            d_init_x = all_target[i][0][0]\n",
    "            d_init_y = all_target[i][0][1]\n",
    "            d_init_z = i\n",
    "        else:\n",
    "            all1.append(100)\n",
    "    \n",
    "    all1     = 100-np.array(all1)\n",
    "    peaks, _ = find_peaks(all1, distance=4, width=3)\n",
    "    #peaks, _ = find_peaks(all1, distance=4, plateau_size=4)\n",
    "    \n",
    "    for p in peaks:\n",
    "        temp = all_target[p][0]*4\n",
    "        result_string = [PatientID, StudyUID, view_name, int(temp[0]), int(temp[2]- temp[0]), int(temp[1]), int(temp[3]-temp[1]), p, 8, all_scores[p][0]]\n",
    "        result_string = [str(x) for x in result_string]\n",
    "        result_string = \",\".join(result_string)\n",
    "        \n",
    "        #print(PatientID, StudyUID, view_name, temp, all_scores[p][0])\n",
    "        #print(PatientID, StudyUID, view_name, int(temp[0]), int(temp[2]- temp[0]), int(temp[1]), int(temp[3]-temp[1]))\n",
    "        print(result_string)\n",
    "        total_prediction.append(result_string)\n",
    "        #print(temp)\n",
    "        #print(temp[0], temp[2]-temp[0], temp[1], temp[3]-temp[1], all_scores[p][0])\n",
    "        #print(all_score[p])\n",
    "    #total_prediction.append(len(peaks))\n",
    "    #print(len(peaks), len(all1), len(all_target), len(all_scores))\n",
    "    break\n",
    "\n",
    "print('Total Prediction ', len(total_prediction))\n",
    "total_prediction = \"\\n\".join(total_prediction)\n",
    "\n",
    "text_file = open(\"model_result5.csv\", \"w\")\n",
    "text_file.write(total_prediction)\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "#plt.plot(all1)\n",
    "#plt.plot(peaks, all1[peaks], 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0,
     20,
     22,
     48,
     57,
     63
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counter is  188\n",
      "{'sensitivity_at_2_fps_all': 0.6938775510204082, 'sensitivity_at_1_fps_positive': 0.5306122448979592, 'sensitivity_at_2_fps_positive': 0.6454810495626822, 'sensitivity_at_3_fps_positive': 0.6938775510204082, 'sensitivity_at_4_fps_positive': 0.6938775510204082, 'mean_sensitivity_positive': 0.6409620991253644}\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For getting the AUC on the Train remaining split\n",
    "\n",
    "from typing import AnyStr, BinaryIO, Dict, List, NamedTuple, Optional, Union\n",
    "\n",
    "labels_fp = \"/home/drilnvm/DBTex//BCS-DBT-labels-train.csv\"\n",
    "boxes_fp  = \"/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv\"\n",
    "#predictions_fp = \"/media/drilnvm/ubuntudata2/train_val.csv\"\n",
    "predictions_fp = \"model_result5.csv\"\n",
    "\n",
    "df_labels = pd.read_csv(labels_fp)\n",
    "df_boxes  = pd.read_csv(boxes_fp, dtype={\"Slice\": float})\n",
    "df_pred   = pd.read_csv(predictions_fp, dtype={\"Score\": float})\n",
    "\n",
    "#df_boxes = df_boxes.iloc[shuffle_index].tail(74)\n",
    "df_boxes = df_boxes.loc[175:224]\n",
    "\n",
    "df_labels = df_labels.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "df_boxes  = df_boxes.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "df_pred   = df_pred.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "\n",
    "def _is_tp(\n",
    "    box_pred: NamedTuple, box_true: NamedTuple, slice_offset: int, min_dist: int = 100\n",
    ") -> bool:\n",
    "    pred_y = box_pred.Y + box_pred.Height / 2\n",
    "    pred_x = box_pred.X + box_pred.Width / 2\n",
    "    #pred_z = box_pred.Z + box_pred.Depth / 2\n",
    "    pred_z = box_pred.Z #+ 4 / 2\n",
    "    \n",
    "    true_y = box_true.Y + box_true.Height / 2\n",
    "    true_x = box_true.X + box_true.Width / 2\n",
    "    true_z = box_true.Slice\n",
    "    \n",
    "    # 2D distance between true and predicted center points\n",
    "    dist = np.linalg.norm((pred_x - true_x, pred_y - true_y))\n",
    "    # compute radius based on true box size\n",
    "    dist_threshold = np.sqrt(box_true.Width ** 2 + box_true.Height ** 2) / 2.0\n",
    "    dist_threshold = max(dist_threshold, min_dist)\n",
    "    slice_diff     = np.abs(pred_z - true_z)\n",
    "    \n",
    "    # TP if predicted center within radius and slice within slice offset\n",
    "    tp_flag = dist <= dist_threshold and slice_diff <=  slice_offset\n",
    "    \n",
    "    #print(pred_x, pred_y, pred_z)\n",
    "    #print(true_x, true_y, true_z)\n",
    "    #print(dist, dist_threshold, slice_diff, slice_offset, tp_flag)\n",
    "    return tp_flag\n",
    "\n",
    "\n",
    "def _distance(box_pred: NamedTuple, box_true: NamedTuple) -> float:\n",
    "    pred_y = box_pred.Y + box_pred.Height / 2\n",
    "    pred_x = box_pred.X + box_pred.Width / 2\n",
    "    pred_z = box_pred.Z #+ box_pred.Depth / 2\n",
    "    true_y = box_true.Y + box_true.Height / 2\n",
    "    true_x = box_true.X + box_true.Width / 2\n",
    "    true_z = box_true.Slice\n",
    "    return np.linalg.norm((pred_x - true_x, pred_y - true_y, pred_z - true_z))\n",
    "\n",
    "def _froc(\n",
    "    df_pred: pd.DataFrame,\n",
    "    thresholds: List[float],\n",
    "    n_volumes: int,\n",
    "    n_boxes: int,\n",
    "    evaluation_fps: tuple,\n",
    ") -> List[float]:\n",
    "    tpr = []\n",
    "    fps = []\n",
    "    for th in sorted(thresholds, reverse=True):\n",
    "        df_th = df_pred.loc[df_pred[\"Score\"] >= th]\n",
    "        df_th_unique_tp = df_th.reset_index().drop_duplicates(\n",
    "            subset=[\"StudyUID\", \"View\", \"TP\", \"GTID\"]\n",
    "        )\n",
    "        n_tps_th = float(sum(df_th_unique_tp[\"TP\"]))\n",
    "        tpr_th = n_tps_th / n_boxes\n",
    "        n_fps_th = float(len(df_th[df_th[\"TP\"] == 0]))\n",
    "        fps_th = n_fps_th / n_volumes\n",
    "        tpr.append(tpr_th)\n",
    "        fps.append(fps_th)\n",
    "        if fps_th > max(evaluation_fps):\n",
    "            break\n",
    "    return [np.interp(x, fps, tpr) for x in evaluation_fps]\n",
    "\n",
    "df_pred[\"TP\"]   = 0\n",
    "df_pred[\"GTID\"] = -1\n",
    "\n",
    "thresholds = [df_pred[\"Score\"].max() + 1.0]\n",
    "\n",
    "counter = 0\n",
    "# find true positive predictions and assign detected ground truth box ID\n",
    "for box_pred in df_pred.itertuples():\n",
    "    #print(df_boxes.index)\n",
    "    #print('---------------------')\n",
    "    if box_pred.Index not in df_boxes.index:\n",
    "        continue\n",
    "    #box_pred.Depth = 4\n",
    "    counter = counter+1\n",
    "    #print(box_pred.Index)\n",
    "    #print('TP found ', box_pred)\n",
    "    df_boxes_view     = df_boxes.loc[[box_pred.Index]]\n",
    "    #print(\"df_boxes.loc \", df_boxes.loc[[box_pred.Index], \"Slice\"].iloc[0])\n",
    "    view_slice_offset = df_boxes.loc[[box_pred.Index], \"Slice\"].iloc[0] / 4\n",
    "    \n",
    "    #print(df_boxes_view)\n",
    "    #print(box_pred)\n",
    "    #print('---------------------------')\n",
    "    tp_boxes = [\n",
    "        b\n",
    "        for b in df_boxes_view.itertuples()\n",
    "        if _is_tp(box_pred, b, slice_offset=view_slice_offset)\n",
    "    ]\n",
    "    if len(tp_boxes) > 1:\n",
    "        # find the nearest GT box\n",
    "        tp_distances = [_distance(box_pred, b) for b in tp_boxes]\n",
    "        tp_boxes     = [tp_boxes[np.argmin(tp_distances)]]\n",
    "    if len(tp_boxes) > 0:\n",
    "        tp_i = tp_boxes[0].index\n",
    "        df_pred.loc[df_pred[\"index\"] == box_pred.index, (\"TP\", \"GTID\")] = (1, tp_i)\n",
    "        thresholds.append(box_pred.Score)\n",
    "#print(thresholds)\n",
    "\n",
    "print('Total counter is ', counter)\n",
    "thresholds.append(df_pred[\"Score\"].min() - 1.0)\n",
    "\n",
    "# compute sensitivity at 2 FPs/volume on all cases\n",
    "evaluation_fps_all = (2.0,)\n",
    "tpr_all = _froc(\n",
    "    df_pred=df_pred,\n",
    "    thresholds=thresholds,\n",
    "    n_volumes=len(df_labels),\n",
    "    n_boxes=len(df_boxes),\n",
    "    evaluation_fps=evaluation_fps_all,\n",
    ")\n",
    "result = {f\"sensitivity_at_2_fps_all\": tpr_all[0]}\n",
    "\n",
    "# compute mean sensitivity at 1, 2, 3, 4 FPs/volume on positive cases\n",
    "df_pred = df_pred[df_pred.index.isin(df_boxes.index)]\n",
    "df_labels = df_labels[df_labels.index.isin(df_boxes.index)]\n",
    "evaluation_fps_positive = (1.0, 2.0, 3.0, 4.0)\n",
    "tpr_positive = _froc(\n",
    "    df_pred=df_pred,\n",
    "    thresholds=thresholds,\n",
    "    n_volumes=len(df_labels),\n",
    "    n_boxes=len(df_boxes),\n",
    "    evaluation_fps=evaluation_fps_positive,\n",
    ")\n",
    "\n",
    "result.update(\n",
    "    dict(\n",
    "        (f\"sensitivity_at_{int(x)}_fps_positive\", y)\n",
    "        for x, y in zip(evaluation_fps_positive, tpr_positive)\n",
    "    )\n",
    ")\n",
    "result.update({\"mean_sensitivity_positive\": np.mean(tpr_positive)})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [TEMPORARY] For storing the files as numpy\n",
    "import os\n",
    "\n",
    "df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "for i in tqdm(range(97, len(df))):\n",
    "    basepath    = '/home/drilnvm/DBTex/'\n",
    "    box_series  = df.iloc[i]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view        = box_series[\"View\"]\n",
    "        \n",
    "    image_path = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #vol        = dcmread_image(fp=image_path, view=view)\n",
    "    #print(vol.shape)\n",
    "    #newtrainx  = np.zeros([len(vol), 1, 3000, 2000], 'float16')\n",
    "    #for i in range(len(vol)):\n",
    "    #    newtrainx[i, 0, :vol[i].shape[0], :vol[i].shape[1]] = vol[i]\n",
    "    \n",
    "    #newtrain1 = []\n",
    "    #for i in range(len(vol)):\n",
    "    #    img          = newtrainx[i, 0].astype('float32')/60000.0\n",
    "    #    img[img > 1] = 1\n",
    "    #    img = ndimage.interpolation.zoom(img, 0.25).astype('float16')\n",
    "    #    newtrain1.append(img)\n",
    "    \n",
    "    numpy_path = '/media/drilnvm/ubuntudata2/DBTEx_numpy/vol_'+str(i)+'.npy'\n",
    "    #vol1       = np.load(numpy_path)\n",
    "    #newtrain1 = np.array(newtrain1)\n",
    "    print(PatientID, StudyUID, view)#, vol1.shape)\n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy/'+PatientID+'_'+StudyUID+'_'+view+'.npy', newtrain1)\n",
    "    temp_path = '/media/drilnvm/ubuntudata2/DBTEx_numpy/'+PatientID+'_'+StudyUID+'_'+view+'.npy'\n",
    "    os.rename(numpy_path, temp_path)\n",
    "    #print(i, vol.shape, vol1.shape)\n",
    "        \n",
    "#print(len(df))\n",
    "#df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Temporary\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt14.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr = []\n",
    "height_arr = []\n",
    "\n",
    "PatientID_arr = []\n",
    "StudyUID_arr = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "\n",
    "    \n",
    "for i in tqdm(range(150, 151)):\n",
    "    #if i in shuffle_index:\n",
    "    print('Processing ', i)\n",
    "    #else:\n",
    "    #    continue\n",
    "    #box_series  = df.iloc[i]\n",
    "    #view        = box_series[\"View\"]\n",
    "    #slice_index = box_series[\"Slice\"]\n",
    "    #image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #print(box_series)\n",
    "    \n",
    "    valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "    #valid_dataset     = DBTDataset(train_set=0)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "        \n",
    "    all_target = []\n",
    "    all_scores = []\n",
    "    all_images = []\n",
    "    \n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        all_images.append(images[0][0].astype('float16'))\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images)\n",
    "        #print(loss_dict)\n",
    "        \n",
    "        all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "        all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    #with open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_score_'+str(i)+'.data', 'wb') as filehandle:\n",
    "    #    # store the data as binary data stream\n",
    "    #    pickle.dump(all_scores, filehandle)\n",
    "        \n",
    "    #with open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_target_'+str(i)+'.data', 'wb') as filehandle:\n",
    "    #    # store the data as binary data stream\n",
    "    #    pickle.dump(all_target, filehandle)\n",
    "    \n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_vol_'+str(i), np.array(all_images).astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0dd109cd0>]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(all_scores)\n",
    "a1 = []\n",
    "for k in all_scores:\n",
    "    if len(k) > 0:\n",
    "        a1.append(k[0])\n",
    "    else:\n",
    "        a1.append(0)\n",
    "plt.plot(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For checking the predictions slice wise for the Validation set\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt26.pth'))\n",
    "model.eval()\n",
    "\n",
    "#valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "valid_dataset     = DBTDataset(train_set=0)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "        \n",
    "all_target = []\n",
    "all_scores = []\n",
    "all_images = []\n",
    "\n",
    "for images, targets, image_ids in valid_data_loader:\n",
    "    all_images.append(images[0][0].astype('float16'))\n",
    "    new_images  = []\n",
    "    for img in images:\n",
    "        new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "    images    = new_images\n",
    "    targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    loss_dict = model(images)\n",
    "    #print(loss_dict)\n",
    "\n",
    "    all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "    all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total validation length  224\n",
      "DBT-P03073,DBT-S04591,lcc,331,417,1040,458,23,8,0.8215158\n",
      "DBT-P03073,DBT-S04591,lcc,271,525,1055,486,28,8,0.959689\n",
      "DBT-P03073,DBT-S04591,lcc,308,383,1096,415,33,8,0.98365015\n",
      "DBT-P03073,DBT-S04591,lmlo,250,125,627,92,22,8,0.97866577\n",
      "DBT-P03073,DBT-S04591,lmlo,508,433,951,423,30,8,0.9719445\n",
      "DBT-P03073,DBT-S04591,lmlo,413,567,927,480,40,8,0.9296037\n",
      "DBT-P03073,DBT-S04591,lmlo,651,259,1017,263,56,8,0.9705861\n",
      "DBT-P03073,DBT-S04591,lmlo,250,125,627,92,22,8,0.97866577\n",
      "DBT-P03073,DBT-S04591,lmlo,508,433,951,423,30,8,0.9719445\n",
      "DBT-P03073,DBT-S04591,lmlo,413,567,927,480,40,8,0.9296037\n",
      "DBT-P03073,DBT-S04591,lmlo,651,259,1017,263,56,8,0.9705861\n",
      "DBT-P03085,DBT-S00863,lcc,196,251,1354,207,27,8,0.98632765\n",
      "DBT-P03085,DBT-S00863,lcc,12,122,635,106,39,8,0.9690986\n",
      "DBT-P03085,DBT-S00863,lmlo,378,102,429,103,20,8,0.9636856\n",
      "DBT-P03085,DBT-S00863,lmlo,167,246,1155,211,35,8,0.98484904\n",
      "DBT-P03085,DBT-S00863,lmlo,174,223,1167,191,39,8,0.981952\n",
      "DBT-P03085,DBT-S00863,lmlo,168,247,1157,213,43,8,0.97582656\n",
      "DBT-P03085,DBT-S00863,lmlo,324,124,901,127,56,8,0.95561975\n",
      "DBT-P03176,DBT-S03730,lcc,61,124,1226,98,3,8,0.5322444\n",
      "DBT-P03176,DBT-S03730,lmlo,69,194,1670,113,13,8,0.7179682\n",
      "DBT-P03203,DBT-S04862,lcc,0,298,302,356,3,8,0.8044188\n",
      "DBT-P03203,DBT-S04862,lcc,18,462,579,716,39,8,0.936784\n",
      "DBT-P03203,DBT-S04862,lcc,27,440,610,708,58,8,0.84535456\n",
      "DBT-P03203,DBT-S04862,lcc,11,502,614,690,67,8,0.9341584\n",
      "DBT-P03212,DBT-S02198,lcc,0,126,307,234,20,8,0.8136543\n",
      "DBT-P03212,DBT-S02198,lmlo,212,261,696,217,11,8,0.99088573\n",
      "DBT-P03212,DBT-S02198,lmlo,199,279,697,196,18,8,0.9584556\n",
      "DBT-P03218,DBT-S04050,lcc,67,124,2019,77,14,8,0.8777449\n",
      "DBT-P03218,DBT-S04050,lcc,338,217,1652,154,45,8,0.9794175\n",
      "DBT-P03218,DBT-S04050,lmlo,381,165,211,219,16,8,0.9093296\n",
      "DBT-P03218,DBT-S04050,lmlo,384,164,219,201,25,8,0.91225976\n",
      "DBT-P03218,DBT-S04050,lmlo,372,176,224,189,37,8,0.9729782\n",
      "DBT-P03218,DBT-S04050,lmlo,446,201,1279,187,57,8,0.97217417\n",
      "DBT-P03218,DBT-S04050,lmlo,381,165,211,219,16,8,0.9093296\n",
      "DBT-P03218,DBT-S04050,lmlo,384,164,219,201,25,8,0.91225976\n",
      "DBT-P03218,DBT-S04050,lmlo,372,176,224,189,37,8,0.9729782\n",
      "DBT-P03218,DBT-S04050,lmlo,446,201,1279,187,57,8,0.97217417\n",
      "DBT-P03222,DBT-S00931,rcc,1468,149,1273,187,9,8,0.9342838\n",
      "DBT-P03222,DBT-S00931,rcc,1836,163,547,403,29,8,0.7372337\n",
      "DBT-P03222,DBT-S00931,rmlo,1648,285,622,290,13,8,0.9667536\n",
      "DBT-P03292,DBT-S03262,lcc,298,459,588,460,11,8,0.50249577\n",
      "DBT-P03292,DBT-S03262,lcc,98,865,645,415,33,8,0.87775934\n",
      "DBT-P03292,DBT-S03262,lcc,663,202,1225,157,40,8,0.9613299\n",
      "DBT-P03292,DBT-S03262,lcc,631,235,1187,216,51,8,0.97418267\n",
      "DBT-P03292,DBT-S03262,lcc,195,622,622,431,56,8,0.89833707\n",
      "DBT-P03292,DBT-S03262,lcc,221,521,638,377,65,8,0.89907163\n",
      "DBT-P03292,DBT-S03262,lmlo,835,333,1086,460,8,8,0.7541944\n",
      "DBT-P03292,DBT-S03262,lmlo,130,211,33,179,24,8,0.952192\n",
      "DBT-P03292,DBT-S03262,lmlo,829,339,1073,435,38,8,0.96645844\n",
      "DBT-P03292,DBT-S03262,lmlo,523,187,1353,187,53,8,0.9108872\n",
      "DBT-P03423,DBT-S05305,rmlo,1423,407,172,432,9,8,0.9723226\n",
      "DBT-P03423,DBT-S05305,rmlo,1431,392,176,420,15,8,0.97326446\n",
      "DBT-P03423,DBT-S05305,rmlo,1436,390,154,472,35,8,0.9836242\n",
      "DBT-P03423,DBT-S05305,rmlo1,1249,343,0,204,8,8,0.7009786\n",
      "DBT-P03423,DBT-S05305,rmlo1,1259,331,0,201,15,8,0.92757744\n",
      "DBT-P03539,DBT-S03755,lcc,379,288,1192,321,45,8,0.9482053\n",
      "DBT-P03539,DBT-S03755,lcc,408,239,1186,357,52,8,0.9328538\n",
      "DBT-P03539,DBT-S03755,lcc,378,372,1181,378,70,8,0.6329904\n",
      "DBT-P03539,DBT-S03755,lmlo,398,121,140,98,9,8,0.9787049\n",
      "DBT-P03539,DBT-S03755,lmlo,406,111,123,132,23,8,0.9570943\n",
      "DBT-P03539,DBT-S03755,lmlo,547,310,1006,372,47,8,0.9796966\n",
      "DBT-P03539,DBT-S03755,lmlo,547,335,977,434,63,8,0.9343202\n",
      "DBT-P03658,DBT-S05241,rcc,1008,172,1510,127,41,8,0.93952286\n",
      "DBT-P03658,DBT-S05241,rmlo,1274,89,1701,67,5,8,0.8754175\n",
      "DBT-P03658,DBT-S05241,rmlo,1771,207,110,159,31,8,0.9775074\n",
      "DBT-P03677,DBT-S00709,lcc,254,346,1033,484,36,8,0.8076495\n",
      "DBT-P03677,DBT-S00709,lmlo,0,78,239,185,16,8,0.74703664\n",
      "DBT-P03677,DBT-S00709,lmlo,0,124,86,121,22,8,0.95568603\n",
      "DBT-P03677,DBT-S00709,lmlo,363,343,1117,450,32,8,0.94373614\n",
      "DBT-P03677,DBT-S00709,rcc,1688,207,1593,251,27,8,0.8753258\n",
      "DBT-P03677,DBT-S00709,rcc,1579,259,1378,362,46,8,0.69968617\n",
      "DBT-P03677,DBT-S00709,rcc,1688,207,1593,251,27,8,0.8753258\n",
      "DBT-P03677,DBT-S00709,rcc,1579,259,1378,362,46,8,0.69968617\n",
      "DBT-P03677,DBT-S00709,rmlo,1422,317,1085,380,52,8,0.83457243\n",
      "DBT-P03677,DBT-S00709,rmlo,1422,317,1085,380,52,8,0.83457243\n",
      "DBT-P03748,DBT-S02094,lcc,0,172,660,662,30,8,0.71295303\n",
      "DBT-P03748,DBT-S02094,lcc,123,167,1676,179,44,8,0.99314415\n",
      "DBT-P03748,DBT-S02094,lcc,0,170,616,574,65,8,0.7565916\n",
      "DBT-P03748,DBT-S02094,lmlo,34,164,967,170,42,8,0.98813754\n",
      "DBT-P03748,DBT-S02094,lmlo,38,157,964,181,60,8,0.922624\n",
      "DBT-P03816,DBT-S03888,rcc,1425,160,729,100,5,8,0.84760094\n",
      "DBT-P03816,DBT-S03888,rcc,1414,175,729,105,12,8,0.8654549\n",
      "DBT-P03816,DBT-S03888,rcc,1041,555,648,508,34,8,0.9512798\n",
      "DBT-P03816,DBT-S03888,rmlo,1634,153,229,153,12,8,0.93168026\n",
      "DBT-P03816,DBT-S03888,rmlo,1610,194,237,160,24,8,0.9575044\n",
      "DBT-P03816,DBT-S03888,rmlo,1599,184,234,137,33,8,0.9371315\n",
      "DBT-P03816,DBT-S03888,rmlo,1374,126,905,90,53,8,0.97412974\n",
      "DBT-P03816,DBT-S03888,rmlo,1375,121,906,87,63,8,0.96146035\n",
      "DBT-P03915,DBT-S05004,lcc,110,186,751,86,18,8,0.9183547\n",
      "DBT-P03915,DBT-S05004,lcc,179,112,1627,89,36,8,0.9776889\n",
      "DBT-P03915,DBT-S05004,lcc,151,93,1326,162,51,8,0.9555404\n",
      "DBT-P03915,DBT-S05004,lcc,155,94,1305,190,58,8,0.89952475\n",
      "DBT-P03978,DBT-S00442,rcc,1504,417,629,460,18,8,0.7350186\n",
      "DBT-P03978,DBT-S00442,rcc,1527,377,655,305,24,8,0.7618176\n",
      "DBT-P03978,DBT-S00442,rmlo,1351,331,828,231,12,8,0.8338209\n",
      "DBT-P03978,DBT-S00442,rmlo,1356,295,817,254,19,8,0.5461801\n",
      "DBT-P04026,DBT-S01650,rcc1,1702,99,1099,74,2,8,0.6626852\n",
      "DBT-P04026,DBT-S01650,rcc1,1605,227,1051,195,18,8,0.9664515\n",
      "DBT-P04026,DBT-S01650,rcc1,1577,86,1484,65,53,8,0.8216202\n",
      "DBT-P04026,DBT-S01650,rmlo,1506,231,1370,185,23,8,0.9521063\n",
      "DBT-P04090,DBT-S01718,rcc,1505,127,726,85,17,8,0.96896297\n",
      "DBT-P04090,DBT-S01718,rcc,1340,174,1325,166,57,8,0.9799396\n",
      "DBT-P04090,DBT-S01718,rcc,1348,158,1330,152,67,8,0.9754199\n",
      "DBT-P04090,DBT-S01718,rcc,1355,154,1335,157,76,8,0.9151572\n",
      "DBT-P04090,DBT-S01718,rmlo,1418,108,1103,83,12,8,0.97226846\n",
      "DBT-P04090,DBT-S01718,rmlo,1199,164,807,155,57,8,0.9865667\n",
      "DBT-P04090,DBT-S01718,rmlo,1201,161,809,151,61,8,0.9828933\n",
      "DBT-P04116,DBT-S03961,rmlo,1401,533,1708,453,14,8,0.932216\n",
      "DBT-P04116,DBT-S03961,rmlo,1431,499,1758,369,32,8,0.88752854\n",
      "DBT-P04326,DBT-S03750,lcc,5,210,958,614,12,8,0.7804348\n",
      "DBT-P04326,DBT-S03750,lcc,13,219,714,364,51,8,0.5753854\n",
      "DBT-P04326,DBT-S03750,lmlo,0,228,1557,466,13,8,0.926187\n",
      "DBT-P04326,DBT-S03750,lmlo,0,238,1527,524,32,8,0.9195195\n",
      "DBT-P04372,DBT-S04281,lcc,932,129,1283,111,32,8,0.973742\n",
      "DBT-P04372,DBT-S04281,lcc,121,77,591,74,45,8,0.9517006\n",
      "DBT-P04372,DBT-S04281,lmlo,842,83,594,70,29,8,0.94299054\n",
      "DBT-P04429,DBT-S00568,lcc,270,330,850,327,34,8,0.92710674\n",
      "DBT-P04429,DBT-S00568,lcc,242,321,899,273,52,8,0.9780151\n",
      "DBT-P04429,DBT-S00568,lcc,244,310,896,282,56,8,0.9792159\n",
      "Total Prediction  119\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch  42\n",
    "# 20 epochs 57\n",
    "# 30 epochs 59, 57, 55\n",
    "# 40 epochs 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all1 = []\n",
    "for t in all_scores:\n",
    "    if len(t) > 0 and t[0] > 0.5:\n",
    "        #print(t[0])\n",
    "        all1.append(t[0])\n",
    "    else:\n",
    "        all1.append(0)\n",
    "\n",
    "\n",
    "d_init_x = -1\n",
    "d_init_y = -1\n",
    "d_init_z = -1\n",
    "all1     = []\n",
    "\n",
    "for i, t in enumerate(all_scores):\n",
    "    if len(t) > 0 and t[0] > 0.5:\n",
    "        if d_init_x == -1:\n",
    "            d_init_x = all_target[i][0][0]\n",
    "            d_init_y = all_target[i][0][1]\n",
    "            d_init_z = i\n",
    "        \n",
    "        temp_dist = np.min([100, np.linalg.norm([all_target[i][0][0]-d_init_x, all_target[i][0][1]-d_init_y, i-d_init_z])])\n",
    "        all1.append(temp_dist)\n",
    "        d_init_x = all_target[i][0][0]\n",
    "        d_init_y = all_target[i][0][1]\n",
    "        d_init_z = i\n",
    "    else:\n",
    "        all1.append(100)\n",
    "all1 = 100-np.array(all1)\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peaks, _ = find_peaks(all1, distance=8, width=4)\n",
    "#print(a.shape)\n",
    "plt.plot(all1)\n",
    "plt.plot(peaks, all1[peaks], 'x')\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice location  0 49\n",
      "[[  2.   273.25  44.   388.75]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case_index   = 0#random.randint(0, len(valid_dataset))\n",
    "img, all_target, _    = valid_dataset[case_index]\n",
    "img          = img.astype('float32')\n",
    "#img        = a.astype('float32')\n",
    "#case_index = 0#random.randint(0, img.shape[0]-1)\n",
    "#case_index = peaks[0]-5\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "ax   = plt.gca()\n",
    "case_index  = 0\n",
    "print('slice location ', case_index, len(valid_dataset))\n",
    "\n",
    "if 1:#len(all_target[case_index]) > 0 and all_scores[case_index][0] > 0.2:\n",
    "    temp  = all_target['boxes'].data.cpu().numpy()#[case_index]\n",
    "    print(temp)\n",
    "    #print(case_index, all_scores[case_index])\n",
    "    index = 0\n",
    "    #rect  = patches.Rectangle((temp[0], temp[1]), temp[2]-temp[0], temp[3]-temp[1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    ax.add_patch(rect)\n",
    "else:\n",
    "    print('Not found 8')\n",
    "\n",
    "plt.show()\n",
    "case_index = case_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Validation Iteration #10 loss: 0.26083502173423767\n",
    "# Validation Iteration #20 loss: 0.12475015223026276\n",
    "# Validation Iteration #30 loss: 0.2311360090970993\n",
    "# Validation Iteration #40 loss: 0.07870643585920334\n",
    "# Validation Iteration #50 loss: 0.12904797494411469\n",
    "# 0.17835015669465065\n",
    "\n",
    "# Validation Iteration #10 loss: 0.16890683770179749\n",
    "# Validation Iteration #20 loss: 0.12697485089302063\n",
    "# Validation Iteration #30 loss: 0.202874094247818\n",
    "# Validation Iteration #40 loss: 0.1275915801525116\n",
    "# Validation Iteration #50 loss: 0.16607160866260529\n",
    "# 0.17254152543842793\n",
    "\n",
    "# Validation Iteration #10 loss: 0.14864173531532288\n",
    "# Validation Iteration #20 loss: 0.13806253671646118\n",
    "# Validation Iteration #30 loss: 0.13079851865768433\n",
    "# Validation Iteration #40 loss: 0.09259304404258728\n",
    "# Validation Iteration #50 loss: 0.13366109132766724\n",
    "# 0.1608045955002308\n",
    "\n",
    "# Validation Iteration #10 loss: 0.2190426141023636\n",
    "# Validation Iteration #20 loss: 0.10993507504463196\n",
    "# Validation Iteration #30 loss: 0.08774184435606003\n",
    "# Validation Iteration #40 loss: 0.14777813851833344\n",
    "# Validation Iteration #50 loss: 0.08807449787855148\n",
    "# 0.1679838129878044\n",
    "\n",
    "# fasterrcnn_resnet50_dbt22.pth\n",
    "# Validation Iteration #10 loss: 0.12817245721817017\n",
    "# Validation Iteration #20 loss: 0.3029731810092926\n",
    "# Validation Iteration #30 loss: 0.06146375834941864\n",
    "# Validation Iteration #40 loss: 0.08439958095550537\n",
    "# Validation Iteration #50 loss: 0.059381939470767975\n",
    "# 0.10177689090371132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For doing inference of the model\n",
    "\n",
    "all_target = []\n",
    "all_scores = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt22.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "for images, targets, image_ids in valid_data_loader:\n",
    "    new_images  = []\n",
    "    for img in images:\n",
    "        new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "    images    = new_images\n",
    "    targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    loss_dict = model(images)\n",
    "    print(loss_dict)\n",
    "    \n",
    "    #print(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "    all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([ 271, 1057,  805, 1490])}\n",
      "Ground Truth  [ 271 1057  805 1490] 35\n",
      "Prediction  [[ 75.71501  283.47375  163.6579   378.79547 ]\n",
      " [  4.241309 263.63602   50.325714 373.7304  ]\n",
      " [101.045715 287.99136  151.38869  370.79993 ]\n",
      " [ 61.922516 258.55548  184.89377  395.74182 ]]\n",
      "Scores  [0.97706246 0.4141349  0.13911489 0.10131314]\n",
      "Prediction  [[ 75.71501  283.47375  163.6579   378.79547 ]\n",
      " [  4.241309 263.63602   50.325714 373.7304  ]\n",
      " [101.045715 287.99136  151.38869  370.79993 ]\n",
      " [ 61.922516 258.55548  184.89377  395.74182 ]]\n",
      "[ 67 264 201 372]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [STAR] Code to compare the ground truth and predicted mask\n",
    "\n",
    "\n",
    "case_index   = 35#random.randint(0, len(valid_dataset)-1)\n",
    "images, b, c = valid_dataset[case_index]\n",
    "print(b)\n",
    "\n",
    "print('Ground Truth ', b['boxes'].data.cpu().numpy(), case_index)\n",
    "print('Prediction ', all_target[case_index])\n",
    "print('Scores ', all_scores[case_index])\n",
    "\n",
    "plt.imshow(images[0], cmap='gray')\n",
    "ax   = plt.gca()\n",
    "\n",
    "# if(len(all_target1[case_index]) > 0):\n",
    "#     #print(all_target1[index])\n",
    "#     #print(all_scores1[index])\n",
    "    \n",
    "#     temp  = all_target1[case_index]\n",
    "#     index = 0\n",
    "#     rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='yellow', fill = False)\n",
    "#     ax.add_patch(rect)\n",
    "# else:\n",
    "#     print('Not found 9')\n",
    "\n",
    "if(len(all_target[case_index]) > 0):\n",
    "    #print(all_target[index])\n",
    "    #print(all_scores[index])\n",
    "    \n",
    "    temp  = all_target[case_index]\n",
    "    print('Prediction ', temp)\n",
    "    index = 0\n",
    "    rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    ax.add_patch(rect)\n",
    "else:\n",
    "    print('Not found 8')\n",
    "\n",
    "temp  = b['boxes'].data.cpu().numpy()//4#all_target[index]\n",
    "index = 0\n",
    "print(temp)\n",
    "rect  = patches.Rectangle((temp[0], temp[1]), temp[2]-temp[0], temp[3]-temp[1], linewidth=1, edgecolor='red', fill = False)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "#rect = patches.Rectangle((0, 0), 500, 100, linewidth=2, edgecolor='cyan', fill = False)\n",
    "\n",
    "plt.show()\n",
    "case_index = case_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error cases for fasterrcnn_resnet50_dbt15.pth\n",
    "Ground Truth  [[ 10.75 304.    51.25 333.75]] 5\n",
    "Ground Truth  [[ 19.   416.25  63.5  447.75]] 6\n",
    "Ground Truth  [[188.25 309.5  216.5  369.75]] 7\n",
    "Ground Truth  [[193.25 389.5  228.   453.5 ]] 8\n",
    "Ground Truth  [[463.75 150.5  498.5  222.75]] 14\n",
    "Ground Truth  [[170.   335.25 195.5  362.25]] 23\n",
    "Ground Truth  [[345.25 414.5  472.25 536.5 ]] 30\n",
    "Ground Truth  [[451.5  333.75 496.   382.  ]] 34\n",
    "Ground Truth  [[398.   166.75 468.25 222.  ]] 37\n",
    "Ground Truth  [[317.75 332.75 388.75 394.  ]] 44\n",
    "Ground Truth  [[  2.   273.25  44.   388.75]] 45\n",
    "Ground Truth  [[5.0000e-01 3.9825e+02 6.1500e+01 5.1375e+02]] 46\n",
    "\n",
    "# Error cases for fasterrcnn_resnet50_dbt14.pth\n",
    "Ground Truth  [[188.25 309.5  216.5  369.75]] 7\n",
    "Ground Truth  [[193.25 389.5  228.   453.5 ]] 8\n",
    "Ground Truth  [[317.75 332.75 388.75 394.  ]] 44\n",
    "Ground Truth  [[299.25 347.75 324.25 387.  ]] 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1200, 3000)\n"
     ]
    }
   ],
   "source": [
    "dbtvol = np.fromfile('/media/drilnvm/ubuntudata2/TEST-DBT-RECONS/04140608-LE-L-CC_3000x1200x80.4_0.0005_-0.2_1_15.raw', dtype=np.float32)\n",
    "dbtvol = np.reshape(dbtvol, [80, 1200, 3000])\n",
    "print(dbtvol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
