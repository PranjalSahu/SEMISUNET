{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "#!pip install monai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "import csv\n",
    "from scipy import ndimage, misc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skimage.measure import label\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "\n",
    "import functools\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "#from ipywidgets import IProgress\n",
    "# [STAR] All imports for DBT\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from duke_dbt_data import dcmread_image, read_boxes, draw_box, evaluate\n",
    "np.random.seed(0)\n",
    "#torch.manual_seed(0)!pip install monai\n",
    "\n",
    "# [STAR] All the Imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     11,
     28,
     48,
     82,
     99,
     114,
     125,
     136,
     163,
     190,
     198,
     206,
     269,
     332,
     393,
     429,
     517,
     650,
     773,
     836,
     934,
     939,
     1021
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Pytorch Models for training\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block \n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(Attention_block, self).__init__()\n",
    "\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        out = x * psi\n",
    "        return out\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class DoubleConv_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Down_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            DoubleConv_3D(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class Up_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up   = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv_3D(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv_3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv_3D, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.dp2 = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "        #x3 = self.dp1(x3)\n",
    "        \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "        #x4 = self.dp2(x4)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_3D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc   = DoubleConv_3D(n_channels, 16)\n",
    "        self.down1 = Down_3D(16, 32)\n",
    "        self.down2 = Down_3D(32, 64)\n",
    "        self.down3 = Down_3D(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down_3D(128, 256 // factor)\n",
    "        self.up1 = Up_3D(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up_3D(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up_3D(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up_3D(32, 16, bilinear)\n",
    "        self.outc = OutConv_3D(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.dp2 = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "        #x3 = self.dp1(x3)\n",
    "        \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "        #x4 = self.dp2(x4)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_with_BN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_with_BN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.BatchNorm2d(16)\n",
    "        self.gn2 = nn.BatchNorm2d(32)\n",
    "        self.gn3 = nn.BatchNorm2d(64)\n",
    "        self.gn4 = nn.BatchNorm2d(128)\n",
    "        self.gn5 = nn.BatchNorm2d(64)\n",
    "        self.gn6 = nn.BatchNorm2d(32)\n",
    "        self.gn7 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.4)\n",
    "        self.dp2 = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class SUNet_without_GN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet_without_GN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        \n",
    "        x5 = self.down4(x4)\n",
    "        x  = self.up1(x5, x4)\n",
    "        x  = self.up2(x, x3)\n",
    "        x  = self.up3(x, x2)\n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN_old(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=256, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.bilinear = bilinear\n",
    "        self.n_classes = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        self.lsgn_a = nn.GroupNorm(128,256)\n",
    "    \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h = torch.unsqueeze(hidden,0)\n",
    "        \n",
    "        embedded = input\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        hidden_bilstm = h[0]\n",
    "        \n",
    "        \n",
    "        hidden_bilinn =  hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "    \n",
    "        hidden_bilinn = self.lsgn_a(hidden_bilinn)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden_bilinn), 1)), dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        attn_weights  = self.lsgn_a(attn_weights)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "   #     print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "  #      print('The output shape is : ',output.shape)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    " #      print('The output shape after is : ',output.shape)\n",
    "        \n",
    "    \n",
    "        hidden_bi = hidden_bilinn.unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #print(\"output and hidden before lstm \",output.shape,hidden_bi.shape)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        output = self.lsgn_a(output)\n",
    "        \n",
    "       #output = self.lsgn_a(output)\n",
    "    \n",
    "        return output,hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "\n",
    "############### MAIN MODEL ##############\n",
    "class UNetDoubleSmallGroupNormdifferent_old(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(128,256)\n",
    "        \n",
    "        self.lsgn2 = nn.GroupNorm(64,256)\n",
    "        \n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        #print('x5 shape is :',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,256,256])\n",
    "\n",
    "        lstm = nn.LSTM(256,256,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "                \n",
    "        #print('xlst',xlst.shape)    \n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        \n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        \n",
    "        #print(hidden)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        \n",
    "        \n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,256,256))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "    \n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,256,16,16])\n",
    "        \n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    " \n",
    "        \n",
    "        \n",
    "        x5 = self.lsgn2(x5)\n",
    "        \n",
    "        ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallGroupNormdifferent(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc     = DoubleConv(n_channels, 16)\n",
    "        self.down1   = Down(16, 32)\n",
    "        self.downnew = Down(16,16)\n",
    "        self.down2   = Down(32, 64)\n",
    "        self.down3   = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4   = Down(128, 256 // factor) \n",
    "        self.upsam   = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        self.ups3  = nn.ConvTranspose2d(1 , 1, kernel_size=2, stride=2)\n",
    "        self.ups4  = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(64,128)\n",
    "        self.lsgn2 = nn.GroupNorm(64,1024)\n",
    "        self.lsgn3 = nn.GroupNorm(64,1024)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        self.gn8 = nn.GroupNorm(4,8)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        #x = self.upsam()\n",
    "        \n",
    "        x1 = self.inc(x)\n",
    "        #x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "        #x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "        #x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        #x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        #x5 = self.gn\n",
    "        #x5 = torch.squeeze(x5)\n",
    "        #x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        #print('x5:',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,128,1024])\n",
    "        \n",
    "\n",
    "        lstm = nn.LSTM(1024,1024,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,128,1024))\n",
    "        #a = ndarray((4,128,1024))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo   = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,128,32,32])\n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    "        #x5 = self.lsgn3(x5)\n",
    "        \n",
    "        #x5 = self.ups4(x5)\n",
    "    \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "        #x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        #x = self.gn7(x)\n",
    "\n",
    "        #x = self.downnew(x)\n",
    "        \n",
    "        #out    = self.out_softmax(logits)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallWithoutGN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallWithoutGN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc   = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        ups4     = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=128, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p   = dropout_p\n",
    "        self.max_length  = max_length\n",
    "        self.bilinear    = bilinear\n",
    "        self.n_classes   = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn      = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.attn2   = nn.Linear(1024, 128)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(3072, 1024)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru     = nn.GRU(1024, 1024)\n",
    "        self.out     = nn.Linear(1024, 1024)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        #self.lsgn_a = nn.GroupNorm(512,1024)\n",
    "        self.lsbn_a1 = nn.BatchNorm1d(1024)\n",
    "        #self.lsgn_a2 = nn.GroupNorm(512,1024)\n",
    "        \n",
    "        #self.lsgn_in = nn.GroupNorm(64,128)\n",
    "        self.lsbn_in1 = nn.BatchNorm1d(2048)\n",
    "        self.lsbn_in2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        \n",
    "        self.lsbn_in3 = nn.BatchNorm1d(128)#nn.GroupNorm(64,   128)\n",
    "        self.lsbn_in4 = nn.BatchNorm1d(128)#nn.GroupNorm(64,   128)\n",
    "        self.lsbn_in5 = nn.BatchNorm1d(1024)#nn.GroupNorm(512,  1024)\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4     = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h        = torch.unsqueeze(hidden, 0)\n",
    "        embedded = input\n",
    "        #embedded = self.lsgn_in1(embedded)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        hidden_bilstm = h[0]\n",
    "        hidden_bilinn = hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "        hidden_bilinn = self.lsbn_a1(hidden_bilinn)\n",
    "        \n",
    "        hidden_bi     = hidden_bilinn.unsqueeze(0)\n",
    "        \n",
    "        #print(hidden_bilinn.shape)\n",
    "        \n",
    "        attn_weights  = torch.cat((embedded[0], hidden_bilinn), 1)\n",
    "        attn_weights  = self.lsbn_in1(attn_weights)\n",
    "        \n",
    "        attn_weights  = self.attn(attn_weights)\n",
    "        attn_weights  = self.lsbn_in2(attn_weights)\n",
    "        \n",
    "        attn_weights  = F.softmax(attn_weights, dim=1)\n",
    "        \n",
    "        attn_weights  = self.attn2(attn_weights)\n",
    "        attn_weights  = self.lsbn_in3(attn_weights)\n",
    "        \n",
    "        #print(attn_weights.unsqueeze(0).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        #print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output = self.lsbn_in4(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = self.out(output[0])\n",
    "        output = self.lsbn_in5(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "\n",
    "class AttU_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Unet implementation\n",
    "    Paper: https://arxiv.org/abs/1804.03999\n",
    "    \"\"\"\n",
    "    def __init__(self, img_ch=1, output_ch=1):\n",
    "        super(AttU_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(img_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        #self.active = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "\n",
    "        #print(x5.shape)\n",
    "        d5 = self.Up5(e5)\n",
    "        #print(d5.shape)\n",
    "        x4 = self.Att5(g=d5, x=e4)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4, x=e3)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3, x=e2)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2, x=e1)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "      #  out = self.active(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class UNetNormal(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNetNormal, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        my_factor = 1\n",
    "        factor    = 1\n",
    "        \n",
    "        self.inc   = DoubleConv(n_channels, 32*my_factor)\n",
    "        self.down1 = Down(32*my_factor, 64*my_factor)\n",
    "        self.down2 = Down(64*my_factor, 128*my_factor)\n",
    "        self.down3 = Down(128*my_factor, 256*my_factor)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(256*my_factor, 512*my_factor // factor)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(256,512)\n",
    "        self.lsgn2 = nn.GroupNorm(512,1024)\n",
    "        \n",
    "        self.up1 = Up(512*my_factor, 256*my_factor // factor, bilinear)\n",
    "        self.up2 = Up(256*my_factor, 128*my_factor // factor, bilinear)\n",
    "        self.up3 = Up(128*my_factor, 64*my_factor // factor, bilinear)\n",
    "        self.up4 = Up(64*my_factor, 32*my_factor, bilinear)\n",
    "        self.outc = OutConv(32*my_factor, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        #self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "#model = SUNet_3D(1, 1)\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Read all the slices in training set without augmentation\n",
    "\n",
    "basepath = '/home/drilnvm/DBTex/'\n",
    "df = read_boxes(boxes_fp=basepath+\"BCS-DBT-boxes-train.csv\", filepaths_fp=basepath+\"BCS-DBT-file-paths-train.csv\")\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr = []\n",
    "height_arr = []\n",
    "\n",
    "for i in tqdm(range(224)):\n",
    "    box_series  = df.iloc[i]\n",
    "    view        = box_series[\"View\"]\n",
    "    slice_index = box_series[\"Slice\"]\n",
    "    image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    image       = dcmread_image(fp=image_path, view=view, index=slice_index-1)\n",
    "    \n",
    "    #trainx.append(image[slice_index-1:slice_index+1])\n",
    "    #trainx.append(image[slice_index])\n",
    "    trainx.append(image)\n",
    "    trainy.append(box_series[\"Class\"])\n",
    "    #image = image[slice_index]\n",
    "    \n",
    "    x, y, width, height = box_series[[\"X\", \"Y\", \"Width\", \"Height\"]]\n",
    "    #image               = draw_box(image=image, x=x, y=y, width=width, height=height, lw=10)\n",
    "    #boximage.append(image)\n",
    "    coordx.append(x)\n",
    "    coordy.append(y)\n",
    "    width_arr.append(width)\n",
    "    height_arr.append(height)\n",
    "\n",
    "print(len(trainx), len(trainy), len(boximage))\n",
    "\n",
    "# mx = 0\n",
    "# my = 0\n",
    "# for i in range(len(trainx)):\n",
    "#     if trainx[i].shape[0] > mx:\n",
    "#         mx = trainx[i].shape[0]\n",
    "#     if trainx[i].shape[1] > my:\n",
    "#         my = trainx[i].shape[1]\n",
    "# print(mx, my)\n",
    "\n",
    "if(1):\n",
    "    np.save('coordx.npy', coordx)\n",
    "    np.save('coordy.npy', coordy)\n",
    "\n",
    "    newtrainx  = np.zeros([len(trainx), 1, 3000, 2000], 'float16')\n",
    "    newtrainy  = np.zeros([len(trainx), 1], 'float16')\n",
    "    for i in range(len(trainx)):\n",
    "        newtrainx[i, 0, :trainx[i].shape[0], :trainx[i].shape[1]] = trainx[i]\n",
    "        if trainy[i] == 'benign':\n",
    "            newtrainy[i, 0] = 0\n",
    "        else:\n",
    "            newtrainy[i, 0] = 1\n",
    "\n",
    "    np.save('trainx.npy', newtrainx)\n",
    "    np.save('trainy.npy', newtrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "code_folding": [
     2,
     121,
     161,
     209,
     215,
     220
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] DBT classes for data loader\n",
    "\n",
    "class DBTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_set = 1, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        suffix_str  = ''#random.choice(['_m2', '_m1', '_p1', '_p2', ''])\n",
    "        print('READING NEW FILE >> ', suffix_str, ' <<')\n",
    "        \n",
    "        #shuffle_index = np.arange(224)\n",
    "        #np.random.shuffle(shuffle_index)\n",
    "        #np.save('shuffle_array.npy', shuffle_index)\n",
    "        #shuffle_index = np.load('shuffle_array.npy')\n",
    "        \n",
    "        trainx = np.load('trainx'+suffix_str+'.npy')\n",
    "        trainy = np.load('trainy'+suffix_str+'.npy')\n",
    "        coordx = np.load('coordx'+suffix_str+'.npy')\n",
    "        coordy = np.load('coordy'+suffix_str+'.npy')\n",
    "        width_arr  = np.load('width_arr'+suffix_str+'.npy')\n",
    "        height_arr = np.load('height_arr'+suffix_str+'.npy')\n",
    "        \n",
    "        #trainx = trainx[shuffle_index]\n",
    "        #trainy = trainy[shuffle_index]\n",
    "        #coordx = coordx[shuffle_index]\n",
    "        #coordy = coordy[shuffle_index]\n",
    "        #width_arr  = width_arr[shuffle_index]\n",
    "        #height_arr = height_arr[shuffle_index]\n",
    "        \n",
    "        self.counter = 0\n",
    "        if train_set == 1:\n",
    "            self.train_start  = 0\n",
    "            self.train_end    = 150\n",
    "        else:\n",
    "            self.train_start  = 150\n",
    "            self.train_end    = 200\n",
    "        \n",
    "        self.train_set = train_set\n",
    "        #t1 = np.load('trainx_m1.npy')[self.train_start:self.train_end]\n",
    "        #t2 = np.load('trainx.npy')[self.train_start:self.train_end]\n",
    "        #t3 = np.load('trainx_p1.npy')[self.train_start:self.train_end]\n",
    "        #self.trainx  =  np.concatenate([t2, t1, t3], axis=1)\n",
    "        \n",
    "        self.trainx = trainx[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "        self.trainy = trainy[self.train_start:self.train_end]\n",
    "        self.coordx = coordx[self.train_start:self.train_end]\n",
    "        self.coordy = coordy[self.train_start:self.train_end]\n",
    "        self.width_arr  = width_arr[self.train_start:self.train_end]\n",
    "        self.height_arr = height_arr[self.train_start:self.train_end]\n",
    "        \n",
    "        print('Total size of dataset ', len(np.load('width_arr'+suffix_str+'.npy')))\n",
    "#         self.trainx = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainx.npy')[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "#         self.trainy = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainy.npy')[self.train_start:self.train_end]\n",
    "#         self.coordx = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordx.npy')[self.train_start:self.train_end]\n",
    "#         self.coordy = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordy.npy')[self.train_start:self.train_end]\n",
    "#         self.width_arr  = np.load('/media/yu-hao/WindowsData/DBT_numpy/width_arr.npy')[self.train_start:self.train_end]\n",
    "#         self.height_arr = np.load('/media/yu-hao/WindowsData/DBT_numpy/height_arr.npy')[self.train_start:self.train_end]\n",
    "        \n",
    "        self.transforms1 = A.Compose(\n",
    "                                    [A.HorizontalFlip(p=0.5),  A.VerticalFlip(p=0.5), ],\n",
    "                                     #A.Downscale(scale_min=0.95, scale_max=0.98, p=0.25, interpolation=3),],\n",
    "                                    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']),\n",
    "                                   )\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        self.counter = self.counter+1\n",
    "        #if self.counter % 10 == 0:\n",
    "        #    print('Counter is ', self.counter)\n",
    "        \n",
    "#         if self.train_set == 1 and self.counter % 150 == 0 and random.random() < 0.2:\n",
    "#             suffix_str  = random.choice([ '_m1', '_p1', ''])\n",
    "#             print('READING NEW FILE >> ', suffix_str, ' <<')\n",
    "#             self.trainx = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainx'+suffix_str+'.npy')[self.train_start:self.train_end]#.astype('float16')/60000.0\n",
    "#             self.trainy = np.load('/media/yu-hao/WindowsData/DBT_numpy/trainy'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.coordx = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordx'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.coordy = np.load('/media/yu-hao/WindowsData/DBT_numpy/coordy'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.width_arr  = np.load('/media/yu-hao/WindowsData/DBT_numpy/width_arr'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "#             self.height_arr = np.load('/media/yu-hao/WindowsData/DBT_numpy/height_arr'+suffix_str+'.npy')[self.train_start:self.train_end]\n",
    "                \n",
    "        #img = self.trainx[idx].astype('float32')/60000.0\n",
    "        img = self.trainx[idx, 0].astype('float32')/60000.0\n",
    "        img[img > 1] = 1\n",
    "        img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        if(self.train_set == 1):\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        \n",
    "        boxes = np.array([self.coordx[idx]/4, self.coordy[idx]/4, self.width_arr[idx]/4, self.height_arr[idx]/4])#records[['x', 'y', 'w', 'h']].values\n",
    "        boxes = np.expand_dims(boxes, axis=0)\n",
    "        boxes[:, 2] = boxes[:, 0]+boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1]+boxes[:, 3]\n",
    "        \n",
    "        area = self.width_arr[idx] * self.height_arr[idx]\n",
    "        area = torch.Tensor(area)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels =  torch.ones((1,)).type(torch.int64)\n",
    "        \n",
    "        if(self.train_set == 1):\n",
    "        #if(0):\n",
    "            transformed = self.transforms1(image=img, bboxes=boxes, labels=labels)\n",
    "            image    = transformed['image']\n",
    "            boxes    = np.array(transformed['bboxes'])\n",
    "            img      = np.moveaxis(image, 2, 0)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.Tensor(np.array([0])).type(torch.int64)\n",
    "        \n",
    "        target              = {}\n",
    "        target['boxes']     = torch.Tensor(boxes)\n",
    "        target['labels']    = labels\n",
    "        target['image_id']  = torch.tensor([idx])\n",
    "        target['area']      = area\n",
    "        target['iscrowd']   = iscrowd\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.trainx.shape[0]\n",
    "\n",
    "class DBTDatasetValidation(torch.utils.data.Dataset):\n",
    "    def __init__(self, val_index = 0, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.basepath  = '/home/drilnvm/DBTex/'\n",
    "        self.counter   = 0\n",
    "        self.val_index = val_index\n",
    "        self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-train.csv')\n",
    "        #self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "        \n",
    "        box_series       = self.df.iloc[self.val_index]\n",
    "        self.PatientID   = box_series[\"PatientID\"]\n",
    "        self.StudyUID    = box_series[\"StudyUID\"]\n",
    "        self.view        = box_series[\"View\"]\n",
    "        \n",
    "        image_path      = os.path.join(self.basepath, box_series[\"descriptive_path\"])\n",
    "        self.vol        = dcmread_image(fp=image_path, view=self.view)\n",
    "        self.newtrainx  = np.zeros([len(self.vol), 1, 3000, 2000], 'float16')\n",
    "        for i in range(len(self.vol)):\n",
    "            self.newtrainx[i, 0, :self.vol[i].shape[0], :self.vol[i].shape[1]] = self.vol[i]\n",
    "        \n",
    "        print('File reading done ', self.vol.shape, image_path)\n",
    "        #print()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img          = self.newtrainx[idx, 0].astype('float32')/60000.0\n",
    "        img[img > 1] = 1\n",
    "        img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        target              = {}\n",
    "        target['image_id']  = torch.tensor([idx])\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vol.shape[0]\n",
    "\n",
    "class DBTDatasetValidationTrain(torch.utils.data.Dataset):\n",
    "    def __init__(self, val_index = 0, transforms = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.basepath  = '/home/drilnvm/DBTex/'\n",
    "        self.counter   = 0\n",
    "        self.val_index = val_index\n",
    "        self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv')\n",
    "        #self.df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "        \n",
    "        box_series       = self.df.iloc[self.val_index]\n",
    "        self.PatientID   = box_series[\"PatientID\"]\n",
    "        self.StudyUID    = box_series[\"StudyUID\"]\n",
    "        self.view        = box_series[\"View\"]\n",
    "        self.slice_index = box_series[\"Slice\"]\n",
    "        self.X           = box_series[\"X\"]\n",
    "        self.Y           = box_series[\"Y\"]\n",
    "        self.Width       = box_series[\"Width\"]\n",
    "        self.Height      = box_series[\"Height\"]\n",
    "        #Slice,X,Y,Width,Height\n",
    "        \n",
    "        #image_path      = os.path.join(self.basepath, box_series[\"descriptive_path\"])\n",
    "        self.vol = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy/'+self.PatientID+'_'+self.StudyUID+'_'+self.view+'.npy')\n",
    "        #self.vol        = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy1/val_vol_'+str(val_index)+'.npy')#dcmread_image(fp=image_path, view=self.view)\n",
    "        self.newtrainx  = np.expand_dims(self.vol, 1)#np.zeros([len(self.vol), 1, 750, 500], 'float16')\n",
    "        #for i in range(len(self.vol)):\n",
    "        #    self.newtrainx[i, 0, :self.vol[i].shape[0], :self.vol[i].shape[1]] = self.vol[i]\n",
    "        print('File reading done ',            self.vol.shape)\n",
    "        #print('Inside DBTDatasetValidationTrain ', box_series)\n",
    "        \n",
    "        #print(box_series[\"descriptive_path\"])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img          = self.newtrainx[idx, 0].astype('float32')#/60000.0\n",
    "        img[img > 1] = 1\n",
    "        #img = ndimage.interpolation.zoom(img, 0.25)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = np.concatenate([img, img, img], axis=0)\n",
    "        \n",
    "        target              = {}\n",
    "        if idx == self.slice_index:\n",
    "            target['boxes']  = torch.tensor([self.X, self.Y, self.X+self.Width, self.Y+self.Height])\n",
    "        \n",
    "        return img, target, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vol.shape[0]\n",
    "\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n",
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n"
     ]
    }
   ],
   "source": [
    "# [STAR] DBT Dataset and Model Creation\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataset     = DBTDataset(train_set=1)\n",
    "valid_dataset     = DBTDataset(train_set=0)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=1, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "#model       = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "params       = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer    = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0001)\n",
    "lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Training loop for DBT dataset\n",
    "\n",
    "loss_hist     = Averager()\n",
    "val_loss_hist = Averager()\n",
    "\n",
    "prev_min   = 1000\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    loss_hist.reset()\n",
    "    \n",
    "    model.train()\n",
    "    itr = 1\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "        \n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses     = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if itr % 50 == 0:\n",
    "        #    print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in valid_data_loader:\n",
    "            new_images  = []\n",
    "            for img in images:\n",
    "                new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "            images    = new_images\n",
    "            targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            #print(loss_dict)\n",
    "\n",
    "            losses     = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            val_loss_hist.send(loss_value)\n",
    "\n",
    "            #if itr % 50 == 0:\n",
    "            #    print(f\"Validation Iteration #{itr} loss: {loss_value}\")\n",
    "            itr = itr+1\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} Train loss: {loss_hist.value}\")\n",
    "    print(f\"Epoch #{epoch} Val   loss: {val_loss_hist.value}\")\n",
    "    \n",
    "    if val_loss_hist.value < prev_min:\n",
    "        print('Saving the model ', prev_min, val_loss_hist.value)\n",
    "        torch.save(model.state_dict(), 'fasterrcnn_resnet50_dbt26.pth')\n",
    "        prev_min = val_loss_hist.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Iteration #10 loss: 0.1522545963525772\n",
      "Validation Iteration #20 loss: 0.14671073853969574\n",
      "Validation Iteration #30 loss: 0.060010723769664764\n",
      "Validation Iteration #40 loss: 0.1513519287109375\n",
      "Validation Iteration #50 loss: 0.10438358038663864\n",
      "0.15411860436201097\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For printing the loss of the trained model\n",
    "\n",
    "# fasterrcnn_resnet50_dbt7.pth  0.24080992616713048\n",
    "# fasterrcnn_resnet50_dbt8.pth  0.1653416310250759\n",
    "# fasterrcnn_resnet50_dbt9.pth  0.17630461007356643\n",
    "# fasterrcnn_resnet50_dbt10.pth 0.17438715264201166\n",
    "# fasterrcnn_resnet50_dbt11.pth 0.16590506657958032\n",
    "# fasterrcnn_resnet50_dbt14.pth 0.1608045955002308\n",
    "# fasterrcnn_resnet50_dbt21.pth 0.15965028703212739\n",
    "# fasterrcnn_resnet50_dbt15.pth (3 adjacent channel)\n",
    "\n",
    "all_target    = []\n",
    "all_scores    = []\n",
    "val_loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt26.pth'))\n",
    "model.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        #print(loss_dict)\n",
    "\n",
    "        losses     = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        val_loss_hist.send(loss_value)\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(f\"Validation Iteration #{itr} loss: {loss_value}\")\n",
    "        itr = itr+1\n",
    "\n",
    "print(val_loss_hist.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  150\n",
      "File reading done  (79, 750, 500)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({'boxes': tensor([ 271, 1057,  805, 1490])},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n",
      "({},)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:05<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({},)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For Obtaining the result on Validation set of the Challenge\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt26.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr  = []\n",
    "height_arr = []\n",
    "\n",
    "PatientID_arr = []\n",
    "StudyUID_arr  = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "        \n",
    "basepath = '/home/drilnvm/DBTex/'\n",
    "df = read_boxes(boxes_fp=basepath+\"BCS-DBT-boxes-train.csv\", filepaths_fp=basepath+\"BCS-DBT-file-paths-train.csv\")\n",
    "\n",
    "    \n",
    "for i in tqdm(range(150, 151)):\n",
    "    #if i in shuffle_index:\n",
    "    print('Processing ', i)\n",
    "    #else:\n",
    "    #    continue\n",
    "    box_series  = df.iloc[i]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view        = box_series[\"View\"]\n",
    "    \n",
    "    #slice_index = box_series[\"Slice\"]\n",
    "    #image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #print(box_series)\n",
    "    \n",
    "    valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "    #valid_dataset     = DBTDataset(train_set=0)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "        \n",
    "    all_target = []\n",
    "    all_scores = []\n",
    "    all_images = []\n",
    "    \n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        print(targets)\n",
    "        all_images.append(images[0][0].astype('float16'))\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        #targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images)\n",
    "        #print(loss_dict)\n",
    "        \n",
    "        all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "        all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_results/'+PatientID+'_'+StudyUID+'_'+view+'_score_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_scores, filehandle)\n",
    "        \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_results/'+PatientID+'_'+StudyUID+'_'+view+'_target_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_target, filehandle)\n",
    "    \n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_vol_'+str(i), np.array(all_images).astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [TEMPORARY] For storing the files as numpy\n",
    "import os\n",
    "\n",
    "df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "for i in tqdm(range(97, len(df))):\n",
    "    basepath    = '/home/drilnvm/DBTex/'\n",
    "    box_series  = df.iloc[i]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view        = box_series[\"View\"]\n",
    "        \n",
    "    image_path = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #vol        = dcmread_image(fp=image_path, view=view)\n",
    "    #print(vol.shape)\n",
    "    #newtrainx  = np.zeros([len(vol), 1, 3000, 2000], 'float16')\n",
    "    #for i in range(len(vol)):\n",
    "    #    newtrainx[i, 0, :vol[i].shape[0], :vol[i].shape[1]] = vol[i]\n",
    "    \n",
    "    #newtrain1 = []\n",
    "    #for i in range(len(vol)):\n",
    "    #    img          = newtrainx[i, 0].astype('float32')/60000.0\n",
    "    #    img[img > 1] = 1\n",
    "    #    img = ndimage.interpolation.zoom(img, 0.25).astype('float16')\n",
    "    #    newtrain1.append(img)\n",
    "    \n",
    "    numpy_path = '/media/drilnvm/ubuntudata2/DBTEx_numpy/vol_'+str(i)+'.npy'\n",
    "    #vol1       = np.load(numpy_path)\n",
    "    #newtrain1 = np.array(newtrain1)\n",
    "    print(PatientID, StudyUID, view)#, vol1.shape)\n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy/'+PatientID+'_'+StudyUID+'_'+view+'.npy', newtrain1)\n",
    "    temp_path = '/media/drilnvm/ubuntudata2/DBTEx_numpy/'+PatientID+'_'+StudyUID+'_'+view+'.npy'\n",
    "    os.rename(numpy_path, temp_path)\n",
    "    #print(i, vol.shape, vol1.shape)\n",
    "        \n",
    "#print(len(df))\n",
    "#df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# [STAR] Temporary\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt26.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "boximage  = []\n",
    "coordx =  []\n",
    "coordy = []\n",
    "\n",
    "width_arr = []\n",
    "height_arr = []\n",
    "\n",
    "PatientID_arr = []\n",
    "StudyUID_arr = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "\n",
    "    \n",
    "for i in tqdm(range(150, 151)):\n",
    "    #if i in shuffle_index:\n",
    "    print('Processing ', i)\n",
    "    #else:\n",
    "    #    continue\n",
    "    #box_series  = df.iloc[i]\n",
    "    #view        = box_series[\"View\"]\n",
    "    #slice_index = box_series[\"Slice\"]\n",
    "    #image_path  = os.path.join(basepath, box_series[\"descriptive_path\"])\n",
    "    #print(box_series)\n",
    "    \n",
    "    valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "    #valid_dataset     = DBTDataset(train_set=0)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "        \n",
    "    all_target = []\n",
    "    all_scores = []\n",
    "    all_images = []\n",
    "    \n",
    "    for images, targets, image_ids in valid_data_loader:\n",
    "        all_images.append(images[0][0].astype('float16'))\n",
    "        new_images  = []\n",
    "        for img in images:\n",
    "            new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "        images    = new_images\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images)\n",
    "        #print(loss_dict)\n",
    "        \n",
    "        all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "        all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_score_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_scores, filehandle)\n",
    "        \n",
    "    with open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_target_'+str(i)+'.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(all_target, filehandle)\n",
    "    \n",
    "    #np.save('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_vol_'+str(i), np.array(all_images).astype('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0dd1a2040>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(all_scores)\n",
    "a1 = []\n",
    "for k in all_scores:\n",
    "    if len(k) > 0:\n",
    "        a1.append(k[0])\n",
    "    else:\n",
    "        a1.append(0)\n",
    "plt.plot(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING NEW FILE >>    <<\n",
      "Total size of dataset  224\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For checking the predictions slice wise for the Validation set\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt26.pth'))\n",
    "model.eval()\n",
    "\n",
    "#valid_dataset     = DBTDatasetValidationTrain(val_index=i)\n",
    "valid_dataset     = DBTDataset(train_set=0)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "        \n",
    "all_target = []\n",
    "all_scores = []\n",
    "all_images = []\n",
    "\n",
    "for images, targets, image_ids in valid_data_loader:\n",
    "    all_images.append(images[0][0].astype('float16'))\n",
    "    new_images  = []\n",
    "    for img in images:\n",
    "        new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "    images    = new_images\n",
    "    targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    loss_dict = model(images)\n",
    "    #print(loss_dict)\n",
    "\n",
    "    all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "    all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_fp = \"/home/drilnvm/DBTex//BCS-DBT-labels-train.csv\"\n",
    "boxes_fp  = \"/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv\"\n",
    "predictions_fp = \"/media/drilnvm/ubuntudata2/train_val.csv\"\n",
    "\n",
    "df_labels = pd.read_csv(labels_fp)\n",
    "df_boxes  = pd.read_csv(boxes_fp, dtype={\"VolumeSlices\": float})\n",
    "df_pred   = pd.read_csv(predictions_fp, dtype={\"Score\": float})\n",
    "\n",
    "#df_boxes = df_boxes.iloc[shuffle_index].tail(74)\n",
    "df_boxes = df_boxes.loc[150:200]\n",
    "\n",
    "df_labels = df_labels.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "df_boxes  = df_boxes.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "df_pred   = df_pred.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     31,
     40,
     46
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For getting the AUC on the Train remaining split\n",
    "\n",
    "from typing import AnyStr, BinaryIO, Dict, List, NamedTuple, Optional, Union\n",
    "\n",
    "\n",
    "def _is_tp(\n",
    "    box_pred: NamedTuple, box_true: NamedTuple, slice_offset: int, min_dist: int = 100\n",
    ") -> bool:\n",
    "    pred_y = box_pred.Y + box_pred.Height / 2\n",
    "    pred_x = box_pred.X + box_pred.Width / 2\n",
    "    pred_z = box_pred.Z + box_pred.Depth / 2\n",
    "    true_y = box_true.Y + box_true.Height / 2\n",
    "    true_x = box_true.X + box_true.Width / 2\n",
    "    true_z = box_true.Slice\n",
    "    \n",
    "    # 2D distance between true and predicted center points\n",
    "    dist = np.linalg.norm((pred_x - true_x, pred_y - true_y))\n",
    "    # compute radius based on true box size\n",
    "    dist_threshold = np.sqrt(box_true.Width ** 2 + box_true.Height ** 2) / 2.0\n",
    "    dist_threshold = max(dist_threshold, min_dist)\n",
    "    slice_diff     = np.abs(pred_z - true_z)\n",
    "    \n",
    "    print(pred_x, pred_y, pred_z)\n",
    "    print(true_x, true_y, true_z)\n",
    "    print(dist, dist_threshold, slice_diff, slice_offset)\n",
    "    \n",
    "    \n",
    "    # TP if predicted center within radius and slice within slice offset\n",
    "    return dist <= dist_threshold and slice_diff <=  slice_offset\n",
    "\n",
    "\n",
    "def _distance(box_pred: NamedTuple, box_true: NamedTuple) -> float:\n",
    "    pred_y = box_pred.Y + box_pred.Height / 2\n",
    "    pred_x = box_pred.X + box_pred.Width / 2\n",
    "    pred_z = box_pred.Z + box_pred.Depth / 2\n",
    "    true_y = box_true.Y + box_true.Height / 2\n",
    "    true_x = box_true.X + box_true.Width / 2\n",
    "    true_z = box_true.Slice\n",
    "    return np.linalg.norm((pred_x - true_x, pred_y - true_y, pred_z - true_z))\n",
    "\n",
    "def _froc(\n",
    "    df_pred: pd.DataFrame,\n",
    "    thresholds: List[float],\n",
    "    n_volumes: int,\n",
    "    n_boxes: int,\n",
    "    evaluation_fps: tuple,\n",
    ") -> List[float]:\n",
    "    tpr = []\n",
    "    fps = []\n",
    "    for th in sorted(thresholds, reverse=True):\n",
    "        df_th = df_pred.loc[df_pred[\"Score\"] >= th]\n",
    "        df_th_unique_tp = df_th.reset_index().drop_duplicates(\n",
    "            subset=[\"StudyUID\", \"View\", \"TP\", \"GTID\"]\n",
    "        )\n",
    "        n_tps_th = float(sum(df_th_unique_tp[\"TP\"]))\n",
    "        tpr_th = n_tps_th / n_boxes\n",
    "        n_fps_th = float(len(df_th[df_th[\"TP\"] == 0]))\n",
    "        fps_th = n_fps_th / n_volumes\n",
    "        tpr.append(tpr_th)\n",
    "        fps.append(fps_th)\n",
    "        if fps_th > max(evaluation_fps):\n",
    "            break\n",
    "    return [np.interp(x, fps, tpr) for x in evaluation_fps]\n",
    "\n",
    "df_pred[\"TP\"]   = 0\n",
    "df_pred[\"GTID\"] = -1\n",
    "\n",
    "thresholds = [df_pred[\"Score\"].max() + 1.0]\n",
    "\n",
    "counter = 0\n",
    "# find true positive predictions and assign detected ground truth box ID\n",
    "for box_pred in df_pred.itertuples():\n",
    "    #print(df_boxes.index)\n",
    "    #print('---------------------')\n",
    "    if box_pred.Index not in df_boxes.index:\n",
    "        continue\n",
    "    counter = counter+1\n",
    "    #print(box_pred.Index)\n",
    "    #print('TP found ', box_pred)\n",
    "    df_boxes_view     = df_boxes.loc[[box_pred.Index]]\n",
    "    view_slice_offset = df_boxes.loc[[box_pred.Index], \"Slice\"].iloc[0] / 4\n",
    "    \n",
    "    #print(df_boxes_view)\n",
    "    #print(box_pred)\n",
    "    \n",
    "    print('---------------------------')\n",
    "    tp_boxes = [\n",
    "        b\n",
    "        for b in df_boxes_view.itertuples()\n",
    "        if _is_tp(box_pred, b, slice_offset=view_slice_offset)\n",
    "    ]\n",
    "    if len(tp_boxes) > 1:\n",
    "        # find the nearest GT box\n",
    "        tp_distances = [_distance(box_pred, b) for b in tp_boxes]\n",
    "        tp_boxes     = [tp_boxes[np.argmin(tp_distances)]]\n",
    "    if len(tp_boxes) > 0:\n",
    "        tp_i = tp_boxes[0].index\n",
    "        df_pred.loc[df_pred[\"index\"] == box_pred.index, (\"TP\", \"GTID\")] = (1, tp_i)\n",
    "        thresholds.append(box_pred.Score)\n",
    "print(thresholds)\n",
    "\n",
    "print('Total counter is ', counter)\n",
    "thresholds.append(df_pred[\"Score\"].min() - 1.0)\n",
    "\n",
    "# compute sensitivity at 2 FPs/volume on all cases\n",
    "evaluation_fps_all = (2.0,)\n",
    "tpr_all = _froc(\n",
    "    df_pred=df_pred,\n",
    "    thresholds=thresholds,\n",
    "    n_volumes=len(df_labels),\n",
    "    n_boxes=len(df_boxes),\n",
    "    evaluation_fps=evaluation_fps_all,\n",
    ")\n",
    "result = {f\"sensitivity_at_2_fps_all\": tpr_all[0]}\n",
    "\n",
    "# compute mean sensitivity at 1, 2, 3, 4 FPs/volume on positive cases\n",
    "df_pred = df_pred[df_pred.index.isin(df_boxes.index)]\n",
    "df_labels = df_labels[df_labels.index.isin(df_boxes.index)]\n",
    "evaluation_fps_positive = (1.0, 2.0, 3.0, 4.0)\n",
    "tpr_positive = _froc(\n",
    "    df_pred=df_pred,\n",
    "    thresholds=thresholds,\n",
    "    n_volumes=len(df_labels),\n",
    "    n_boxes=len(df_boxes),\n",
    "    evaluation_fps=evaluation_fps_positive,\n",
    ")\n",
    "\n",
    "result.update(\n",
    "    dict(\n",
    "        (f\"sensitivity_at_{int(x)}_fps_positive\", y)\n",
    "        for x, y in zip(evaluation_fps_positive, tpr_positive)\n",
    "    )\n",
    ")\n",
    "result.update({\"mean_sensitivity_positive\": np.mean(tpr_positive)})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total validation length  224\n",
      "DBT-P03073 DBT-S04591 lcc (84, 750, 500) 84 84\n",
      "DBT-P03073,DBT-S04591,lcc,598,230,977,205,12,8,0.7269998\n",
      "Total Prediction  1\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For writing the csv file for submission\n",
    "# 0.25 -> output3 -> score_2 0.648, score_3 0.68\n",
    "# 0.50 -> output2 -> score_2 0.646, score_3 0.65\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "total_prediction = []\n",
    "prediction_lines = []\n",
    "\n",
    "#df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-validation.csv')\n",
    "#df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-file-paths-train.csv')\n",
    "df        = pd.read_csv('/home/drilnvm/DBTex/BCS-DBT-boxes-train.csv')\n",
    "print('Total validation length ', len(df))\n",
    "\n",
    "#shuffle_index = np.load('shuffle_array.npy')\n",
    "#shuffle_index = shuffle_index[150:]\n",
    "\n",
    "\n",
    "for case_index in range(150, 151):\n",
    "    #if case_index not in shuffle_index:\n",
    "    #    continue\n",
    "    \n",
    "    box_series  = df.iloc[case_index]\n",
    "    PatientID   = box_series[\"PatientID\"]\n",
    "    StudyUID    = box_series[\"StudyUID\"]\n",
    "    view_name   = box_series[\"View\"]\n",
    "    \n",
    "    \n",
    "    img        = np.load('/media/drilnvm/ubuntudata2/DBTEx_numpy1/val_vol_'+str(case_index)+'.npy')\n",
    "    all_target = pickle.load(open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_target_'+str(case_index)+'.data', 'rb'))\n",
    "    all_scores = pickle.load(open('/media/drilnvm/ubuntudata2/DBTEx_numpy2/val_score_'+str(case_index)+'.data', 'rb'))\n",
    "    \n",
    "    print(PatientID, StudyUID, view_name, img.shape, len(all_target), len(all_scores))\n",
    "    \n",
    "    d_init_x = -1\n",
    "    d_init_y = -1\n",
    "    d_init_z = -1\n",
    "    all1     = []\n",
    "\n",
    "    for i, t in enumerate(all_scores):\n",
    "        if len(t) > 0 and t[0] > 0.5:\n",
    "            if d_init_x == -1:\n",
    "                d_init_x = all_target[i][0][0]\n",
    "                d_init_y = all_target[i][0][1]\n",
    "                d_init_z = i\n",
    "        \n",
    "            temp_dist = np.min([100, np.linalg.norm([all_target[i][0][0]-d_init_x, all_target[i][0][1]-d_init_y, i-d_init_z])])\n",
    "            all1.append(temp_dist)\n",
    "            \n",
    "            # update previous coordinate\n",
    "            d_init_x = all_target[i][0][0]\n",
    "            d_init_y = all_target[i][0][1]\n",
    "            d_init_z = i\n",
    "        else:\n",
    "            all1.append(100)\n",
    "    \n",
    "    all1     = 100-np.array(all1)\n",
    "    peaks, _ = find_peaks(all1, distance=4, width=4)\n",
    "    \n",
    "    for p in peaks:\n",
    "        temp = all_target[p][0]*4\n",
    "        result_string = [PatientID, StudyUID, view_name, int(temp[0]), int(temp[2]- temp[0]), int(temp[1]), int(temp[3]-temp[1]), p, 8, all_scores[p][0]]\n",
    "        result_string = [str(x) for x in result_string]\n",
    "        result_string = \",\".join(result_string)\n",
    "        \n",
    "        #print(PatientID, StudyUID, view_name, temp, all_scores[p][0])\n",
    "        #print(PatientID, StudyUID, view_name, int(temp[0]), int(temp[2]- temp[0]), int(temp[1]), int(temp[3]-temp[1]))\n",
    "        print(result_string)\n",
    "        total_prediction.append(result_string)\n",
    "        #print(temp)\n",
    "        #print(temp[0], temp[2]-temp[0], temp[1], temp[3]-temp[1], all_scores[p][0])\n",
    "        #print(all_score[p])\n",
    "    #total_prediction.append(len(peaks))\n",
    "    #print(len(peaks), len(all1), len(all_target), len(all_scores))\n",
    "    \n",
    "    \n",
    "print('Total Prediction ', len(total_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0e6c50250>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#DBT-P03073,DBT-S04591,lcc,0,35,271,1057,534,433,benign,0\n",
    "#DBT-P03073,DBT-S04591,lmlo,0,19,236,612,139,110,benign,0\n",
    "#DBT-P03073,DBT-S04591,lmlo,0,44,326,924,563,423,benign,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all1 = []\n",
    "for t in all_scores:\n",
    "    if len(t) > 0 and t[0] > 0.5:\n",
    "        #print(t[0])\n",
    "        all1.append(t[0])\n",
    "    else:\n",
    "        all1.append(0)\n",
    "\n",
    "\n",
    "d_init_x = -1\n",
    "d_init_y = -1\n",
    "d_init_z = -1\n",
    "all1     = []\n",
    "\n",
    "for i, t in enumerate(all_scores):\n",
    "    if len(t) > 0 and t[0] > 0.5:\n",
    "        if d_init_x == -1:\n",
    "            d_init_x = all_target[i][0][0]\n",
    "            d_init_y = all_target[i][0][1]\n",
    "            d_init_z = i\n",
    "        \n",
    "        temp_dist = np.min([100, np.linalg.norm([all_target[i][0][0]-d_init_x, all_target[i][0][1]-d_init_y, i-d_init_z])])\n",
    "        all1.append(temp_dist)\n",
    "        d_init_x = all_target[i][0][0]\n",
    "        d_init_y = all_target[i][0][1]\n",
    "        d_init_z = i\n",
    "    else:\n",
    "        all1.append(100)\n",
    "all1 = 100-np.array(all1)\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peaks, _ = find_peaks(all1, distance=8, width=4)\n",
    "#print(a.shape)\n",
    "plt.plot(all1)\n",
    "plt.plot(peaks, all1[peaks], 'x')\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice location  0 49\n",
      "[[  2.   273.25  44.   388.75]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case_index   = 0#random.randint(0, len(valid_dataset))\n",
    "img, all_target, _    = valid_dataset[case_index]\n",
    "img          = img.astype('float32')\n",
    "#img        = a.astype('float32')\n",
    "#case_index = 0#random.randint(0, img.shape[0]-1)\n",
    "#case_index = peaks[0]-5\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "ax   = plt.gca()\n",
    "case_index  = 0\n",
    "print('slice location ', case_index, len(valid_dataset))\n",
    "\n",
    "if 1:#len(all_target[case_index]) > 0 and all_scores[case_index][0] > 0.2:\n",
    "    temp  = all_target['boxes'].data.cpu().numpy()#[case_index]\n",
    "    print(temp)\n",
    "    #print(case_index, all_scores[case_index])\n",
    "    index = 0\n",
    "    #rect  = patches.Rectangle((temp[0], temp[1]), temp[2]-temp[0], temp[3]-temp[1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    ax.add_patch(rect)\n",
    "else:\n",
    "    print('Not found 8')\n",
    "\n",
    "plt.show()\n",
    "case_index = case_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Validation Iteration #10 loss: 0.26083502173423767\n",
    "# Validation Iteration #20 loss: 0.12475015223026276\n",
    "# Validation Iteration #30 loss: 0.2311360090970993\n",
    "# Validation Iteration #40 loss: 0.07870643585920334\n",
    "# Validation Iteration #50 loss: 0.12904797494411469\n",
    "# 0.17835015669465065\n",
    "\n",
    "# Validation Iteration #10 loss: 0.16890683770179749\n",
    "# Validation Iteration #20 loss: 0.12697485089302063\n",
    "# Validation Iteration #30 loss: 0.202874094247818\n",
    "# Validation Iteration #40 loss: 0.1275915801525116\n",
    "# Validation Iteration #50 loss: 0.16607160866260529\n",
    "# 0.17254152543842793\n",
    "\n",
    "# Validation Iteration #10 loss: 0.14864173531532288\n",
    "# Validation Iteration #20 loss: 0.13806253671646118\n",
    "# Validation Iteration #30 loss: 0.13079851865768433\n",
    "# Validation Iteration #40 loss: 0.09259304404258728\n",
    "# Validation Iteration #50 loss: 0.13366109132766724\n",
    "# 0.1608045955002308\n",
    "\n",
    "# Validation Iteration #10 loss: 0.2190426141023636\n",
    "# Validation Iteration #20 loss: 0.10993507504463196\n",
    "# Validation Iteration #30 loss: 0.08774184435606003\n",
    "# Validation Iteration #40 loss: 0.14777813851833344\n",
    "# Validation Iteration #50 loss: 0.08807449787855148\n",
    "# 0.1679838129878044\n",
    "\n",
    "# fasterrcnn_resnet50_dbt22.pth\n",
    "# Validation Iteration #10 loss: 0.12817245721817017\n",
    "# Validation Iteration #20 loss: 0.3029731810092926\n",
    "# Validation Iteration #30 loss: 0.06146375834941864\n",
    "# Validation Iteration #40 loss: 0.08439958095550537\n",
    "# Validation Iteration #50 loss: 0.059381939470767975\n",
    "# 0.10177689090371132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For doing inference of the model\n",
    "\n",
    "all_target = []\n",
    "all_scores = []\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_dbt22.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "for images, targets, image_ids in valid_data_loader:\n",
    "    new_images  = []\n",
    "    for img in images:\n",
    "        new_images.append(torch.Tensor(img).to(device))\n",
    "\n",
    "    images    = new_images\n",
    "    targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    loss_dict = model(images)\n",
    "    print(loss_dict)\n",
    "    \n",
    "    #print(loss_dict[0]['boxes'].data.cpu().numpy())\n",
    "    \n",
    "    all_scores.append(loss_dict[0]['scores'].data.cpu().numpy())\n",
    "    all_target.append(loss_dict[0]['boxes'].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([ 271, 1057,  805, 1490])}\n",
      "Ground Truth  [ 271 1057  805 1490] 35\n",
      "Prediction  [[ 75.71501  283.47375  163.6579   378.79547 ]\n",
      " [  4.241309 263.63602   50.325714 373.7304  ]\n",
      " [101.045715 287.99136  151.38869  370.79993 ]\n",
      " [ 61.922516 258.55548  184.89377  395.74182 ]]\n",
      "Scores  [0.97706246 0.4141349  0.13911489 0.10131314]\n",
      "Prediction  [[ 75.71501  283.47375  163.6579   378.79547 ]\n",
      " [  4.241309 263.63602   50.325714 373.7304  ]\n",
      " [101.045715 287.99136  151.38869  370.79993 ]\n",
      " [ 61.922516 258.55548  184.89377  395.74182 ]]\n",
      "[ 271 1057  805 1490]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [STAR] Code to compare the ground truth and predicted mask\n",
    "\n",
    "\n",
    "case_index   = 35#random.randint(0, len(valid_dataset)-1)\n",
    "images, b, c = valid_dataset[case_index]\n",
    "print(b)\n",
    "\n",
    "print('Ground Truth ', b['boxes'].data.cpu().numpy(), case_index)\n",
    "print('Prediction ', all_target[case_index])\n",
    "print('Scores ', all_scores[case_index])\n",
    "\n",
    "plt.imshow(images[0], cmap='gray')\n",
    "ax   = plt.gca()\n",
    "\n",
    "# if(len(all_target1[case_index]) > 0):\n",
    "#     #print(all_target1[index])\n",
    "#     #print(all_scores1[index])\n",
    "    \n",
    "#     temp  = all_target1[case_index]\n",
    "#     index = 0\n",
    "#     rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='yellow', fill = False)\n",
    "#     ax.add_patch(rect)\n",
    "# else:\n",
    "#     print('Not found 9')\n",
    "\n",
    "if(len(all_target[case_index]) > 0):\n",
    "    #print(all_target[index])\n",
    "    #print(all_scores[index])\n",
    "    \n",
    "    temp  = all_target[case_index]\n",
    "    print('Prediction ', temp)\n",
    "    index = 0\n",
    "    rect  = patches.Rectangle((temp[index][0], temp[index][1]), temp[index][2]-temp[index][0], temp[index][3]-temp[index][1], linewidth=1, edgecolor='cyan', fill = False)\n",
    "    ax.add_patch(rect)\n",
    "else:\n",
    "    print('Not found 8')\n",
    "\n",
    "temp  = b['boxes'].data.cpu().numpy()//4#all_target[index]\n",
    "index = 0\n",
    "print(temp)\n",
    "rect  = patches.Rectangle((temp[0], temp[1]), temp[2]-temp[0], temp[3]-temp[1], linewidth=2, edgecolor='red', fill = False)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "#rect = patches.Rectangle((0, 0), 500, 100, linewidth=2, edgecolor='cyan', fill = False)\n",
    "\n",
    "plt.show()\n",
    "case_index = case_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 271, 1057,  534,  433])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['boxes'].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error cases for fasterrcnn_resnet50_dbt15.pth\n",
    "Ground Truth  [[ 10.75 304.    51.25 333.75]] 5\n",
    "Ground Truth  [[ 19.   416.25  63.5  447.75]] 6\n",
    "Ground Truth  [[188.25 309.5  216.5  369.75]] 7\n",
    "Ground Truth  [[193.25 389.5  228.   453.5 ]] 8\n",
    "Ground Truth  [[463.75 150.5  498.5  222.75]] 14\n",
    "Ground Truth  [[170.   335.25 195.5  362.25]] 23\n",
    "Ground Truth  [[345.25 414.5  472.25 536.5 ]] 30\n",
    "Ground Truth  [[451.5  333.75 496.   382.  ]] 34\n",
    "Ground Truth  [[398.   166.75 468.25 222.  ]] 37\n",
    "Ground Truth  [[317.75 332.75 388.75 394.  ]] 44\n",
    "Ground Truth  [[  2.   273.25  44.   388.75]] 45\n",
    "Ground Truth  [[5.0000e-01 3.9825e+02 6.1500e+01 5.1375e+02]] 46\n",
    "\n",
    "# Error cases for fasterrcnn_resnet50_dbt14.pth\n",
    "Ground Truth  [[188.25 309.5  216.5  369.75]] 7\n",
    "Ground Truth  [[193.25 389.5  228.   453.5 ]] 8\n",
    "Ground Truth  [[317.75 332.75 388.75 394.  ]] 44\n",
    "Ground Truth  [[299.25 347.75 324.25 387.  ]] 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1200, 3000)\n"
     ]
    }
   ],
   "source": [
    "dbtvol = np.fromfile('/media/drilnvm/ubuntudata2/TEST-DBT-RECONS/04140608-LE-L-CC_3000x1200x80.4_0.0005_-0.2_1_15.raw', dtype=np.float32)\n",
    "dbtvol = np.reshape(dbtvol, [80, 1200, 3000])\n",
    "print(dbtvol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
