{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# All Imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import time\n",
    "import pydicom\n",
    "import glob\n",
    "from numba import jit\n",
    "from skimage import filters\n",
    "import copy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "\n",
    "#import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#from scipy.misc import imresize\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "# GAN model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "#from scipy.misc import imsave\n",
    "import scipy.stats\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import pydicom\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "import glob\n",
    "#from scipy.misc import imread\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_psnr\n",
    "import numpy\n",
    "from numpy.fft import fft2, ifft2, fftshift\n",
    "import scipy.ndimage.interpolation as ndii\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "code_folding": [
     3,
     20,
     55,
     100,
     136,
     159,
     204,
     251,
     332
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5, 5])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# [STAR] PyTorch models for training the regularizer\n",
    "\n",
    "\n",
    "class RegCNN(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_features = 125\n",
    "        self.in_features  = 125\n",
    "        \n",
    "        self.weight = torch.nn.Parameter(torch.randn(self.out_features, self.in_features))\n",
    "        self.bias   = torch.nn.Parameter(torch.randn(self.out_features, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.weight, x)\n",
    "        x = self.bias + x\n",
    "        x = torch.tanh(x)\n",
    "        x = torch.mean(x, dim=0)\n",
    "        return(x)\n",
    "\n",
    "class RegCNNA(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features   = 125\n",
    "        self.out_features1 = 125\n",
    "        self.out_features2 = 125\n",
    "        self.out_features3 =   5\n",
    "        \n",
    "        self.weight1 = torch.nn.Parameter(torch.randn(self.out_features1, self.in_features))\n",
    "        self.bias1   = torch.nn.Parameter(torch.randn(self.out_features1, 1))\n",
    "        \n",
    "        self.weight2 = torch.nn.Parameter(torch.randn(self.out_features2, self.out_features1))\n",
    "        self.bias2   = torch.nn.Parameter(torch.randn(self.out_features2, 1))\n",
    "        \n",
    "        #self.weight3 = torch.nn.Parameter(torch.randn(self.out_features3, self.out_features2))\n",
    "        #self.bias3   = torch.nn.Parameter(torch.randn(self.out_features3, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.weight1, x)\n",
    "        x = self.bias1 + x\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "        x = torch.matmul(self.weight2, x)\n",
    "        x = self.bias2 + x\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "        #x = torch.matmul(self.weight3, x)\n",
    "        #x = self.bias3 + x\n",
    "        #x = torch.tanh(x)\n",
    "        #print(x[124])\n",
    "        \n",
    "        x = torch.mean(x, dim=0)\n",
    "        return x\n",
    "\n",
    "class RegCNNC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 16\n",
    "        self.filter1 = 16\n",
    "        self.filter2 = 8\n",
    "        self.filter3 = 64\n",
    "        self.filter4 = 64\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #self.conv_block2 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter0, self.filter1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "        \n",
    "        #self.conv_block3 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter1, 1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "            #nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block4 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter2, self.filter3, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block5 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter3, self.filter4, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU())\n",
    "        #self.conv_block4 = nn.MaxPool3d(2, stride=2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block2(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block3(x)\n",
    "        \n",
    "        out, _ = torch.max(x, 1)\n",
    "        out = torch.reshape(out, [-1, 1])\n",
    "        return out\n",
    "\n",
    "class RegCNND(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 16\n",
    "        self.filter1 = 16\n",
    "        self.filter2 = 16\n",
    "        self.filter3 = 64\n",
    "        self.filter4 = 64\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "    \n",
    "    def forward(self, x, x1, x2):\n",
    "        x    = self.conv_block1(x)\n",
    "        x    = torch.sum(x, 1)\n",
    "        \n",
    "        x1   = self.conv_block2(x1)\n",
    "        x1   = torch.sum(x1, 1)\n",
    "        \n",
    "        x2   = self.conv_block3(x2)\n",
    "        x2   = torch.sum(x2, 1)\n",
    "        \n",
    "        out = x + x1 + x2\n",
    "        out = torch.reshape(out, [-1, 1])\n",
    "        return out\n",
    "\n",
    "class RegCNNE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 64\n",
    "        self.filter1 = 16\n",
    "        self.filter2 = 16\n",
    "        self.filter3 = 64\n",
    "        self.filter4 = 64\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(3, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x    = self.conv_block1(x)\n",
    "        x    = torch.sum(x, 1)\n",
    "        \n",
    "        out = x\n",
    "        out = torch.reshape(out, [-1, 1])\n",
    "        return out\n",
    "\n",
    "class RegCNNF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 16\n",
    "        self.filter1 = 16\n",
    "        self.filter2 = 8\n",
    "        self.filter3 = 64\n",
    "        self.filter4 = 64\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        #self.conv_block2 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter0, self.filter1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "        \n",
    "        #self.conv_block3 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter1, 1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "            #nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block4 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter2, self.filter3, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block5 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter3, self.filter4, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU())\n",
    "        #self.conv_block4 = nn.MaxPool3d(2, stride=2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block2(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block3(x)\n",
    "        \n",
    "        x    = torch.sum(x, 1)\n",
    "        out =  torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        return out\n",
    "\n",
    "class RegCNNG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 16\n",
    "        self.filter1 = 16\n",
    "        self.filter2 = 8\n",
    "        self.filter3 = 64\n",
    "        self.filter4 = 64\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "           nn.Conv3d(self.filter0, self.filter1, kernel_size=5, stride=1, padding=0),\n",
    "           nn.ReLU())\n",
    "        \n",
    "        #self.conv_block3 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter1, 1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "            #nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block4 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter2, self.filter3, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block5 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter3, self.filter4, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU())\n",
    "        #self.conv_block4 = nn.MaxPool3d(2, stride=2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        \n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block2(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block3(x)\n",
    "        \n",
    "        x    = torch.sum(x, 1)\n",
    "        out =  torch.reshape(x, [-1, 1])\n",
    "        return out\n",
    "\n",
    "class RegCNNH(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 8\n",
    "        self.filter1 = 8\n",
    "        self.filter2 = 8\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "           nn.Conv3d(1, self.filter1, kernel_size=5, stride=1, padding=2),\n",
    "           nn.ReLU())\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "           nn.Conv3d(1, self.filter2, kernel_size=5, stride=1, padding=2),\n",
    "           nn.ReLU())\n",
    "        \n",
    "        self.conv_block4 = nn.Sequential(\n",
    "           nn.Conv3d(1, self.filter2, kernel_size=5, stride=1, padding=2),\n",
    "           nn.ReLU())\n",
    "        \n",
    "        self.conv_block5 = nn.Sequential(\n",
    "           nn.Conv3d(1, self.filter2, kernel_size=5, stride=1, padding=0),\n",
    "           nn.ReLU())\n",
    "        \n",
    "        #self.conv_block3 = nn.Sequential(\n",
    "        #    nn.Conv3d(self.filter1, 1, kernel_size=5, stride=1, padding=2),\n",
    "        #    nn.ReLU())\n",
    "            #nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block4 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter2, self.filter3, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool3d(2, stride=2))\n",
    "        \n",
    "#         self.conv_block5 = nn.Sequential(\n",
    "#             nn.Conv3d(self.filter3, self.filter4, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU())\n",
    "        #self.conv_block4 = nn.MaxPool3d(2, stride=2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        inputx = x\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = torch.sum(x, 1)\n",
    "        x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        x = inputx + x\n",
    "        x = self.conv_block2(x)\n",
    "        x = torch.sum(x, 1)\n",
    "        x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #x = inputx + x\n",
    "        #x = self.conv_block3(x)\n",
    "        #x = torch.sum(x, 1)\n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #x = inputx + x\n",
    "        #x = self.conv_block4(x)\n",
    "        #x = torch.sum(x, 1)\n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        x = inputx + x\n",
    "        x = self.conv_block5(x)\n",
    "        x = torch.sum(x, 1)\n",
    "        \n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block2(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block3(x)\n",
    "        \n",
    "        #x    = torch.sum(x, 1)\n",
    "        out =  torch.reshape(x, [-1, 1])\n",
    "        return out\n",
    "\n",
    "class RegCNNI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter0 = 125\n",
    "        self.filter1 = 125\n",
    "        self.filter2 = 125\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.filter0, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "           nn.Conv3d(1, self.filter1, kernel_size=5, stride=1, padding=0),\n",
    "           nn.ReLU())\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        inputx = x\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        x = inputx + x\n",
    "        x = self.conv_block2(x)\n",
    "        x = torch.sum(x, 1)\n",
    "        \n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #x = inputx + x\n",
    "        #x = self.conv_block3(x)\n",
    "        #x = torch.sum(x, 1)\n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #x = inputx + x\n",
    "        #x = self.conv_block4(x)\n",
    "        #x = torch.sum(x, 1)\n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #x = inputx + x\n",
    "        #x = self.conv_block5(x)\n",
    "        #x = torch.sum(x, 1)\n",
    "        \n",
    "        #x = torch.reshape(x, [-1, 1, 5, 5, 5])\n",
    "        \n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block2(x)\n",
    "        #print('x shape is ', x.shape)\n",
    "        #x = self.conv_block3(x)\n",
    "        \n",
    "        #x    = torch.sum(x, 1)\n",
    "        out =  torch.reshape(x, [-1, 1])\n",
    "        return out\n",
    "    \n",
    "model  = RegCNNI()\n",
    "inx    = torch.tensor(np.random.rand(10, 1, 5, 5, 5).astype('float32'))\n",
    "print(inx.shape)\n",
    "result = model.forward(inx)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     14,
     63,
     104,
     138
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Model for training the de-noising network\n",
    "\n",
    "img_shape  = (256, 256, 1)\n",
    "\n",
    "def huber_loss(y_true, y_pred, clip_delta=0.04):\n",
    "    error        = y_true - y_pred\n",
    "    cond         = tf.keras.backend.abs(error) < clip_delta\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "    return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "class AdversarialAutoencoder():\n",
    "    def __init__(self):\n",
    "        self.optimizer1  = RMSprop(0.0005)\n",
    "        self.optimizer2  = RMSprop(0.00001)\n",
    "        \n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        \n",
    "        \n",
    "        #self.discriminator.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_data/Results/vanilla-gan-weights-mse-0.1/discriminator_weights_8050.h5')\n",
    "        self.d_arr = []\n",
    "        self.g_arr = []\n",
    "        \n",
    "        # Build the encoder / decoder\n",
    "        self.generator = self.build_generator()\n",
    "         \n",
    "        img = Input(shape=img_shape)\n",
    "        # The generator takes the image, encodes it and reconstructs it\n",
    "        # from the encoding\n",
    "        reconstructed_img            = self.generator(img)\n",
    "        #self.adversarial_autoencoder = Model(img, reconstructed_img)\n",
    "        #self.adversarial_autoencoder.compile()\n",
    "        # For the adversarial_autoencoder model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # The discriminator determines validity of the cleaned image\n",
    "        validity = self.discriminator(reconstructed_img)\n",
    "\n",
    "        # The adversarial_autoencoder model  (stacked generator and discriminator)\n",
    "        self.adversarial_autoencoder = Model(img, [reconstructed_img, validity])\n",
    "        self.adversarial_autoencoder.compile(loss=[huber_loss_mean, 'mse'],\n",
    "            loss_weights=[0.9, 0.1],\n",
    "            optimizer=self.optimizer2)\n",
    "        \n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=self.optimizer1, \n",
    "            metrics=['accuracy'])\n",
    "        #self.discriminator.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_data/Results/gan-proj-mse-0.99-sub-weights/discriminator_weights_8400.h5')\n",
    "        #self.generator.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_data/Results/gan-proj-mse-0.99-sub-weights/generator_weights_8400.h5')\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    def build_autoencoder(self):\n",
    "        self.generator.compile(loss=['mse'],optimizer=self.optimizer)\n",
    "     \n",
    "    def build_generator(self):\n",
    "        x = Input(shape=img_shape)\n",
    "        x1 = Conv2D(32, (3, 3), padding='same')(x)\n",
    "        x1 = LeakyReLU(alpha=0.2)(x1)\n",
    "        \n",
    "        x2 = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "        #x2 = BatchNormalization(momentum=0.8)(x2)\n",
    "        x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "        \n",
    "        x3 = Conv2D(64, (3, 3), padding='same')(x2)\n",
    "        #x3 = BatchNormalization(momentum=0.8)(x3)\n",
    "        x3 = LeakyReLU(alpha=0.2)(x3)\n",
    "        \n",
    "        #x3_m = merge([x2, x3], mode='concat', concat_axis=3)\n",
    "        x4 = Conv2D(64, (3, 3), padding='same')(x3)\n",
    "        #x4 = BatchNormalization(momentum=0.8)(x4)\n",
    "        x4 = LeakyReLU(alpha=0.2)(x4)\n",
    "        #x6_i = merge([x2, x6], mode='concat', concat_axis=3)\n",
    "        \n",
    "        \n",
    "        x5 = Conv2D(128, (3, 3), padding='same')(x4)\\\n",
    "        #x5 = BatchNormalization(momentum=0.8)(x5)\n",
    "        x5 = LeakyReLU(alpha=0.2)(x5)\n",
    "        \n",
    "        #x7_i = merge([x1, x7], mode='concat', concat_axis=3)\n",
    "        x6 = Conv2D(128, (3, 3), padding='same')(x5)\n",
    "        x6 = LeakyReLU(alpha=0.2)(x6)\n",
    "        \n",
    "        x7 = Conv2D(64, (3, 3), padding='same')(x6)\n",
    "        #x8 = BatchNormalization(momentum=0.8)(x8)\n",
    "        x7 = LeakyReLU(alpha=0.2)(x7)\n",
    "        #x7_m = merge([x1, x6], mode='concat', concat_axis=3)\n",
    "        #x8    = Conv2D(1, (3, 3), activation='relu', padding='same')(x6)\n",
    "        x8 = Conv2D(1, (3, 3), padding='same')(x7)\n",
    "        x8 = LeakyReLU(alpha=0.2)(x8)\n",
    "        \n",
    "        out = keras.layers.Subtract()([x, x8])\n",
    "        #out = ReLU()(out)\n",
    "        model = Model(x, out)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (3, 3), input_shape=img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64,  (3, 3),  strides=(2, 2)))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        #         model.add(Conv2D(16, (6, 6),  strides=(2, 2)))\n",
    "        #         model.add(LeakyReLU(alpha=0.2))\n",
    "        #         model.add(Dropout(0.5))\n",
    "        model.add(Conv2D(64, (3, 3),  strides=(2, 2)))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, (3, 3)))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, (3, 3),  strides=(2, 2)))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Dense(1))\n",
    "        return model\n",
    "    \n",
    "    def train_generator_autoencoder(self, epochs, batch_size=128):\n",
    "        for epoch in range(epochs):\n",
    "            # Load the dataset\n",
    "            X_train, Y_train = get_train_data(epoch, batch_size)\n",
    "            \n",
    "            X_train = np.expand_dims(X_train, axis=3)\n",
    "            Y_train = np.expand_dims(Y_train, axis=3)\n",
    "            \n",
    "            g_loss = self.generator.train_on_batch(X_train, Y_train)\n",
    "            \n",
    "            # Plot the progress\n",
    "            print (\"Epoch \", epoch, \" G loss \", g_loss)\n",
    "            if epoch%50 == 0:\n",
    "                store_results(epoch)\n",
    "                self.generator.save_weights(savepath+modelname+'-weights/generator_weights_'+str(epoch)+'.h5')\n",
    "                self.discriminator.save_weights(savepath+modelname+'-weights/discriminator_weights_'+str(epoch)+'.h5')\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, sampling=50, saveseed=5, startepoch=0, discriminator_epochs=5):\n",
    "        for epoch in range(startepoch, epochs):\n",
    "            # Train the discriminator 5 times\n",
    "            #print('Training Discriminator ', epoch)\n",
    "            \n",
    "            projindex = str(random.randint(43, 68))#+'.dcm'\n",
    "    \n",
    "            lowfilename  = projectionpath+'3200x1600x25.'+str(projindex)+'.raw'\n",
    "            highfilename = highprojectionpath+'3200x1600x25.'+str(projindex)+'.raw'\n",
    "\n",
    "            lowimg  = np.fromfile(lowfilename, dtype='float32')\n",
    "            highimg = np.fromfile(highfilename, dtype='float32')\n",
    "            \n",
    "            lowvol  = np.reshape(lowimg,  [25, 1600, 3200])/1250.0\n",
    "            highvol = np.reshape(highimg, [25, 1600, 3200])/3750.0\n",
    "            \n",
    "            for itd in range(discriminator_epochs):\n",
    "                slice_index = random.randint(0, 24)\n",
    "                lowimg      = lowvol[slice_index]\n",
    "                highimg     = highvol[slice_index]\n",
    "                \n",
    "                # get the cropped image\n",
    "                lowimg, highimg =  get_crop_image(lowimg, highimg)\n",
    "                \n",
    "                # Load the dataset\n",
    "                X_train, Y_train = get_train_data_proj(lowimg, highimg, epoch, batch_size)\n",
    "                X_train = X_train - 0.5\n",
    "                Y_train = Y_train - 0.5\n",
    "                \n",
    "                #print(X_train.shape, Y_train.shape)\n",
    "                \n",
    "                X_train = np.expand_dims(X_train, axis=3)\n",
    "                Y_train = np.expand_dims(Y_train, axis=3)\n",
    "\n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size, 1))\n",
    "                fake  = np.zeros((batch_size, 1))\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # get the noisy image and feed it into the generator\n",
    "                X_train_clean = self.generator.predict(X_train)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(Y_train, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(X_train_clean, fake)\n",
    "                d_loss      = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            #print('Training Generator ', epoch)\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator\n",
    "            g_loss = self.adversarial_autoencoder.train_on_batch(X_train, [Y_train, valid])\n",
    "            #print('g_loss ', g_loss)\n",
    "            self.d_arr.append(d_loss)\n",
    "            self.g_arr.append(g_loss)\n",
    "            \n",
    "            #print('Epoch ', epoch, ' Total D loss ', -d_loss, ' D loss real ', -d_loss_real, ' D loss fake ', d_loss_fake, ' G_loss ', g_loss[0], g_loss[1], g_loss[2])\n",
    "            # Plot the progress\n",
    "            #print (\"%d [D loss: %f] [G loss: %f] [G loss: %f %f]\" % (epoch, 1 - d_loss, 1 - g_loss[0], g_loss[0], g_loss[1]))\n",
    "            #print('Epoch ', epoch, ' Total D loss ', -d_loss, ' G_loss ', g_loss[0], g_loss[1], g_loss[2])\n",
    "            \n",
    "            if epoch%sampling == 0:\n",
    "                store_results(epoch, saveseed)\n",
    "                self.generator.save_weights(savepath+modelname+'-weights/generator_weights_'+str(epoch)+'.h5')\n",
    "                #self.discriminator.save_weights(savepath+modelname+'-weights/discriminator_weights_'+str(epoch)+'.h5')\n",
    "            \n",
    "            print (\"%d [D loss: %f, mean_acc: %.2f%% real_acc: %.2f%% fake_acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1], 100*d_loss_real[1], 100*d_loss_fake[1], g_loss[2]*0.0001, g_loss[1]*0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1600, 3200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "index = 68\n",
    "all_proj = np.fromfile(\"/media/pranjal/cewitdata1/DBT-PROJ-DENOISE/NORMAL/3200x1600x25.\"+str(index)+\".raw\", dtype='float32')\n",
    "all_proj = np.reshape(all_proj, [25, 1600, 3200])\n",
    "                      \n",
    "print(all_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 448, 320)\n"
     ]
    }
   ],
   "source": [
    "a       = sio.loadmat(\"/media/pranjal/cewitdata2/DBT-PROJ-DENOISE/attenuation_values_cropped/LE/\"+str(index)+\".mat\")[\"head\"]\n",
    "print(a.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 2748, 1073)\n"
     ]
    }
   ],
   "source": [
    "# [STAR] Code to read the data\n",
    "\n",
    "a = np.fromfile('/media/pranjal/cewitdata1/pranjal/CT-RECON-DATA/MC_CE27_slice32_atzz666_dense_uppaddle_pc_209923395_crop_1073x2748x816.raw', dtype='uint8')\n",
    "a = np.reshape(a, [816, 2748, 1073])\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "temp = a[666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('calcification_cluster.npy', temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 2415, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81a14b9160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.fromfile('/media/pranjal/cewitdata1/pranjal/CT-RECON-DATA/pcl_22183101_crop.raw', dtype='uint8')\n",
    "a = np.reshape(a, [1140, 2415, 1740])\n",
    "#  1740   2415   1140\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "#temp = a[666]\n",
    "plt.imshow(a[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 350)\n"
     ]
    }
   ],
   "source": [
    "temp1 = np.load('calcification_cluster.npy')\n",
    "print(temp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1    = a[500, 1500:1500+temp1.shape[0], 150:150+temp1.shape[1]]\n",
    "temp1[temp1 != 250] = a1[temp1 != 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f819f79c198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a[499, 1500:1500+temp1.shape[0], 150:150+temp1.shape[1]] =  temp1\n",
    "#a[500, 1500:1500+temp1.shape[0], 150:150+temp1.shape[1]] =  temp1\n",
    "#a[501, 1500:1500+temp1.shape[0], 150:150+temp1.shape[1]] =  temp1\n",
    "\n",
    "plt.imshow(a[501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tofile('/media/pranjal/cewitdata1/pranjal/CT-RECON-DATA/pcl_22183101_crop_calci.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858161,) (858161,)\n",
      "(58, 1200, 3000) (58, 1200, 3000) (58, 1200, 3000)\n"
     ]
    }
   ],
   "source": [
    "e = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.4_4_0.0005_-0.5_1_anistropic_three_1.raw', dtype='float32')\n",
    "e = np.reshape(e, [58, 1200, 3000])\n",
    "\n",
    "temp               = e[27]#, 900:1150, 950:1350]\n",
    "temp[temp < 0.03] = 0\n",
    "temp[temp > 0.03] = 1\n",
    "#plt.imshow(temp, cmap='gray')\n",
    "\n",
    "non_zero_index = np.nonzero(temp)\n",
    "\n",
    "print(non_zero_index[0].shape, non_zero_index[1].shape)\n",
    "print(a.shape, b.shape, e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858161,) (858161,)\n",
      "86378 86378 858161\n",
      "(86378, 3, 5, 5, 5) (86378, 1) (86378, 1, 5, 5, 5) (86378, 1, 5, 5, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACpCAYAAADHoe3cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2de3wTZbrHf88kk6QBSimltFCg0CKlsFIEpSsouCBQ8AisLJYFQY9S6UHEgrtLRc+CfGQRRT+Cezmoq6CisiICi55drBdYdkXuaEVuQiktWLQL9PTe5Dl/ZBpbmhR6SWaSPN/P5/lk8mZm3uedmfzy5nlvxMwQBEEQQgNFbwcEQRAE/yGiLwiCEEKI6AuCIIQQIvqCIAghhIi+IAhCCCGiLwiCEEL4XfSJaCwRHSWiE0S00N/5C4IghDLkz376RGQCcAzA7QDOAtgDYCozf+03JwRBEEIYf9f0bwJwgpm/ZeYqAG8DmOBnHwRBEEIWf4t+VwD5dd6f1dIEQRAEP2D2c37kIa1BfImIMgBkaG8H+dQjQRCE4OR7Zu50ZaK/Rf8sgG513scBKLxyJ2ZeA2ANABCRTA4kCILQdPI8Jfo7vLMHQG8i6klEFgDpALb42QdBEISQxa81fWauIaKHAPwNgAnAn5k5158+CIIghDJ+7bLZHCS8IwiC0Cz2MfPgKxNlRK4gCEIIIaIvCIIQQojoC4IghBAi+gaEiNyvtduCIDSNut8j4UdE9A2EqqogIphMJgCAoijo06ePzl4JQuCRlJTk/h6ZTCYQEWw2m85eGQN/D84SGqG6uhoAUFNTAwBwOByIiIjQ0yVBCEgiIiLc36Pa14qKCj1dMgxS0xcEQQghRPQFQRBCCBF9QRCEEEJEXxAEIYQQ0RcEIeiobbwVGiKib3AURW6RIDQVs1k6JnpDFEUQhKBEBmV5RkRfEAQhhGi26BNRNyL6hIiOEFEuEc3T0iOJaDsRHddeO9Q5JpuIThDRUSIa0xoFEARBuJKKigoYfdp4vWhJTb8GwAJm7gsgFcAcIkoGsBBADjP3BpCjvYf2WTqAfgDGAvgDEZla4nwo4HA49HZBEIQgotmiz8znmHm/tl0C4AiArgAmAFir7bYWwERtewKAt5m5kplPATgB4Kbm5i8IguCN2nl3hIa0SkyfiOIBDASwG0BnZj4HuH4YAERru3UFkF/nsLNamqfzZRDRXiLa2xr+BTLy8ApC05Eum95pcb8mImoLYCOAR5j5ciMt5p4+8Bh0Y+Y1ANZo5w/pwJxMEiUITUdVVb1dMCwtqukTkQqX4L/JzO9pyd8RUaz2eSyAIi39LIBudQ6PA1DYkvxDAXl4BaHpVFVVSZdNL7Sk9w4BeAXAEWZ+rs5HWwDM1LZnAthcJz2diKxE1BNAbwBfNDf/UEEeXEFoOlVVVXq7YFhaEt4ZCuAeAF8S0UEt7TEAywFsIKL7AZwB8AsAYOZcItoA4Gu4ev7MYWbpmtIIRCTdzoKIuj/gtQt71K6hILQuEtP3TrNFn5n/Ac9xegAY6eWYpwA81dw8Qw1mloc3gDGZTFBVFWFhYUhISEBFRQV69uwJi8WCvLw8VFdXQ1VVVFRU4OLFiygqKpIaaithtVr1dsGwyAQVBkbWyA1czGYzBg0ahMrKSnz77bcwm8144okncPPNNyMmJgYHDhzA6NGjcfHiRVitVvTu3Rs/+clPcPjwYRQUFOjtfsAjbWGNwMyGNrh6+ISsDRkyRHcfxJpmRMRDhw7lHTt2cGFhIa9evZoTExN5+PDhnJKSwufOnWOHw8GLFy9mk8nEAFhRFDaZTKyqKiuKonsZAt1SUlJ098EAtteTpsrcOwZHYr6BRZs2bfDQQw9h/fr1GDZsGDp16oT9+/fj1KlT+Oyzz3Do0CHs3LkTiqLgwQcfRExMDEwmEzIyMpCdnY1x48bBYrHoXYygQP4le0ZE3+A4nU69XRCuEbvdjh49eiAjIwPdu3cHEaG4uBgHDhzAsmXLYDabwcwoLi4GAERGRmL27Nmw2+144403EB0djbVr12LSpEkiWILPENE3MIqiyLzgAURZWRkURUG3bj8OR+nUqRM2b96M1NRU9718/fXX3Y22hYWFeOWVV7BgwQL85je/wbhx4xAdHY0pU6agT58+UutvJtIBwjsi+gaGmWVEboAQHh6OKVOmoLi4GJ999hmYGS+++CJmz56NAwcOoG/fvujYsaO7G+6mTZtgMpmwa9cuPPnkkzh16hScTif++c9/4oUXXsCWLVsQFxeHlStX4j/+4z8QFhamdxEDCqvVKv+WvCDVSIMjXc+MiaIo6N+/PxISEvCvf/0LpaWl2Lx5M+Lj49G3b1/k5+fjT3/6E3Jzc1FdXY2OHTuivLwciqIgPT0dVVVVUFUVKSkpWLduHb766qt65y8vL0dOTg5yc3MxduxYrFmzBq+88gp27twpM69eA6qqiuh7Q+/eOdJ7x7spisKpqam6+yFW39q3b89PPPEEFxcX8+OPP+7ubZOamsonT57kI0eOcFJSEo8ePZotFgtbrVaOjIx0H282m3nQoEF8+vRp/uKLL9hms9U7vzbfVD1LSUnhv/3tb/z0009z+/btdb8GRrfU1FTpBSW9dwIPIoLNZtPbDUHDarXivvvuwyeffILFixfj448/xpo1a9yN7UVFRVi/fj3atm2Lxx57DH379kW7du1QVVXlbrwFXPHmffv2Ye7cuYiNjUVaWlq9fJgZ4eHh9dpzDh48iOnTpyM2NhZbtmzBiBEjZP3kqyA1fS/oXZOXmr53IyIeMGCA7n6Igfv168dbtmzh6upqZmY+c+YMd+/evcF+kyZNYofDwczMu3bt4qlTp3qtmSuKwpMmTeKXXnqJLRZLvc/mzJnDY8eObXCMxWLhrKwsLiws5F//+tdst9t1vzZGtOTkZKnpe6np6y7qIvrezWw287Bhw3T3I5QtKiqK//u//5sLCgq4Lh999JF7YBURcUxMDGdlZfGqVas4KyuLP/74Y964cSPb7fZGhZmIeOzYsRwVFVUv/Y477uCtW7c2CP0Arh+L9PR0Ligo4LVr13Lnzp11v05Gs/79+7PZbNbdD51NRD/QTFVVHjFihO5+hKKFhYXx7Nmzec+ePex0OusJ/g8//MAZGRncoUMHHjp0KK9YsYLz8vL41Vdf5fDwcAbAERERPHfuXP7www95xYoVjeaVmJjIkyZNqpcWERHBX375JY8ZM8bjMUTEs2bN4kuXLvHOnTv5hhtu0P2aGckGDBjAqqrq7ofOJqIfaGY2m2UaBj+boiicnJzMmzZt4kuXLvHWrVu5pqbGLfhOp5NXrFjBCQkJ/Pvf/54rKyuZmfno0aOcnJzsboQlIn7++ee5qqqKFy1a1Gio4YEHHuDDhw/Xa+wlIp43bx4fPnyYR40a5bHWqigKT5gwgYuKirigoIAnT54sIQ3NkpOTRfR9JfoATAAOAPir9j4SwHYAx7XXDnX2zYZrbdyjAMaI6DduFouFBw0apLsfoWLR0dH8xz/+kQsLCzkvL49LSkr4ShwOBz/77LN84MCBBulnzpzh66+/ngHw4MGDuaioiJmZP/zww3oCZDKZ3KEhAPzrX/+aS0pK3MfWGhHxtGnTuKCggJ977jnu2rUrm83mBr17Ro0axXl5eXz58mXOysqSsAZcvZ3qXuMQNZ+J/nwA6/Gj6K8AsFDbXgjgaW07GcAhAFYAPQGcBGAS0fduqqryrbfeqrsfwW42m43vvfde3r17Nz/zzDOcm5vLly5daiD410JmZiYD4GnTpvHOnTv5iy++4Pvuu8+dFxHxsmXLeMGCBQy4wjiJiYmcl5fHc+fOdcfw09LS+LXXXuN3332XS0tLmZn59OnTvHXrVl60aBHfddddHBERwWFhYQyA09PTubKyksvLy/nRRx8NecFLSkqSHz9fiD5cSx7mAPgZfhT9owBite1YAEf5x1p+dp1j/wbgpyL63s1sNks/fR+b1Wrl559/nk+dOsWzZs3i2267jcvLy5sl+DU1NXzbbbe5711tI+6VAjxs2DA+duwY33///bxu3ToeO3Ysl5SUcFVVFb/55pv8+OOP8/Hjx73m43A4+PLly3zo0CF+8803ecyYMdylSxfes2cPMzOXlpbyvHnzQlr4BwwYwFarVXc/dDafiP67AAYBGIEfRf/iFfv8W3t9EcD0OumvAJgsou/dVFWV8I4PLSoqiv/nf/6H8/PzediwYawoCmdlZdWL4V+NiooK3rVrF1+8eJEvXLjA8fHx3LFjR4+xdVVVefbs2ZycnMxff/01O51OdjgcTf5Xcfr0aV60aBGvWrWKZ8+ezf/85z85MTGR582b5+4uWl5ezr/61a9Ctrbbv39/DgsL8zjQLYTMo+g3exoGIroDQBEz7yOiEddyiIc09nLuDAAZzfUtWGBmGWDiA4gII0aMwPLly/GTn/wEM2bMwK5du8DM+Pvf/44nn3wSbdu2vaZzffrpp5gwYQL+8z//EzU1NTh79myjk32NHz8e8+bNQ3x8vHuRnPDw8Hr7OJ3ORgdede3aFffccw8AoGPHjoiLi8O4ceNQVVWFmpoaWCwW2Gw2LF26FIqiYOXKlSE3AVlNTQ0cDkdtxVGoSwtq+b8DcBbAaQDnAZQBeAMS3mk1M5vNMjirlc1ut3NmZia/9NJLnJaWxvPmzXP3ozebzbxy5com1bpff/31BnkoitKght22bVt+4YUX+MSJE1xVVcXV1dVcWlrKeXl5TcrPG2VlZVxQUNCge2lFRQU//PDDIRfqkd47YPiyyybqh3eeQf2G3BXadj/Ub8j9FtKQ26jVztGitx/BYjExMfz+++/zU0895Y731v79t9lsvHr1aq6oqLiqwFZWVvL777/PDz74IPfv37/RPG02G/fq1YtfffVVd+jF4XBwSUkJl5aWcmFhYXM0vkmUlpby1KlTQyrUITF9MPwo+h3hatw9rr1G1tlvEVy9do4CSLvGc+t94XQzs9nM/fr1092PQDdFUXj06NG8e/dufvLJJ91i0KNHD+7WrRurqsqTJk1y95LxhNPp5E2bNvG9997Ld911F//ud7/jFStWeJxioVZcVVXl6667jo8fP+6xnaD2R8AfFBcXuxuZQ8H69+/fYGqLEDQZnBVoZjabZaRlC81ut/PSpUv5ww8/5AMHDnB8fDxbrVYeP348Hz58mFNTUzk7O5uLi4v5rbfe4m+++YaZXYJ88eJFZnYJ/pYtWzgiIoIBl6jPnTuXf/Ob3zSoPbdt25YnTpzIEydO5G3btnFubm6DwV16cfr06ZB5nkT0wZBZNgMPRVFkucQWEBMTgxdffBERERF45513EBcXhxUrVuCTTz7Bu+++i/DwcFRUVGDWrFnIyclBRkYGJk6ciIULF2L58uXIyMhAcXEx1q1bhxkzZuDixYsAXA3B+fn52LZtGyIjI9G+fXtERUVhxIgRWLt2LW666SaUlZVh+/btMJvNMJlMbp/0bJjv0aMHXn75ZfTo0UM3H/zFlddd+BFiV23asGg1qZDEZrMhKSkJBw8e1NuVgEJRFEyYMAF33HEHPvroIyQnJ+Ohhx5CREREvf0uX76M8+fPw263Y+TIkTh16hSqq6tBRDCZTDCbzYiOjsb58+dRVVXlMa8RI0ZgyJAheOCBB6AoCnJzc/HDDz9g3bp1eOSRRzB69GjDTY/917/+FTNmzMC///1vvV3xGSkpKfjmm29CfeW5fcw8uEGqp+q/kQz6/0XSzVRV5ZSUFN39CCSzWq2clZXFGzdu5NjYWB47dixXVVXx1q1bOSsriz///HN3uKO2n3xOTo57ZKsn89bzRVVVzszM5MLCQi4vL+cpU6bw4MGDedu2be4pmK8Ff4d8nE4nP//880Hdh1/CO2BITD/wzGKxhEwMtjWsa9eu/NJLL/Hq1avd8fesrCz+4IMP3N0yx48fX28A06pVqxpMa9yYmc1mDgsL4/j4eH766ae5rKyMmV2jcTds2MCbN29u9ohef1JWVsZTp07V/Z75ykT0wRDRDzwT0b82UxSFR40axTt37uQFCxawxWJhi8XCRMSTJ0/madOmsdls5q5du/L48ePdE6mdPHmSO3TowGaz+ZrmpCciHjlyJH/22Wf85ZdfNhDS6upqdjgcujbWNoW8vDzu06eP7vfPFyZdNsEQ0Q88U1W1wcyLYvXNZrNxVlYW79mzh8eMGcOKonBYWBivW7eOExMT3fsNHjyYb7jhBt69e7db9I4cOcJxcXH8+OOP87vvvnvVcEdYWBhv2LChSdM0GJ2PPvooKNfcTUlJEdEX0Q88U1VVRuQ2Yp07d+b169fziRMn6k1MN3nyZL58+bK7PcRms3F2djYXFRWx0+nkiooKfu655zglJYVvv/12vnz5Mk+fPp3btGnjVQBNJhPHxsbyK6+84tf+9b7G6XTy6tWrg27Erog+GNJlM/ConZtFaEhSUhLWr1+PsLAw3Hbbbfj8888BuK5Zv379UFFRAUVRsHr1auzYsQPz5s1Dp06dQETYunUrFi5ciIMHDyI3Nxdz5sxBaWkpNm7ciKlTp3rMz2KxYPTo0ZgyZUpQLUhORJg5cyZGjx6ttyuCv/D0S2Akg/6/lrqZxPQbGhFxamoq5+bm8gcffOBusAVcsf1HHnmEv//+ey4uLuYZM2bw+fPn3TXakpISzsvL4zvvvLPBeZOSkvj+++/nuLg4r/necccd7pWygo3c3Fzu2rWr7ve3tUxq+mBIeCfwTES/vhER33vvvZyfn88ff/yxe94bs9nMMTExPHLkSPdqVcyuEajLly/ngwcPcnp6OicnJ3NkZCRbLBaeNm0ax8TENJpfbcijc+fOPGPGDD527FjrKq2BcDqdvGbNmqDp8SKiD4aIfuCZiP6Ppqoqz5o1i48dO8aZmZncpk0bBlw/BFlZWXzu3Dl398la9u7dy/379+fc3FxOSEiod766yw6aTCZu06YNR0dHu4WeiNhsNnN8fDz/7//+b9DW8OtSWVlZb5WvQDYRfTBE9APPLBaLDM6Ca8DVE088wYcOHeLhw4e7xVpRFJ49ezZfvny5gYAdP36cMzIyODU1ldPS0rhdu3buYwC4Bf2ZZ57hdevW8f79+3nXrl3cvXt39752u51HjRrlca3cYOX8+fNB0XlARB+M1l5ERRD8gc1mw5IlSzBz5kxMnDjR3WALAKqqYtq0aWjXrh0AwOFwuOdbKS0txbBhw5Cfn4+8vDxUV1dDURQQERISEpCRkYG0tDQkJye7j6msrMScOXPQq1cvfP7557jxxhsxZsyYa15QJRjo3LkznnnmGUycOBFlZWV6uyP4Ak+/BNdqACLgWjLxGwBHAPwUQCSA7XBNrbwdQIc6+2cDOAHX1MpjrjEPvX8tdbNQD+9ERkbyunXrOD8/n6dMmeKupSuKwqmpqfyXv/zFPR1yYWEhr1q1is+cOeMOxTgcDj5//jyXlJTwp59+yunp6UxEPHjwYF66dCmXlZW5p2JgZi4pKeH8/HxDd8msrq72+TiB6urqgA/zSE0fDB+tkbsWwAPatgWuH4EVqL+IytPadjLqL6JyErKISqMWyqIfFxfH27Zt43379vH111/PRMSRkZGcnZ3N27Zt4/z8fLdIlZSU8LRp09hut/OcOXP4hx9+8ChmRUVFvGTJEncbQE1NDefk5HB2djZfvHjRLfZGHny1c+dOXr16tc/zKSgo4KSkJN2fg+aaiD4YrS36AMIBnII2U2eddFkusZUsVEU/Pj6e9+zZw8XFxTx8+HD3tXj77bcbTHFQXl7O2dnZ7ji81WrlYcOG1ftRqEvt4Kxali5dyjabjfft2+dOM2qjbWVlJZeXl/OFCxf8MtXDpk2bAlY4U1JS2Gaz6e6Hztbqg7N6AbgA4FUiOkBELxNRGwCdmfkcAGiv0dr+XQHk1zn+rJYmNEKozaeflJSETZs24brrrsOcOXOwY8cOAMDEiRMxadKkBoPVLBYLkpKS3PHnyspKHDhwwGs8mohgtVoBAFVVVcjNzcWdd96Jvn371junEbFYLDCZTLDb7X55LtLS0jBu3Dif5+MrTCaTDG70QEtE3wzgBgB/ZOaBAErhCud4w9PVZ487EmUQ0V4i2tsC/4KCYBr9eTUSExOxYcMGtGvXDpMnT8Y777wDZkafPn0wf/58j2KsKAp69OhRT7Srqqrw/fffe82HXf8goaoqnnrqKSxbtgxhYWGoqalp/UK1MoqiwG63N1ggpCU/AtXV1fi///u/BulWqxXZ2dkIDw9v9rn1xOFwuO+18CMtUZSzAM4y827t/btw/Qh8R0SxAKC9FtXZv1ud4+MAFHo6MTOvYebB7GkBgBAjVGr6SUlJeOutt1BRUYH09HRs374dTqcT0dHReOeddzBkyBCvx95yyy3o3bs34uLicP/992Po0KFITk72un/tgihEhF69eiEhIQEAAmKlJW8+tqRyoKqq1x5KgwYNwn/9139BVdVmn18vpKbvmWZ32WTm80SUT0R9mPkogJEAvtZsJoDl2utm7ZAtANYT0XMAugDoDeCLljgvBAfXXXcdXn/9dbfgFxQUuD975JFHMGDAgEaPVxQF8+fPR7du3WC1WlFZWdlglSzAVfMjIq/hGxGIhiiKgocffhjbt2/H/v37peYcDHgK9F+rAUgBsBfAYQDvA+gAoCOAHLi6bOYAiKyz/yK4eu0cBZB2jXno3Riim9lstqBvyO3Vqxfv3r2bDx8+XG8qZMDVNXPLli2t0ihZXFzM7733XpNWtPJEoMyV39q8//773KlTJ92fl2s16b0DhozIDTyzWq1BLfpdunThHTt28IULF+pNjVxrUVFRnJeX1yqidfz4cf72229bfB6Hw2HoLp2+oqqqirOzswNmCmYRfTBkauXAI5gbcbt374633noLAwcOxIIFC7B7926P+0RHR3s4uukkJiaiZ8+erXKuUAwDqaqK6dOnIy4uTm9XrhlVVUPyXl2N4FWVICBYG3E7d+6MtWvXYsiQIVi6dCneeOONerFis9mM+Ph43HnnnTCbW2+mkNa4nrVTORgBZvbrM3Ldddfh5z//ecBURmpqaqQNwhOeqv9GMuj/F0k3U1XVPX1wsFjbtm15/fr1XFNTw8888wyrqtpgnwcffJALCgr8GkZxOp3XHK/3dVy/KeUuLy/nqqoqH3pTn3379nGvXr10f46uZhLeAUPCO4FHYz1NAhGbzYZly5bh7rvvRk5ODhYvXozq6mr351arFZmZmVi8eDG6dOnity6UNTU1cDqd11yD93VN32QyXXMNfvPmzVi1alW96+hLrr/+eowZMyZgavtCQ+TOGZhA6Dd+rdjtdixduhSZmZmorKzEa6+9htLSUvfnqqpi0aJFeOGFF9C+fXu/+kZEhrvW1yqqw4cPx6FDh/D000+joqLC4z6tGQIym81IT09Hhw4dWu2cgn8R0Rd8Ttu2bfGnP/0J8+fPh9lshqqquP322xEfH4/27duDiHDjjTdiwYIFUBQFDofDr/4ZTfCbQkxMDJYtW4bY2Fh88MEHHvdp7Vp5ampqQKwVHMj31ad4ivkYyaB/XEw3C4YJ1xRF4eXLlzeIUzudTv7uu+/49ddf51tvvZV37NjReoHnECQ/P58zMzP91g5y6NAhQ8f2U1JS2G63uxfcCVGTmH6gYZReIi1h1KhRmDNnToNaV0VFBY4dO4Z//OMfWLVqFW655RadPAwOYmJisGTJEr/Vbvv164f77rsvKJ7RUENE38AE+heqV69eeP755xvM61JRUYGHH34Ys2bNwsyZM686zYJwdcxmMzp16gTAP119TSYTZsyYgR49evg8r+YS6N8fXyGiL/iEtm3b4oUXXvA48dk777yDy5cv47333sNPf/pTHbwLbnwda68NE3Tr1g0PPfSQYcWVfwwRC3UQ0TcwgTo4S1EUPProo0hLS0NJSUm97oQXL17Epk2bsHLlynrTIdcSql/SQLrXROS2u+++GzExMXq75JFAuqb+RETfwARq74PJkydjwYIFKCgowJIlS3D27Fn3Zz/88AMyMzM9Dud3Op3Iz89vkA4E/4+B0XvCeKNLly4YO3as3m54RFXVgL2uvkSuiIHxd9fF1qBfv35YuXIlACAjIwN//vOf6/UfT0hIwJgxYzweqygKunfv7vEzo4YQQp3aqZfbtWuntysNqB10J9SnRaJPRFlElEtEXxHRW0RkI6JIItpORMe11w519s8mohNEdJSIPH/zBTeBVktp3749nnvuOcTFxWHjxo3Ys2cPkpOT3Q2MgncC+Z9McnIybr75Zr3daICR5kkyEs1WFSLqCuBhAIOZuT8AE4B0uJZMzGHm3nDNp79Q2z9Z+7wfgLEA/kBEgRm/8ANE1KqTjfkak8mExx57DKNGjUJZWRnCw8ORk5ODP/zhD4iKitLbPcMTyOJksVgwffp0w4UjZeUsz7S0KmkGEEZEZgB2uJY/nABgrfb5WgATte0JAN5m5kpmPgXgBICbWph/0MLMAbFmay2/+MUvMHfuXBARXn75ZcTFxaFfv34eG2uF4GP8+PFISkrS2416yBq5nmm26DNzAYBnAZwBcA7AJWb+O4DOzHxO2+ccgNoJ0bsCqNtKd1ZLE7wQKA9sYmKie3FxIsItt9yCL7/8Ep999tk1/Vv5/PPPcfr06Rb7IfHbq+OrZ6pDhw5IT0/3ybmbi4i+Z1oS3ukAV+29J1xr3rYhoumNHeIhzeMdIaIMItpLRHub618wEAgxfZvNhmeffbbeAiUREREoKyuD3W6Hw+Fo9B9LRUUFPv74Y5w5c6bFvgTC9Qpm7rrrLoSHh+vthhuz2SzhHQ+05FsyCsApZr7AzNUA3gNwM4DviCgWALTXIm3/swC61Tk+Dq5wUAOYeQ0zD2bmwS3wL+AJhFrKjBkzMH78ePf7kydPYsGCBfj0008RHx/fqBDX1NTgsccewyeffII+ffr4w92QpbYnmC9FsHfv3hg6dKjPzt9UqqurA+I75G9aIvpnAKQSkZ1cT9JIAEcAbAEwU9tnJoDN2vYWAOlEZCWingB6A/iiBfkHPUZ/YKOjo5GVleUO4TidTqxcuRL5+aaKdm0AAAs+SURBVPlIS0tDVFQUFEVpNMRz4cIFTJ48GZ07d/aX2yGJPxpZzWYz7r77bqldG5xmdw9h5t1E9C6A/QBqABwAsAZAWwAbiOh+uH4YfqHtn0tEGwB8re0/h5kDryO6HzGy6BMR5s+fX6+G/v3336O8vBybN29Gly5drnoOs9mMJUuWwG63X3Vfh8PhFi5mFmFpAXWvZWszevRoxMTE4Ny5cz45f1OQcJ9nyMjCAgDa1KghicViQf/+/bF//369XWlASkoKcnJyEBkZ6U5zOp0oKytrMMHa1WiqiFdXV8NsNrumiZUvtqFgZvzyl7/E22+/rasfKSkpOHr0KMrLy3X1Q2f2eQqRyzdGaDIWiwW//e1v6wk+4KpZNVXwgabHmVVVBRGJ4BsQIjLM4unSm8sz+t8ZwStGG+xSy8SJEzFu3Di93RAMytChQw07CZsgom9ojFhTad++PRYtWuRxwfZLly6huLi4VfNzOp0eu3wa8doILjp37myIaRmk3cczIvoGxojtLffccw/69+/fIN3pdOLYsWP1plFuKU6nE1VVVaioqGgg8kYIHwQyvpxr3mQy4c4779RddGXuHc/IN8fAGC2806VLF/zqV7/yKLilpaW44YYbWrXrZXV1Nc6ePYs2bdq02jlDEU9TetTOh+8rhg4dioiICJ+d/1qQRVQ8I6JvYIwWwvjlL3+Jbt26efysXbt2rf4jZbVakZiYKL10Wogek/d1794dKSkpfs3zSoz2/TEK8k0yKEabZTMqKgoZGRm6/F0WwW8dampq/DaJn9lsxogRI/ySlzeM9k/ZKMi3yaAws6FqKnfddRcSEhL0dkNoAWazGYqi+C3kMWzYMI8N/v5CQjueEdE3MEZZOatDhw6YP3++1LiDAH82bg4cOPCaRmb7CmnE9Yx8i4Wr8rOf/QyJiYl6uyEEGBEREbjxxht1y19q+p4R0TcwRqhZW61WZGZmGsIXoXXxdfiQiHDTTfqtk+TrHkqBinyTDYpRphkYOHCgIQbaCK2PP56v1NRUqKrq83w8IV02PaO/qggeMUJDLhHh3nvvRVhYmK5+CIFLUlKSbtNm6/39MSoi+gZG71pKly5dMGHCBF19EAKbyMhIDBo0SJe8jfBP2Yhc9aoQ0Z+JqIiIvqqTFklE24nouPbaoc5n2UR0goiOEtGYOumDiOhL7bNVJMG2q+J0OnXtwTNlyhRZ3ERoEYqi4LbbbtMlb70rTUblWn4KXwMw9oq0hQBymLk3gBztPYgoGUA6gH7aMX8gotoREn8EkAHXilm9PZxTuAI9G6JUVUVaWppf8zdKF1WhdRk4cKAucX0Rfc9cVfSZeQeAK6dOnABgrba9FsDEOulvM3MlM58CcALATdpaueHM/C923Yl1dY4RGkGvv6gJCQkYMmSIX/OUP3/BSc+ePdGuXTu/5yvPk2eaqyidmfkcAGiv0Vp6VwD5dfY7q6V11bavTBcaQc+HduTIkQgPD/drnhKDDU6io6PRs2dPv+crou+Z1v6WebrK3Ei655MQZRDRXiLa22qeBSB6PbRms9kQDbgS7gkOLBaLLoP7pPeOZ5or+t9pIRtor0Va+lkAdadhjANQqKXHeUj3CDOvYebBntZ3DCX0emgjIyPRr18/XfKui0yYFRwQEZKSkvR2Q9BoruhvATBT254JYHOd9HQishJRT7gabL/QQkAlRJSq9dqZUecYwWAMGDBAeu0IrUpUVJTeLggaV527l4jeAjACQBQRnQXwWwDLAWwgovsBnAHwCwBg5lwi2gDgawA1AOYwc+1/9Ey4egKFAfhQM8GAjBo1ql4tm5lRXV3t1xkTnU6nxPiDiOuvvx6qqrbqympC87iq6DPzVC8fjfSy/1MAnvKQvhdAw3X2hEbxd4jHarVi+PDh9dKY2e9z+4vgBxdxcXGw2+24dOmS3q6EPPLNMjB6zB3Svn17xMfH10tzOByorKyUhlWh2URFRUmIxyCI6BsYPQZn9e3bF5GRkfXSVFXFxYsXcfDgQb/64kukZ4d/adOmjdelNgX/Ypz1+ASP+DvMMXjwYI+jJ2NjYxETE+NXX3yJhI/8i8lkQlxc3NV3FHyOPPlCPRpbzFoGuwgtIZgqDYGMiL7B8afQ2u12DBgwwG/5CaFFjx499HZBgIi+ofF3Q26nTp3QvXt3v+UnhBYy9sMYiOgbGH+HU2JjY2G32/2apxA6qKoqIUIDIKJvYPw9DUHPnj393h9fCB2ioqKkAd0AyB0wMA6Hw681ozZt2khNTPAZJpPJb89XTU2NzKfvBRF9A+N0OlFZWem3/CS0I/gSf4qw2WyWCowXRPQNDDP7NcTTqVMnv+UlhB42m81vz3NVVZUMwPOCiL7BsdlsfstL4q2CLwkLC5NnzADIHTAwzOy3v6iKouiy0IUQOkiM3RiI6Bucqqoqv+Xlz6mThdCjvLzcb5P21dTUSHjHCyL6BsafNSN/NxoLoYc/RV8E3zsi+gZGURS/Pbwmk0n66AtBgyy16R0RfYPjLyEOCwuT+fIFn1JcXOy3SkxFRYU8z14gozeuEFEJgKN6++FDogB8r7cTPiKYywZI+QKdYC9fD2Zu0A87EP7PH2XmwXo74SuIaG+wli+YywZI+QKdYC+fNyS8IwiCEEKI6AuCIIQQgSD6a/R2wMcEc/mCuWyAlC/QCfbyecTwDbmCIAhC6xEINX1BEAShlTCs6BPRWCI6SkQniGih3v40FyI6TURfEtFBItqrpUUS0XYiOq69dqizf7ZW5qNENEY/zz1DRH8moiIi+qpOWpPLQ0SDtOtygohWkUHmwfVSvsVEVKDdw4NENK7OZwFTPiLqRkSfENERIsolonlaelDcv0bKFxT3r9WoXYfVSAbABOAkgF4ALAAOAUjW269mluU0gKgr0lYAWKhtLwTwtLadrJXVCqCndg1MepfhCt9vBXADgK9aUh4AXwD4KQAC8CGANL3L1kj5FgN41MO+AVU+ALEAbtC22wE4ppUhKO5fI+ULivvXWmbUmv5NAE4w87fMXAXgbQATdPapNZkAYK22vRbAxDrpbzNzJTOfAnACrmthGJh5B4DiK5KbVB4iigUQzsz/Ytc3bF2dY3TFS/m8EVDlY+ZzzLxf2y4BcARAVwTJ/WukfN4IqPK1FkYV/a4A8uu8P4vGb56RYQB/J6J9RJShpXVm5nOA60EFEK2lB2q5m1qertr2lelG5iEiOqyFf2rDHwFbPiKKBzAQwG4E4f27onxAkN2/lmBU0fcUPwvUbkZDmfkGAGkA5hDRrY3sG0zlBryXJ9DK+UcACQBSAJwDsFJLD8jyEVFbABsBPMLMlxvb1UNaIJYvqO5fSzGq6J8F0K3O+zgAhTr50iKYuVB7LQKwCa5wzXfaX0hor0Xa7oFa7qaW56y2fWW6IWHm75jZwcxOAC/hx5BbwJWPiFS4BPFNZn5PSw6a++epfMF0/1oDo4r+HgC9iagnEVkApAPYorNPTYaI2hBRu9ptAKMBfAVXWWZqu80EsFnb3gIgnYisRNQTQG+4GpSMTpPKo4UQSogoVesVMaPOMYajVhA1JsF1D4EAK5/myysAjjDzc3U+Cor75618wXL/Wg29W5K9GYBxcLW+nwSwSG9/mlmGXnD1DjgEILe2HAA6AsgBcFx7jaxzzCKtzEdhwB4DAN6C6y9yNVw1ovubUx4Ag+H68p0E8CK0gYJ6m5fyvQ7gSwCH4RKK2EAsH4BhcIUpDgM4qNm4YLl/jZQvKO5fa5mMyBUEQQghjBreEQRBEHyAiL4gCEIIIaIvCIIQQojoC4IghBAi+oIgCCGEiL4gCEIIIaIvCIIQQojoC4IghBD/D/aEHhz5GSqvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [STAR] For creating the dataset to train the potential function\n",
    "\n",
    "e = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.4_4_0.0005_-0.5_1_anistropic_three_1.raw', dtype='float32')\n",
    "e = np.reshape(e, [58, 1200, 3000])\n",
    "\n",
    "a = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3200x1280x58.0_0_0.0005_0_1_anistropic_normal8_1.raw', dtype='float32')\n",
    "#a = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.0_1_0.0005_0.5_1_anistropic_normalmlp1_1.raw', dtype='float32')\n",
    "#a = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.0_0_0.0005_0.5_1_anistropic_normalmlp1_1.raw', dtype='float32')\n",
    "a = np.reshape(a, [58, 1280, 3200])\n",
    "\n",
    "#b = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.0_1_0.0005_0_1_anistropic_normal_1.raw', dtype='float32')\n",
    "#b = np.reshape(b, [58, 1200, 3000])\n",
    "\n",
    "#c = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3000x1200x58.0_1_0.0005_0_1_anistropic_three_1.raw', dtype='float32')\n",
    "#c = np.reshape(c, [58, 1200, 3000])\n",
    "\n",
    "d = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3200x1280x58.0_0_0.0005_-0.1_1_anistropic_three8_1.raw', dtype='float32')\n",
    "d = np.reshape(d, [58, 1280, 3200])\n",
    "\n",
    "#temp1 = a[:, 900:1150, 950:1350]\n",
    "#D2    = d[:, 900:1150, 950:1350]\n",
    "\n",
    "Y_array = d\n",
    "X_array = a\n",
    "\n",
    "\n",
    "# For getting the locations of the training data points\n",
    "\n",
    "temp               = e[27]#, 900:1150, 950:1350]\n",
    "temp[temp < 0.03] = 0\n",
    "temp[temp > 0.03] = 1\n",
    "\n",
    "#temp[temp < 0.045] = 0\n",
    "plt.imshow(temp, cmap='gray')\n",
    "\n",
    "non_zero_index = np.nonzero(temp)\n",
    "\n",
    "print(non_zero_index[0].shape, non_zero_index[1].shape)\n",
    "#print(a.shape, b.shape, e.shape)\n",
    "\n",
    "\n",
    "# Generate the samples for the Regression Model\n",
    "\n",
    "X      = []\n",
    "X1     = []\n",
    "X2     = []\n",
    "\n",
    "Y      = []\n",
    "voxels = 5\n",
    "\n",
    "\n",
    "for i in range(non_zero_index[0].shape[0]):\n",
    "    if np.random.rand() > 0.1:\n",
    "        continue\n",
    "    \n",
    "    ind_z = random.randint(15, 45)\n",
    "    ind_y = non_zero_index[0][i]\n",
    "    ind_x = non_zero_index[1][i]\n",
    "    \n",
    "    tx = X_array[ind_z-2:ind_z+3, non_zero_index[0][i]-2:non_zero_index[0][i]+3, non_zero_index[1][i]-2:non_zero_index[1][i]+3]\n",
    "    #ty = Y_array[ind_z-2:ind_z+3, non_zero_index[0][i]-2:non_zero_index[0][i]+3, non_zero_index[1][i]-2:non_zero_index[1][i]+3]\n",
    "    ty = Y_array[ind_z,           non_zero_index[0][i], non_zero_index[1][i]]\n",
    "    \n",
    "    if len(tx.flatten()) ==  voxels*voxels*voxels:\n",
    "        X.append([tx])# - X_array[ind_z, non_zero_index[0][i], non_zero_index[1][i]])\n",
    "        X1.append([np.ones([5, 5, 5])*ind_z/58.0])\n",
    "        X2.append([np.ones([5, 5, 5])*ind_y/1280.0])\n",
    "        Y.append([ty])\n",
    "\n",
    "print(len(X), len(Y), non_zero_index[0].shape[0])\n",
    "\n",
    "X  =  np.array(X)\n",
    "X1 =  np.array(X1)\n",
    "X2 =  np.array(X2)\n",
    "#X =  np.reshape(X, [X.shape[0], voxels*voxels*voxels])\n",
    "Y =  np.array(Y)\n",
    "#Y =  np.reshape(Y, [Y.shape[0], voxels*voxels*voxels])\n",
    "\n",
    "X = np.concatenate([X, X1, X2], axis=1)\n",
    "print(X.shape, Y.shape, X1.shape, X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print('classname is ', classname)\n",
    "    \n",
    "    # for every Linear layer in a model..\n",
    "    #if classname.find('Linear') != -1:\n",
    "    # apply a uniform distribution to the weights and a bias=0\n",
    "    m.weight1.data.uniform_(0.0, 0.03)\n",
    "    m.bias1.data.data.uniform_(0.0, 0.03)#.fill_(0)\n",
    "    \n",
    "    m.weight2.data.uniform_(0.0, 0.03)\n",
    "    m.bias2.data.data.uniform_(0.0, 0.03)#.fill_(0)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.001)\n",
    "\n",
    "#weights_init_uniform(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "code_folding": [
     18,
     52
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation Accuracy  0.00025939112\n",
      "2 Validation Accuracy  0.0002322952\n",
      "9 Validation Accuracy  0.00016021625\n",
      "12 Validation Accuracy  0.00015773677\n",
      "16 Validation Accuracy  0.0001531725\n",
      "26 Validation Accuracy  0.00014854637\n",
      "29 Validation Accuracy  0.00014648587\n",
      "30 Validation Accuracy  0.00014395086\n",
      "32 Validation Accuracy  0.00014350735\n",
      "34 Validation Accuracy  0.00014184168\n",
      "37 Validation Accuracy  0.00014170015\n",
      "42 Validation Accuracy  0.00013983225\n",
      "54 Validation Accuracy  0.0001379678\n",
      "55 Validation Accuracy  0.00013637583\n",
      "57 Validation Accuracy  0.00013599663\n",
      "62 Validation Accuracy  0.00013425971\n",
      "65 Validation Accuracy  0.00013413944\n",
      "71 Validation Accuracy  0.00013401444\n",
      "82 Validation Accuracy  0.0001307002\n",
      "87 Validation Accuracy  0.00012936546\n",
      "96 Validation Accuracy  0.00012846198\n",
      "102 Validation Accuracy  0.00012722783\n",
      "112 Validation Accuracy  0.00012655917\n",
      "114 Validation Accuracy  0.00012568849\n",
      "118 Validation Accuracy  0.00012553507\n",
      "134 Validation Accuracy  0.00012405393\n",
      "146 Validation Accuracy  0.00012348575\n",
      "156 Validation Accuracy  0.00012318221\n",
      "178 Validation Accuracy  0.00012273136\n",
      "180 Validation Accuracy  0.00012253004\n",
      "183 Validation Accuracy  0.00012250982\n",
      "195 Validation Accuracy  0.00012193349\n",
      "199 Validation Accuracy  0.00012107946\n",
      "201 Validation Accuracy  0.00012062149\n",
      "210 Validation Accuracy  0.00012048388\n",
      "227 Validation Accuracy  0.00012031752\n",
      "239 Validation Accuracy  0.00012008477\n",
      "258 Validation Accuracy  0.00011964652\n",
      "277 Validation Accuracy  0.00011961876\n",
      "300 Validation Accuracy  0.00011915982\n",
      "371 Validation Accuracy  0.00011914128\n",
      "396 Validation Accuracy  0.00011868984\n",
      "399 Validation Accuracy  0.0001185583\n",
      "428 Validation Accuracy  0.0001178019\n",
      "449 Validation Accuracy  0.00011775612\n",
      "509 Validation Accuracy  0.000117522446\n",
      "530 Validation Accuracy  0.00011706233\n",
      "544 Validation Accuracy  0.000117013486\n",
      "562 Validation Accuracy  0.000116686635\n",
      "571 Validation Accuracy  0.000116514\n",
      "586 Validation Accuracy  0.00011637256\n",
      "601 Validation Accuracy  0.0001162819\n",
      "609 Validation Accuracy  0.00011625818\n",
      "690 Validation Accuracy  0.00011602862\n",
      "709 Validation Accuracy  0.00011574569\n",
      "791 Validation Accuracy  0.000115725205\n",
      "910 Validation Accuracy  0.00011570232\n",
      "932 Validation Accuracy  0.00011531928\n",
      "962 Validation Accuracy  0.00011525757\n",
      "977 Validation Accuracy  0.00011505495\n",
      "990 Validation Accuracy  0.00011505268\n",
      "1054 Validation Accuracy  0.00011504374\n",
      "1083 Validation Accuracy  0.00011499417\n",
      "1109 Validation Accuracy  0.000114762246\n",
      "1126 Validation Accuracy  0.00011475501\n",
      "1146 Validation Accuracy  0.00011475322\n",
      "1255 Validation Accuracy  0.00011475242\n",
      "1289 Validation Accuracy  0.00011453909\n",
      "1536 Validation Accuracy  0.000114359005\n",
      "1634 Validation Accuracy  0.00011427482\n",
      "1855 Validation Accuracy  0.000114205846\n",
      "2061 Validation Accuracy  0.00011419926\n",
      "2233 Validation Accuracy  0.000114198985\n",
      "2356 Validation Accuracy  0.0001141921\n",
      "2677 Validation Accuracy  0.00011414075\n",
      "3188 Validation Accuracy  0.00011411856\n",
      "3276 Validation Accuracy  0.000114113864\n",
      "3520 Validation Accuracy  0.000114095244\n"
     ]
    }
   ],
   "source": [
    "# For training the Regression Model using PyTorch\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "model  = RegCNNI()\n",
    "init_weights(model)\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "#criterion          = nn.L1Loss(reduction='mean')#nn.MSELoss(reduction='mean')#nn.L1Loss(reduce=False, )#.MSELoss()\n",
    "criterion1          = nn.MSELoss(reduction='mean')\n",
    "criterion2          = nn.L1Loss(reduction='mean')\n",
    "\n",
    "optimizer_student  = optim.Adam(model.parameters(), lr=0.0001)#, weight_decay=0.01)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 100\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size]#.T\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size]\n",
    "        \n",
    "        if 0:\n",
    "            x0 = np.expand_dims(x[:, 0], 1)\n",
    "            x1 = np.expand_dims(x[:, 1], 1)\n",
    "            x2 = np.expand_dims(x[:, 2], 1)\n",
    "            \n",
    "            x0 = torch.tensor(x0, device=device).float()\n",
    "            x1 = torch.tensor(x1, device=device).float()\n",
    "            x2 = torch.tensor(x2, device=device).float()\n",
    "        else:\n",
    "            x0 = np.expand_dims(x[:, 0], 1)\n",
    "            x0 = torch.tensor(x0, device=device).float()\n",
    "        \n",
    "        if 0:\n",
    "            output =  model.forward(x0, x1, x2)\n",
    "        else:\n",
    "            output =  model.forward(x0)\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        \n",
    "        dt = np.abs(y - output)\n",
    "        dt = np.mean(dt)\n",
    "        \n",
    "        val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion1, criterion2, trainx, trainy):\n",
    "    loss_array = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size]#.T\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size]#.T\n",
    "        \n",
    "        y  = torch.tensor(y, device=device).float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if 0:\n",
    "            x0 = np.expand_dims(x[:, 0], 1)\n",
    "            x1 = np.expand_dims(x[:, 1], 1)\n",
    "            x2 = np.expand_dims(x[:, 2], 1)\n",
    "        \n",
    "            x0 = torch.tensor(x0, device=device).float()\n",
    "            x1 = torch.tensor(x1, device=device).float()\n",
    "            x2 = torch.tensor(x2, device=device).float()\n",
    "        else:\n",
    "            x0 = np.expand_dims(x[:, 0], 1)\n",
    "            x0 = torch.tensor(x0, device=device).float()\n",
    "        \n",
    "        if 0:\n",
    "            output = model.forward(x0, x1, x2)\n",
    "        else:\n",
    "            output = model.forward(x0)\n",
    "        \n",
    "        loss1   = criterion1(output , y)\n",
    "        loss2   = criterion2(output , y)\n",
    "        loss    = loss2#loss1+ loss2\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "prev_min = 1000\n",
    "\n",
    "for i in range(10000):\n",
    "    index = np.random.permutation(len(X_train))\n",
    "    \n",
    "    X_train = X_train[index]\n",
    "    y_train = y_train[index]\n",
    "    \n",
    "    train_model(model, 32, optimizer_student, criterion1, criterion2, X_train, y_train)\n",
    "    result = evaluate_result(model, X_test, y_test)\n",
    "    \n",
    "    if np.mean(result) < prev_min:\n",
    "        prev_min = np.mean(result)\n",
    "        print(i, 'Validation Accuracy ', np.mean(result))\n",
    "        torch.save(model.state_dict(), 'new_modelI_three_layer_l1loss.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Code to Predict results\n",
    "\n",
    "# 8  Filters: 944 Validation Accuracy  0.00019152784\n",
    "# 16 Filters: 191 Validation Accuracy  0.00016972028\n",
    "\n",
    "\n",
    "def predict_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    result       = []\n",
    "    ground_truth = []\n",
    "    inputx       = []\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size]#.T\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size]#.T\n",
    "        \n",
    "        x = np.expand_dims(x[:, 0], 1)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = output.data.cpu().numpy()\n",
    "        \n",
    "        inputx.append(x.data.cpu().numpy())\n",
    "        result.append(output)\n",
    "        ground_truth.append(y)\n",
    "    \n",
    "    return inputx, result, ground_truth\n",
    "\n",
    "inputx, result, ground_truth = predict_result(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03314869]\n",
      "[0.03311555]\n",
      "0.032477982\n"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, len(ground_truth)-1)\n",
    "\n",
    "print(ground_truth[index].flatten()[:10])\n",
    "print(result[index].flatten()[:10])\n",
    "ix = np.reshape(inputx[index], [5, 5, 5])\n",
    "\n",
    "print(ix[2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Result Comparison\n",
    "\n",
    "# 1500  Validation Accuracy  0.005796282 -> 500       (Per voxel)\n",
    "# 1500  Validation Accuracy  0.005799574 -> 125       (Per voxel)\n",
    "# 1500  Validation Accuracy  0.006036232 ->  25       (Per voxel)\n",
    "# 10000 Validation Accuracy  0.00512195  -> 500       (Per voxel) \n",
    "# 23427 Validation Accuracy  0.00366580  -> 125       (Per voxel)\n",
    "# 1639  Validation Accuracy  0.00320234  -> 125 x 125 (Per voxel)\n",
    "# 10100 Validation Accuracy  0.00266177  -> 125 x 125 (Per voxel)\n",
    "\n",
    "# conv_prior_1-out_8-filter_0.0001368996_loss.pt -> 16 filter with padding -> all out\n",
    "# 1500  Validation Accuracy  0.00013689  -> 125       (All voxels)\n",
    "\n",
    "# 2501  Validation Accuracy  0.00012629  -> 125\n",
    "\n",
    "\n",
    "# conv_prior_1-out_16-filter_loss.pt\n",
    "# 3196 Validation Accuracy  0.00012279117\n",
    "\n",
    "# conv_prior_1-out_8-filter_loss.pt\n",
    "# 4542 Validation Accuracy  0.00012307017\n",
    "\n",
    "\n",
    "# conv_prior_1-out_16-filter_loss_x_x1_x2.pt\n",
    "# 5416 Validation Accuracy  0.00012176224\n",
    "\n",
    "\n",
    "\n",
    "# Compare with and without coordinate\n",
    "# conv_prior_1-out_64-filter_loss_x_x1_x2.pt\n",
    "# 2384 Validation Accuracy  0.000119205004\n",
    "# conv_prior_1-out_64-filter_loss.pt (3 times filter)\n",
    "# 3114 Validation Accuracy  0.000119580625\n",
    "# conv_prior_1-out_128-filter_loss_x0_x1_x2.pt\n",
    "# 3411 Validation Accuracy  0.00011920285\n",
    "# conv_prior_1-out_16-filter_loss.pt\n",
    "# 2667 Validation Accuracy  0.00011919564\n",
    "# conv_prior_1-out_16-filter_loss_max_operation.pt\n",
    "# 2606 Validation Accuracy  0.00011918982\n",
    "# conv_prior_1-out_16-filter_loss_max_operation_mseloss.pt\n",
    "# 746 Validation Accuracy  0.00012135917 (trained for 7000 epochs)\n",
    "# conv_prior_1-out_16-filter_loss_max_operation_mseloss_l1loss.pt\n",
    "# 1493 Validation Accuracy  0.00011918354 (trained for 6907 epochs)\n",
    "\n",
    "\n",
    "# Compare for all 125 voxels\n",
    "# conv_prior_125-out_16-filter_loss_l1loss.pt\n",
    "# 3400 Validation Accuracy  0.00014144198 (trained for 10000 epochs)\n",
    "# conv_prior_125-out_16-filter_loss_mseloss.pt\n",
    "# 5049 Validation Accuracy  0.00013886021 (trained for 10000 epochs)\n",
    "\n",
    "\n",
    "# These results are together\n",
    "# conv_prior_125-out_16-one-layer-filter_loss_l1loss.pt\n",
    "# 2689 Validation Accuracy  0.00012106062  (trained for 10000 epochs)\n",
    "# conv_prior_125-out_two-layer-sum-in-between-8-filter_loss_l1loss.pt\n",
    "# 6191 Validation Accuracy 0.00011660263  (trained for 7084 epochs)\n",
    "# conv_prior_125-out_16-two-layer-filter_loss_l1loss.pt\n",
    "# 587 Validation Accuracy  0.0001153327   (trained for 2200 epochs)\n",
    "# conv_prior_125-out_three-layer-sum-in-between-8-filter_loss_l1loss.pt\n",
    "# 1926 Validation Accuracy  0.00011476242 (trained for 7185 epochs)\n",
    "# conv_prior_125-out_16-three-layer-filter_loss_l1loss.pt\n",
    "# 1211 Validation Accuracy  0.000114355775 (trained for 3200 epochs)\n",
    "# conv_prior_125-out_three-layer-sum-in-between-filter_loss_l1loss.pt\n",
    "# 5247 Validation Accuracy  0.00011456212  (trained for 8225 epochs)\n",
    "# conv_prior_125-out_four-layer-sum-in-between-filter_loss_l1loss.pt\n",
    "# 1312 Validation Accuracy  0.000114336646 (trained for 10000 epochs)\n",
    "# conv_prior_125-out_four-layer-sum-in-between-8-filter_loss_l1loss.pt \n",
    "# 1719 Validation Accuracy  0.00011444714  (trained for 9500 epochs)\n",
    "# conv_prior_125-out_five-layer-sum-in-between-4-filter_loss_l1loss.pt\n",
    "# 2283 Validation Accuracy  0.000115051    (trained for 7047 epochs)\n",
    "# new_modelI_two_layer_l1loss.pt\n",
    "# 3520 Validation Accuracy  0.000114095244 (trained for 9999 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64165, 125) (21389, 125) (64165,) (21389,)\n"
     ]
    }
   ],
   "source": [
    "# For training the Regression Model\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X, y = make_regression(n_samples=200, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "#X_train = X_train*100\n",
    "#X_test  = X_test*100\n",
    "#y_train = y_train*100\n",
    "#y_test  = y_test*100\n",
    "\n",
    "regr   = MLPRegressor(activation='tanh', \n",
    "                      random_state=0, \n",
    "                      solver='adam',\n",
    "                      learning_rate_init=0.0001,\n",
    "                      #learning_rate='adaptive', \n",
    "                      #hidden_layer_sizes=(125,25,),\n",
    "                      hidden_layer_sizes=(125,),\n",
    "                      #verbose=True,\n",
    "                      tol=0.00001,\n",
    "                      alpha=0.0001, max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "result = regr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('Score is ', r2_score(result, y_test))\n",
    "#print(result.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "error = result - y_test\n",
    "error = np.square(error)\n",
    "print('Error is ', np.mean(error)*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81aab3d5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Understanding Numba Code\n",
    "\n",
    "import numpy\n",
    "from numba import cuda\n",
    "\n",
    "def escape_time(p, maxtime):\n",
    "    \"\"\"Perform the Mandelbrot iteration until it's clear that p diverges\n",
    "    or the maximum number of iterations has been reached.\n",
    "    \"\"\"\n",
    "    z = 0j\n",
    "    for i in range(maxtime):\n",
    "        z = z ** 2 + p\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxtime\n",
    "\n",
    "escape_time_gpu = cuda.jit(device=True)(escape_time)\n",
    "\n",
    "@cuda.jit\n",
    "def mandelbrot_gpu(M, real_min, real_max, imag_min, imag_max):\n",
    "    \"\"\"Calculate the Mandelbrot set on the GPU.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M : numpy.ndarray\n",
    "        a two-dimensional integer array that will contain the \n",
    "        escape times for each point.\n",
    "    real_min: float\n",
    "        minimum value on the real axis\n",
    "    real_max: float\n",
    "        maximum value on the real axis\n",
    "    imag_min: float\n",
    "        minimum value on the imaginary axis\n",
    "    imag_max: float\n",
    "        maximum value on the imaginary axis\n",
    "    \"\"\"\n",
    "    ny, nx = M.shape\n",
    "    i, j = cuda.grid(2)\n",
    "    \n",
    "    if i < ny and j < nx:\n",
    "        dx = (real_max - real_min) / nx\n",
    "        dy = (imag_max - imag_min) / ny\n",
    "        p = real_min + dx * i + (imag_min + dy * j) * 1j\n",
    "        M[i, j] = j#escape_time_gpu(p, 20)\n",
    "        \n",
    "        \n",
    "M = numpy.zeros((1024, 1024), dtype=numpy.int32)\n",
    "block = (32, 32)\n",
    "grid = (M.shape[0] // block[0] if M.shape[0] % block[0] == 0 \n",
    "            else M.shape[0] // block[0] + 1,\n",
    "        int(M.shape[0] // block[1] if M.shape[1] % block[1] == 0 \n",
    "            else M.shape[1] // block[1] + 1))\n",
    "\n",
    "\n",
    "mandelbrot_gpu[grid, block](M, -2.0, 2.0, -1.6, 1.6)\n",
    "\n",
    "plt.imshow(M, interpolation=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 125)\n",
      "(1, 25) (25, 1) (1,)\n",
      "Predicted Value From Model is  [[0.02117195]]\n",
      "Ground Truth Value is          0.021088189\n",
      "0.0209226\n"
     ]
    }
   ],
   "source": [
    "# Predicted Value from Regression Model is\n",
    "\n",
    "a = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3200x1280x58.0_0_0.0005_0_1_anistropic_normal8_1.raw', dtype='float32')\n",
    "a = np.reshape(a, [58, 1280, 3200])\n",
    "\n",
    "d = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3200x1280x58.0_0_0.0005_-0.1_1_anistropic_three8_1.raw', dtype='float32')\n",
    "d = np.reshape(d, [58, 1280, 3200])\n",
    "\n",
    "Y_array = d\n",
    "X_array = a\n",
    "\n",
    "ind_z = 43\n",
    "ind_y = 1000\n",
    "ind_x = 2200\n",
    "\n",
    "tx = X_array[ind_z-2:ind_z+3, ind_y-2:ind_y+3, ind_x-2:ind_x+3]\n",
    "ty = Y_array[ind_z,           ind_y, ind_x]\n",
    "\n",
    "X_test = np.array([tx.flatten()])\n",
    "print(X_test.shape)\n",
    "\n",
    "tp1 = np.dot(X_test, regr.coefs_[0])\n",
    "tp2 = tp1 + regr.intercepts_[0]\n",
    "tp3 = np.tanh(tp2)\n",
    "\n",
    "print(tp3.shape, regr.coefs_[1].shape, regr.intercepts_[1].shape)\n",
    "\n",
    "tp4 = np.dot(tp3, regr.coefs_[1])\n",
    "tp4 = tp4 + regr.intercepts_[1]\n",
    "\n",
    "print('Predicted Value From Model is ', tp4)\n",
    "print('Ground Truth Value is         ', ty)\n",
    "print(X_array[ind_z,           ind_y, ind_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.fromfile('/media/pranjal/BackupPlus/REAL-DBT-PROJECTIONS/RECONS-HUBER/xiaoyu_data-LE-L-CC_3200x1280x58.0_0_0.0005_0_1_anistropic_result8_a_1.raw', dtype='float32')\n",
    "e = np.reshape(e, [58, 1280, 3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039948188\n",
      "0.04013158\n",
      "0.00018339232\n"
     ]
    }
   ],
   "source": [
    "print(e[27, 1152, 1315])\n",
    "print(d[27, 1152, 1315])\n",
    "print(d[27, 1152, 1315] - e[27, 1152, 1315])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import njit, prange\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002435831882374 0.5002436\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of the volume\n",
    "IMGSIZx = 3200\n",
    "IMGSIZy = 1280\n",
    "IMGSIZz = 58\n",
    "\n",
    "# Cuda Kernel to calculate mean of neighboring voxels for each voxel\n",
    "@cuda.jit(debug=True)\n",
    "def calculate_mean(outbuf, inbuf):\n",
    "    # Calculate the index of the voxel being considered\n",
    "    \n",
    "    ind_x, ind_y, ind_z = cuda.grid(3)\n",
    "    #ind_x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    #ind_y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "    #ind_z = cuda.blockIdx.z * cuda.blockDim.z + cuda.threadIdx.z\n",
    "    \n",
    "    if ind_x < 0 or  ind_y < 0 or  ind_z < 0:\n",
    "        return\n",
    "    \n",
    "    if ind_x > IMGSIZx-1 or ind_y > IMGSIZy-1 or ind_z > IMGSIZz-1:\n",
    "        return\n",
    "    \n",
    "    sum1    = 0.0\n",
    "    counter = 0\n",
    "    for ind_nr_z in range(ind_z-2, ind_z+3):\n",
    "        for ind_nr_y in range(ind_y-2, ind_y+3):\n",
    "            for ind_nr_x in range(ind_x-2, ind_x+3):\n",
    "                if ind_nr_x<0 or ind_nr_y<0 or ind_nr_z<0:\n",
    "                    continue\n",
    "                \n",
    "                if ind_nr_x>(IMGSIZx-1) or ind_nr_y>(IMGSIZy-1) or ind_nr_z>(IMGSIZz-1):\n",
    "                    continue\n",
    "                \n",
    "                sum1    = sum1 + inbuf[ind_nr_z, ind_nr_y, ind_nr_x]\n",
    "                counter = counter+1\n",
    "    \n",
    "    outbuf[ind_z, ind_y, ind_x] = sum1/counter\n",
    "    return\n",
    "\n",
    "\n",
    "# Create random input matrix for which to calculate voxel wise mean\n",
    "inbuf = np.random.rand(58, 1280, 3200)\n",
    "# Create output matrix to store the output \n",
    "outbuf  = np.zeros((58, 1280, 3200), np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Code to Launch the Cuda kernel in Numba\n",
    "# 8*400 = 3200 = IMGSIZx\n",
    "# 8*160 = 1280 = IMGSIZy\n",
    "# 2*29  = 58   = IMGSIZz\n",
    "THREADS_PER_BLOCK = (8, 8, 2)\n",
    "BLOCKS_PER_GRID   = (400, 160, 29)\n",
    "calculate_mean[BLOCKS_PER_GRID, THREADS_PER_BLOCK](outbuf, inbuf)\n",
    "cuda.synchronize()\n",
    "\n",
    "\n",
    "\n",
    "# Checking result for a random voxel (c_z, c_y, c_x)\n",
    "c_x = random.randint(0, IMGSIZx)\n",
    "c_y = random.randint(0, IMGSIZy)\n",
    "c_z = random.randint(0, IMGSIZz)\n",
    "result_manual = np.mean(inbuf[c_z-2:c_z+3,c_y-2:c_y+3,c_x-2:c_x+3])\n",
    "result_cuda   = outbuf[c_z, c_y, c_x]\n",
    "print(result_manual, result_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4530233603179261 0.45302337\n"
     ]
    }
   ],
   "source": [
    "# Checking result for a random voxel (c_z, c_y, c_x)\n",
    "c_x = random.randint(0, IMGSIZx)\n",
    "c_y = random.randint(0, IMGSIZy)\n",
    "c_z = random.randint(0, IMGSIZz)\n",
    "result_manual = np.mean(inbuf[c_z-2:c_z+3,c_y-2:c_y+3,c_x-2:c_x+3])\n",
    "result_cuda   = outbuf[c_z, c_y, c_x]\n",
    "print(result_manual, result_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 542 22\n"
     ]
    }
   ],
   "source": [
    "print(c_x, c_y, c_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_manual = np.mean(inbuf[c_z-2:c_z+3,c_y-2:c_y+3,c_x-2:c_x+3].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4530233603179261\n"
     ]
    }
   ],
   "source": [
    "print(result_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
