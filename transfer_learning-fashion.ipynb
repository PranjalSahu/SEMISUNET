{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] All the Imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import csv\n",
    "from scipy import ndimage, misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "code_folding": [
     0,
     2,
     9,
     29,
     53
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Attribute and Category Model\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "class MyAttrCateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model    = models.resnet18(pretrained=True)\n",
    "        self.model.fc = Identity()\n",
    "        \n",
    "        #self.attr_layer = nn.Sequential(nn.Linear(512, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 26, bias=False)\n",
    "        #                               )\n",
    "        \n",
    "        #self.cate_layer = nn.Sequential(nn.Linear(512, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 50, bias=False))\n",
    "        self.attr_layer = nn.Linear(512, 26)\n",
    "        self.cate_layer = nn.Linear(512, 50)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1     = self.model(x)\n",
    "        attr_out = self.attr_layer(out1)\n",
    "        cate_out = self.cate_layer(out1)\n",
    "        #cate_out = torch.flatten(cate_out)\n",
    "        return attr_out, cate_out\n",
    "\n",
    "class MyAttrCateModel50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model    = models.resnet50(pretrained=True)\n",
    "        self.model.fc = Identity()\n",
    "        \n",
    "        #self.attr_layer = nn.Sequential(nn.Linear(2048, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 26, bias=False))\n",
    "        #self.cate_layer = nn.Sequential(nn.Linear(2048, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 50, bias=False))\n",
    "        self.attr_layer = nn.Linear(2048, 201)\n",
    "        self.cate_layer = nn.Linear(2048, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1     = self.model(x)\n",
    "        attr_out = self.attr_layer(out1)\n",
    "        cate_out = self.cate_layer(out1)\n",
    "        #cate_out = torch.flatten(cate_out)\n",
    "        return attr_out, cate_out\n",
    "#model  = MyAttrCateModel()\n",
    "# x      = torch.randn(1, 3, 224, 224)\n",
    "# output = model(x)\n",
    "# print(output[0].shape, output[1].shape)\n",
    "\n",
    "#print(model)\n",
    "#model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEMP Code to Read the BP images\n",
    "\n",
    "images = glob.glob('/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/**/*.png', recursive=True)\n",
    "#print(images)\n",
    "filtered_images  = []\n",
    "counter          = 0\n",
    "\n",
    "for m in images:\n",
    "    #if 'Top' in m or 'Bottom' in m :\n",
    "        #continue\n",
    "    filtered_images.append(m[64:])\n",
    "valid_dataset = \"\\n\".join(filtered_images)\n",
    "\n",
    "f = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/newval.txt\", \"w\")\n",
    "f.write(valid_dataset)\n",
    "f.close()\n",
    "\n",
    "#print(filtered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "code_folding": [
     0,
     15,
     78
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Data Loaders for Fashion Dataset\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class AttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r')\n",
    "        self.img_list = [x.strip() for x in fp]\n",
    "\n",
    "        # read attribute labels and category annotations\n",
    "        self.labels = np.loadtxt(label_file, dtype=np.float32)\n",
    "\n",
    "        # read categories\n",
    "        self.categories = []\n",
    "        catefn = open(cate_file).readlines()\n",
    "        for i, line in enumerate(catefn):\n",
    "            self.categories.append(line.strip('\\n'))\n",
    "\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        print(os.path.join(self.img_path, self.img_list[idx]))\n",
    "        img = Image.open(os.path.join(self.img_path,\n",
    "                                      self.img_list[idx])).convert('RGB')\n",
    "\n",
    "        width, height  = img.size\n",
    "        print('Original Image size is ', width, height)\n",
    "        # Very Important\n",
    "        # For getting the cropped and resized region of interest image\n",
    "        img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "        img   = self.transform(img)\n",
    "\n",
    "        label    = torch.from_numpy(self.labels[idx])\n",
    "        cate     = torch.LongTensor([int(self.categories[idx]) - 1])\n",
    "\n",
    "        data = {'img': img, 'attr': label, 'cate': cate}\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "\n",
    "class ValidAttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r').read().split('\\n')\n",
    "        self.img_list = fp#[x.strip() for x in fp]\n",
    "        \n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        try:\n",
    "            #print(os.path.join(self.img_path, self.img_list[idx]))\n",
    "            img = Image.open(os.path.join(self.img_path,\n",
    "                                          self.img_list[idx])).convert('RGB')\n",
    "\n",
    "            width, height  = img.size\n",
    "            img.resize((width//2, height//2))\n",
    "            width, height  = img.size\n",
    "\n",
    "            #print('Original Image size is ', width, height)\n",
    "            # Very Important\n",
    "            # For getting the cropped and resized region of interest image\n",
    "            img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "            img   = self.transform(img)\n",
    "\n",
    "            #label    = torch.from_numpy(self.labels[idx])\n",
    "            #cate     = torch.LongTensor([int(self.categories[idx]) - 1])\n",
    "\n",
    "            data = {'img': img, 'imgpath': os.path.join(self.img_path,\n",
    "                                          self.img_list[idx])}#, 'attr': label, 'cate': cate}\n",
    "            return data\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "img_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/\"\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "label_file = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_attr.txt\"\n",
    "cate_file  = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_cate.txt\"\n",
    "img_size   = [224, 224]\n",
    "#img_size   = [256, 256]\n",
    "\n",
    "landmark_file = None\n",
    "bbox_file     = None\n",
    "\n",
    "d1 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val.txt\"\n",
    "label_file = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val_attr.txt\"\n",
    "cate_file  = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val_cate.txt\"\n",
    "\n",
    "d2 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "img_path   = \"/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/\"\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/newval.txt\"\n",
    "\n",
    "d3 = ValidAttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_dataloader(dataset, batch_size, shuffle):\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=False)\n",
    "    return data_loader\n",
    "\n",
    "train_data_loader = build_dataloader(d1, 4, True)\n",
    "val_data_loader   = build_dataloader(d2, 4, False)\n",
    "\n",
    "model  = MyAttrCateModel50()\n",
    "#model  = MyAttrCateModel()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "params       = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer    = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0001)\n",
    "lr_scheduler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "code_folding": [
     111
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Data Loaders for New Fashion Dataset\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from os import path\n",
    "\n",
    "class AttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r').read().split('\\n')\n",
    "        \n",
    "        self.img_list   = []\n",
    "        self.labels     = []\n",
    "        self.categories = []\n",
    "        \n",
    "        self.all_categories = ['accessories', 'bottoms' ,'dresses', 'footwear' ,'outerwear', 'tops']\n",
    "        self.all_labels     = ['totebag', 'beige', 'black', 'brown', 'darkred', 'green', 'grey', 'lightpink', 'multicolor', 'offwhite', 'orange', 'pink', 'purple', 'yellow', 'clutchbag', 'silver', 'white', 'neckscarf', 'golden', 'lightblue', 'lightgreen', 'navyblue', 'red', 'redfloral', 'layerednecklace', 'cream', 'ecru', 'hoops', 'rosegold', 'crossbody', 'blue', 'mustard', 'skinnybelt', 'navy', 'tan', 'statementbelt', 'burgundy', 'camel', 'darkbrown', 'chainnecklace', 'statementnecklace', 'teardropearrings', 'strawtote', 'camelbrown', 'scrunchie', 'blackwhite', 'headband', 'olive', 'crushbag', 'beltbag', 'blackvirgin', 'bucketbag', 'backpack', 'khakigreen', 'leopard', 'rosepink', 'minibag', 'socks', 'beanie', 'buckethat', 'fedora', 'ivory', 'olivegreen', 'jeans', 'long', 'lightdenim', 'mediumdenim', 'darkdenim', 'regular', 'lightblack', 'ankle', 'frayed', 'boyfriend', 'bootcut', 'distressed', 'skinny', 'straight', 'wide', 'highrise', 'midrise', 'lowrise', 'pant', 'blackcheck', 'maroon', 'greycheck', 'darkgrey', 'browncheck', 'greyblue', 'legging', 'plum', 'skyblue', 'loose', 'metallicblack', 'bluefloral', 'trouser', 'darkgreen', 'wideleg', 'pinkfloral', 'darkdenimblue', 'skirts', 'aline', 'high', 'denimblue', 'oatmeal', 'asymmetrical', 'brownfloral', 'mettalicpink', 'blackfloral', 'greyfloral', 'pleated', 'blush', 'slit', 'tulle', 'wrap', 'creamfloral', 'maxi', 'greenfloral', 'yellowfloral', 'mini', 'taupe', 'khaki', 'knee', 'midi', 'tank', 'sleeveless', 'dustypink', 'short', 'shortsleeves', 'puff', 'longsleeves', 'whitefloral', 'lightpurple', 'tflength', 'oneshoulder', 'strapless', 'turtleneck', 'lightgrey', 'fitandflare', 'openback', 'lightskyblue', 'ruched', 'slip', 'sweater', 'tea', 'midcalfboots', 'kneehighboots', 'pumps', 'combatboots', 'chelseaboots', 'flats', 'wedges', 'mules', 'darkblue', 'platformsandals', 'blockheelsandals', 'classicsneakers', 'retrorunning', 'lowtopsneakers', 'hightopsneakers', 'crocs', 'slides', 'turquoice', 'slippers', 'platformsneakers', 'slingbacksandals', 'loafers', 'booties', 'blazer', 'collarless', 'doublebreasted', 'onebutton', 'oversized', 'anthracitegrey', 'singlebreasted', 'midnightblue', 'coat', 'peacoat', 'button', 'quilted', 'nobutton', 'robe', 'trench', 'teddy', 'jacket', 'denim', 'moto', 'puffer', 'withoutsleeves', 'shearling', 'crewneck', 'tight', 'collared', 'cardigan', 'vneck', 'crop', 'square', 'tshirt', 'mock', 'blouse', 'smocked', 'lonsleeves']\n",
    "        \n",
    "        for t in fp:\n",
    "            self.img_list.append(t.split(',')[0])\n",
    "            self.categories.append(self.all_categories.index(t.split(',')[1]))\n",
    "            temp = np.zeros(len(self.all_labels))\n",
    "            \n",
    "            for k in t.split(',')[2:]:\n",
    "                if k in self.all_labels:\n",
    "                    temp[self.all_labels.index(k)] = 1\n",
    "                    #temp.append(self.all_labels.index(k))\n",
    "            self.labels.append(temp)\n",
    "        \n",
    "        #self.img_list = [x.strip() for x in fp]\n",
    "\n",
    "        # read attribute labels and category annotations\n",
    "        #self.labels = np.loadtxt(label_file, dtype=np.float32)\n",
    "\n",
    "        # read categories\n",
    "        #self.categories = []\n",
    "        #catefn = open(cate_file).readlines()\n",
    "        #for i, line in enumerate(catefn):\n",
    "        #    self.categories.append(line.strip('\\n'))\n",
    "\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        #print(self.img_list[idx])\n",
    "        if path.exists(self.img_list[idx].replace('.jpg', '.JPG')):\n",
    "            img = Image.open(self.img_list[idx].replace('.jpg', '.JPG')).convert('RGB')\n",
    "            width, height  = img.size\n",
    "            new_width  = width//4\n",
    "            new_height = height//4\n",
    "            \n",
    "            img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "            \n",
    "            #elif path.exists(self.img_list[idx].replace('.jpg', ''))\n",
    "            \n",
    "            #print('Original Image size is ', width, height)\n",
    "            # Very Important\n",
    "            # For getting the cropped and resized region of interest image\n",
    "            img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "            #print('Downsampled Image size is ', width, height)\n",
    "            img   = self.transform(img)\n",
    "            \n",
    "            #print('Original Image size is ', width, height)\n",
    "            \n",
    "            label    = torch.from_numpy(self.labels[idx])\n",
    "            cate     = torch.LongTensor([int(self.categories[idx])])\n",
    "            \n",
    "            #print('Label is ', self.labels[idx])\n",
    "            #print('Cate is ',  cate)\n",
    "            \n",
    "            data = {'img': img, 'attr': label, 'cate': cate}\n",
    "            return data\n",
    "        #else:\n",
    "        #    return pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "\n",
    "class ValidAttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r').read().split('\\n')\n",
    "        self.img_list = fp#[x.strip() for x in fp]\n",
    "        \n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        try:\n",
    "            #print(os.path.join(self.img_path, self.img_list[idx]))\n",
    "            img = Image.open(os.path.join(self.img_path,\n",
    "                                          self.img_list[idx])).convert('RGB')\n",
    "\n",
    "            width, height  = img.size\n",
    "            img.resize((width//2, height//2))\n",
    "            width, height  = img.size\n",
    "\n",
    "            #print('Original Image size is ', width, height)\n",
    "            # Very Important\n",
    "            # For getting the cropped and resized region of interest image\n",
    "            img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "            img   = self.transform(img)\n",
    "\n",
    "            #label    = torch.from_numpy(self.labels[idx])\n",
    "            #cate     = torch.LongTensor([int(self.categories[idx]) - 1])\n",
    "\n",
    "            data = {'img': img, 'imgpath': os.path.join(self.img_path,\n",
    "                                          self.img_list[idx])}#, 'attr': label, 'cate': cate}\n",
    "            return data\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "img_path   = \"\"\n",
    "\n",
    "img_file   = \"newdataset_train.txt\"\n",
    "label_file = \"\"\n",
    "cate_file  = \"\"\n",
    "img_size   = [224, 224]\n",
    "\n",
    "landmark_file = None\n",
    "bbox_file     = None\n",
    "\n",
    "d1 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "img_file   = \"newdataset_val.txt\"\n",
    "label_file = \"\"\n",
    "cate_file  = \"\"\n",
    "\n",
    "d2 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "#img_path   = \"/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/\"\n",
    "#img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/newval.txt\"\n",
    "\n",
    "#d3 = ValidAttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_dataloader(dataset, batch_size, shuffle):\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=False)\n",
    "    return data_loader\n",
    "\n",
    "train_data_loader = build_dataloader(d1, 4, True)\n",
    "val_data_loader   = build_dataloader(d2, 4, False)\n",
    "\n",
    "model  = MyAttrCateModel50()\n",
    "#model  = MyAttrCateModel()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "params       = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer    = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0001)\n",
    "lr_scheduler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Some garbage code to check the results\n",
    "\n",
    "#img_file   = \"newdataset_train.txt\"\n",
    "img_file   = \"newdataset.txt\"\n",
    "fp         = open(img_file, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "# read img names\n",
    "#fp = open(img_file, 'r').read().split('\\n')\n",
    "\n",
    "h = {}\n",
    "\n",
    "img_list = []\n",
    "labels   = []\n",
    "categories = []\n",
    "\n",
    "for t in fp:\n",
    "    #print(t)\n",
    "    #img_list.append(t.split(',')[0])\n",
    "    categories.append(str(t.split(',')[1]))\n",
    "    for k in t.split(',')[2:]:\n",
    "        if k in h:\n",
    "            h[k] = h[k]+1\n",
    "        else:\n",
    "            h[k] = 0\n",
    "        #labels.append(str(k))\n",
    "\n",
    "#print(\",\".join(np.unique(labels)))\n",
    "#print(np.unique(categories))\n",
    "\n",
    "filtered_h = []\n",
    "for k in h:\n",
    "    if h[k] >= 5:\n",
    "        filtered_h.append(k)\n",
    "\n",
    "print(filtered_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anorak' 'Blazer' 'Blouse' 'Bomber' 'Button-Down' 'Cardigan' 'Flannel'\n",
      " 'Halter' 'Henley' 'Hoodie' 'Jacket' 'Jersey' 'Parka' 'Peacoat' 'Poncho'\n",
      " 'Sweater' 'Tank' 'Tee' 'Top' 'Turtleneck' 'Capris' 'Chinos' 'Culottes'\n",
      " 'Cutoffs' 'Gauchos' 'Jeans' 'Jeggings' 'Jodhpurs' 'Joggers' 'Leggings'\n",
      " 'Sarong' 'Shorts' 'Skirt' 'Sweatpants' 'Sweatshorts' 'Trunks' 'Caftan'\n",
      " 'Cape' 'Coat' 'Coverup' 'Dress' 'Jumpsuit' 'Kaftan' 'Kimono' 'Nightdress'\n",
      " 'Onesie' 'Robe' 'Romper' 'Shirtdress' 'Sundress']\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For loading the labels and categories etc.\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "print(cate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some Garbage Code\n",
    "\n",
    "index = random.randint(0, len(d3))\n",
    "temp  = d3[index]\n",
    "#print(temp['cate'])\n",
    "\n",
    "#attr_index = np.nonzero(temp['attr'].data.numpy())[0]#temp['attr'].data.numpy().astype('int')\n",
    "#cate_index = temp['cate'].data.numpy()\n",
    "#print(attr_index)\n",
    "#print(cate_index)\n",
    "#.astype('int')\n",
    "\n",
    "temp = temp['img'].data.numpy()\n",
    "#print(temp.shape)\n",
    "temp = np.moveaxis(temp, 0, -1)\n",
    "#print(temp.shape)\n",
    "\n",
    "plt.imshow(temp)\n",
    "#print(attr_index)\n",
    "#print(cate_index)\n",
    "\n",
    "#print(cate_list[cate_index])\n",
    "#print(attr_list[attr_index])\n",
    "\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  1000 0.9232637988000989\n",
      "Epoch >>  0 0.9232637988000989 0.0627569079667213 0.8605068908333778\n",
      "Saving the model  0.9232637988000989 0.8758175215058676\n",
      "Epoch >>  1 0.8758175215058676 0.06124019580415359 0.8145773257017136\n",
      "Saving the model  0.8758175215058676 0.8400856482920053\n",
      "Epoch >>  2 0.8400856482920053 0.06041263331840409 0.7796730149736008\n",
      "Saving the model  0.8400856482920053 0.8062075332953186\n",
      "Epoch >>  3 0.8062075332953186 0.05945169513584579 0.7467558381594718\n",
      "Saving the model  0.8062075332953186 0.7870475353319275\n",
      "Epoch >>  4 0.7870475353319275 0.058722007041058795 0.7283255282908678\n",
      "Saving the model  0.7870475353319275 0.7568802406556282\n",
      "Epoch >>  5 0.7568802406556282 0.058022297446117525 0.698857943209509\n",
      "Saving the model  0.7568802406556282 0.7323031041190121\n",
      "Epoch >>  6 0.7323031041190121 0.05734317256713264 0.674959931551878\n",
      "Saving the model  0.7323031041190121 0.7116779226097771\n",
      "Epoch >>  7 0.7116779226097771 0.05679359039715583 0.6548843322126194\n",
      "Saving the model  0.7116779226097771 0.6924595698621266\n",
      "Epoch >>  8 0.6924595698621266 0.05624420831664124 0.6362153615454833\n",
      "Saving the model  0.6924595698621266 0.6745066819148027\n",
      "Epoch >>  9 0.6745066819148027 0.05568016139397912 0.6188265205208212\n",
      "Saving the model  0.6745066819148027 0.6560545117503643\n",
      "Epoch >>  10 0.6560545117503643 0.05521359254833773 0.6008409192020243\n",
      "Saving the model  0.6560545117503643 0.6455390689831663\n",
      "Epoch >>  11 0.6455390689831663 0.054945580687601595 0.5905934882955626\n",
      "Saving the model  0.6455390689831663 0.6310893564645157\n",
      "Epoch >>  12 0.6310893564645157 0.05454103355779659 0.5765483229067176\n",
      "Saving the model  0.6310893564645157 0.6212181871075558\n",
      "Epoch >>  13 0.6212181871075558 0.05415346271662789 0.5670647243909271\n",
      "Saving the model  0.6212181871075558 0.6118758789869497\n",
      "Epoch >>  14 0.6118758789869497 0.05378691063832179 0.5580889683486273\n",
      "Saving the model  0.6118758789869497 0.6039467176548278\n",
      "Epoch >>  15 0.6039467176548278 0.05346269649698636 0.5504840211578412\n",
      "Saving the model  0.6039467176548278 0.590695470907442\n",
      "Epoch >>  16 0.590695470907442 0.05309056468569978 0.5376049062217422\n",
      "Saving the model  0.590695470907442 0.5794630373476308\n",
      "Epoch >>  17 0.5794630373476308 0.05281934300479292 0.5266436943428384\n",
      "Saving the model  0.5794630373476308 0.5701340827955133\n",
      "Epoch >>  18 0.5701340827955133 0.0525344692383356 0.5175996135571775\n",
      "Saving the model  0.5701340827955133 0.5623366730937246\n",
      "Epoch >>  19 0.5623366730937246 0.052264331311194484 0.5100723417825298\n",
      "Saving the model  0.5623366730937246 0.554313177566266\n",
      "Epoch >>  20 0.554313177566266 0.05200757293893273 0.5023056046273338\n",
      "Saving the model  0.554313177566266 0.5457237282164573\n",
      "Epoch >>  21 0.5457237282164573 0.05174451772721919 0.49397921048923904\n",
      "Saving the model  0.5457237282164573 0.5398150212701948\n",
      "Epoch >>  22 0.5398150212701948 0.05149403560471093 0.48832098566548415\n",
      "Saving the model  0.5398150212701948 0.5339993487422544\n",
      "Epoch >>  23 0.5339993487422544 0.05128633098510639 0.4827130177571477\n",
      "Saving the model  0.5339993487422544 0.5272769823741\n",
      "Epoch >>  24 0.5272769823741 0.05106071355354185 0.47621626882055773\n",
      "Saving the model  0.5272769823741 0.5200185868049442\n",
      "Epoch >>  25 0.5200185868049442 0.05083250036434173 0.46918608644060217\n",
      "Saving the model  0.5200185868049442 0.5164525250821644\n",
      "Epoch >>  26 0.5164525250821644 0.05064530142005117 0.46580722366211313\n",
      "Saving the model  0.5164525250821644 0.5122623185048191\n",
      "Epoch >>  27 0.5122623185048191 0.05045931595994038 0.4618030025448783\n",
      "Saving the model  0.5122623185048191 0.508923082686061\n",
      "Epoch >>  28 0.508923082686061 0.05028082175678 0.45864226092928057\n",
      "Saving the model  0.508923082686061 0.5038548912533787\n",
      "Epoch >>  29 0.5038548912533787 0.050062721029357424 0.4537921702240206\n",
      "Saving the model  0.5038548912533787 0.4987787932201027\n",
      "Epoch >>  30 0.4987787932201027 0.04986027217683602 0.4489185210432662\n",
      "Saving the model  0.4987787932201027 0.49408222393000883\n",
      "Epoch >>  31 0.49408222393000883 0.04969019812022266 0.444392025809786\n",
      "Saving the model  0.49408222393000883 0.48931036526914784\n",
      "Epoch >>  32 0.48931036526914784 0.04949293252761932 0.43981743274152874\n",
      "Saving the model  0.48931036526914784 0.48530236436240287\n",
      "Epoch >>  33 0.48530236436240287 0.04933768402017349 0.4359646803422297\n",
      "Saving the model  0.48530236436240287 0.48124678089563\n",
      "Epoch >>  34 0.48124678089563 0.049170142998196005 0.4320766378974342\n",
      "Saving the model  0.48124678089563 0.47824444154770523\n",
      "Epoch >>  35 0.47824444154770523 0.04903551430700791 0.42920892724069803\n",
      "Saving the model  0.47824444154770523 0.4748584183063145\n",
      "Epoch >>  36 0.4748584183063145 0.04888231926672678 0.4259760990395884\n",
      "Saving the model  0.4748584183063145 0.4720460201782568\n",
      "Epoch >>  37 0.4720460201782568 0.048734910299064974 0.423311109879192\n",
      "Saving the model  0.4720460201782568 0.4684991629812507\n",
      "Epoch >>  38 0.4684991629812507 0.04859790401509043 0.41990125896616015\n",
      "Saving the model  0.4684991629812507 0.46466150179487414\n",
      "Epoch >>  39 0.46466150179487414 0.048452500240467565 0.41620900155440615\n",
      "Saving the model  0.46466150179487414 0.4613591463473262\n",
      "Epoch >>  40 0.4613591463473262 0.048326879636421384 0.41303226671090476\n",
      "Saving the model  0.4613591463473262 0.45991482333279426\n",
      "Epoch >>  41 0.45991482333279426 0.04820056407621079 0.41171425925658384\n",
      "Saving the model  0.45991482333279426 0.45719992774761625\n",
      "Epoch >>  42 0.45719992774761625 0.0480622986711836 0.4091376290764324\n",
      "Saving the model  0.45719992774761625 0.45345537593559454\n",
      "Epoch >>  43 0.45345537593559454 0.04791821621851878 0.40553715971707555\n",
      "Saving the model  0.45345537593559454 0.4494791749752972\n",
      "Epoch >>  44 0.4494791749752972 0.04777892190046904 0.4017002530748283\n",
      "Saving the model  0.4494791749752972 0.44681185116546807\n",
      "Epoch >>  45 0.44681185116546807 0.04764771362596581 0.39916413753950314\n",
      "Saving the model  0.44681185116546807 0.4438289847547718\n",
      "Epoch >>  46 0.4438289847547718 0.04754020785032288 0.3962887769044498\n",
      "Saving the model  0.4438289847547718 0.43984370759263336\n",
      "Epoch >>  47 0.43984370759263336 0.04740617812146916 0.39243752947116567\n",
      "Saving the model  0.43984370759263336 0.4375848145360333\n",
      "Epoch >>  48 0.4375848145360333 0.047291058473726715 0.39029375606230865\n",
      "Saving the model  0.4375848145360333 0.43454777653991317\n",
      "Epoch >>  49 0.43454777653991317 0.047164471086653975 0.3873833054532611\n",
      "Saving the model  0.43454777653991317 0.4317059997730561\n",
      "Epoch >>  50 0.4317059997730561 0.047041884692360134 0.3846641150806978\n",
      "Saving the model  0.4317059997730561 0.42888123334142625\n",
      "Epoch >>  51 0.42888123334142625 0.04693658252232452 0.3819446508191031\n",
      "Saving the model  0.42888123334142625 0.42673597355975607\n",
      "Epoch >>  52 0.42673597355975607 0.04682554486975392 0.37991042869000363\n",
      "Saving the model  0.42673597355975607 0.42470718848249034\n",
      "Epoch >>  53 0.42470718848249034 0.046721923061293476 0.3779852654211982\n",
      "Saving the model  0.42470718848249034 0.4226891183874443\n",
      "Epoch >>  54 0.4226891183874443 0.046624657324508205 0.37606446106293745\n",
      "Saving the model  0.4226891183874443 0.42168406178229906\n",
      "Epoch >>  55 0.42168406178229906 0.04654569654248857 0.3751383652398113\n",
      "Saving the model  0.42168406178229906 0.4195809930592615\n",
      "Epoch >>  56 0.4195809930592615 0.046448895505743534 0.37313209755351895\n",
      "Saving the model  0.4195809930592615 0.41729628546398384\n",
      "Epoch >>  57 0.41729628546398384 0.04634668425224315 0.37094960121174164\n",
      "Saving the model  0.41729628546398384 0.4150039613227431\n",
      "Epoch >>  58 0.4150039613227431 0.046248666529352195 0.368755294793392\n",
      "Saving the model  0.4150039613227431 0.4130709402330091\n",
      "Epoch >>  59 0.4130709402330091 0.04615901604136891 0.3669119241916414\n",
      "Saving the model  0.4130709402330091 0.4109697852136891\n",
      "Epoch >>  60 0.4109697852136891 0.04606137614162241 0.36490840907206856\n",
      "Saving the model  0.4109697852136891 0.40865057015503053\n",
      "Epoch >>  61 0.40865057015503053 0.04596907352858112 0.36268149662645105\n",
      "Saving the model  0.40865057015503053 0.4069727267740521\n",
      "Epoch >>  62 0.4069727267740521 0.04588319439553979 0.36108953237851354\n",
      "Saving the model  0.4069727267740521 0.40558724070004903\n",
      "Epoch >>  63 0.40558724070004903 0.04579327563019911 0.3597939650698513\n",
      "Saving the model  0.40558724070004903 0.40296280597523465\n",
      "Epoch >>  64 0.40296280597523465 0.045700414183323095 0.35726239179191316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.40296280597523465 0.4013631047377028\n",
      "Epoch >>  65 0.4013631047377028 0.04562069657902578 0.35574240815867875\n",
      "Saving the model  0.4013631047377028 0.399566118833117\n",
      "Epoch >>  66 0.399566118833117 0.0455349050478659 0.3540312137852528\n",
      "Saving the model  0.399566118833117 0.3981529123602153\n",
      "Epoch >>  67 0.3981529123602153 0.045454318353085485 0.3526985940071313\n",
      "Saving the model  0.3981529123602153 0.3960209502041357\n",
      "Epoch >>  68 0.3960209502041357 0.04536529634989179 0.35065565385424535\n",
      "Saving the model  0.3960209502041357 0.39418076704759486\n",
      "Epoch >>  69 0.39418076704759486 0.04528566263937806 0.348895104408218\n",
      "Saving the model  0.39418076704759486 0.39321263120329997\n",
      "Epoch >>  70 0.39321263120329997 0.0452135801938448 0.3479990510094561\n",
      "Saving the model  0.39321263120329997 0.3912830834462035\n",
      "Epoch >>  71 0.3912830834462035 0.045132132679674655 0.3461509507665295\n",
      "Saving the model  0.3912830834462035 0.38980107703769834\n",
      "Epoch >>  72 0.38980107703769834 0.045059128885595046 0.34474194815210407\n",
      "Saving the model  0.38980107703769834 0.3885753163316244\n",
      "Epoch >>  73 0.3885753163316244 0.04498104748467391 0.3435942688469513\n",
      "Saving the model  0.3885753163316244 0.3868130328987547\n",
      "Epoch >>  74 0.3868130328987547 0.04489936861029191 0.34191366428846376\n",
      "Saving the model  0.3868130328987547 0.38558386587950616\n",
      "Epoch >>  75 0.38558386587950616 0.0448332967518273 0.34075056912767965\n",
      "Saving the model  0.38558386587950616 0.3847635323680599\n",
      "Epoch >>  76 0.3847635323680599 0.04476974775826537 0.3399937846097954\n",
      "Saving the model  0.3847635323680599 0.3831897466827595\n",
      "Epoch >>  77 0.3831897466827595 0.04469885190017795 0.33849089478258265\n",
      "Saving the model  0.3831897466827595 0.38145788564693284\n",
      "Epoch >>  78 0.38145788564693284 0.04462866388680012 0.3368292217601339\n",
      "Saving the model  0.38145788564693284 0.38017529588848936\n",
      "Epoch >>  79 0.38017529588848936 0.044562659448640754 0.3356126364398497\n",
      "Saving the model  0.38017529588848936 0.37906112572948597\n",
      "Epoch >>  80 0.37906112572948597 0.044498973689525836 0.33456215203996104\n",
      "Saving the model  0.37906112572948597 0.3779255451054895\n",
      "Epoch >>  81 0.3779255451054895 0.04443674640918294 0.3334887986963075\n",
      "Saving the model  0.3779255451054895 0.3767961949800352\n",
      "Epoch >>  82 0.3767961949800352 0.04437400674175177 0.3324221882382846\n",
      "Saving the model  0.3767961949800352 0.3753910294882708\n",
      "Epoch >>  83 0.3753910294882708 0.04431042223672084 0.33108060725155136\n",
      "Saving the model  0.3753910294882708 0.37423472808450414\n",
      "Epoch >>  84 0.37423472808450414 0.04424380420282788 0.32999092388167767\n",
      "Saving the model  0.37423472808450414 0.3725826663927673\n",
      "Epoch >>  85 0.3725826663927673 0.044176529796099616 0.3284061365966691\n",
      "Saving the model  0.3725826663927673 0.3713094276318596\n",
      "Epoch >>  86 0.3713094276318596 0.04410757735621494 0.32720185027564586\n",
      "Saving the model  0.3713094276318596 0.37060666473082043\n",
      "Epoch >>  87 0.37060666473082043 0.04404397780967112 0.3265626869211506\n",
      "Saving the model  0.37060666473082043 0.36982175234119236\n",
      "Epoch >>  88 0.36982175234119236 0.04399142544279404 0.32583032689839925\n",
      "Saving the model  0.36982175234119236 0.36880534097102297\n",
      "Epoch >>  89 0.36880534097102297 0.04393732950279649 0.3248680114682271\n",
      "Saving the model  0.36880534097102297 0.36783049269513873\n",
      "Epoch >>  90 0.36783049269513873 0.04388295761595798 0.32394753507918095\n",
      "Saving the model  0.36783049269513873 0.3662747750102853\n",
      "Epoch >>  91 0.3662747750102853 0.04382396412409953 0.32245081088618543\n",
      "Saving the model  0.3662747750102853 0.3650152693706484\n",
      "Epoch >>  92 0.3650152693706484 0.04376833225990025 0.32124693711074764\n",
      "Saving the model  0.3650152693706484 0.3633393821099998\n",
      "Epoch >>  93 0.3633393821099998 0.043711403717255015 0.31962797839274465\n",
      "Saving the model  0.3633393821099998 0.3620031551138042\n",
      "Epoch >>  94 0.3620031551138042 0.04365574376562639 0.31834741134817796\n",
      "Saving the model  0.3620031551138042 0.36082521503779685\n",
      "Epoch >>  95 0.36082521503779685 0.043604870584546776 0.31722034445325015\n",
      "Saving the model  0.36082521503779685 0.3595912771246889\n",
      "Epoch >>  96 0.3595912771246889 0.043545138096974134 0.31604613902771495\n",
      "Saving the model  0.3595912771246889 0.35862765473756364\n",
      "Epoch >>  97 0.35862765473756364 0.043496730043582725 0.3151309246939816\n",
      "Saving the model  0.35862765473756364 0.35764692955673055\n",
      "Epoch >>  98 0.35764692955673055 0.04344181655182695 0.3142051130049041\n",
      "Saving the model  0.35764692955673055 0.3564592719034972\n",
      "Epoch >>  99 0.3564592719034972 0.04338743201669612 0.31307183988680176\n",
      "Saving the model  0.3564592719034972 0.3555607911841106\n",
      "Epoch >>  100 0.3555607911841106 0.04333540934875969 0.31222538183535153\n",
      "Saving the model  0.3555607911841106 0.3545444840030647\n",
      "Epoch >>  101 0.3545444840030647 0.04328831424120526 0.31125616976186016\n",
      "Saving the model  0.3545444840030647 0.3532495862326355\n",
      "Epoch >>  102 0.3532495862326355 0.04323588076016894 0.31001370547246737\n",
      "Saving the model  0.3532495862326355 0.35222145526396625\n",
      "Epoch >>  103 0.35222145526396625 0.04318535542963871 0.3090360998343278\n",
      "Saving the model  0.35222145526396625 0.35073690740881974\n",
      "Epoch >>  104 0.35073690740881974 0.04312734489697126 0.30760956251184896\n",
      "Saving the model  0.35073690740881974 0.3497959806426288\n",
      "Epoch >>  105 0.3497959806426288 0.04307634690359611 0.30671963373903294\n",
      "Saving the model  0.3497959806426288 0.3488979903660445\n",
      "Epoch >>  106 0.3488979903660445 0.043022371096616954 0.3058756192694281\n",
      "Saving the model  0.3488979903660445 0.3480188506346911\n",
      "Epoch >>  107 0.3480188506346911 0.04297850228007397 0.305040348354618\n",
      "Saving the model  0.3480188506346911 0.347270265140857\n",
      "Epoch >>  108 0.347270265140857 0.04293529998867667 0.30433496515218095\n",
      "Saving the model  0.347270265140857 0.3462263237703703\n",
      "Epoch >>  109 0.3462263237703703 0.042887044231143236 0.3033392795392279\n",
      "Saving the model  0.3462263237703703 0.3451486184943857\n",
      "Epoch >>  110 0.3451486184943857 0.042836520095680654 0.30231209839870593\n",
      "Saving the model  0.3451486184943857 0.34411244961878035\n",
      "Epoch >>  111 0.34411244961878035 0.042785391426595286 0.30132705819218597\n",
      "Saving the model  0.34411244961878035 0.3428391906751775\n",
      "Epoch >>  112 0.3428391906751775 0.0427393314035673 0.300099859271611\n",
      "Saving the model  0.3428391906751775 0.3418318521210468\n",
      "Epoch >>  113 0.3418318521210468 0.04269340633588765 0.29913844578516025\n",
      "Saving the model  0.3418318521210468 0.34104879032688584\n",
      "Epoch >>  114 0.34104879032688584 0.04265036943336158 0.2983984208935253\n",
      "Saving the model  0.34104879032688584 0.3405372933288987\n",
      "Epoch >>  115 0.3405372933288987 0.04261367982142508 0.2979236135074746\n",
      "Saving the model  0.3405372933288987 0.3396690235492307\n",
      "Epoch >>  116 0.3396690235492307 0.042572951814149634 0.2970960717350815\n",
      "Saving the model  0.3396690235492307 0.3385498095865204\n",
      "Epoch >>  117 0.3385498095865204 0.042531814080316956 0.2960179955062038\n",
      "Saving the model  0.3385498095865204 0.3376097979968715\n",
      "Epoch >>  118 0.3376097979968715 0.0424889768320253 0.2951208211648467\n",
      "Saving the model  0.3376097979968715 0.3367210534354115\n",
      "Epoch >>  119 0.3367210534354115 0.04244639575667782 0.29427465767873423\n",
      "Saving the model  0.3367210534354115 0.3359187944062878\n",
      "Epoch >>  120 0.3359187944062878 0.04240377760089805 0.2935150168053903\n",
      "Saving the model  0.3359187944062878 0.33531764371617784\n",
      "Epoch >>  121 0.33531764371617784 0.04236345938318869 0.29295418433298953\n",
      "Saving the model  0.33531764371617784 0.3344169725395744\n",
      "Epoch >>  122 0.3344169725395744 0.04232572803549186 0.29209124450408297\n",
      "Saving the model  0.3344169725395744 0.3335885840637733\n",
      "Epoch >>  123 0.3335885840637733 0.0422802890549396 0.29130829500883404\n",
      "Saving the model  0.3335885840637733 0.33280575291258696\n",
      "Epoch >>  124 0.33280575291258696 0.04223953103889067 0.290566221873697\n",
      "Saving the model  0.33280575291258696 0.3321639689599106\n",
      "Epoch >>  125 0.3321639689599106 0.04219809528743387 0.28996587367247734\n",
      "Saving the model  0.3321639689599106 0.33117587187408376\n",
      "Epoch >>  126 0.33117587187408376 0.042159664060487996 0.28901620781359616\n",
      "Saving the model  0.33117587187408376 0.3305564045544412\n",
      "Epoch >>  127 0.3305564045544412 0.0421237815000324 0.2884326230544094\n",
      "Saving the model  0.3305564045544412 0.3298718167652637\n",
      "Epoch >>  128 0.3298718167652637 0.042082818690977755 0.2877889980742868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.3298718167652637 0.3291481122237427\n",
      "Epoch >>  129 0.3291481122237427 0.04204846770526761 0.28709964451847575\n",
      "Saving the model  0.3291481122237427 0.3282758845107983\n",
      "Epoch >>  130 0.3282758845107983 0.042006799576762156 0.2862690849340364\n",
      "Saving the model  0.3282758845107983 0.32738696303485215\n",
      "Epoch >>  131 0.32738696303485215 0.041968687821529835 0.28541827521332286\n",
      "Saving the model  0.32738696303485215 0.32699630083816594\n",
      "Epoch >>  132 0.32699630083816594 0.04193737473022045 0.28505892610794603\n",
      "Saving the model  0.32699630083816594 0.3262613515252762\n",
      "Epoch >>  133 0.3262613515252762 0.041901889201344175 0.28435946232393267\n",
      "Saving the model  0.3262613515252762 0.3255190026790282\n",
      "Epoch >>  134 0.3255190026790282 0.04186505750095401 0.28365394517807513\n",
      "Saving the model  0.3255190026790282 0.3248519510021343\n",
      "Epoch >>  135 0.3248519510021343 0.04182764120006063 0.283024309802075\n",
      "Saving the model  0.3248519510021343 0.32397678862742807\n",
      "Epoch >>  136 0.32397678862742807 0.04179075788210534 0.28218603074532406\n",
      "Saving the model  0.32397678862742807 0.3230670119488944\n",
      "Epoch >>  137 0.3230670119488944 0.041752633001555337 0.2813143789473402\n",
      "Saving the model  0.3230670119488944 0.3222777498599874\n",
      "Epoch >>  138 0.3222777498599874 0.0417159014397277 0.2805618484202608\n",
      "Saving the model  0.3222777498599874 0.32189035624756335\n",
      "Epoch >>  139 0.32189035624756335 0.04168027236525605 0.28021008388230867\n",
      "Saving the model  0.32189035624756335 0.321317217145974\n",
      "Epoch >>  140 0.321317217145974 0.04164608957998243 0.2796711275659928\n",
      "Saving the model  0.321317217145974 0.3204779549325936\n",
      "Epoch >>  141 0.3204779549325936 0.04161338849443054 0.2788645664381641\n",
      "Saving the model  0.3204779549325936 0.3197101901911654\n",
      "Epoch >>  142 0.3197101901911654 0.04157609621112061 0.27813409398004607\n",
      "Saving the model  0.3197101901911654 0.31951329057584954\n",
      "Epoch >>  143 0.31951329057584954 0.04154234372660561 0.27797094684924506\n",
      "Saving the model  0.31951329057584954 0.3188217082847699\n",
      "Epoch >>  144 0.3188217082847699 0.04151084123642462 0.2773108670483466\n",
      "Saving the model  0.3188217082847699 0.3182590114123152\n",
      "Epoch >>  145 0.3182590114123152 0.04147614830159321 0.27678286311072364\n",
      "Saving the model  0.3182590114123152 0.317945759646619\n",
      "Epoch >>  146 0.317945759646619 0.04144690879943453 0.27649885084718573\n",
      "Saving the model  0.317945759646619 0.3174475075298698\n",
      "Epoch >>  147 0.3174475075298698 0.04141292935418725 0.2760345781756838\n",
      "Saving the model  0.3174475075298698 0.3167841632631872\n",
      "Epoch >>  148 0.3167841632631872 0.04137850300088224 0.27540566026230623\n",
      "Saving the model  0.3167841632631872 0.31631341056692064\n",
      "Epoch >>  149 0.31631341056692064 0.04134941184345506 0.2749639987234669\n",
      "Saving the model  0.31631341056692064 0.31555358804426775\n",
      "Epoch >>  150 0.31555358804426775 0.04132115401359449 0.27423243403067454\n",
      "Saving the model  0.31555358804426775 0.31521876698872464\n",
      "Epoch >>  151 0.31521876698872464 0.041294092136344135 0.27392467485238187\n",
      "Saving the model  0.31521876698872464 0.31435025843611414\n",
      "Epoch >>  152 0.31435025843611414 0.041256383559849764 0.2730938748762659\n",
      "Saving the model  0.31435025843611414 0.3139487853146398\n",
      "Epoch >>  153 0.3139487853146398 0.041224109812201176 0.2727246755024399\n",
      "Saving the model  0.3139487853146398 0.31319248632593105\n",
      "Epoch >>  154 0.31319248632593105 0.04119085231087146 0.2720016340150607\n",
      "Saving the model  0.31319248632593105 0.31256267599882587\n",
      "Epoch >>  155 0.31256267599882587 0.04116073699375228 0.2714019390050749\n",
      "Saving the model  0.31256267599882587 0.31211475453063225\n",
      "Epoch >>  156 0.31211475453063225 0.041133366037227836 0.270981388493406\n",
      "Saving the model  0.31211475453063225 0.31137874313630176\n",
      "Epoch >>  157 0.31137874313630176 0.041099816196130554 0.27027892694017264\n",
      "Saving the model  0.31137874313630176 0.31088905396995203\n",
      "Epoch >>  158 0.31088905396995203 0.041072620244160175 0.269816433725793\n",
      "Saving the model  0.31088905396995203 0.31061043008881145\n",
      "Epoch >>  159 0.31061043008881145 0.04104648588847819 0.26956394420033436\n",
      "Saving the model  0.31061043008881145 0.3099046701284011\n",
      "Epoch >>  160 0.3099046701284011 0.041013534122584655 0.2688911360058173\n",
      "Saving the model  0.3099046701284011 0.30921884593948407\n",
      "Epoch >>  161 0.30921884593948407 0.04098409528188597 0.2682347506575989\n",
      "Saving the model  0.30921884593948407 0.30844496886014944\n",
      "Epoch >>  162 0.30844496886014944 0.04095952065100548 0.26748544820914455\n",
      "Saving the model  0.30844496886014944 0.30788822147706846\n",
      "Epoch >>  163 0.30788822147706846 0.040933052846193516 0.2669551686308756\n",
      "Saving the model  0.30788822147706846 0.30736988395195025\n",
      "Epoch >>  164 0.30736988395195025 0.04090504998016047 0.2664648339717904\n",
      "Saving the model  0.30736988395195025 0.3068492660811941\n",
      "Epoch >>  165 0.3068492660811941 0.04088233337996674 0.26596693270122806\n",
      "Saving the model  0.3068492660811941 0.30627452810547084\n",
      "Epoch >>  166 0.30627452810547084 0.04085510850056342 0.26541941960490806\n",
      "Saving the model  0.30627452810547084 0.30557028545268683\n",
      "Epoch >>  167 0.30557028545268683 0.04082588876808786 0.2647443966845994\n",
      "Saving the model  0.30557028545268683 0.30510816084257736\n",
      "Epoch >>  168 0.30510816084257736 0.0407992387879041 0.26430892205467393\n",
      "Saving the model  0.30510816084257736 0.30479060619472703\n",
      "Epoch >>  169 0.30479060619472703 0.04077272170723853 0.264017884487489\n",
      "Saving the model  0.30479060619472703 0.30435746500304317\n",
      "Epoch >>  170 0.30435746500304317 0.04075237252664775 0.26360509247639585\n",
      "Saving the model  0.30435746500304317 0.30382502319807414\n",
      "Epoch >>  171 0.30382502319807414 0.040720117303503944 0.26310490589457025\n",
      "Saving the model  0.30382502319807414 0.3033991478535398\n",
      "Epoch >>  172 0.3033991478535398 0.040692496647804666 0.2627066512057352\n",
      "Saving the model  0.3033991478535398 0.30278460277916475\n",
      "Epoch >>  173 0.30278460277916475 0.04066173616147871 0.26212286661768586\n",
      "Saving the model  0.30278460277916475 0.3023901314664078\n",
      "Epoch >>  174 0.3023901314664078 0.040635327738718086 0.26175480372768967\n",
      "Saving the model  0.3023901314664078 0.3022154550019946\n",
      "Epoch >>  175 0.3022154550019946 0.040612252416996564 0.2616032025849981\n",
      "Saving the model  0.3022154550019946 0.30159208907734086\n",
      "Epoch >>  176 0.30159208907734086 0.04058434051119741 0.26100774856614345\n",
      "Saving the model  0.30159208907734086 0.3010054464819364\n",
      "Epoch >>  177 0.3010054464819364 0.040557554338018734 0.26044789214391767\n",
      "Saving the model  0.3010054464819364 0.3002965144926377\n",
      "Epoch >>  178 0.3002965144926377 0.04053094485652867 0.259765569636109\n",
      "Saving the model  0.3002965144926377 0.29983540955843707\n",
      "Epoch >>  179 0.29983540955843707 0.040508542190330225 0.25932686736810695\n",
      "Saving the model  0.29983540955843707 0.2991617726178285\n",
      "Epoch >>  180 0.2991617726178285 0.040479373669786656 0.2586823989480419\n",
      "Saving the model  0.2991617726178285 0.2986583411651791\n",
      "Epoch >>  181 0.2986583411651791 0.040454377692723704 0.2582039634724555\n",
      "Saving the model  0.2986583411651791 0.29834743232054567\n",
      "Epoch >>  182 0.29834743232054567 0.04043335001125307 0.2579140823092927\n",
      "Saving the model  0.29834743232054567 0.2978243683365785\n",
      "Epoch >>  183 0.2978243683365785 0.04040502401520692 0.25741934432137176\n",
      "Saving the model  0.2978243683365785 0.297508479253308\n",
      "Epoch >>  184 0.297508479253308 0.040381636680677305 0.25712684257263074\n",
      "Saving the model  0.297508479253308 0.29702441284744546\n",
      "Epoch >>  185 0.29702441284744546 0.040355849927391364 0.2566685629200544\n",
      "Saving the model  0.29702441284744546 0.2966664820429442\n",
      "Epoch >>  186 0.2966664820429442 0.04033206268338379 0.2563344193595608\n",
      "Saving the model  0.2966664820429442 0.2961654394698172\n",
      "Epoch >>  187 0.2961654394698172 0.04030893823085489 0.2558565012389628\n",
      "Saving the model  0.2961654394698172 0.2957881313213018\n",
      "Epoch >>  188 0.2957881313213018 0.04028373353323986 0.25550439778806233\n",
      "Saving the model  0.2957881313213018 0.2952767182378068\n",
      "Epoch >>  189 0.2952767182378068 0.04025931936973841 0.2550173988680688\n",
      "Saving the model  0.2952767182378068 0.29486344093649847\n",
      "Epoch >>  190 0.29486344093649847 0.04023785590674835 0.2546255850297506\n",
      "Saving the model  0.29486344093649847 0.2944512393927902\n",
      "Epoch >>  191 0.2944512393927902 0.040214209071057556 0.2542370303217332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.2944512393927902 0.2941349655978772\n",
      "Epoch >>  192 0.2941349655978772 0.04018887868201867 0.25394608691585924\n",
      "Saving the model  0.2941349655978772 0.2935983489141999\n",
      "Epoch >>  193 0.2935983489141999 0.040162545401001636 0.25343580351319867\n",
      "Saving the model  0.2935983489141999 0.2930304779979389\n",
      "Epoch >>  194 0.2930304779979389 0.04013548289476154 0.25289499510317753\n",
      "Saving the model  0.2930304779979389 0.29257439625935766\n",
      "Epoch >>  195 0.29257439625935766 0.040109234345383334 0.25246516191397456\n",
      "Saving the model  0.29257439625935766 0.2922680974063609\n",
      "Epoch >>  196 0.2922680974063609 0.04008916704170324 0.25217893036465777\n",
      "Saving the model  0.2922680974063609 0.29184269222122267\n",
      "Epoch >>  197 0.29184269222122267 0.040068129681693224 0.2517745625395297\n",
      "Saving the model  0.29184269222122267 0.2913695512540397\n",
      "Epoch >>  198 0.2913695512540397 0.04004495289460321 0.25132459835943693\n",
      "Saving the model  0.2913695512540397 0.29091766020901905\n",
      "Epoch >>  199 0.29091766020901905 0.04002275490054937 0.2508949053084702\n",
      "Saving the model  0.29091766020901905 0.2905677693568469\n",
      "Epoch >>  200 0.2905677693568469 0.039997472228158186 0.25057029712868917\n",
      "Saving the model  0.2905677693568469 0.29012292137599227\n",
      "Epoch >>  201 0.29012292137599227 0.039974397246556145 0.25014852412943683\n",
      "Saving the model  0.29012292137599227 0.2897128440900274\n",
      "Epoch >>  202 0.2897128440900274 0.03994960521398191 0.2497632388760462\n",
      "Saving the model  0.2897128440900274 0.2892999667349352\n",
      "Epoch >>  203 0.2892999667349352 0.03993049877801681 0.2493694679569191\n",
      "Saving the model  0.2892999667349352 0.28889625984864803\n",
      "Epoch >>  204 0.28889625984864803 0.03990866964588367 0.24898759020276534\n",
      "Saving the model  0.28889625984864803 0.288360716812465\n",
      "Epoch >>  205 0.288360716812465 0.03988451372035293 0.24847620309211327\n",
      "Saving the model  0.288360716812465 0.2880890674052095\n",
      "Epoch >>  206 0.2880890674052095 0.039862745964795145 0.24822632144041548\n",
      "Saving the model  0.2880890674052095 0.2877878104744274\n",
      "Epoch >>  207 0.2877878104744274 0.03984254802652911 0.2479452624478994\n",
      "Saving the model  0.2877878104744274 0.28752020103504994\n",
      "Epoch >>  208 0.28752020103504994 0.03981878200888702 0.2477014190261642\n",
      "Saving the model  0.28752020103504994 0.286994808636184\n",
      "Epoch >>  209 0.286994808636184 0.039797056496631844 0.2471977521395535\n",
      "Saving the model  0.286994808636184 0.28655424556967213\n",
      "Epoch >>  210 0.28655424556967213 0.03977289136556724 0.24678135420410627\n",
      "Saving the model  0.28655424556967213 0.2860822010552464\n",
      "Epoch >>  211 0.2860822010552464 0.039750459182597814 0.24633174187264967\n",
      "Saving the model  0.2860822010552464 0.28555409684532557\n",
      "Epoch >>  212 0.28555409684532557 0.039726670107598464 0.24582742673772817\n",
      "Saving the model  0.28555409684532557 0.28513501620642445\n",
      "Epoch >>  213 0.28513501620642445 0.03970929563118294 0.24542572057524248\n",
      "Saving the model  0.28513501620642445 0.28488118806627327\n",
      "Epoch >>  214 0.28488118806627327 0.039688884003913454 0.2451923040623608\n",
      "Saving the model  0.28488118806627327 0.2844897634813679\n",
      "Epoch >>  215 0.2844897634813679 0.03966738621546152 0.24482237726590736\n",
      "Saving the model  0.2844897634813679 0.28418103474813\n",
      "Epoch >>  216 0.28418103474813 0.03964929490485274 0.24453173984327853\n",
      "Saving the model  0.28418103474813 0.2838501186835781\n",
      "Epoch >>  217 0.2838501186835781 0.03962663292599369 0.2442234857575859\n",
      "Saving the model  0.2838501186835781 0.2832764842579788\n",
      "Epoch >>  218 0.2832764842579788 0.039604014795455375 0.2436724694625246\n",
      "Saving the model  0.2832764842579788 0.2829215609983938\n",
      "Epoch >>  219 0.2829215609983938 0.03958244136728383 0.24333911963111107\n",
      "Saving the model  0.2829215609983938 0.2825177279833572\n",
      "Epoch >>  220 0.2825177279833572 0.039564283586868025 0.24295344439649047\n",
      "Saving the model  0.2825177279833572 0.2820795182299443\n",
      "Epoch >>  221 0.2820795182299443 0.03954203294369036 0.24253748528625513\n",
      "Saving the model  0.2820795182299443 0.2818349889734662\n",
      "Epoch >>  222 0.2818349889734662 0.039523159854394106 0.2423118291190732\n",
      "Saving the model  0.2818349889734662 0.2814340938353337\n",
      "Epoch >>  223 0.2814340938353337 0.039503210407447045 0.24193088342788777\n",
      "Saving the model  0.2814340938353337 0.2812037527196831\n",
      "Epoch >>  224 0.2812037527196831 0.039485306160243684 0.24171844655944047\n",
      "Saving the model  0.2812037527196831 0.28081376375110234\n",
      "Epoch >>  225 0.28081376375110234 0.039463033959885076 0.24135072979121805\n",
      "Saving the model  0.28081376375110234 0.2806506421836898\n",
      "Epoch >>  226 0.2806506421836898 0.03944643202810425 0.24120421015558635\n",
      "Saving the model  0.2806506421836898 0.2801880395390704\n",
      "Epoch >>  227 0.2801880395390704 0.03942265677874608 0.2407653827603252\n",
      "Saving the model  0.2801880395390704 0.27982050892810967\n",
      "Epoch >>  228 0.27982050892810967 0.03940141991429517 0.24041908901381534\n",
      "Saving the model  0.27982050892810967 0.27947962144671445\n",
      "Epoch >>  229 0.27947962144671445 0.039379878154431745 0.24009974329228342\n",
      "Saving the model  0.27947962144671445 0.27915738698779086\n",
      "Epoch >>  230 0.27915738698779086 0.039358017608824264 0.23979936937896734\n",
      "Saving the model  0.27915738698779086 0.27879330235615823\n",
      "Epoch >>  231 0.27879330235615823 0.03933848219082687 0.23945482016533198\n",
      "Saving the model  0.27879330235615823 0.27845510126982187\n",
      "Epoch >>  232 0.27845510126982187 0.03931871430504716 0.2391363869647753\n",
      "Saving the model  0.27845510126982187 0.2779540782060342\n",
      "Epoch >>  233 0.2779540782060342 0.03929953002245857 0.23865454818357626\n",
      "Saving the model  0.2779540782060342 0.2775745091553198\n",
      "Epoch >>  234 0.2775745091553198 0.03927680675423171 0.23829770240108855\n",
      "Saving the model  0.2775745091553198 0.2772379062233222\n",
      "Epoch >>  235 0.2772379062233222 0.039258544535658885 0.23797936168766382\n",
      "Saving the model  0.2772379062233222 0.27699449348209704\n",
      "Epoch >>  236 0.27699449348209704 0.03923934377958192 0.23775514970251554\n",
      "Saving the model  0.27699449348209704 0.2766360967524104\n",
      "Epoch >>  237 0.2766360967524104 0.03922048789536778 0.23741560885704274\n",
      "Saving the model  0.2766360967524104 0.2763200229624836\n",
      "Epoch >>  238 0.2763200229624836 0.039201890799876155 0.2371181321626079\n",
      "Saving the model  0.2763200229624836 0.27593167047377\n",
      "Epoch >>  239 0.27593167047377 0.03918280317498457 0.23674886729878572\n",
      "Saving the model  0.27593167047377 0.2756821484117256\n",
      "Epoch >>  240 0.2756821484117256 0.03916558308296102 0.23651656532876567\n",
      "Saving the model  0.2756821484117256 0.2755122135742851\n",
      "Epoch >>  241 0.2755122135742851 0.03914800643038626 0.23636420714389964\n",
      "Saving the model  0.2755122135742851 0.27522158984039374\n",
      "Epoch >>  242 0.27522158984039374 0.03913035243369728 0.23609123740669732\n",
      "Saving the model  0.27522158984039374 0.27519291110717553\n",
      "Epoch >>  243 0.27519291110717553 0.03911575747871215 0.23607715362846435\n",
      "Saving the model  0.27519291110717553 0.27498890457063835\n",
      "Epoch >>  244 0.27498890457063835 0.03910097761404643 0.23588792695659286\n",
      "Saving the model  0.27498890457063835 0.27463210207890654\n",
      "Epoch >>  245 0.27463210207890654 0.039080880086948606 0.23555122199195896\n",
      "Saving the model  0.27463210207890654 0.274144427760056\n",
      "Epoch >>  246 0.274144427760056 0.03906155379119689 0.23508287396886035\n",
      "Saving the model  0.274144427760056 0.27393543155163935\n",
      "Epoch >>  247 0.27393543155163935 0.0390441923050093 0.23489123924663144\n",
      "Saving the model  0.27393543155163935 0.27371933191824344\n",
      "Epoch >>  248 0.27371933191824344 0.03902328877827342 0.23469604313997114\n",
      "Saving the model  0.27371933191824344 0.2733300394069891\n",
      "Epoch >>  249 0.2733300394069891 0.03900548000752582 0.2343245593994642\n",
      "Saving the model  0.2733300394069891 0.2729833267625588\n",
      "Epoch >>  250 0.2729833267625588 0.03898549407589689 0.23399783268666285\n",
      "Saving the model  0.2729833267625588 0.27262367816854055\n",
      "Epoch >>  251 0.27262367816854055 0.03896777677578608 0.23365590139275574\n",
      "Saving the model  0.27262367816854055 0.2722115390327473\n",
      "Epoch >>  252 0.2722115390327473 0.03894760908224714 0.23326392995050152\n",
      "Saving the model  0.2722115390327473 0.27183319279754303\n",
      "Epoch >>  253 0.27183319279754303 0.038930177528316554 0.23290301526922763\n",
      "Saving the model  0.27183319279754303 0.27146216698196585\n",
      "Epoch >>  254 0.27146216698196585 0.038909269239891575 0.2325528977420757\n",
      "Saving the model  0.27146216698196585 0.2713372059188406\n",
      "Epoch >>  255 0.2713372059188406 0.03889261045905506 0.23244459545978696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.2713372059188406 0.271124451971969\n",
      "Epoch >>  256 0.271124451971969 0.03887476332215912 0.23224968864981127\n",
      "Saving the model  0.271124451971969 0.27090037249676147\n",
      "Epoch >>  257 0.27090037249676147 0.038858100620039304 0.23204227187672355\n",
      "Saving the model  0.27090037249676147 0.2705048271643459\n",
      "Epoch >>  258 0.2705048271643459 0.03884109167992236 0.2316637354844246\n",
      "Saving the model  0.2705048271643459 0.27010573160328566\n",
      "Epoch >>  259 0.27010573160328566 0.03882039753104618 0.2312853340722408\n",
      "Saving the model  0.27010573160328566 0.2696802501479962\n",
      "Epoch >>  260 0.2696802501479962 0.038799500383924095 0.2308807497640734\n",
      "Saving the model  0.2696802501479962 0.26940961700995464\n",
      "Epoch >>  261 0.26940961700995464 0.038782560645602475 0.23062705636435368\n",
      "Saving the model  0.26940961700995464 0.269140896196799\n",
      "Epoch >>  262 0.269140896196799 0.038762902349690175 0.23037799384711005\n",
      "Saving the model  0.269140896196799 0.26888083962502024\n",
      "Epoch >>  263 0.26888083962502024 0.0387464656593512 0.2301343739656703\n",
      "Saving the model  0.26888083962502024 0.2687531021427337\n",
      "Epoch >>  264 0.2687531021427337 0.038730900390290944 0.23002220175244414\n",
      "Saving the model  0.2687531021427337 0.2684947271234463\n",
      "Epoch >>  265 0.2684947271234463 0.038712327618341806 0.22978239950510598\n",
      "Saving the model  0.2684947271234463 0.2681648599597287\n",
      "Epoch >>  266 0.2681648599597287 0.03869443464402099 0.2294704253157091\n",
      "Saving the model  0.2681648599597287 0.26780889177253736\n",
      "Epoch >>  267 0.26780889177253736 0.03867702403579175 0.22913186773674693\n",
      "Saving the model  0.26780889177253736 0.26758173817923164\n",
      "Epoch >>  268 0.26758173817923164 0.038661235119718085 0.2289205030595148\n",
      "Saving the model  0.26758173817923164 0.26743476923858533\n",
      "Epoch >>  269 0.26743476923858533 0.03864691835364553 0.22878785088494122\n",
      "Saving the model  0.26743476923858533 0.2671150142701273\n",
      "Epoch >>  270 0.2671150142701273 0.03862910371480901 0.22848591055532025\n",
      "Saving the model  0.2671150142701273 0.26675264208495186\n",
      "Epoch >>  271 0.26675264208495186 0.03860994333606028 0.2281426987488939\n",
      "Saving the model  0.26675264208495186 0.2665703386290882\n",
      "Epoch >>  272 0.2665703386290882 0.038592876009994566 0.22797746261909568\n",
      "Saving the model  0.2665703386290882 0.26626097680780375\n",
      "Epoch >>  273 0.26626097680780375 0.03857632943481851 0.2276846473729872\n",
      "Saving the model  0.26626097680780375 0.2658450507991725\n",
      "Epoch >>  274 0.2658450507991725 0.03855836349791548 0.22728668730125892\n",
      "Saving the model  0.2658450507991725 0.26565949697869806\n",
      "Epoch >>  275 0.26565949697869806 0.03854138738424003 0.22711810959445977\n",
      "Saving the model  0.26565949697869806 0.2655659556786963\n",
      "Epoch >>  276 0.2655659556786963 0.038526728576210194 0.22703922710248792\n",
      "Saving the model  0.2655659556786963 0.2653575844713913\n",
      "Epoch >>  277 0.2653575844713913 0.03851142700043747 0.22684615747095532\n",
      "Saving the model  0.2653575844713913 0.2650607013617815\n",
      "Epoch >>  278 0.2650607013617815 0.03849873281928715 0.22656196854249594\n",
      "Saving the model  0.2650607013617815 0.2647970032259874\n",
      "Epoch >>  279 0.2647970032259874 0.03848506118428421 0.22631194204170457\n",
      "Saving the model  0.2647970032259874 0.2644077706445259\n",
      "Epoch >>  280 0.2644077706445259 0.03846666821940607 0.2259411024251214\n",
      "Saving the model  0.2644077706445259 0.2641384649871048\n",
      "Epoch >>  281 0.2641384649871048 0.03845073481240197 0.22568773017470475\n",
      "Saving the model  0.2641384649871048 0.26367987260804815\n",
      "Epoch >>  282 0.26367987260804815 0.03843366567726853 0.22524620693078165\n",
      "Saving the model  0.26367987260804815 0.2632815209927225\n",
      "Epoch >>  283 0.2632815209927225 0.038415102418106375 0.2248664185746182\n",
      "Saving the model  0.2632815209927225 0.263051464094661\n",
      "Epoch >>  284 0.263051464094661 0.03839848920664044 0.22465297488802227\n",
      "Saving the model  0.263051464094661 0.2629043487611214\n",
      "Epoch >>  285 0.2629043487611214 0.03838296429875789 0.22452138446236547\n",
      "Saving the model  0.2629043487611214 0.26263076081541586\n",
      "Epoch >>  286 0.26263076081541586 0.038366009523375134 0.22426475129204265\n",
      "Saving the model  0.26263076081541586 0.2623429966991352\n",
      "Epoch >>  287 0.2623429966991352 0.038350962292017024 0.22399203440712026\n",
      "Saving the model  0.2623429966991352 0.2621428060502173\n",
      "Epoch >>  288 0.2621428060502173 0.03833533205707404 0.2238074739931454\n",
      "Saving the model  0.2621428060502173 0.2619117999834548\n",
      "Epoch >>  289 0.2619117999834548 0.038320123010102514 0.22359167697335444\n",
      "Saving the model  0.2619117999834548 0.26181828342041613\n",
      "Epoch >>  290 0.26181828342041613 0.038305501204806074 0.22351278221561185\n",
      "Saving the model  0.26181828342041613 0.26169981943510595\n",
      "Epoch >>  291 0.26169981943510595 0.03829081680620269 0.2234090026289049\n",
      "Saving the model  0.26169981943510595 0.26161567576993844\n",
      "Epoch >>  292 0.26161567576993844 0.038275752107041476 0.22333992366289906\n",
      "Saving the model  0.26161567576993844 0.2614825670534658\n",
      "Epoch >>  293 0.2614825670534658 0.03826194516927203 0.2232206218841959\n",
      "Saving the model  0.2614825670534658 0.2612561493726603\n",
      "Epoch >>  294 0.2612561493726603 0.03824720499877575 0.22300894437388669\n",
      "Saving the model  0.2612561493726603 0.2609943639440767\n",
      "Epoch >>  295 0.2609943639440767 0.0382329985097345 0.22276136543434413\n",
      "Saving the model  0.2609943639440767 0.2607544561989321\n",
      "Epoch >>  296 0.2607544561989321 0.0382166204214506 0.22253783577748354\n",
      "Saving the model  0.2607544561989321 0.2604539417646902\n",
      "Epoch >>  297 0.2604539417646902 0.03820383666738685 0.22225010509730514\n",
      "Saving the model  0.2604539417646902 0.2601371963607381\n",
      "Epoch >>  298 0.2601371963607381 0.0381868311167964 0.22195036524394365\n",
      "Saving the model  0.2601371963607381 0.2600026480453447\n",
      "Epoch >>  299 0.2600026480453447 0.03817215778980163 0.22183049025554497\n",
      "Saving the model  0.2600026480453447 0.25973660623764333\n",
      "Epoch >>  300 0.25973660623764333 0.038156502134030705 0.22158010410361467\n",
      "Saving the model  0.25973660623764333 0.2594107700908415\n",
      "Epoch >>  301 0.2594107700908415 0.03814179533762503 0.22126897475321886\n",
      "Saving the model  0.2594107700908415 0.25922012980546605\n",
      "Epoch >>  302 0.25922012980546605 0.038125171454227176 0.22109495835124154\n",
      "Saving the model  0.25922012980546605 0.2590398610280388\n",
      "Epoch >>  303 0.2590398610280388 0.038109941550395696 0.22092991947764581\n",
      "Saving the model  0.2590398610280388 0.2588568776243854\n",
      "Epoch >>  304 0.2588568776243854 0.03809493601928168 0.22076194160510643\n",
      "Saving the model  0.2588568776243854 0.258590943838947\n",
      "Epoch >>  305 0.258590943838947 0.03807991133579346 0.22051103250315604\n",
      "Saving the model  0.258590943838947 0.25833214214334116\n",
      "Epoch >>  306 0.25833214214334116 0.03806669476105693 0.2202654473822869\n",
      "Saving the model  0.25833214214334116 0.2580242457791553\n",
      "Epoch >>  307 0.2580242457791553 0.03805011078485555 0.21997413499430254\n",
      "Saving the model  0.2580242457791553 0.257815257527796\n",
      "Epoch >>  308 0.257815257527796 0.0380365691532103 0.21977868837458833\n",
      "Saving the model  0.257815257527796 0.25755076433513496\n",
      "Epoch >>  309 0.25755076433513496 0.038022144661554326 0.21952861967358345\n",
      "Saving the model  0.25755076433513496 0.25738024542705235\n",
      "Epoch >>  310 0.25738024542705235 0.038007201792281876 0.2193730436347732\n",
      "Saving the model  0.25738024542705235 0.2570844684656346\n",
      "Epoch >>  311 0.2570844684656346 0.03799506791727553 0.21908940054836198\n",
      "Saving the model  0.2570844684656346 0.25686591348963517\n",
      "Epoch >>  312 0.25686591348963517 0.0379829572292025 0.21888295626043586\n",
      "Saving the model  0.25686591348963517 0.2566825755153039\n",
      "Epoch >>  313 0.2566825755153039 0.037969681642475266 0.21871289387283172\n",
      "Saving the model  0.2566825755153039 0.2565221745387831\n",
      "Epoch >>  314 0.2565221745387831 0.037954978880458186 0.21856719565832797\n",
      "Saving the model  0.2565221745387831 0.2562900827708968\n",
      "Epoch >>  315 0.2562900827708968 0.037941077588214696 0.21834900518268502\n",
      "Saving the model  0.2562900827708968 0.2560303802740018\n",
      "Epoch >>  316 0.2560303802740018 0.037926861176332295 0.21810351909767198\n",
      "Saving the model  0.2560303802740018 0.2558407704828627\n",
      "Epoch >>  317 0.2558407704828627 0.037912646535692165 0.21792812394717279\n",
      "Saving the model  0.2558407704828627 0.25576740767220224\n",
      "Epoch >>  318 0.25576740767220224 0.03789882113634431 0.21786858653586003\n",
      "Saving the model  0.25576740767220224 0.25560117667946886\n",
      "Epoch >>  319 0.25560117667946886 0.03788233320548856 0.217718843473982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.25560117667946886 0.2553221618633419\n",
      "Epoch >>  320 0.2553221618633419 0.03787109221035489 0.21745106965298888\n",
      "Saving the model  0.2553221618633419 0.25505350277280636\n",
      "Epoch >>  321 0.25505350277280636 0.03785784572947292 0.2171956570433352\n",
      "Saving the model  0.25505350277280636 0.2547802367550791\n",
      "Epoch >>  322 0.2547802367550791 0.03784396318090636 0.21693627357417422\n",
      "Saving the model  0.2547802367550791 0.2544798143590203\n",
      "Epoch >>  323 0.2544798143590203 0.037828941301498734 0.21665087305752312\n",
      "Saving the model  0.2544798143590203 0.2543119013830974\n",
      "Epoch >>  324 0.2543119013830974 0.03781562949475605 0.2164962718883428\n",
      "Saving the model  0.2543119013830974 0.25402400630945077\n",
      "Epoch >>  325 0.25402400630945077 0.03780113017982265 0.21622287612962934\n",
      "Saving the model  0.25402400630945077 0.2537989076646405\n",
      "Epoch >>  326 0.2537989076646405 0.03778609553498152 0.21601281212966014\n",
      "Saving the model  0.2537989076646405 0.2535123747235833\n",
      "Epoch >>  327 0.2535123747235833 0.03777228537698686 0.2157400893465978\n",
      "Saving the model  0.2535123747235833 0.2532555584121094\n",
      "Epoch >>  328 0.2532555584121094 0.03775588583868184 0.21549967257342856\n",
      "Saving the model  0.2532555584121094 0.2531485212537351\n",
      "Epoch >>  329 0.2531485212537351 0.037742298266870915 0.2154062229868655\n",
      "Saving the model  0.2531485212537351 0.2529358097685025\n",
      "Epoch >>  330 0.2529358097685025 0.0377264156508204 0.21520939411768336\n",
      "Saving the model  0.2529358097685025 0.2526813694648796\n",
      "Epoch >>  331 0.2526813694648796 0.03771328180033964 0.2149680876645411\n",
      "Saving the model  0.2526813694648796 0.25237530941031405\n",
      "Epoch >>  332 0.25237530941031405 0.03769810282460123 0.2146772065857142\n",
      "Saving the model  0.25237530941031405 0.25222384004678805\n",
      "Epoch >>  333 0.25222384004678805 0.037685474601970935 0.21453836544481833\n",
      "Saving the model  0.25222384004678805 0.25201535797592856\n",
      "Epoch >>  334 0.25201535797592856 0.03767345764244661 0.21434190033348313\n",
      "Saving the model  0.25201535797592856 0.25176730660766433\n",
      "Epoch >>  335 0.25176730660766433 0.0376595218906756 0.21410778471698957\n",
      "Saving the model  0.25176730660766433 0.2515444423096215\n",
      "Epoch >>  336 0.2515444423096215 0.03764376491962435 0.21390067738999816\n",
      "Saving the model  0.2515444423096215 0.25141197061057813\n",
      "Epoch >>  337 0.25141197061057813 0.037632912921872534 0.21377905768870684\n",
      "Saving the model  0.25141197061057813 0.25132506851231023\n",
      "Epoch >>  338 0.25132506851231023 0.03762067331547215 0.2137043951968395\n",
      "Saving the model  0.25132506851231023 0.25124949671943136\n",
      "Epoch >>  339 0.25124949671943136 0.03760907910488873 0.2136404176145442\n",
      "Saving the model  0.25124949671943136 0.2509936393914753\n",
      "Epoch >>  340 0.2509936393914753 0.03759536313206286 0.21339827625941402\n",
      "Saving the model  0.2509936393914753 0.2507521293845194\n",
      "Epoch >>  341 0.2507521293845194 0.03758129349517105 0.21317083588934974\n",
      "Saving the model  0.2507521293845194 0.2504025403306182\n",
      "Epoch >>  342 0.2504025403306182 0.037566864893044 0.2128356754375757\n",
      "Saving the model  0.2504025403306182 0.25010837135043873\n",
      "Epoch >>  343 0.25010837135043873 0.037553313097023214 0.21255505825341717\n",
      "Saving the model  0.25010837135043873 0.24992814738896335\n",
      "Epoch >>  344 0.24992814738896335 0.03753902778543282 0.21238911960353218\n",
      "Saving the model  0.24992814738896335 0.24967459655690308\n",
      "Epoch >>  345 0.24967459655690308 0.03752621739568491 0.21214837916121984\n",
      "Saving the model  0.24967459655690308 0.24950090321428048\n",
      "Epoch >>  346 0.24950090321428048 0.037512976079919214 0.2119879271343628\n",
      "Saving the model  0.24950090321428048 0.24928461751482633\n",
      "Epoch >>  347 0.24928461751482633 0.037497994706441065 0.2117866228083872\n",
      "Saving the model  0.24928461751482633 0.24910134523352515\n",
      "Epoch >>  348 0.24910134523352515 0.03748534116155521 0.21161600407197198\n",
      "Saving the model  0.24910134523352515 0.24882400128906\n",
      "Epoch >>  349 0.24882400128906 0.037470575123108966 0.2113534261659534\n",
      "Saving the model  0.24882400128906 0.2486272615750323\n",
      "Epoch >>  350 0.2486272615750323 0.03745662293378189 0.2111706386412528\n",
      "Saving the model  0.2486272615750323 0.2484993422150898\n",
      "Epoch >>  351 0.2484993422150898 0.037443621021839825 0.21105572119325222\n",
      "Saving the model  0.2484993422150898 0.2482841665377665\n",
      "Epoch >>  352 0.2482841665377665 0.03743037475434382 0.2108537917834251\n",
      "Saving the model  0.2482841665377665 0.24813924546474445\n",
      "Epoch >>  353 0.24813924546474445 0.0374192577502292 0.21071998771451758\n",
      "Saving the model  0.24813924546474445 0.24786922384856547\n",
      "Epoch >>  354 0.24786922384856547 0.037405024994141514 0.21046419885442655\n",
      "Saving the model  0.24786922384856547 0.24768179362828655\n",
      "Epoch >>  355 0.24768179362828655 0.037390103918905106 0.21029168970938378\n",
      "Saving the model  0.24768179362828655 0.2475034739986853\n",
      "Epoch >>  356 0.2475034739986853 0.0373774179514477 0.21012605604723977\n",
      "Saving the model  0.2475034739986853 0.24732989099888503\n",
      "Epoch >>  357 0.24732989099888503 0.0373624145885988 0.20996747641028837\n",
      "Saving the model  0.24732989099888503 0.2470394471718283\n",
      "Epoch >>  358 0.2470394471718283 0.037347687234406006 0.2096917599374246\n",
      "Saving the model  0.2470394471718283 0.24674133594147987\n",
      "Epoch >>  359 0.24674133594147987 0.037334492851032026 0.2094068430904498\n",
      "Saving the model  0.24674133594147987 0.2464755320194302\n",
      "Epoch >>  360 0.2464755320194302 0.03732152379646505 0.2091540082229668\n",
      "Saving the model  0.2464755320194302 0.2462904442901885\n",
      "Epoch >>  361 0.2462904442901885 0.03730930131960537 0.20898114297058457\n",
      "Saving the model  0.2462904442901885 0.24611434394486054\n",
      "Epoch >>  362 0.24611434394486054 0.03729788765371385 0.20881645629114826\n",
      "Saving the model  0.24611434394486054 0.24591362388526689\n",
      "Epoch >>  363 0.24591362388526689 0.037286527078497674 0.20862709680677094\n",
      "Saving the model  0.24591362388526689 0.24577258624073978\n",
      "Epoch >>  364 0.24577258624073978 0.037275376085077756 0.20849721015566375\n",
      "Saving the model  0.24577258624073978 0.24573671221738883\n",
      "Epoch >>  365 0.24573671221738883 0.03726416455680002 0.20847254766059037\n",
      "Saving the model  0.24573671221738883 0.245507011073212\n",
      "Epoch >>  366 0.245507011073212 0.03725207186673965 0.20825493920647367\n",
      "Saving the model  0.245507011073212 0.24534999706961655\n",
      "Epoch >>  367 0.24534999706961655 0.037239381263086166 0.20811061580653167\n",
      "Saving the model  0.24534999706961655 0.24513649265868234\n",
      "Epoch >>  368 0.24513649265868234 0.037225169635091496 0.20791132302359236\n",
      "Saving the model  0.24513649265868234 0.24495540670837684\n",
      "Epoch >>  369 0.24495540670837684 0.03721444972826228 0.20774095698011594\n",
      "Saving the model  0.24495540670837684 0.2448321799712262\n",
      "Epoch >>  370 0.2448321799712262 0.037202164083717945 0.20763001588750934\n",
      "Saving the model  0.2448321799712262 0.2446383310589168\n",
      "Epoch >>  371 0.2446383310589168 0.03719033241515504 0.20744799864376265\n",
      "Saving the model  0.2446383310589168 0.24448909740388786\n",
      "Epoch >>  372 0.24448909740388786 0.037177759293861225 0.20731133811002744\n",
      "Saving the model  0.24448909740388786 0.24423327713947024\n",
      "Epoch >>  373 0.24423327713947024 0.03716478996771652 0.20706848717175447\n",
      "Saving the model  0.24423327713947024 0.2440109653313782\n",
      "Epoch >>  374 0.2440109653313782 0.037152939557022854 0.20685802577435614\n",
      "Saving the model  0.2440109653313782 0.2437285469899187\n",
      "Epoch >>  375 0.2437285469899187 0.037139773497832554 0.20658877349208674\n",
      "Saving the model  0.2437285469899187 0.24359630795650936\n",
      "Epoch >>  376 0.24359630795650936 0.0371281038270625 0.2064682041294474\n",
      "Saving the model  0.24359630795650936 0.2433825342829608\n",
      "Epoch >>  377 0.2433825342829608 0.03711477980352153 0.2062677544794397\n",
      "Saving the model  0.2433825342829608 0.24320692764819396\n",
      "Epoch >>  378 0.24320692764819396 0.037102956242367896 0.20610397140582679\n",
      "Saving the model  0.24320692764819396 0.2429966609223662\n",
      "Epoch >>  379 0.2429966609223662 0.03709228648940024 0.20590437443296686\n",
      "Saving the model  0.2429966609223662 0.24282287396029217\n",
      "Epoch >>  380 0.24282287396029217 0.037081237010748516 0.2057416369495445\n",
      "Saving the model  0.24282287396029217 0.24261697848331978\n",
      "Epoch >>  381 0.24261697848331978 0.0370681489632704 0.20554882952005005\n",
      "Saving the model  0.24261697848331978 0.24240612708196096\n",
      "Epoch >>  382 0.24240612708196096 0.03705622762850393 0.20534989945345758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.24240612708196096 0.24219627298134874\n",
      "Epoch >>  383 0.24219627298134874 0.03704433325025217 0.2051519397310971\n",
      "Saving the model  0.24219627298134874 0.24202592330410727\n",
      "Epoch >>  384 0.24202592330410727 0.037033658928202665 0.20499226437590523\n",
      "Saving the model  0.24202592330410727 0.241837958949536\n",
      "Epoch >>  385 0.241837958949536 0.03702130064916991 0.20481665830036666\n",
      "Saving the model  0.241837958949536 0.2416962861659931\n",
      "Epoch >>  386 0.2416962861659931 0.03701173474011414 0.20468455142587955\n",
      "Saving the model  0.2416962861659931 0.24150639429116935\n",
      "Epoch >>  387 0.24150639429116935 0.037001070315346204 0.20450532397582377\n",
      "Saving the model  0.24150639429116935 0.24130562704591504\n",
      "Epoch >>  388 0.24130562704591504 0.03698943712724197 0.2043161899186737\n",
      "Saving the model  0.24130562704591504 0.24115261750142086\n",
      "Epoch >>  389 0.24115261750142086 0.036978656759076155 0.20417396074234562\n",
      "Saving the model  0.24115261750142086 0.24102066961336158\n",
      "Epoch >>  390 0.24102066961336158 0.0369677899858183 0.20405287962754434\n",
      "Saving the model  0.24102066961336158 0.24083706537208613\n",
      "Epoch >>  391 0.24083706537208613 0.03695512294291729 0.20388194242917024\n",
      "Saving the model  0.24083706537208613 0.2405813213102331\n",
      "Epoch >>  392 0.2405813213102331 0.036942760581311976 0.20363856072892245\n",
      "Saving the model  0.2405813213102331 0.2404516576151043\n",
      "Epoch >>  393 0.2404516576151043 0.03693254222849438 0.2035191153866112\n",
      "Saving the model  0.2404516576151043 0.24023279284786733\n",
      "Epoch >>  394 0.24023279284786733 0.03691998897176905 0.2033128038760995\n",
      "Saving the model  0.24023279284786733 0.24003609047391086\n",
      "Epoch >>  395 0.24003609047391086 0.03690963638387666 0.20312645409003538\n",
      "Saving the model  0.24003609047391086 0.23984270571686855\n",
      "Epoch >>  396 0.23984270571686855 0.03689900956187191 0.20294369615499788\n",
      "Saving the model  0.23984270571686855 0.23969212628193273\n",
      "Epoch >>  397 0.23969212628193273 0.036888069837474724 0.20280405644445954\n",
      "Saving the model  0.23969212628193273 0.23962392371184554\n",
      "Epoch >>  398 0.23962392371184554 0.0368766948899035 0.20274722882194335\n",
      "Saving the model  0.23962392371184554 0.2394353476723156\n",
      "Epoch >>  399 0.2394353476723156 0.03686503929888846 0.20257030837342857\n",
      "Saving the model  0.2394353476723156 0.2393224177042993\n",
      "Epoch >>  400 0.2393224177042993 0.03685498034128673 0.20246743736301398\n",
      "Saving the model  0.2393224177042993 0.2391367171140866\n",
      "Epoch >>  401 0.2391367171140866 0.03684358561646181 0.20229313149762596\n",
      "Saving the model  0.2391367171140866 0.23897059674438875\n",
      "Epoch >>  402 0.23897059674438875 0.036833824879381236 0.20213677186500845\n",
      "Saving the model  0.23897059674438875 0.23878283990639343\n",
      "Epoch >>  403 0.23878283990639343 0.03682288889932656 0.20195995100706796\n",
      "Saving the model  0.23878283990639343 0.23866813255093233\n",
      "Epoch >>  404 0.23866813255093233 0.03681550555612201 0.2018526269948113\n",
      "Saving the model  0.23866813255093233 0.238558762689929\n",
      "Epoch >>  405 0.238558762689929 0.03680452916049003 0.20175423352943997\n",
      "Saving the model  0.238558762689929 0.2383469923347699\n",
      "Epoch >>  406 0.2383469923347699 0.03679395305603274 0.20155303927873827\n",
      "Saving the model  0.2383469923347699 0.23813043173215623\n",
      "Epoch >>  407 0.23813043173215623 0.03678279178035052 0.20134763995180677\n",
      "Saving the model  0.23813043173215623 0.23791679502931065\n",
      "Epoch >>  408 0.23791679502931065 0.036770515405572704 0.20114627962373904\n",
      "Saving the model  0.23791679502931065 0.2377384010574644\n",
      "Epoch >>  409 0.2377384010574644 0.03675803499511051 0.200980366062355\n",
      "Saving the model  0.2377384010574644 0.23753808481572114\n",
      "Epoch >>  410 0.23753808481572114 0.03674747625620022 0.20079060855952222\n",
      "Saving the model  0.23753808481572114 0.23735698349498352\n",
      "Epoch >>  411 0.23735698349498352 0.036736349412941946 0.2006206340820428\n",
      "Saving the model  0.23735698349498352 0.23725927029661514\n",
      "Epoch >>  412 0.23725927029661514 0.03672641087985606 0.20053285941676044\n",
      "Saving the model  0.23725927029661514 0.2371520992392722\n",
      "Epoch >>  413 0.2371520992392722 0.036714365368139525 0.20043773387113392\n",
      "Saving the model  0.2371520992392722 0.23697821401651334\n",
      "Epoch >>  414 0.23697821401651334 0.036703299153029625 0.20027491486348473\n",
      "Saving the model  0.23697821401651334 0.23679974715578234\n",
      "Epoch >>  415 0.23679974715578234 0.0366931984155619 0.2001065487402214\n",
      "Saving the model  0.23679974715578234 0.2365936087832421\n",
      "Epoch >>  416 0.2365936087832421 0.03667974122995006 0.19991386755329277\n",
      "Saving the model  0.2365936087832421 0.23651250539980176\n",
      "Epoch >>  417 0.23651250539980176 0.03666971724933834 0.19984278815046405\n",
      "Saving the model  0.23651250539980176 0.23631281977448484\n",
      "Epoch >>  418 0.23631281977448484 0.03665698329113411 0.19965583648335108\n",
      "Saving the model  0.23631281977448484 0.23615383933012893\n",
      "Epoch >>  419 0.23615383933012893 0.03664599349561252 0.1995078458345168\n",
      "Saving the model  0.23615383933012893 0.2360909680025888\n",
      "Epoch >>  420 0.2360909680025888 0.03663769064508091 0.19945327735750815\n",
      "Saving the model  0.2360909680025888 0.23594212610304968\n",
      "Epoch >>  421 0.23594212610304968 0.03662711291997273 0.1993150131830771\n",
      "Saving the model  0.23594212610304968 0.2358286535233188\n",
      "Epoch >>  422 0.2358286535233188 0.03661798219470322 0.1992106713286157\n",
      "Saving the model  0.2358286535233188 0.23569044874668008\n",
      "Epoch >>  423 0.23569044874668008 0.03660566350902446 0.1990847852376559\n",
      "Saving the model  0.23569044874668008 0.23554284469180084\n",
      "Epoch >>  424 0.23554284469180084 0.03659313017310867 0.19894971451869245\n",
      "Saving the model  0.23554284469180084 0.2353797774436509\n",
      "Epoch >>  425 0.2353797774436509 0.03658266285152801 0.1987971145921231\n",
      "Saving the model  0.2353797774436509 0.23516753797971143\n",
      "Epoch >>  426 0.23516753797971143 0.03657185947096201 0.19859567850874948\n",
      "Saving the model  0.23516753797971143 0.23508207906908438\n",
      "Epoch >>  427 0.23508207906908438 0.0365628922919915 0.1985191867770929\n",
      "Saving the model  0.23508207906908438 0.2348691577397163\n",
      "Epoch >>  428 0.2348691577397163 0.03655196753939788 0.1983171902003185\n",
      "Saving the model  0.2348691577397163 0.23475351635007144\n",
      "Epoch >>  429 0.23475351635007144 0.03654200586159053 0.19821151048848093\n",
      "Saving the model  0.23475351635007144 0.23461740883740947\n",
      "Epoch >>  430 0.23461740883740947 0.03653210932025787 0.1980852995171518\n",
      "Saving the model  0.23461740883740947 0.2344554455402771\n",
      "Epoch >>  431 0.2344554455402771 0.03652078801211332 0.19793465752816392\n",
      "Saving the model  0.2344554455402771 0.23430180392886757\n",
      "Epoch >>  432 0.23430180392886757 0.036511355498072835 0.19779044843079469\n",
      "Saving the model  0.23430180392886757 0.2340977636110252\n",
      "Epoch >>  433 0.2340977636110252 0.036500437312138034 0.19759732629888702\n",
      "Saving the model  0.2340977636110252 0.2339732513693585\n",
      "Epoch >>  434 0.2339732513693585 0.03648972257651986 0.19748352879283862\n",
      "Saving the model  0.2339732513693585 0.23388420829750553\n",
      "Epoch >>  435 0.23388420829750553 0.03648028142592657 0.1974039268715787\n",
      "Saving the model  0.23388420829750553 0.23371129700952878\n",
      "Epoch >>  436 0.23371129700952878 0.03646964038124762 0.19724165662828078\n",
      "Saving the model  0.23371129700952878 0.2335121701115262\n",
      "Epoch >>  437 0.2335121701115262 0.03645930316447232 0.1970528669470537\n",
      "Saving the model  0.2335121701115262 0.23335441973119564\n",
      "Epoch >>  438 0.23335441973119564 0.036447900328676286 0.19690651940251938\n",
      "Saving the model  0.23335441973119564 0.23321741958534975\n",
      "Epoch >>  439 0.23321741958534975 0.036438412467984585 0.19677900711736532\n",
      "Saving the model  0.23321741958534975 0.23310621527533174\n",
      "Epoch >>  440 0.23310621527533174 0.03642649381525164 0.1966797214600803\n",
      "Saving the model  0.23310621527533174 0.23291301350823945\n",
      "Epoch >>  441 0.23291301350823945 0.03641449175614945 0.1964985217520901\n",
      "Saving the model  0.23291301350823945 0.23277879260701015\n",
      "Epoch >>  442 0.23277879260701015 0.03640436527601077 0.1963744273309997\n",
      "Epoch >>  443 0.23278262551467996 0.03639484018296881 0.19638778533171156\n",
      "Saving the model  0.23277879260701015 0.23263882033773792\n",
      "Epoch >>  444 0.23263882033773792 0.036384611468875 0.19625420886886336\n",
      "Saving the model  0.23263882033773792 0.23252674366743875\n",
      "Epoch >>  445 0.23252674366743875 0.036376025812712175 0.196150717854727\n",
      "Saving the model  0.23252674366743875 0.2323390125478446\n",
      "Epoch >>  446 0.2323390125478446 0.03636546960063974 0.19597354294720537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.2323390125478446 0.23213731724139444\n",
      "Epoch >>  447 0.23213731724139444 0.03635418044307853 0.19578313679831655\n",
      "Saving the model  0.23213731724139444 0.2319725676557531\n",
      "Epoch >>  448 0.2319725676557531 0.03634340859523963 0.19562915906051395\n",
      "Saving the model  0.2319725676557531 0.23188005112650953\n",
      "Epoch >>  449 0.23188005112650953 0.03633219016495408 0.19554786096155594\n",
      "Saving the model  0.23188005112650953 0.2318107700921952\n",
      "Epoch >>  450 0.2318107700921952 0.036324528749011924 0.19548624134318401\n",
      "Saving the model  0.2318107700921952 0.23165082383062527\n",
      "Epoch >>  451 0.23165082383062527 0.0363146912009375 0.1953361326296885\n",
      "Saving the model  0.23165082383062527 0.23154268309398623\n",
      "Epoch >>  452 0.23154268309398623 0.036304406398830556 0.19523827669515614\n",
      "Saving the model  0.23154268309398623 0.23135974735541967\n",
      "Epoch >>  453 0.23135974735541967 0.036294424300371664 0.1950653230550484\n",
      "Saving the model  0.23135974735541967 0.23126452805169764\n",
      "Epoch >>  454 0.23126452805169764 0.03628503198962764 0.19497949606207057\n",
      "Saving the model  0.23126452805169764 0.23124423965205726\n",
      "Epoch >>  455 0.23124423965205726 0.036276781174089445 0.1949674584779683\n",
      "Saving the model  0.23124423965205726 0.23115855990539494\n",
      "Epoch >>  456 0.23115855990539494 0.0362667214175843 0.1948918384878112\n",
      "Saving the model  0.23115855990539494 0.2309416573323877\n",
      "Epoch >>  457 0.2309416573323877 0.0362551223068841 0.19468653502550423\n",
      "Saving the model  0.2309416573323877 0.23084719128485262\n",
      "Epoch >>  458 0.23084719128485262 0.03624647062208441 0.1946007206627689\n",
      "Saving the model  0.23084719128485262 0.23074109835128048\n",
      "Epoch >>  459 0.23074109835128048 0.03623608070230034 0.19450501764898065\n",
      "Saving the model  0.23074109835128048 0.2306415915944199\n",
      "Epoch >>  460 0.2306415915944199 0.03622749350238383 0.19441409809203639\n",
      "Saving the model  0.2306415915944199 0.23053217783609384\n",
      "Epoch >>  461 0.23053217783609384 0.0362184982804396 0.19431367955565468\n",
      "Saving the model  0.23053217783609384 0.23038725089173426\n",
      "Epoch >>  462 0.23038725089173426 0.03620922857767077 0.1941780223140642\n",
      "Saving the model  0.23038725089173426 0.23023755745661614\n",
      "Epoch >>  463 0.23023755745661614 0.03619901407772339 0.19403854337889362\n",
      "Saving the model  0.23023755745661614 0.23014629254681448\n",
      "Epoch >>  464 0.23014629254681448 0.036190251099605525 0.19395604144720982\n",
      "Saving the model  0.23014629254681448 0.2299910613754602\n",
      "Epoch >>  465 0.2299910613754602 0.03618157672292026 0.19380948465254091\n",
      "Saving the model  0.2299910613754602 0.2298336253529446\n",
      "Epoch >>  466 0.2298336253529446 0.03617231001178495 0.19366131534116038\n",
      "Saving the model  0.2298336253529446 0.22964068717508138\n",
      "Epoch >>  467 0.22964068717508138 0.03616118029928003 0.19347950687580218\n",
      "Saving the model  0.22964068717508138 0.22949110087474525\n",
      "Epoch >>  468 0.22949110087474525 0.036151198468053335 0.19333990240669274\n",
      "Saving the model  0.22949110087474525 0.22942244546066176\n",
      "Epoch >>  469 0.22942244546066176 0.03614214232142556 0.19328030313923716\n",
      "Saving the model  0.22942244546066176 0.22929553292037042\n",
      "Epoch >>  470 0.22929553292037042 0.03613340979879098 0.1931621231215806\n",
      "Saving the model  0.22929553292037042 0.22922980630943596\n",
      "Epoch >>  471 0.22922980630943596 0.03612555224753778 0.1931042540618995\n",
      "Saving the model  0.22922980630943596 0.2290686931282353\n",
      "Epoch >>  472 0.2290686931282353 0.03611617142982828 0.19295252169840843\n",
      "Saving the model  0.2290686931282353 0.22903526786293352\n",
      "Epoch >>  473 0.22903526786293352 0.036108413968750384 0.19292685389418465\n",
      "Saving the model  0.22903526786293352 0.22891402076843936\n",
      "Epoch >>  474 0.22891402076843936 0.03609848986251557 0.19281553090592546\n",
      "Saving the model  0.22891402076843936 0.22873970331900234\n",
      "Epoch >>  475 0.22873970331900234 0.03608864063750953 0.19265106268149448\n",
      "Saving the model  0.22873970331900234 0.22869139909428005\n",
      "Epoch >>  476 0.22869139909428005 0.03608080580597731 0.1926105932883044\n",
      "Saving the model  0.22869139909428005 0.22856733918922761\n",
      "Epoch >>  477 0.22856733918922761 0.03607220503391896 0.19249513415531047\n",
      "Saving the model  0.22856733918922761 0.22838412957356052\n",
      "Epoch >>  478 0.22838412957356052 0.036062083951720114 0.1923220456218422\n",
      "Saving the model  0.22838412957356052 0.22823749956136385\n",
      "Epoch >>  479 0.22823749956136385 0.03605307443583708 0.19218442512552875\n",
      "Saving the model  0.22823749956136385 0.2280851670679563\n",
      "Epoch >>  480 0.2280851670679563 0.03604401267926413 0.19204115438869415\n",
      "Saving the model  0.2280851670679563 0.22793795181779936\n",
      "Epoch >>  481 0.22793795181779936 0.03603535536136525 0.19190259645643606\n",
      "Saving the model  0.22793795181779936 0.22775145833145136\n",
      "Epoch >>  482 0.22775145833145136 0.03602530138305397 0.19172615694839912\n",
      "Saving the model  0.22775145833145136 0.2276198088416414\n",
      "Epoch >>  483 0.2276198088416414 0.03601696274858169 0.19160284609306139\n",
      "Saving the model  0.2276198088416414 0.22756168706129204\n",
      "Epoch >>  484 0.22756168706129204 0.0360103572361538 0.19155132982513995\n",
      "Saving the model  0.22756168706129204 0.22742818439248177\n",
      "Epoch >>  485 0.22742818439248177 0.03600214432813067 0.19142604006435265\n",
      "Saving the model  0.22742818439248177 0.2272581980152915\n",
      "Epoch >>  486 0.2272581980152915 0.03599278306404909 0.1912654149512441\n",
      "Saving the model  0.2272581980152915 0.22711344005003792\n",
      "Epoch >>  487 0.22711344005003792 0.035982559350080594 0.19113088069995907\n",
      "Saving the model  0.22711344005003792 0.22703040346174355\n",
      "Epoch >>  488 0.22703040346174355 0.035973133727074925 0.1910572697346704\n",
      "Saving the model  0.22703040346174355 0.22691460440700081\n",
      "Epoch >>  489 0.22691460440700081 0.03596362945867616 0.19095097494832652\n",
      "Saving the model  0.22691460440700081 0.22680374421299118\n",
      "Epoch >>  490 0.22680374421299118 0.0359542771111917 0.19084946710180128\n",
      "Saving the model  0.22680374421299118 0.22673197508890588\n",
      "Epoch >>  491 0.22673197508890588 0.03594613534565865 0.19078583974324914\n",
      "Saving the model  0.22673197508890588 0.2265838388999217\n",
      "Epoch >>  492 0.2265838388999217 0.03593689003772063 0.19064694886220288\n",
      "Saving the model  0.2265838388999217 0.2264413163772792\n",
      "Epoch >>  493 0.2264413163772792 0.035927327281026204 0.19051398909625475\n",
      "Saving the model  0.2264413163772792 0.22627615728678466\n",
      "Epoch >>  494 0.22627615728678466 0.03591930732920023 0.19035684995758648\n",
      "Saving the model  0.22627615728678466 0.22615917696350157\n",
      "Epoch >>  495 0.22615917696350157 0.03590996499207787 0.19024921197142558\n",
      "Saving the model  0.22615917696350157 0.2260546459985737\n",
      "Epoch >>  496 0.2260546459985737 0.03589980347472398 0.19015484252385134\n",
      "Saving the model  0.2260546459985737 0.2259013042441513\n",
      "Epoch >>  497 0.2259013042441513 0.03589050233938533 0.19001080190476768\n",
      "Saving the model  0.2259013042441513 0.22574287749960353\n",
      "Epoch >>  498 0.22574287749960353 0.03588119655431514 0.18986168094529024\n",
      "Saving the model  0.22574287749960353 0.2255974748011217\n",
      "Epoch >>  499 0.2255974748011217 0.03587182829108236 0.18972564651004115\n",
      "Saving the model  0.2255974748011217 0.22545657889738321\n",
      "Epoch >>  500 0.22545657889738321 0.03586181652818969 0.18959476236919526\n",
      "Saving the model  0.22545657889738321 0.22533531558810618\n",
      "Epoch >>  501 0.22533531558810618 0.03585176534439304 0.18948355024371505\n",
      "Saving the model  0.22533531558810618 0.22524314980416957\n",
      "Epoch >>  502 0.22524314980416957 0.035843335545512285 0.18939981425865896\n",
      "Saving the model  0.22524314980416957 0.22516133877301367\n",
      "Epoch >>  503 0.22516133877301367 0.03583558203501664 0.1893257567379985\n",
      "Saving the model  0.22516133877301367 0.22505068360426833\n",
      "Epoch >>  504 0.22505068360426833 0.03582703107019337 0.18922365253407644\n",
      "Saving the model  0.22505068360426833 0.22497196553613094\n",
      "Epoch >>  505 0.22497196553613094 0.03581885248869923 0.18915311304743299\n",
      "Saving the model  0.22497196553613094 0.22484125200241953\n",
      "Epoch >>  506 0.22484125200241953 0.03581089979357584 0.18903035220884506\n",
      "Saving the model  0.22484125200241953 0.2246890366279177\n",
      "Epoch >>  507 0.2246890366279177 0.035800279441566454 0.1888887571863525\n",
      "Saving the model  0.2246890366279177 0.22454943335081132\n",
      "Epoch >>  508 0.22454943335081132 0.035791700419142904 0.18875773293166964\n",
      "Saving the model  0.22454943335081132 0.22442676327562983\n",
      "Epoch >>  509 0.22442676327562983 0.035783623768461045 0.18864313950717002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.22442676327562983 0.22433674910532703\n",
      "Epoch >>  510 0.22433674910532703 0.035775946149373294 0.18856080295595495\n",
      "Saving the model  0.22433674910532703 0.2242158883809107\n",
      "Epoch >>  511 0.2242158883809107 0.03576769082809381 0.18844819755281814\n",
      "Saving the model  0.2242158883809107 0.22407775463648408\n",
      "Epoch >>  512 0.22407775463648408 0.03575926545218769 0.1883184891842975\n",
      "Saving the model  0.22407775463648408 0.22399010855226925\n",
      "Epoch >>  513 0.22399010855226925 0.03575145845266225 0.18823865009960816\n",
      "Saving the model  0.22399010855226925 0.22393955797861634\n",
      "Epoch >>  514 0.22393955797861634 0.0357438400960626 0.18819571788255485\n",
      "Saving the model  0.22393955797861634 0.22385779457980434\n",
      "Epoch >>  515 0.22385779457980434 0.035737294436738086 0.18812050014306733\n",
      "Saving the model  0.22385779457980434 0.22378182514581083\n",
      "Epoch >>  516 0.22378182514581083 0.03572945898862248 0.1880523661571893\n",
      "Saving the model  0.22378182514581083 0.22364317639827588\n",
      "Epoch >>  517 0.22364317639827588 0.03572048335325684 0.18792269304501982\n",
      "Saving the model  0.22364317639827588 0.2234819385550287\n",
      "Epoch >>  518 0.2234819385550287 0.035711412727730756 0.1877705258272987\n",
      "Saving the model  0.2234819385550287 0.22331627858804903\n",
      "Epoch >>  519 0.22331627858804903 0.03570273032141543 0.18761354826663415\n",
      "Saving the model  0.22331627858804903 0.2232065410432391\n",
      "Epoch >>  520 0.2232065410432391 0.03569465763233316 0.18751188341090663\n",
      "Saving the model  0.2232065410432391 0.2230786270120585\n",
      "Epoch >>  521 0.2230786270120585 0.03568535853785955 0.18739326847419951\n",
      "Saving the model  0.2230786270120585 0.22297744611389742\n",
      "Epoch >>  522 0.22297744611389742 0.03567708635145993 0.18730035976243795\n",
      "Saving the model  0.22297744611389742 0.22284142849829017\n",
      "Epoch >>  523 0.22284142849829017 0.03566785613314726 0.18717357236514345\n",
      "Saving the model  0.22284142849829017 0.22276125335026473\n",
      "Epoch >>  524 0.22276125335026473 0.03565970895546475 0.18710154439480056\n",
      "Saving the model  0.22276125335026473 0.22259461876483388\n",
      "Epoch >>  525 0.22259461876483388 0.035650602294411395 0.1869440164704227\n",
      "Saving the model  0.22259461876483388 0.22247481586641848\n",
      "Epoch >>  526 0.22247481586641848 0.03564310238742833 0.18683171347899047\n",
      "Saving the model  0.22247481586641848 0.22239115271762733\n",
      "Epoch >>  527 0.22239115271762733 0.03563566127261781 0.18675549144500966\n",
      "Saving the model  0.22239115271762733 0.22225506182927252\n",
      "Epoch >>  528 0.22225506182927252 0.03562638545547422 0.18662867637379826\n",
      "Saving the model  0.22225506182927252 0.2221117206850934\n",
      "Epoch >>  529 0.2221117206850934 0.03561758523538396 0.18649413544970933\n",
      "Saving the model  0.2221117206850934 0.22200685564088607\n",
      "Epoch >>  530 0.22200685564088607 0.03560847196986234 0.18639838367102354\n",
      "Saving the model  0.22200685564088607 0.22189826498759255\n",
      "Epoch >>  531 0.22189826498759255 0.035600304994342566 0.1862979599932498\n",
      "Saving the model  0.22189826498759255 0.2218083999793896\n",
      "Epoch >>  532 0.2218083999793896 0.03559201286979026 0.18621638710959912\n",
      "Saving the model  0.2218083999793896 0.22165994386768453\n",
      "Epoch >>  533 0.22165994386768453 0.03558336938763902 0.18607657448004516\n",
      "Saving the model  0.22165994386768453 0.22156471176074927\n",
      "Epoch >>  534 0.22156471176074927 0.0355739923650045 0.18599071939574435\n",
      "Saving the model  0.22156471176074927 0.22143682698336797\n",
      "Epoch >>  535 0.22143682698336797 0.03556649670036212 0.18587033028300523\n",
      "Saving the model  0.22143682698336797 0.22134368634564167\n",
      "Epoch >>  536 0.22134368634564167 0.03555800471896871 0.18578568162667206\n",
      "Saving the model  0.22134368634564167 0.22120305605681873\n",
      "Epoch >>  537 0.22120305605681873 0.03555025340693957 0.1856528026498785\n",
      "Saving the model  0.22120305605681873 0.221093800035008\n",
      "Epoch >>  538 0.221093800035008 0.03554136112109825 0.18555243891390905\n",
      "Saving the model  0.221093800035008 0.2209770938196329\n",
      "Epoch >>  539 0.2209770938196329 0.03553293387969303 0.18544415993993912\n",
      "Saving the model  0.2209770938196329 0.22082282829670907\n",
      "Epoch >>  540 0.22082282829670907 0.03552470906781589 0.1852981192288923\n",
      "Saving the model  0.22082282829670907 0.22078739194526378\n",
      "Epoch >>  541 0.22078739194526378 0.03551720931505731 0.18527018263020537\n",
      "Saving the model  0.22078739194526378 0.22065967448333926\n",
      "Epoch >>  542 0.22065967448333926 0.03550965269032933 0.1851500217930089\n",
      "Saving the model  0.22065967448333926 0.22056536774482416\n",
      "Epoch >>  543 0.22056536774482416 0.035500562374869093 0.18506480536995407\n",
      "Saving the model  0.22056536774482416 0.22049206282851266\n",
      "Epoch >>  544 0.22049206282851266 0.035493664584513245 0.18499839824399836\n",
      "Saving the model  0.22049206282851266 0.2203655547109074\n",
      "Epoch >>  545 0.2203655547109074 0.03548600734394805 0.18487954736695844\n",
      "Saving the model  0.2203655547109074 0.22033096333336055\n",
      "Epoch >>  546 0.22033096333336055 0.03547827968449437 0.18485268364886517\n",
      "Saving the model  0.22033096333336055 0.22024561529251646\n",
      "Epoch >>  547 0.22024561529251646 0.03547036912532986 0.18477524616718577\n",
      "Saving the model  0.22024561529251646 0.22011157529951889\n",
      "Epoch >>  548 0.22011157529951889 0.03546233142029634 0.1846492438792217\n",
      "Saving the model  0.22011157529951889 0.21996315417205886\n",
      "Epoch >>  549 0.21996315417205886 0.0354538534627071 0.18450930070935107\n",
      "Saving the model  0.21996315417205886 0.21983612634590927\n",
      "Epoch >>  550 0.21983612634590927 0.035445614490487685 0.18439051185542107\n",
      "Saving the model  0.21983612634590927 0.21977613066447507\n",
      "Epoch >>  551 0.21977613066447507 0.03543758791762438 0.18433854274685005\n",
      "Saving the model  0.21977613066447507 0.21966334192072887\n",
      "Epoch >>  552 0.21966334192072887 0.03542887021554363 0.18423447170518464\n",
      "Saving the model  0.21966334192072887 0.2195444593131729\n",
      "Epoch >>  553 0.2195444593131729 0.035422029390080545 0.18412242992309166\n",
      "Saving the model  0.2195444593131729 0.21950414180924013\n",
      "Epoch >>  554 0.21950414180924013 0.03541398541264573 0.1840901563965937\n",
      "Saving the model  0.21950414180924013 0.21942515641857174\n",
      "Epoch >>  555 0.21942515641857174 0.03540722932426149 0.1840179270943094\n",
      "Saving the model  0.21942515641857174 0.21932748626306298\n",
      "Epoch >>  556 0.21932748626306298 0.03539868321919871 0.18392880304386364\n",
      "Saving the model  0.21932748626306298 0.2192547962131753\n",
      "Epoch >>  557 0.2192547962131753 0.035390801483028415 0.18386399473014645\n",
      "Saving the model  0.2192547962131753 0.21910525346942528\n",
      "Epoch >>  558 0.21910525346942528 0.03538228203240001 0.18372297143702496\n",
      "Saving the model  0.21910525346942528 0.2190172451122811\n",
      "Epoch >>  559 0.2190172451122811 0.03537399337346972 0.1836432517388114\n",
      "Saving the model  0.2190172451122811 0.21886287018275247\n",
      "Epoch >>  560 0.21886287018275247 0.03536514410963805 0.1834977260731144\n",
      "Saving the model  0.21886287018275247 0.2187403957959811\n",
      "Epoch >>  561 0.2187403957959811 0.035356348169618634 0.18338404762636226\n",
      "Saving the model  0.2187403957959811 0.21864356735789436\n",
      "Epoch >>  562 0.21864356735789436 0.03534845853753672 0.18329510882035754\n",
      "Saving the model  0.21864356735789436 0.21849348583760103\n",
      "Epoch >>  563 0.21849348583760103 0.035339667388907904 0.18315381844869286\n",
      "Saving the model  0.21849348583760103 0.2183992463754652\n",
      "Epoch >>  564 0.2183992463754652 0.03533192611381578 0.1830673202616491\n",
      "Saving the model  0.2183992463754652 0.21827734518229125\n",
      "Epoch >>  565 0.21827734518229125 0.03532519495242393 0.1829521502298671\n",
      "Saving the model  0.21827734518229125 0.2182291484730407\n",
      "Epoch >>  566 0.2182291484730407 0.035316686228859154 0.1829124622441813\n",
      "Saving the model  0.2182291484730407 0.21815615459986745\n",
      "Epoch >>  567 0.21815615459986745 0.03530893206193207 0.18284722253793514\n",
      "Saving the model  0.21815615459986745 0.2180449275442161\n",
      "Epoch >>  568 0.2180449275442161 0.03530113125610533 0.18274379628811058\n",
      "Saving the model  0.2180449275442161 0.2179507573217872\n",
      "Epoch >>  569 0.2179507573217872 0.03529360960924671 0.18265714771254032\n",
      "Saving the model  0.2179507573217872 0.21782590957920664\n",
      "Epoch >>  570 0.21782590957920664 0.03528604655318886 0.18253986302601757\n",
      "Saving the model  0.21782590957920664 0.2177034323626722\n",
      "Epoch >>  571 0.2177034323626722 0.03527620011681263 0.18242723224585938\n",
      "Saving the model  0.2177034323626722 0.2176133551693678\n",
      "Epoch >>  572 0.2176133551693678 0.03526865276571586 0.18234470240365183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.2176133551693678 0.2175973895992874\n",
      "Epoch >>  573 0.2175973895992874 0.035261697487412536 0.18233569211187484\n",
      "Saving the model  0.2175973895992874 0.21752436120080348\n",
      "Epoch >>  574 0.21752436120080348 0.03525407500554348 0.18227028619526003\n",
      "Saving the model  0.21752436120080348 0.21741678761487981\n",
      "Epoch >>  575 0.21741678761487981 0.03524693064264456 0.18216985697223512\n",
      "Saving the model  0.21741678761487981 0.21727888520659575\n",
      "Epoch >>  576 0.21727888520659575 0.035239248712567534 0.18203963649402832\n",
      "Saving the model  0.21727888520659575 0.21718467544203426\n",
      "Epoch >>  577 0.21718467544203426 0.03523153299839637 0.1819531424436381\n",
      "Saving the model  0.21718467544203426 0.21704714846266793\n",
      "Epoch >>  578 0.21704714846266793 0.035222664829865746 0.1818244836328026\n",
      "Saving the model  0.21704714846266793 0.21692573689638012\n",
      "Epoch >>  579 0.21692573689638012 0.03521449007020745 0.1817112468261728\n",
      "Epoch >>  580 0.2169758102522097 0.0352082264500283 0.18176758380218158\n",
      "Saving the model  0.21692573689638012 0.2168294066479744\n",
      "Epoch >>  581 0.2168294066479744 0.03519836041149629 0.1816310462364784\n",
      "Saving the model  0.2168294066479744 0.21675428792491386\n",
      "Epoch >>  582 0.21675428792491386 0.03519147034314846 0.1815628175817655\n",
      "Saving the model  0.21675428792491386 0.21667899899739354\n",
      "Epoch >>  583 0.21667899899739354 0.03518372247481799 0.18149527652257555\n",
      "Saving the model  0.21667899899739354 0.21657486888520275\n",
      "Epoch >>  584 0.21657486888520275 0.03517593427742367 0.1813989346077791\n",
      "Saving the model  0.21657486888520275 0.21639495774524578\n",
      "Epoch >>  585 0.21639495774524578 0.035167640337530254 0.18122731740771553\n",
      "Saving the model  0.21639495774524578 0.21624883074362955\n",
      "Epoch >>  586 0.21624883074362955 0.035159142945072774 0.18108968779855686\n",
      "Saving the model  0.21624883074362955 0.21611902504297112\n",
      "Epoch >>  587 0.21611902504297112 0.03515071975062692 0.18096830529234417\n",
      "Saving the model  0.21611902504297112 0.21603208890085449\n",
      "Epoch >>  588 0.21603208890085449 0.035143250075838 0.18088883882501652\n",
      "Saving the model  0.21603208890085449 0.2159143650452603\n",
      "Epoch >>  589 0.2159143650452603 0.03513556784582337 0.180778797199437\n",
      "Saving the model  0.2159143650452603 0.21581272417488326\n",
      "Epoch >>  590 0.21581272417488326 0.03512735535791018 0.180685368816973\n",
      "Saving the model  0.21581272417488326 0.21571042754017206\n",
      "Epoch >>  591 0.21571042754017206 0.03512103269590154 0.18058939484427053\n",
      "Saving the model  0.21571042754017206 0.21559253486919888\n",
      "Epoch >>  592 0.21559253486919888 0.03511313423528614 0.18047940063391252\n",
      "Saving the model  0.21559253486919888 0.21547079178323542\n",
      "Epoch >>  593 0.21547079178323542 0.035104422549230484 0.18036636923400473\n",
      "Saving the model  0.21547079178323542 0.21544859808828576\n",
      "Epoch >>  594 0.21544859808828576 0.035098033393674906 0.18035056469461072\n",
      "Saving the model  0.21544859808828576 0.21530899893716707\n",
      "Epoch >>  595 0.21530899893716707 0.035091162591143456 0.18021783634602345\n",
      "Saving the model  0.21530899893716707 0.21521416375527436\n",
      "Epoch >>  596 0.21521416375527436 0.0350837592459204 0.1801304045093538\n",
      "Saving the model  0.21521416375527436 0.21513580134348084\n",
      "Epoch >>  597 0.21513580134348084 0.03507709970204274 0.1800587016414381\n",
      "Saving the model  0.21513580134348084 0.21497964835567615\n",
      "Epoch >>  598 0.21497964835567615 0.03506840905085987 0.17991123930481617\n",
      "Saving the model  0.21497964835567615 0.21484626944209367\n",
      "Epoch >>  599 0.21484626944209367 0.03506113531262547 0.179785134129468\n",
      "Saving the model  0.21484626944209367 0.214725607743562\n",
      "Epoch >>  600 0.214725607743562 0.03505293944719257 0.17967266829636894\n",
      "Saving the model  0.214725607743562 0.2146379308858016\n",
      "Epoch >>  601 0.2146379308858016 0.03504536287074063 0.17959256801506035\n",
      "Saving the model  0.2146379308858016 0.214505918425707\n",
      "Epoch >>  602 0.214505918425707 0.035037191138608335 0.17946872728709792\n",
      "Saving the model  0.214505918425707 0.2143887448904422\n",
      "Epoch >>  603 0.2143887448904422 0.03503001010430262 0.17935873478613892\n",
      "Saving the model  0.2143887448904422 0.21432709518250806\n",
      "Epoch >>  604 0.21432709518250806 0.03502365702047589 0.17930343816203145\n",
      "Saving the model  0.21432709518250806 0.2141756145901042\n",
      "Epoch >>  605 0.2141756145901042 0.03501617138032991 0.17915944320977362\n",
      "Saving the model  0.2141756145901042 0.21405647183385668\n",
      "Epoch >>  606 0.21405647183385668 0.03500817219720929 0.1790482996366467\n",
      "Saving the model  0.21405647183385668 0.2139347019366915\n",
      "Epoch >>  607 0.2139347019366915 0.035000869781065085 0.17893383215562564\n",
      "Saving the model  0.2139347019366915 0.2138773249811445\n",
      "Epoch >>  608 0.2138773249811445 0.03499415242036431 0.1788831725607796\n",
      "Saving the model  0.2138773249811445 0.2137689692935846\n",
      "Epoch >>  609 0.2137689692935846 0.03498697103184338 0.17878199826174054\n",
      "Saving the model  0.2137689692935846 0.21367403960248801\n",
      "Epoch >>  610 0.21367403960248801 0.03497915148267588 0.17869488811981143\n",
      "Saving the model  0.21367403960248801 0.21361648055337568\n",
      "Epoch >>  611 0.21361648055337568 0.0349711969275219 0.1786452836258532\n",
      "Saving the model  0.21361648055337568 0.21353583627653183\n",
      "Epoch >>  612 0.21353583627653183 0.03496472347545154 0.17857111280107973\n",
      "Saving the model  0.21353583627653183 0.2134143501198618\n",
      "Epoch >>  613 0.2134143501198618 0.034955907905298136 0.178458442214563\n",
      "Saving the model  0.2134143501198618 0.21333309758020128\n",
      "Epoch >>  614 0.21333309758020128 0.034949214172555906 0.17838388340764508\n",
      "Saving the model  0.21333309758020128 0.2132311087520453\n",
      "Epoch >>  615 0.2132311087520453 0.03494159534950156 0.1782895134025432\n",
      "Saving the model  0.2132311087520453 0.21313742094463226\n",
      "Epoch >>  616 0.21313742094463226 0.03493494806069635 0.17820247288393531\n",
      "Saving the model  0.21313742094463226 0.21305227570126717\n",
      "Epoch >>  617 0.21305227570126717 0.03492840094392832 0.17812387475733835\n",
      "Saving the model  0.21305227570126717 0.21296527849547173\n",
      "Epoch >>  618 0.21296527849547173 0.03492156619323349 0.17804371230223767\n",
      "Saving the model  0.21296527849547173 0.21290815206503622\n",
      "Epoch >>  619 0.21290815206503622 0.034914736036355906 0.17799341602867977\n",
      "Saving the model  0.21290815206503622 0.2127812157014642\n",
      "Epoch >>  620 0.2127812157014642 0.034906553140678996 0.17787466256078469\n",
      "Saving the model  0.2127812157014642 0.2127320013790292\n",
      "Epoch >>  621 0.2127320013790292 0.03489899358412882 0.17783300779489972\n",
      "Saving the model  0.2127320013790292 0.21258625323336125\n",
      "Epoch >>  622 0.21258625323336125 0.034890287825514336 0.17769596540784638\n",
      "Saving the model  0.21258625323336125 0.21244985310525002\n",
      "Epoch >>  623 0.21244985310525002 0.03488326792346396 0.17756658518178559\n",
      "Saving the model  0.21244985310525002 0.21232075122249103\n",
      "Epoch >>  624 0.21232075122249103 0.03487592053329679 0.1774448306891941\n",
      "Saving the model  0.21232075122249103 0.21230517660899528\n",
      "Epoch >>  625 0.21230517660899528 0.034870640471926624 0.17743453613706814\n",
      "Saving the model  0.21230517660899528 0.21216102430693834\n",
      "Epoch >>  626 0.21216102430693834 0.034862176564134095 0.17729884774280388\n",
      "Saving the model  0.21216102430693834 0.21204878105278732\n",
      "Epoch >>  627 0.21204878105278732 0.03485526342157497 0.17719351763121188\n",
      "Saving the model  0.21204878105278732 0.21192957623921704\n",
      "Epoch >>  628 0.21192957623921704 0.034847772417486045 0.17708180382173072\n",
      "Saving the model  0.21192957623921704 0.21186926042236987\n",
      "Epoch >>  629 0.21186926042236987 0.03484113074724515 0.17702812967512424\n",
      "Saving the model  0.21186926042236987 0.21179958957423126\n",
      "Epoch >>  630 0.21179958957423126 0.034834407542650644 0.17696518203158026\n",
      "Saving the model  0.21179958957423126 0.21170517638154637\n",
      "Epoch >>  631 0.21170517638154637 0.03482799633606875 0.17687718004547764\n",
      "Saving the model  0.21170517638154637 0.21167017361079843\n",
      "Epoch >>  632 0.21167017361079843 0.034822754576855956 0.17684741903394263\n",
      "Saving the model  0.21167017361079843 0.21160491189163916\n",
      "Epoch >>  633 0.21160491189163916 0.03481593543157167 0.17678897646006717\n",
      "Saving the model  0.21160491189163916 0.21146731796622584\n",
      "Epoch >>  634 0.21146731796622584 0.03480919191509271 0.1766581260511329\n",
      "Saving the model  0.21146731796622584 0.2113875428354033\n",
      "Epoch >>  635 0.2113875428354033 0.03480171246460369 0.17658583037079975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.2113875428354033 0.21129836260577517\n",
      "Epoch >>  636 0.21129836260577517 0.03479467694900613 0.17650368565676922\n",
      "Saving the model  0.21129836260577517 0.2112791264476374\n",
      "Epoch >>  637 0.2112791264476374 0.03478885750960267 0.17649026893803518\n",
      "Saving the model  0.2112791264476374 0.2111511878866657\n",
      "Epoch >>  638 0.2111511878866657 0.034781388443988634 0.17636979944267767\n",
      "Saving the model  0.2111511878866657 0.2110797048313249\n",
      "Epoch >>  639 0.2110797048313249 0.03477460745863388 0.17630509737269176\n",
      "Saving the model  0.2110797048313249 0.21098984674210078\n",
      "Epoch >>  640 0.21098984674210078 0.034766947739289816 0.17622289900281168\n",
      "Saving the model  0.21098984674210078 0.21087047371286588\n",
      "Epoch >>  641 0.21087047371286588 0.03476051440123144 0.17610995931163503\n",
      "Saving the model  0.21087047371286588 0.21079287945883607\n",
      "Epoch >>  642 0.21079287945883607 0.03475430527106731 0.17603857418776891\n",
      "Saving the model  0.21079287945883607 0.21072388789895152\n",
      "Epoch >>  643 0.21072388789895152 0.03474808538140896 0.17597580251754302\n",
      "Saving the model  0.21072388789895152 0.21061448182609324\n",
      "Epoch >>  644 0.21061448182609324 0.03474064284944819 0.17587383897664519\n",
      "Saving the model  0.21061448182609324 0.21049914807632789\n",
      "Epoch >>  645 0.21049914807632789 0.034732470389179586 0.1757666776871485\n",
      "Saving the model  0.21049914807632789 0.21041427986427658\n",
      "Epoch >>  646 0.21041427986427658 0.03472578450410734 0.17568849536016956\n",
      "Saving the model  0.21041427986427658 0.2103305527375501\n",
      "Epoch >>  647 0.2103305527375501 0.03471843009830892 0.1756121226392412\n",
      "Saving the model  0.2103305527375501 0.21023629199415936\n",
      "Epoch >>  648 0.21023629199415936 0.03471097630429165 0.17552531568986815\n",
      "Saving the model  0.21023629199415936 0.2101639385943759\n",
      "Epoch >>  649 0.2101639385943759 0.03470362357482647 0.17546031501955034\n",
      "Saving the model  0.2101639385943759 0.2100768869594985\n",
      "Epoch >>  650 0.2100768869594985 0.03469662522724156 0.1753802617322579\n",
      "Saving the model  0.2100768869594985 0.2099689052570445\n",
      "Epoch >>  651 0.2099689052570445 0.03468971397834295 0.17527919127870262\n",
      "Saving the model  0.2099689052570445 0.20987943517104912\n",
      "Epoch >>  652 0.20987943517104912 0.03468211716586123 0.1751973180051888\n",
      "Saving the model  0.20987943517104912 0.2097394545473198\n",
      "Epoch >>  653 0.2097394545473198 0.034674284240601545 0.1750651703067187\n",
      "Saving the model  0.2097394545473198 0.20966337511694297\n",
      "Epoch >>  654 0.20966337511694297 0.03466690716308319 0.17499646795385995\n",
      "Saving the model  0.20966337511694297 0.20953861354930836\n",
      "Epoch >>  655 0.20953861354930836 0.03465928805060017 0.17487932549870808\n",
      "Saving the model  0.20953861354930836 0.20946500026805992\n",
      "Epoch >>  656 0.20946500026805992 0.03465292815936495 0.17481207210869512\n",
      "Saving the model  0.20946500026805992 0.20937011561136237\n",
      "Epoch >>  657 0.20937011561136237 0.03464601195416063 0.17472410365720173\n",
      "Saving the model  0.20937011561136237 0.20930640098647724\n",
      "Epoch >>  658 0.20930640098647724 0.03463810849157516 0.17466829249490232\n",
      "Saving the model  0.20930640098647724 0.20923341529000586\n",
      "Epoch >>  659 0.20923341529000586 0.03463135815038507 0.17460205713962137\n",
      "Saving the model  0.20923341529000586 0.20914260473481633\n",
      "Epoch >>  660 0.20914260473481633 0.03462423967165518 0.1745183650631617\n",
      "Epoch >>  661 0.20915726557619893 0.034618203706212054 0.17453906186998758\n",
      "Saving the model  0.20914260473481633 0.20907305323911915\n",
      "Epoch >>  662 0.20907305323911915 0.0346114197961352 0.17446163344298454\n",
      "Saving the model  0.20907305323911915 0.20901899782780872\n",
      "Epoch >>  663 0.20901899782780872 0.034605711582342054 0.17441328624546718\n",
      "Saving the model  0.20901899782780872 0.2089427113037236\n",
      "Epoch >>  664 0.2089427113037236 0.03459979001938988 0.17434292128433443\n",
      "Saving the model  0.2089427113037236 0.20881587852845537\n",
      "Epoch >>  665 0.20881587852845537 0.03459246064963447 0.17422341787882162\n",
      "Saving the model  0.20881587852845537 0.20873770045913304\n",
      "Epoch >>  666 0.20873770045913304 0.03458559234798523 0.1741521081111487\n",
      "Saving the model  0.20873770045913304 0.20863813239216558\n",
      "Epoch >>  667 0.20863813239216558 0.03457794449648121 0.1740601878956851\n",
      "Saving the model  0.20863813239216558 0.20854170980689282\n",
      "Epoch >>  668 0.20854170980689282 0.03457049723211748 0.17397121257477638\n",
      "Saving the model  0.20854170980689282 0.20847266984213983\n",
      "Epoch >>  669 0.20847266984213983 0.03456332660762931 0.17390934323451138\n",
      "Saving the model  0.20847266984213983 0.20838897833251502\n",
      "Epoch >>  670 0.20838897833251502 0.034556378793564664 0.1738325995389513\n",
      "Saving the model  0.20838897833251502 0.2083040534912339\n",
      "Epoch >>  671 0.2083040534912339 0.034549504069914895 0.17375454942131963\n",
      "Saving the model  0.2083040534912339 0.20826154849517503\n",
      "Epoch >>  672 0.20826154849517503 0.034542674554546175 0.17371887394062935\n",
      "Saving the model  0.20826154849517503 0.20819770146264188\n",
      "Epoch >>  673 0.20819770146264188 0.03453597879457404 0.1736617226680685\n",
      "Saving the model  0.20819770146264188 0.208124301597538\n",
      "Epoch >>  674 0.208124301597538 0.034528773939239046 0.17359552765829928\n",
      "Saving the model  0.208124301597538 0.20798215995067362\n",
      "Epoch >>  675 0.20798215995067362 0.03452116449389651 0.17346099545677762\n",
      "Saving the model  0.20798215995067362 0.20785824134416114\n",
      "Epoch >>  676 0.20785824134416114 0.034514188474376026 0.17334405286978558\n",
      "Saving the model  0.20785824134416114 0.20774152865671908\n",
      "Epoch >>  677 0.20774152865671908 0.03450629198856074 0.17323523666815868\n",
      "Saving the model  0.20774152865671908 0.20765453971627443\n",
      "Epoch >>  678 0.20765453971627443 0.03449956534064961 0.17315497437562502\n",
      "Saving the model  0.20765453971627443 0.20760669833628945\n",
      "Epoch >>  679 0.20760669833628945 0.034494764027630076 0.1731119343086598\n",
      "Saving the model  0.20760669833628945 0.20755252128038676\n",
      "Epoch >>  680 0.20755252128038676 0.034488360577661525 0.1730641607027258\n",
      "Saving the model  0.20755252128038676 0.2074930292901813\n",
      "Epoch >>  681 0.2074930292901813 0.03448178296113938 0.17301124632904247\n",
      "Saving the model  0.2074930292901813 0.20740377465743057\n",
      "Epoch >>  682 0.20740377465743057 0.03447590063089075 0.17292787402654042\n",
      "Saving the model  0.20740377465743057 0.20734651390511893\n",
      "Epoch >>  683 0.20734651390511893 0.03446880629307491 0.17287770761204477\n",
      "Saving the model  0.20734651390511893 0.20726335487224976\n",
      "Epoch >>  684 0.20726335487224976 0.03446238477443917 0.17280097009781112\n",
      "Saving the model  0.20726335487224976 0.20722549402763196\n",
      "Epoch >>  685 0.20722549402763196 0.03445603028533312 0.17276946374229948\n",
      "Saving the model  0.20722549402763196 0.20715265643009878\n",
      "Epoch >>  686 0.20715265643009878 0.03444899989738726 0.17270365653271225\n",
      "Saving the model  0.20715265643009878 0.20711748595782722\n",
      "Epoch >>  687 0.20711748595782722 0.034442915583330604 0.1726745703744973\n",
      "Saving the model  0.20711748595782722 0.20703274406092742\n",
      "Epoch >>  688 0.20703274406092742 0.03443574700248941 0.17259699705843876\n",
      "Saving the model  0.20703274406092742 0.20694727728576678\n",
      "Epoch >>  689 0.20694727728576678 0.03442846827029295 0.1725188090154745\n",
      "Saving the model  0.20694727728576678 0.20694409687697932\n",
      "Epoch >>  690 0.20694409687697932 0.03442262644448849 0.17252147043249144\n",
      "Saving the model  0.20694409687697932 0.20684865367928715\n",
      "Epoch >>  691 0.20684865367928715 0.03441623662791506 0.1724324170513727\n",
      "Saving the model  0.20684865367928715 0.20677129351601833\n",
      "Epoch >>  692 0.20677129351601833 0.03440907253858142 0.17236222097743756\n",
      "Saving the model  0.20677129351601833 0.2067205278655951\n",
      "Epoch >>  693 0.2067205278655951 0.03440217840512049 0.17231834946047575\n",
      "Saving the model  0.2067205278655951 0.20663834214597038\n",
      "Epoch >>  694 0.20663834214597038 0.034395751012635735 0.1722425911333358\n",
      "Saving the model  0.20663834214597038 0.20657649542307724\n",
      "Epoch >>  695 0.20657649542307724 0.03438944619301255 0.17218704923006573\n",
      "Saving the model  0.20657649542307724 0.20643033025059612\n",
      "Epoch >>  696 0.20643033025059612 0.03438200968950053 0.17204832056109653\n",
      "Saving the model  0.20643033025059612 0.20635519389465087\n",
      "Epoch >>  697 0.20635519389465087 0.03437498249546543 0.17198021139918637\n",
      "Saving the model  0.20635519389465087 0.20626453699122874\n",
      "Epoch >>  698 0.20626453699122874 0.03436882689577759 0.1718957100954519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.20626453699122874 0.20617061245102902\n",
      "Epoch >>  699 0.20617061245102902 0.03436187811905472 0.17180873433197497\n",
      "Saving the model  0.20617061245102902 0.20612850671310254\n",
      "Epoch >>  700 0.20612850671310254 0.034355607465918064 0.17177289924718536\n",
      "Saving the model  0.20612850671310254 0.20604281324028936\n",
      "Epoch >>  701 0.20604281324028936 0.034349375686612595 0.17169343755367747\n",
      "Saving the model  0.20604281324028936 0.20594310840428542\n",
      "Epoch >>  702 0.20594310840428542 0.03434222237339152 0.17160088603089468\n",
      "Saving the model  0.20594310840428542 0.20584079620184098\n",
      "Epoch >>  703 0.20584079620184098 0.03433481693079507 0.17150597927104688\n",
      "Saving the model  0.20584079620184098 0.2057329584093263\n",
      "Epoch >>  704 0.2057329584093263 0.034328474838991346 0.1714044835703357\n",
      "Saving the model  0.2057329584093263 0.2056711688545344\n",
      "Epoch >>  705 0.2056711688545344 0.03432157707646944 0.17134959177806566\n",
      "Saving the model  0.2056711688545344 0.20565561316134956\n",
      "Epoch >>  706 0.20565561316134956 0.03431544784885895 0.1713401653124914\n",
      "Saving the model  0.20565561316134956 0.20556463755257606\n",
      "Epoch >>  707 0.20556463755257606 0.03431012715725597 0.17125451039532064\n",
      "Saving the model  0.20556463755257606 0.20546363722191335\n",
      "Epoch >>  708 0.20546363722191335 0.03430338299793157 0.17116025422398232\n",
      "Epoch >>  709 0.20547734812953206 0.03430031970088692 0.1711770284286457\n",
      "Saving the model  0.20546363722191335 0.20542158029496535\n",
      "Epoch >>  710 0.20542158029496535 0.034294342354063985 0.1711272379409021\n",
      "Saving the model  0.20542158029496535 0.20540400578429321\n",
      "Epoch >>  711 0.20540400578429321 0.0342886930804624 0.1711153127038316\n",
      "Saving the model  0.20540400578429321 0.20532788881005737\n",
      "Epoch >>  712 0.20532788881005737 0.03428215515045429 0.17104573365960368\n",
      "Saving the model  0.20532788881005737 0.20524839014543927\n",
      "Epoch >>  713 0.20524839014543927 0.034276632235970404 0.17097175790946947\n",
      "Saving the model  0.20524839014543927 0.20517944330254312\n",
      "Epoch >>  714 0.20517944330254312 0.034270494779197344 0.1709089485233465\n",
      "Saving the model  0.20517944330254312 0.20510465149459903\n",
      "Epoch >>  715 0.20510465149459903 0.034264465915556576 0.17084018557904326\n",
      "Saving the model  0.20510465149459903 0.20500086630895162\n",
      "Epoch >>  716 0.20500086630895162 0.03425844860355048 0.17074241770540205\n",
      "Saving the model  0.20500086630895162 0.20488281318917945\n",
      "Epoch >>  717 0.20488281318917945 0.03425190652760308 0.1706309066615767\n",
      "Saving the model  0.20488281318917945 0.20479454527773883\n",
      "Epoch >>  718 0.20479454527773883 0.03424497941709777 0.17054956586064157\n",
      "Saving the model  0.20479454527773883 0.2047006555981611\n",
      "Epoch >>  719 0.2047006555981611 0.03423935816958907 0.17046129742857238\n",
      "Saving the model  0.2047006555981611 0.20460489724721742\n",
      "Epoch >>  720 0.20460489724721742 0.03423390244904861 0.17037099479816947\n",
      "Saving the model  0.20460489724721742 0.20451765489111212\n",
      "Epoch >>  721 0.20451765489111212 0.03422734729192315 0.1702903075991896\n",
      "Saving the model  0.20451765489111212 0.20445323739162982\n",
      "Epoch >>  722 0.20445323739162982 0.03421995033126666 0.1702332870603641\n",
      "Saving the model  0.20445323739162982 0.20440563673291443\n",
      "Epoch >>  723 0.20440563673291443 0.03421504125137846 0.17019059548153706\n",
      "Saving the model  0.20440563673291443 0.20433626421115067\n",
      "Epoch >>  724 0.20433626421115067 0.03420853676074344 0.1701277274504083\n",
      "Saving the model  0.20433626421115067 0.2042573871982694\n",
      "Epoch >>  725 0.2042573871982694 0.03420311982548846 0.17005426737278187\n",
      "Saving the model  0.2042573871982694 0.20420149183701097\n",
      "Epoch >>  726 0.20420149183701097 0.0341967250209876 0.17000476681602442\n",
      "Saving the model  0.20420149183701097 0.20412244287635037\n",
      "Epoch >>  727 0.20412244287635037 0.034190395152650176 0.1699320477237012\n",
      "Saving the model  0.20412244287635037 0.20405778758055299\n",
      "Epoch >>  728 0.20405778758055299 0.034183448555543124 0.169874339025011\n",
      "Saving the model  0.20405778758055299 0.20398162388050836\n",
      "Epoch >>  729 0.20398162388050836 0.03417746281740283 0.16980416106310658\n",
      "Saving the model  0.20398162388050836 0.2038926803788901\n",
      "Epoch >>  730 0.2038926803788901 0.0341718449615018 0.1697208354173895\n",
      "Saving the model  0.2038926803788901 0.20380856572448278\n",
      "Epoch >>  731 0.20380856572448278 0.03416523492857493 0.16964333079590885\n",
      "Saving the model  0.20380856572448278 0.20371830103546384\n",
      "Epoch >>  732 0.20371830103546384 0.03415900230061572 0.16955929873484923\n",
      "Saving the model  0.20371830103546384 0.20367715857521906\n",
      "Epoch >>  733 0.20367715857521906 0.03415420249059159 0.16952295608462858\n",
      "Saving the model  0.20367715857521906 0.20362650970166396\n",
      "Epoch >>  734 0.20362650970166396 0.03414773579654678 0.1694787739051185\n",
      "Saving the model  0.20362650970166396 0.20358731667734487\n",
      "Epoch >>  735 0.20358731667734487 0.03414200510765804 0.16944531156968806\n",
      "Epoch >>  736 0.20359984846080492 0.034136877052568626 0.1694629714082372\n",
      "Saving the model  0.20358731667734487 0.20354706832693664\n",
      "Epoch >>  737 0.20354706832693664 0.03413160845557419 0.169415459871363\n",
      "Saving the model  0.20354706832693664 0.20343083274988652\n",
      "Epoch >>  738 0.20343083274988652 0.03412593204179285 0.16930490070809487\n",
      "Saving the model  0.20343083274988652 0.20340728091999088\n",
      "Epoch >>  739 0.20340728091999088 0.034119936486784824 0.16928734443320734\n",
      "Saving the model  0.20340728091999088 0.20332574771796635\n",
      "Epoch >>  740 0.20332574771796635 0.034113631617703345 0.16921211610026435\n",
      "Saving the model  0.20332574771796635 0.20328950679661018\n",
      "Epoch >>  741 0.20328950679661018 0.03410919708948929 0.16918030970712208\n",
      "Saving the model  0.20328950679661018 0.20323766844386995\n",
      "Epoch >>  742 0.20323766844386995 0.03410278531047084 0.1691348831334002\n",
      "Saving the model  0.20323766844386995 0.203150511509997\n",
      "Epoch >>  743 0.203150511509997 0.034095988134610004 0.1690545233753881\n",
      "Saving the model  0.203150511509997 0.20305332040774868\n",
      "Epoch >>  744 0.20305332040774868 0.0340887457113961 0.1689645746963538\n",
      "Saving the model  0.20305332040774868 0.20302105091036804\n",
      "Epoch >>  745 0.20302105091036804 0.03408309534454584 0.16893795556582317\n",
      "Saving the model  0.20302105091036804 0.2029848746467863\n",
      "Epoch >>  746 0.2029848746467863 0.034076627499358254 0.16890824714742902\n",
      "Saving the model  0.2029848746467863 0.20291414636715777\n",
      "Epoch >>  747 0.20291414636715777 0.034070803216958115 0.16884334315020058\n",
      "Saving the model  0.20291414636715777 0.2028513930273991\n",
      "Epoch >>  748 0.2028513930273991 0.034065560450093506 0.16878583257730648\n",
      "Saving the model  0.2028513930273991 0.2027841117900857\n",
      "Epoch >>  749 0.2027841117900857 0.03406039268222443 0.16872371910786207\n",
      "Saving the model  0.2027841117900857 0.2027183097954094\n",
      "Epoch >>  750 0.2027183097954094 0.034054276001391354 0.16866403379401887\n",
      "Saving the model  0.2027183097954094 0.202663288611696\n",
      "Epoch >>  751 0.202663288611696 0.03404904637543797 0.16861424223625898\n",
      "Saving the model  0.202663288611696 0.20255819528376165\n",
      "Epoch >>  752 0.20255819528376165 0.03404340575980707 0.16851478952395552\n",
      "Saving the model  0.20255819528376165 0.20249227624316785\n",
      "Epoch >>  753 0.20249227624316785 0.03403815253721342 0.16845412370595564\n",
      "Saving the model  0.20249227624316785 0.20241140333083096\n",
      "Epoch >>  754 0.20241140333083096 0.03403272488136709 0.1683786784494654\n",
      "Saving the model  0.20241140333083096 0.20229511219320545\n",
      "Epoch >>  755 0.20229511219320545 0.034026467387073815 0.1682686448061332\n",
      "Saving the model  0.20229511219320545 0.2022134730010597\n",
      "Epoch >>  756 0.2022134730010597 0.03401988565765911 0.16819358734340223\n",
      "Saving the model  0.2022134730010597 0.20213620065393764\n",
      "Epoch >>  757 0.20213620065393764 0.034013679963148816 0.16812252069079028\n",
      "Saving the model  0.20213620065393764 0.20210057404399004\n",
      "Epoch >>  758 0.20210057404399004 0.03400759551595613 0.16809297852803515\n",
      "Saving the model  0.20210057404399004 0.20201341200094708\n",
      "Epoch >>  759 0.20201341200094708 0.03400153157571479 0.1680118804252338\n",
      "Saving the model  0.20201341200094708 0.2019262732689286\n",
      "Epoch >>  760 0.2019262732689286 0.03399638590832648 0.16792988736060363\n",
      "Saving the model  0.2019262732689286 0.2019108899353362\n",
      "Epoch >>  761 0.2019108899353362 0.0339906316854892 0.16792025824984846\n",
      "Saving the model  0.2019108899353362 0.2017884750642797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch >>  762 0.2017884750642797 0.033983960379031466 0.16780451468524948\n",
      "Saving the model  0.2017884750642797 0.2017011359967944\n",
      "Epoch >>  763 0.2017011359967944 0.03397750170780901 0.1677236342889866\n",
      "Saving the model  0.2017011359967944 0.2016288550321379\n",
      "Epoch >>  764 0.2016288550321379 0.03397099192380904 0.16765786310833014\n",
      "Epoch >>  765 0.20163111605571776 0.03396587003547659 0.16766524602024258\n",
      "Saving the model  0.2016288550321379 0.20157283759992475\n",
      "Epoch >>  766 0.20157283759992475 0.03395982321425015 0.16761301438567638\n",
      "Saving the model  0.20157283759992475 0.2014906223008642\n",
      "Epoch >>  767 0.2014906223008642 0.03395409763535073 0.16753652466551525\n",
      "Saving the model  0.2014906223008642 0.20144421368174684\n",
      "Epoch >>  768 0.20144421368174684 0.03394708569328398 0.16749712798846467\n",
      "Saving the model  0.20144421368174684 0.20134124004608467\n",
      "Epoch >>  769 0.20134124004608467 0.03394217636031313 0.16739906368577348\n",
      "Saving the model  0.20134124004608467 0.2012830515018036\n",
      "Epoch >>  770 0.2012830515018036 0.033937760821386415 0.16734529068041928\n",
      "Saving the model  0.2012830515018036 0.201218263287268\n",
      "Epoch >>  771 0.201218263287268 0.03393213031256221 0.167286132974708\n",
      "Saving the model  0.201218263287268 0.20114298594827099\n",
      "Epoch >>  772 0.20114298594827099 0.03392647687689048 0.1672165090713825\n",
      "Saving the model  0.20114298594827099 0.20102955242252638\n",
      "Epoch >>  773 0.20102955242252638 0.03392072707847345 0.16710882534405488\n",
      "Saving the model  0.20102955242252638 0.20095943999078433\n",
      "Epoch >>  774 0.20095943999078433 0.033915345656458575 0.16704409433432765\n",
      "Saving the model  0.20095943999078433 0.20094099943484636\n",
      "Epoch >>  775 0.20094099943484636 0.03391065961353176 0.16703033982131668\n",
      "Saving the model  0.20094099943484636 0.20083380880620672\n",
      "Epoch >>  776 0.20083380880620672 0.03390458699934078 0.16692922180686795\n",
      "Saving the model  0.20083380880620672 0.20077934803608996\n",
      "Epoch >>  777 0.20077934803608996 0.03389904318838351 0.16688030484770822\n",
      "Saving the model  0.20077934803608996 0.2006806397527249\n",
      "Epoch >>  778 0.2006806397527249 0.033892824404431185 0.16678781534829568\n",
      "Saving the model  0.2006806397527249 0.20064446703697086\n",
      "Epoch >>  779 0.20064446703697086 0.03388774648087026 0.1667567205561023\n",
      "Saving the model  0.20064446703697086 0.20056318962911643\n",
      "Epoch >>  780 0.20056318962911643 0.03388165738346559 0.16668153224565255\n",
      "Saving the model  0.20056318962911643 0.20046334792028822\n",
      "Epoch >>  781 0.20046334792028822 0.033875881359226735 0.16658746656106332\n",
      "Saving the model  0.20046334792028822 0.20039655901853723\n",
      "Epoch >>  782 0.20039655901853723 0.033869464978266275 0.16652709404027286\n",
      "Saving the model  0.20039655901853723 0.2003351578539046\n",
      "Epoch >>  783 0.2003351578539046 0.03386363220956308 0.16647152564434345\n",
      "Saving the model  0.2003351578539046 0.20025101958484157\n",
      "Epoch >>  784 0.20025101958484157 0.033857306343679755 0.16639371324116375\n",
      "Saving the model  0.20025101958484157 0.20018564172659128\n",
      "Epoch >>  785 0.20018564172659128 0.033852209459389444 0.16633343226720385\n",
      "Saving the model  0.20018564172659128 0.20011798036410514\n",
      "Epoch >>  786 0.20011798036410514 0.03384787367252761 0.1662701066915796\n",
      "Saving the model  0.20011798036410514 0.20004510504326872\n",
      "Epoch >>  787 0.20004510504326872 0.033842529218801674 0.16620257582446912\n",
      "Saving the model  0.20004510504326872 0.1999326326135916\n",
      "Epoch >>  788 0.1999326326135916 0.03383616997040873 0.1660964626431853\n",
      "Saving the model  0.1999326326135916 0.19984050007162335\n",
      "Epoch >>  789 0.19984050007162335 0.0338298499018156 0.16601065016981023\n",
      "Epoch >>  790 0.1998482349534385 0.03382464490378864 0.16602359004965253\n",
      "Saving the model  0.19984050007162335 0.1997731871599758\n",
      "Epoch >>  791 0.1997731871599758 0.033819296545156315 0.1659538906148218\n",
      "Saving the model  0.1997731871599758 0.19971010959814525\n",
      "Epoch >>  792 0.19971010959814525 0.033813064330215616 0.16589704526793178\n",
      "Saving the model  0.19971010959814525 0.19969399601877472\n",
      "Epoch >>  793 0.19969399601877472 0.03380795444392888 0.16588604157484765\n",
      "Saving the model  0.19969399601877472 0.1996584994802897\n",
      "Epoch >>  794 0.1996584994802897 0.03380275502221004 0.16585574445808163\n",
      "Saving the model  0.1996584994802897 0.19958402355815183\n",
      "Epoch >>  795 0.19958402355815183 0.03379633958451454 0.1657876839736395\n",
      "Saving the model  0.19958402355815183 0.19952202713216552\n",
      "Epoch >>  796 0.19952202713216552 0.03379020691319142 0.16573182021897626\n",
      "Saving the model  0.19952202713216552 0.19947704672303015\n",
      "Epoch >>  797 0.19947704672303015 0.033785094794437476 0.16569195192859493\n",
      "Saving the model  0.19947704672303015 0.19942775966347098\n",
      "Epoch >>  798 0.19942775966347098 0.03377959657776234 0.16564816308571076\n",
      "Saving the model  0.19942775966347098 0.19936252626996354\n",
      "Epoch >>  799 0.19936252626996354 0.03377323905688255 0.16558928721308308\n",
      "Saving the model  0.19936252626996354 0.19930887224472318\n",
      "Epoch >>  800 0.19930887224472318 0.03376779037524023 0.1655410818694851\n",
      "Saving the model  0.19930887224472318 0.19925537068242877\n",
      "Epoch >>  801 0.19925537068242877 0.0337637523445779 0.16549161833785278\n",
      "Saving the model  0.19925537068242877 0.19916538414584478\n",
      "Epoch >>  802 0.19916538414584478 0.03375790320952386 0.16540748093632296\n",
      "Saving the model  0.19916538414584478 0.19913097260533422\n",
      "Epoch >>  803 0.19913097260533422 0.033752909015334516 0.16537806359000182\n",
      "Saving the model  0.19913097260533422 0.19907656910841678\n",
      "Epoch >>  804 0.19907656910841678 0.03374725527505105 0.16532931383336755\n",
      "Saving the model  0.19907656910841678 0.1990266620295233\n",
      "Epoch >>  805 0.1990266620295233 0.033741828114666764 0.16528483391485863\n",
      "Saving the model  0.1990266620295233 0.19896916569332204\n",
      "Epoch >>  806 0.19896916569332204 0.033736743595196475 0.16523242209812808\n",
      "Saving the model  0.19896916569332204 0.19890230774927176\n",
      "Epoch >>  807 0.19890230774927176 0.03373118388455376 0.1651711238647203\n",
      "Saving the model  0.19890230774927176 0.19885723494415836\n",
      "Epoch >>  808 0.19885723494415836 0.033726024207455615 0.16513121073670495\n",
      "Saving the model  0.19885723494415836 0.19877543094384445\n",
      "Epoch >>  809 0.19877543094384445 0.033720604921554063 0.16505482602229213\n",
      "Saving the model  0.19877543094384445 0.19874977245156886\n",
      "Epoch >>  810 0.19874977245156886 0.03371561589276933 0.16503415655880135\n",
      "Saving the model  0.19874977245156886 0.1987125913481086\n",
      "Epoch >>  811 0.1987125913481086 0.03371008335577156 0.16500250799233926\n",
      "Saving the model  0.1987125913481086 0.19868664021391574\n",
      "Epoch >>  812 0.19868664021391574 0.03370457141309996 0.16498206880081784\n",
      "Saving the model  0.19868664021391574 0.19862838615014053\n",
      "Epoch >>  813 0.19862838615014053 0.03369879226956023 0.1649295938805826\n",
      "Saving the model  0.19862838615014053 0.19857673797835287\n",
      "Epoch >>  814 0.19857673797835287 0.03369288296161952 0.1648838550167359\n",
      "Saving the model  0.19857673797835287 0.198559696851926\n",
      "Epoch >>  815 0.198559696851926 0.033688260683746314 0.1648714361681822\n",
      "Saving the model  0.198559696851926 0.198494493605\n",
      "Epoch >>  816 0.198494493605 0.03368223098552038 0.16481226261948215\n",
      "Saving the model  0.198494493605 0.19843314225062234\n",
      "Epoch >>  817 0.19843314225062234 0.03367688343082511 0.16475625881979952\n",
      "Saving the model  0.19843314225062234 0.1983658033247517\n",
      "Epoch >>  818 0.1983658033247517 0.033671613761189816 0.16469418956356405\n",
      "Saving the model  0.1983658033247517 0.19826029018879635\n",
      "Epoch >>  819 0.19826029018879635 0.03366516763278198 0.16459512255601663\n",
      "Saving the model  0.19826029018879635 0.19817682165915373\n",
      "Epoch >>  820 0.19817682165915373 0.033659775128613775 0.16451704653054214\n",
      "Saving the model  0.19817682165915373 0.19810136817367138\n",
      "Epoch >>  821 0.19810136817367138 0.033653392855393684 0.16444797531827995\n",
      "Saving the model  0.19810136817367138 0.1980534217723313\n",
      "Epoch >>  822 0.1980534217723313 0.033648560800315086 0.16440486097201834\n",
      "Saving the model  0.1980534217723313 0.19797177735352534\n",
      "Epoch >>  823 0.19797177735352534 0.0336425444937514 0.1643292328597757\n",
      "Saving the model  0.19797177735352534 0.19789570703370138\n",
      "Epoch >>  824 0.19789570703370138 0.03363717973223367 0.1642585273014695\n",
      "Saving the model  0.19789570703370138 0.1978209086621695\n",
      "Epoch >>  825 0.1978209086621695 0.03363212592782465 0.1641887827343466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.1978209086621695 0.1977762888388476\n",
      "Epoch >>  826 0.1977762888388476 0.03362695149654194 0.1641493373423073\n",
      "Saving the model  0.1977762888388476 0.1977326280726302\n",
      "Epoch >>  827 0.1977326280726302 0.03362168410138439 0.16411094397124748\n",
      "Saving the model  0.1977326280726302 0.19770716975506497\n",
      "Epoch >>  828 0.19770716975506497 0.03361641831424341 0.16409075144082327\n",
      "Saving the model  0.19770716975506497 0.19764589608124125\n",
      "Epoch >>  829 0.19764589608124125 0.033610716207443304 0.16403517987379965\n",
      "Saving the model  0.19764589608124125 0.19760379994056557\n",
      "Epoch >>  830 0.19760379994056557 0.033606547240284584 0.16399725270028262\n",
      "Saving the model  0.19760379994056557 0.19751171807548784\n",
      "Epoch >>  831 0.19751171807548784 0.03360097908123995 0.16391073899424963\n",
      "Saving the model  0.19751171807548784 0.1974776205002255\n",
      "Epoch >>  832 0.1974776205002255 0.03359640999289494 0.16388121050733215\n",
      "Saving the model  0.1974776205002255 0.19745385662462728\n",
      "Epoch >>  833 0.19745385662462728 0.03359197231344062 0.16386188431118814\n",
      "Saving the model  0.19745385662462728 0.1973830031906601\n",
      "Epoch >>  834 0.1973830031906601 0.03358620334490936 0.16379679984575218\n",
      "Saving the model  0.1973830031906601 0.1973029994321843\n",
      "Epoch >>  835 0.1973029994321843 0.033581068429965895 0.16372193100221996\n",
      "Saving the model  0.1973029994321843 0.19725029222086915\n",
      "Epoch >>  836 0.19725029222086915 0.03357625649102819 0.16367403572984274\n",
      "Saving the model  0.19725029222086915 0.1971689528313079\n",
      "Epoch >>  837 0.1971689528313079 0.033570698780052775 0.16359825405125697\n",
      "Saving the model  0.1971689528313079 0.1970956647743033\n",
      "Epoch >>  838 0.1970956647743033 0.03356551147380325 0.16353015330050186\n",
      "Saving the model  0.1970956647743033 0.19702945817942613\n",
      "Epoch >>  839 0.19702945817942613 0.03356034019219604 0.1634691179872318\n",
      "Saving the model  0.19702945817942613 0.19702520104731136\n",
      "Epoch >>  840 0.19702520104731136 0.03355540112320047 0.1634697999241126\n",
      "Saving the model  0.19702520104731136 0.19695750987093563\n",
      "Epoch >>  841 0.19695750987093563 0.03355002367057568 0.16340748620036175\n",
      "Saving the model  0.19695750987093563 0.1968729806970774\n",
      "Epoch >>  842 0.1968729806970774 0.03354437619906043 0.16332860449801867\n",
      "Saving the model  0.1968729806970774 0.19682309989611868\n",
      "Epoch >>  843 0.19682309989611868 0.03353897779992815 0.16328412209619228\n",
      "Saving the model  0.19682309989611868 0.19676715945275336\n",
      "Epoch >>  844 0.19676715945275336 0.03353373207634117 0.16323342737641394\n",
      "Epoch >>  845 0.19680448178959192 0.03352876133763023 0.16327572045196337\n",
      "Saving the model  0.19676715945275336 0.19675695863564416\n",
      "Epoch >>  846 0.19675695863564416 0.03352394567835946 0.16323301295728648\n",
      "Saving the model  0.19675695863564416 0.19668565383895356\n",
      "Epoch >>  847 0.19668565383895356 0.03351862583548606 0.16316702800346897\n",
      "Saving the model  0.19668565383895356 0.1966246685259989\n",
      "Epoch >>  848 0.1966246685259989 0.033513008118232775 0.1631116604077676\n",
      "Saving the model  0.1966246685259989 0.19654854693258078\n",
      "Epoch >>  849 0.19654854693258078 0.03350694850557181 0.1630415984270102\n",
      "Saving the model  0.19654854693258078 0.19652159832285315\n",
      "Epoch >>  850 0.19652159832285315 0.0335026269632193 0.16301897135963514\n",
      "Saving the model  0.19652159832285315 0.19648543611185465\n",
      "Epoch >>  851 0.19648543611185465 0.03349729139610034 0.1629881447157558\n",
      "Saving the model  0.19648543611185465 0.19643954374874528\n",
      "Epoch >>  852 0.19643954374874528 0.03349234799132784 0.16294719575741884\n",
      "Saving the model  0.19643954374874528 0.1964118577170348\n",
      "Epoch >>  853 0.1964118577170348 0.03348827516804297 0.16292358254899314\n",
      "Saving the model  0.1964118577170348 0.19634176501876688\n",
      "Epoch >>  854 0.19634176501876688 0.03348326963983048 0.16285849537893746\n",
      "Saving the model  0.19634176501876688 0.19626193993843774\n",
      "Epoch >>  855 0.19626193993843774 0.033478397642220215 0.16278354229621816\n",
      "Saving the model  0.19626193993843774 0.1962155698809307\n",
      "Epoch >>  856 0.1962155698809307 0.03347279270347152 0.1627427771774597\n",
      "Saving the model  0.1962155698809307 0.19616210999192382\n",
      "Epoch >>  857 0.19616210999192382 0.03346939543059715 0.16269271456132728\n",
      "Saving the model  0.19616210999192382 0.19608850279275308\n",
      "Epoch >>  858 0.19608850279275308 0.03346455270215158 0.16262395009060193\n",
      "Saving the model  0.19608850279275308 0.19603617175252638\n",
      "Epoch >>  859 0.19603617175252638 0.03345929255114475 0.16257687920138217\n",
      "Saving the model  0.19603617175252638 0.19601147246229036\n",
      "Epoch >>  860 0.19601147246229036 0.03345504629866425 0.1625564261636267\n",
      "Saving the model  0.19601147246229036 0.19595454597650952\n",
      "Epoch >>  861 0.19595454597650952 0.033449637190216416 0.1625049087862937\n",
      "Saving the model  0.19595454597650952 0.1959043060816072\n",
      "Epoch >>  862 0.1959043060816072 0.033444561232881476 0.16245974484872633\n",
      "Saving the model  0.1959043060816072 0.1958480312064451\n",
      "Epoch >>  863 0.1958480312064451 0.0334387482127882 0.16240928299365742\n",
      "Saving the model  0.1958480312064451 0.1957632588626731\n",
      "Epoch >>  864 0.1957632588626731 0.03343321212076523 0.16233004674190846\n",
      "Saving the model  0.1957632588626731 0.1956887648704189\n",
      "Epoch >>  865 0.1956887648704189 0.03342773082540656 0.16226103404501327\n",
      "Saving the model  0.1956887648704189 0.19566758110897223\n",
      "Epoch >>  866 0.19566758110897223 0.03342287157223775 0.16224470953673553\n",
      "Saving the model  0.19566758110897223 0.19557500248813636\n",
      "Epoch >>  867 0.19557500248813636 0.03341791122022425 0.16215709126791292\n",
      "Saving the model  0.19557500248813636 0.19556757482048523\n",
      "Epoch >>  868 0.19556757482048523 0.033412317844189056 0.1621552569762969\n",
      "Saving the model  0.19556757482048523 0.19552676783498923\n",
      "Epoch >>  869 0.19552676783498923 0.03340716800549391 0.162119599829496\n",
      "Saving the model  0.19552676783498923 0.19551573890783083\n",
      "Epoch >>  870 0.19551573890783083 0.033402231986674524 0.16211350692115684\n",
      "Saving the model  0.19551573890783083 0.19543422693943532\n",
      "Epoch >>  871 0.19543422693943532 0.03339845420058981 0.16203577273884595\n",
      "Saving the model  0.19543422693943532 0.19539662851924297\n",
      "Epoch >>  872 0.19539662851924297 0.033393858932481875 0.16200276958676138\n",
      "Saving the model  0.19539662851924297 0.19534339344611437\n",
      "Epoch >>  873 0.19534339344611437 0.033388528887148695 0.16195486455896624\n",
      "Saving the model  0.19534339344611437 0.19530043360107982\n",
      "Epoch >>  874 0.19530043360107982 0.033383037892201144 0.16191739570887922\n",
      "Saving the model  0.19530043360107982 0.19527455053362433\n",
      "Epoch >>  875 0.19527455053362433 0.03337868654192688 0.161895863991698\n",
      "Saving the model  0.19527455053362433 0.19520544217026517\n",
      "Epoch >>  876 0.19520544217026517 0.03337331190406539 0.16183213026620016\n",
      "Saving the model  0.19520544217026517 0.19517798649186283\n",
      "Epoch >>  877 0.19517798649186283 0.0333682610383459 0.1618097254535175\n",
      "Saving the model  0.19517798649186283 0.1951278289532014\n",
      "Epoch >>  878 0.1951278289532014 0.033363195461044354 0.16176463349215772\n",
      "Saving the model  0.1951278289532014 0.19510857138297047\n",
      "Epoch >>  879 0.19510857138297047 0.03335734284224728 0.16175122854072388\n",
      "Saving the model  0.19510857138297047 0.19505963979232188\n",
      "Epoch >>  880 0.19505963979232188 0.03335257927573453 0.16170706051658812\n",
      "Saving the model  0.19505963979232188 0.19500178123041031\n",
      "Epoch >>  881 0.19500178123041031 0.033347655503735085 0.16165412572667617\n",
      "Saving the model  0.19500178123041031 0.19497089312388197\n",
      "Epoch >>  882 0.19497089312388197 0.03334327988605264 0.16162761323783037\n",
      "Epoch >>  883 0.1949863577492611 0.03334038938564496 0.16164596836361714\n",
      "Saving the model  0.19497089312388197 0.19492019567376856\n",
      "Epoch >>  884 0.19492019567376856 0.03333539981928964 0.16158479585447996\n",
      "Saving the model  0.19492019567376856 0.1948708354204318\n",
      "Epoch >>  885 0.1948708354204318 0.03333047812655489 0.16154035729387817\n",
      "Saving the model  0.1948708354204318 0.19481387329903319\n",
      "Epoch >>  886 0.19481387329903319 0.03332457479173336 0.16148929850730118\n",
      "Saving the model  0.19481387329903319 0.1947567404690228\n",
      "Epoch >>  887 0.1947567404690228 0.0333191017833703 0.1614376386856538\n",
      "Saving the model  0.1947567404690228 0.1947008069322488\n",
      "Epoch >>  888 0.1947008069322488 0.03331413969151349 0.16138666724073675\n",
      "Saving the model  0.1947008069322488 0.19467871728837172\n",
      "Epoch >>  889 0.19467871728837172 0.033309618908883704 0.16136909837948926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.19467871728837172 0.1946517850398231\n",
      "Epoch >>  890 0.1946517850398231 0.033305261350065736 0.1613465236897587\n",
      "Saving the model  0.1946517850398231 0.19455819873922064\n",
      "Epoch >>  891 0.19455819873922064 0.033300268228466066 0.16125793051075582\n",
      "Saving the model  0.19455819873922064 0.19450947145061356\n",
      "Epoch >>  892 0.19450947145061356 0.033295135560937966 0.1612143358896766\n",
      "Saving the model  0.19450947145061356 0.19442492928122646\n",
      "Epoch >>  893 0.19442492928122646 0.033289839423336715 0.16113508985789063\n",
      "Saving the model  0.19442492928122646 0.19437336113996762\n",
      "Epoch >>  894 0.19437336113996762 0.0332854622169634 0.1610878989230053\n",
      "Saving the model  0.19437336113996762 0.1943286128353666\n",
      "Epoch >>  895 0.1943286128353666 0.03328051108825318 0.1610481017471147\n",
      "Saving the model  0.1943286128353666 0.19427011285588283\n",
      "Epoch >>  896 0.19427011285588283 0.03327561517931308 0.16099449767657095\n",
      "Saving the model  0.19427011285588283 0.19422488830878937\n",
      "Epoch >>  897 0.19422488830878937 0.033269970242540456 0.1609549180662498\n",
      "Saving the model  0.19422488830878937 0.19415275619665995\n",
      "Epoch >>  898 0.19415275619665995 0.03326477626893894 0.16088797992772205\n",
      "Epoch >>  899 0.19416029949382807 0.03326062898635571 0.1608996705074732\n",
      "Saving the model  0.19415275619665995 0.19412518485030472\n",
      "Epoch >>  900 0.19412518485030472 0.033256078325470534 0.160869106524835\n",
      "Saving the model  0.19412518485030472 0.19410090326925064\n",
      "Epoch >>  901 0.19410090326925064 0.033251334037907816 0.1608495692313436\n",
      "Saving the model  0.19410090326925064 0.194055514969916\n",
      "Epoch >>  902 0.194055514969916 0.03324642552547492 0.16080908944444194\n",
      "Saving the model  0.194055514969916 0.19403036982967606\n",
      "Epoch >>  903 0.19403036982967606 0.033241476858173725 0.1607888929715031\n",
      "Saving the model  0.19403036982967606 0.19395289749294004\n",
      "Epoch >>  904 0.19395289749294004 0.033236571197767094 0.16071632629517374\n",
      "Saving the model  0.19395289749294004 0.19392304412647993\n",
      "Epoch >>  905 0.19392304412647993 0.03323217598841807 0.16069086813806252\n",
      "Saving the model  0.19392304412647993 0.19387184907095573\n",
      "Epoch >>  906 0.19387184907095573 0.033227633817392244 0.1606442152535641\n",
      "Epoch >>  907 0.19387302648013627 0.03322305347128556 0.16064997300885137\n",
      "Saving the model  0.19387184907095573 0.1937978380390948\n",
      "Epoch >>  908 0.1937978380390948 0.03321765191991151 0.16058018611918404\n",
      "Saving the model  0.1937978380390948 0.19376068073015976\n",
      "Epoch >>  909 0.19376068073015976 0.03321256711327537 0.160548113616885\n",
      "Saving the model  0.19376068073015976 0.19372739217380422\n",
      "Epoch >>  910 0.19372739217380422 0.033207903538524895 0.16051948863528\n",
      "Saving the model  0.19372739217380422 0.19368103089466657\n",
      "Epoch >>  911 0.19368103089466657 0.033203120829619466 0.16047791006504794\n",
      "Epoch >>  912 0.19368796368281854 0.03319870837351834 0.1604892553093009\n",
      "Saving the model  0.19368103089466657 0.19362795475752126\n",
      "Epoch >>  913 0.19362795475752126 0.03319399485838883 0.160433959899133\n",
      "Saving the model  0.19362795475752126 0.19360656014571948\n",
      "Epoch >>  914 0.19360656014571948 0.03318881185032745 0.16041774829539265\n",
      "Saving the model  0.19360656014571948 0.1935434595261391\n",
      "Epoch >>  915 0.1935434595261391 0.033183426181804296 0.16036003334433552\n",
      "Saving the model  0.1935434595261391 0.19347409250409753\n",
      "Epoch >>  916 0.19347409250409753 0.03317864706559659 0.16029544543850166\n",
      "Saving the model  0.19347409250409753 0.19341600023495495\n",
      "Epoch >>  917 0.19341600023495495 0.033173677910717576 0.1602423223242381\n",
      "Saving the model  0.19341600023495495 0.19334508121895586\n",
      "Epoch >>  918 0.19334508121895586 0.033168415799519194 0.16017666541943734\n",
      "Saving the model  0.19334508121895586 0.1933347271944297\n",
      "Epoch >>  919 0.1933347271944297 0.03316422420197193 0.16017050299245808\n",
      "Epoch >>  920 0.19334325481459694 0.03315965948721162 0.16018359532738594\n",
      "Saving the model  0.1933347271944297 0.19329525539484252\n",
      "Epoch >>  921 0.19329525539484252 0.03315490836264079 0.16014034703220242\n",
      "Saving the model  0.19329525539484252 0.19323347785360964\n",
      "Epoch >>  922 0.19323347785360964 0.03315035685796277 0.16008312099564742\n",
      "Saving the model  0.19323347785360964 0.19319512833977848\n",
      "Epoch >>  923 0.19319512833977848 0.033145705573993524 0.16004942276578554\n",
      "Saving the model  0.19319512833977848 0.19314640291252774\n",
      "Epoch >>  924 0.19314640291252774 0.033140499260055654 0.1600059036524726\n",
      "Saving the model  0.19314640291252774 0.19309708874976877\n",
      "Epoch >>  925 0.19309708874976877 0.033135655900754124 0.15996143284901515\n",
      "Saving the model  0.19309708874976877 0.19307308036921128\n",
      "Epoch >>  926 0.19307308036921128 0.033130655952420714 0.15994242441679074\n",
      "Saving the model  0.19307308036921128 0.19301832360742657\n",
      "Epoch >>  927 0.19301832360742657 0.03312514957032259 0.15989317403710404\n",
      "Saving the model  0.19301832360742657 0.19295083529315207\n",
      "Epoch >>  928 0.19295083529315207 0.03312007314401069 0.15983076214914171\n",
      "Saving the model  0.19295083529315207 0.1928839182182331\n",
      "Epoch >>  929 0.1928839182182331 0.033114952582180855 0.15976896563605275\n",
      "Saving the model  0.1928839182182331 0.19280746845536598\n",
      "Epoch >>  930 0.19280746845536598 0.03310979330006297 0.15969767515530353\n",
      "Saving the model  0.19280746845536598 0.1927649640652475\n",
      "Epoch >>  931 0.1927649640652475 0.033104830641964754 0.15966013342328342\n",
      "Saving the model  0.1927649640652475 0.19268827770725053\n",
      "Epoch >>  932 0.19268827770725053 0.03309918997542569 0.15958908773182578\n",
      "Saving the model  0.19268827770725053 0.19261629630562713\n",
      "Epoch >>  933 0.19261629630562713 0.033094007851558686 0.15952228845406963\n",
      "Saving the model  0.19261629630562713 0.19256321555016442\n",
      "Epoch >>  934 0.19256321555016442 0.033088973673060997 0.15947424187710468\n",
      "Saving the model  0.19256321555016442 0.19248588413534162\n",
      "Epoch >>  935 0.19248588413534162 0.03308461442292703 0.1594012697124157\n",
      "Saving the model  0.19248588413534162 0.19241995982084104\n",
      "Epoch >>  936 0.19241995982084104 0.03307951426438783 0.15934044555645435\n",
      "Saving the model  0.19241995982084104 0.19238013784816801\n",
      "Epoch >>  937 0.19238013784816801 0.033075114373608175 0.15930502347456096\n",
      "Saving the model  0.19238013784816801 0.19233021600956735\n",
      "Epoch >>  938 0.19233021600956735 0.03306983350661559 0.15926038250295318\n",
      "Saving the model  0.19233021600956735 0.19226851745299847\n",
      "Epoch >>  939 0.19226851745299847 0.03306481530702783 0.1592037021459721\n",
      "Saving the model  0.19226851745299847 0.1922058378605868\n",
      "Epoch >>  940 0.1922058378605868 0.03305997044684015 0.159145867413748\n",
      "Saving the model  0.1922058378605868 0.19212815394561383\n",
      "Epoch >>  941 0.19212815394561383 0.03305450839297587 0.15907364555263945\n",
      "Saving the model  0.19212815394561383 0.1921154843507359\n",
      "Epoch >>  942 0.1921154843507359 0.03304947837802974 0.1590660059727078\n",
      "Saving the model  0.1921154843507359 0.19205492517863593\n",
      "Epoch >>  943 0.19205492517863593 0.03304497914988918 0.15900994602874835\n",
      "Saving the model  0.19205492517863593 0.19198986605466395\n",
      "Epoch >>  944 0.19198986605466395 0.03304060263658485 0.15894926341808063\n",
      "Saving the model  0.19198986605466395 0.1919469277730551\n",
      "Epoch >>  945 0.1919469277730551 0.033036144958682345 0.15891078281437448\n",
      "Saving the model  0.1919469277730551 0.19189379192117595\n",
      "Epoch >>  946 0.19189379192117595 0.03303186267844441 0.15886192924273326\n",
      "Saving the model  0.19189379192117595 0.19182327037287136\n",
      "Epoch >>  947 0.19182327037287136 0.03302669540084756 0.15879657497202548\n",
      "Saving the model  0.19182327037287136 0.19175392925493198\n",
      "Epoch >>  948 0.19175392925493198 0.03302174062659718 0.15873218862833646\n",
      "Saving the model  0.19175392925493198 0.19170669540289267\n",
      "Epoch >>  949 0.19170669540289267 0.03301742826316902 0.1586892671397253\n",
      "Saving the model  0.19170669540289267 0.19163944422022697\n",
      "Epoch >>  950 0.19163944422022697 0.03301265434680437 0.158626789873424\n",
      "Saving the model  0.19163944422022697 0.19160026328999746\n",
      "Epoch >>  951 0.19160026328999746 0.03300797651738669 0.1585922867726121\n",
      "Saving the model  0.19160026328999746 0.19158745286396803\n",
      "Epoch >>  952 0.19158745286396803 0.03300386504657943 0.15858358781739001\n",
      "Saving the model  0.19158745286396803 0.19155344756070156\n",
      "Epoch >>  953 0.19155344756070156 0.03299928310684577 0.1585541644538571\n",
      "Saving the model  0.19155344756070156 0.19153238422953825\n",
      "Epoch >>  954 0.19153238422953825 0.032995568105097274 0.1585368161244422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.19153238422953825 0.19148997000684578\n",
      "Epoch >>  955 0.19148997000684578 0.0329907815179234 0.15849918848892358\n",
      "Saving the model  0.19148997000684578 0.19142136607298313\n",
      "Epoch >>  956 0.19142136607298313 0.03298635652296736 0.15843500955001713\n",
      "Saving the model  0.19142136607298313 0.19140656036156806\n",
      "Epoch >>  957 0.19140656036156806 0.03298221611507893 0.15842434424649063\n",
      "Saving the model  0.19140656036156806 0.1913544140245529\n",
      "Epoch >>  958 0.1913544140245529 0.03297715864260213 0.1583772553819523\n",
      "Saving the model  0.1913544140245529 0.1913319418335954\n",
      "Epoch >>  959 0.1913319418335954 0.03297241271148205 0.15835952912211493\n",
      "Saving the model  0.1913319418335954 0.1912546928265985\n",
      "Epoch >>  960 0.1912546928265985 0.03296703262010035 0.15828766020649968\n",
      "Saving the model  0.1912546928265985 0.1912498608535854\n",
      "Epoch >>  961 0.1912498608535854 0.03296351830961308 0.15828634254397372\n",
      "Saving the model  0.1912498608535854 0.1911976166232965\n",
      "Epoch >>  962 0.1911976166232965 0.032959334031782646 0.15823828259151554\n",
      "Saving the model  0.1911976166232965 0.19115290388306294\n",
      "Epoch >>  963 0.19115290388306294 0.03295449722913489 0.15819840665392948\n",
      "Saving the model  0.19115290388306294 0.19109529393923838\n",
      "Epoch >>  964 0.19109529393923838 0.0329499385403302 0.15814535539890953\n",
      "Saving the model  0.19109529393923838 0.19105697005896016\n",
      "Epoch >>  965 0.19105697005896016 0.03294502457096907 0.15811194548799268\n",
      "Saving the model  0.19105697005896016 0.19101692663032607\n",
      "Epoch >>  966 0.19101692663032607 0.03294045654463857 0.15807647008568917\n",
      "Saving the model  0.19101692663032607 0.19098535188876367\n",
      "Epoch >>  967 0.19098535188876367 0.03293599197742035 0.1580493599113449\n",
      "Saving the model  0.19098535188876367 0.19091038294475451\n",
      "Epoch >>  968 0.19091038294475451 0.03293075172790341 0.15797963121685257\n",
      "Saving the model  0.19091038294475451 0.19084355677288412\n",
      "Epoch >>  969 0.19084355677288412 0.03292694298334388 0.15791661378954183\n",
      "Epoch >>  970 0.1908570276784841 0.03292260603250611 0.15793442164597948\n",
      "Saving the model  0.19084355677288412 0.19081707956728913\n",
      "Epoch >>  971 0.19081707956728913 0.032917833931194 0.15789924563609659\n",
      "Saving the model  0.19081707956728913 0.19077258839743141\n",
      "Epoch >>  972 0.19077258839743141 0.03291369167802858 0.15785889671940428\n",
      "Saving the model  0.19077258839743141 0.19073591917538785\n",
      "Epoch >>  973 0.19073591917538785 0.03290908976339213 0.15782682941199702\n",
      "Saving the model  0.19073591917538785 0.19067317853635005\n",
      "Epoch >>  974 0.19067317853635005 0.03290461685396911 0.15776856168238232\n",
      "Saving the model  0.19067317853635005 0.19060632969603694\n",
      "Epoch >>  975 0.19060632969603694 0.03289908913685954 0.15770724055917867\n",
      "Saving the model  0.19060632969603694 0.19056298402055716\n",
      "Epoch >>  976 0.19056298402055716 0.03289361664874233 0.15766936737181592\n",
      "Saving the model  0.19056298402055716 0.19049344015893233\n",
      "Epoch >>  977 0.19049344015893233 0.032888396525014685 0.15760504363391883\n",
      "Epoch >>  978 0.19053327704871914 0.03288476374342078 0.15764851330529955\n",
      "Epoch >>  979 0.1904951723347159 0.032879829309788396 0.15761534302492877\n",
      "Saving the model  0.19049344015893233 0.19045212165680844\n",
      "Epoch >>  980 0.19045212165680844 0.032875294843664686 0.15757682681314514\n",
      "Saving the model  0.19045212165680844 0.1904110045476745\n",
      "Epoch >>  981 0.1904110045476745 0.03287047440690144 0.1575405301407745\n",
      "Saving the model  0.1904110045476745 0.19037181123706032\n",
      "Epoch >>  982 0.19037181123706032 0.03286599298013892 0.1575058182569225\n",
      "Saving the model  0.19037181123706032 0.19031132903487805\n",
      "Epoch >>  983 0.19031132903487805 0.032861041732320746 0.15745028730255853\n",
      "Saving the model  0.19031132903487805 0.1902470197033858\n",
      "Epoch >>  984 0.1902470197033858 0.0328567225766146 0.15739029712677238\n",
      "Saving the model  0.1902470197033858 0.1902294939004179\n",
      "Epoch >>  985 0.1902294939004179 0.03285197636999854 0.15737751753042056\n",
      "Saving the model  0.1902294939004179 0.1901764846607303\n",
      "Epoch >>  986 0.1901764846607303 0.03284725248326295 0.15732923217746841\n",
      "Epoch >>  987 0.19018467193244334 0.03284303754447905 0.15734163438796545\n",
      "Saving the model  0.1901764846607303 0.1900983320894238\n",
      "Epoch >>  988 0.1900983320894238 0.032837458856115005 0.15726087323330962\n",
      "Saving the model  0.1900983320894238 0.1900515155799209\n",
      "Epoch >>  989 0.1900515155799209 0.03283318231789863 0.1572183332620229\n",
      "Saving the model  0.1900515155799209 0.18997999954893477\n",
      "Epoch >>  990 0.18997999954893477 0.03282851877562109 0.15715148077331398\n",
      "Saving the model  0.18997999954893477 0.18992442122856215\n",
      "Epoch >>  991 0.18992442122856215 0.03282456986906153 0.157099851359501\n",
      "Saving the model  0.18992442122856215 0.1898822015607059\n",
      "Epoch >>  992 0.1898822015607059 0.03281970877133194 0.1570624927893741\n",
      "Saving the model  0.1898822015607059 0.18985019122471744\n",
      "Epoch >>  993 0.18985019122471744 0.0328150413976174 0.1570351498271003\n",
      "Saving the model  0.18985019122471744 0.18982217675178123\n",
      "Epoch >>  994 0.18982217675178123 0.03281072877801009 0.15701144797377134\n",
      "Saving the model  0.18982217675178123 0.18976761043248488\n",
      "Epoch >>  995 0.18976761043248488 0.032806791167120444 0.15696081926536465\n",
      "Saving the model  0.18976761043248488 0.18970396474868778\n",
      "Epoch >>  996 0.18970396474868778 0.03280210879139419 0.1569018559572937\n",
      "Saving the model  0.18970396474868778 0.18966145163261766\n",
      "Epoch >>  997 0.18966145163261766 0.032797949973426235 0.15686350165919155\n",
      "Saving the model  0.18966145163261766 0.1895906547593882\n",
      "Epoch >>  998 0.1895906547593882 0.0327928275997039 0.15679782715968446\n",
      "Saving the model  0.1895906547593882 0.1895838738841476\n",
      "Epoch >>  999 0.1895838738841476 0.03278855265123971 0.15679532123290812\n",
      "Saving the model  0.1895838738841476 0.18953277459448117\n",
      "Epoch >>  1000 0.18953277459448117 0.03278374630665979 0.1567490282878217\n",
      "Saving the model  0.18953277459448117 0.18949485146238573\n",
      "Epoch >>  1001 0.18949485146238573 0.03277975031691065 0.15671510114547554\n",
      "Saving the model  0.18949485146238573 0.1894416754722342\n",
      "Epoch >>  1002 0.1894416754722342 0.03277592053990065 0.15666575493233398\n",
      "Saving the model  0.1894416754722342 0.18937807134322443\n",
      "Epoch >>  1003 0.18937807134322443 0.032770727315861954 0.15660734402736304\n",
      "Saving the model  0.18937807134322443 0.1893185696817773\n",
      "Epoch >>  1004 0.1893185696817773 0.03276595843685552 0.1565526112449223\n",
      "Saving the model  0.1893185696817773 0.18926257878072159\n",
      "Epoch >>  1005 0.18926257878072159 0.0327622994205048 0.15650027936021743\n",
      "Saving the model  0.18926257878072159 0.18926157951793848\n",
      "Epoch >>  1006 0.18926157951793848 0.032758391470915894 0.15650318804702315\n",
      "Epoch >>  1007 0.18929852797418836 0.03275486143561607 0.15654366653857296\n",
      "Epoch >>  1008 0.18929839211400576 0.0327506882370455 0.15654770387696101\n",
      "Saving the model  0.18926157951793848 0.18924866875892293\n",
      "Epoch >>  1009 0.18924866875892293 0.03274596541329458 0.15650270334562918\n",
      "Saving the model  0.18924866875892293 0.1891923888298999\n",
      "Epoch >>  1010 0.1891923888298999 0.03274221268402843 0.15645017614587223\n",
      "Saving the model  0.1891923888298999 0.18914935109821457\n",
      "Epoch >>  1011 0.18914935109821457 0.032737888341876235 0.1564114627563393\n",
      "Saving the model  0.18914935109821457 0.18909747005511185\n",
      "Epoch >>  1012 0.18909747005511185 0.032733815808588876 0.15636365424652382\n",
      "Saving the model  0.18909747005511185 0.18904888061401362\n",
      "Epoch >>  1013 0.18904888061401362 0.03272869560403398 0.1563201850099805\n",
      "Saving the model  0.18904888061401362 0.18896682706338588\n",
      "Epoch >>  1014 0.18896682706338588 0.03272324263277995 0.15624358443060674\n",
      "Saving the model  0.18896682706338588 0.1889164958829663\n",
      "Epoch >>  1015 0.1889164958829663 0.03271896699352339 0.15619752888944383\n",
      "Saving the model  0.1889164958829663 0.1888289997652199\n",
      "Epoch >>  1016 0.1888289997652199 0.03271390643341307 0.15611509333180787\n",
      "Saving the model  0.1888289997652199 0.188827538476469\n",
      "Epoch >>  1017 0.188827538476469 0.03271082587897068 0.15611671259749926\n",
      "Saving the model  0.188827538476469 0.18877349972964386\n",
      "Epoch >>  1018 0.18877349972964386 0.03270655283820173 0.1560669468914431\n",
      "Saving the model  0.18877349972964386 0.1887045635440623\n",
      "Epoch >>  1019 0.1887045635440623 0.03270184278301777 0.15600272076104552\n",
      "Saving the model  0.1887045635440623 0.18867404564677004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch >>  1020 0.18867404564677004 0.032697837199923696 0.15597620844684743\n",
      "Saving the model  0.18867404564677004 0.18863647101789963\n",
      "Epoch >>  1021 0.18863647101789963 0.03269344760507102 0.15594302341282973\n",
      "Saving the model  0.18863647101789963 0.18859918272819523\n",
      "Epoch >>  1022 0.18859918272819523 0.03268903713025903 0.15591014559793748\n",
      "Saving the model  0.18859918272819523 0.18852591784462905\n",
      "Epoch >>  1023 0.18852591784462905 0.03268380136610322 0.1558421164785271\n",
      "Epoch >>  1024 0.1885317812561205 0.03267899523122213 0.15585278602489946\n",
      "Saving the model  0.18852591784462905 0.18845146274053387\n",
      "Epoch >>  1025 0.18845146274053387 0.032674047364960754 0.15577741537557413\n",
      "Saving the model  0.18845146274053387 0.18838589995766547\n",
      "Epoch >>  1026 0.18838589995766547 0.03266926807464382 0.1557166318830228\n",
      "Saving the model  0.18838589995766547 0.18833723634885383\n",
      "Epoch >>  1027 0.18833723634885383 0.0326647545024738 0.15567248184638144\n",
      "Saving the model  0.18833723634885383 0.1882904706740183\n",
      "Epoch >>  1028 0.1882904706740183 0.03266046204827957 0.15563000862574017\n",
      "Saving the model  0.1882904706740183 0.1882235515204713\n",
      "Epoch >>  1029 0.1882235515204713 0.032655498517496405 0.1555680530029761\n",
      "Saving the model  0.1882235515204713 0.18814668144521685\n",
      "Epoch >>  1030 0.18814668144521685 0.03265049776113052 0.15549618368408766\n",
      "Saving the model  0.18814668144521685 0.18808076232501295\n",
      "Epoch >>  1031 0.18808076232501295 0.03264575755353255 0.15543500477148153\n",
      "Saving the model  0.18808076232501295 0.1880198710329734\n",
      "Epoch >>  1032 0.1880198710329734 0.03264121410352019 0.15537865692945427\n",
      "Saving the model  0.1880198710329734 0.18800187787635053\n",
      "Epoch >>  1033 0.18800187787635053 0.03263732357024153 0.15536455430611007\n",
      "Saving the model  0.18800187787635053 0.18794036913736353\n",
      "Epoch >>  1034 0.18794036913736353 0.032632238890834366 0.15530813024653006\n",
      "Saving the model  0.18794036913736353 0.18790800425728713\n",
      "Epoch >>  1035 0.18790800425728713 0.032628058568331314 0.15527994568895667\n",
      "Saving the model  0.18790800425728713 0.187853801707394\n",
      "Epoch >>  1036 0.187853801707394 0.032624055833045354 0.15522974587434968\n",
      "Saving the model  0.187853801707394 0.18781301349939417\n",
      "Epoch >>  1037 0.18781301349939417 0.03261994340383352 0.15519307009556155\n",
      "Saving the model  0.18781301349939417 0.18774661601319786\n",
      "Epoch >>  1038 0.18774661601319786 0.03261532549200694 0.15513129052119162\n",
      "Saving the model  0.18774661601319786 0.18767991002074721\n",
      "Epoch >>  1039 0.18767991002074721 0.03261096374219048 0.1550689462785574\n",
      "Saving the model  0.18767991002074721 0.18762830895681948\n",
      "Epoch >>  1040 0.18762830895681948 0.03260667512227137 0.1550216338345488\n",
      "Epoch >>  1041 0.18763694278544454 0.032602859637964596 0.15503408314748093\n",
      "Saving the model  0.18762830895681948 0.1875886009428217\n",
      "Epoch >>  1042 0.1875886009428217 0.032597950123173576 0.15499065081964902\n",
      "Saving the model  0.1875886009428217 0.18756129333206226\n",
      "Epoch >>  1043 0.18756129333206226 0.03259374640763684 0.15496754692442646\n",
      "Saving the model  0.18756129333206226 0.18748301087593924\n",
      "Epoch >>  1044 0.18748301087593924 0.03258859683043514 0.1548944140455052\n",
      "Saving the model  0.18748301087593924 0.18743275460022024\n",
      "Epoch >>  1045 0.18743275460022024 0.03258416562373999 0.15484858897648135\n",
      "Saving the model  0.18743275460022024 0.18738502127234047\n",
      "Epoch >>  1046 0.18738502127234047 0.03258010190327458 0.154804919369067\n",
      "Saving the model  0.18738502127234047 0.1873824770962591\n",
      "Epoch >>  1047 0.1873824770962591 0.032576309852770574 0.1548061672434898\n",
      "Saving the model  0.1873824770962591 0.18732898506547746\n",
      "Epoch >>  1048 0.18732898506547746 0.032572150856034376 0.15475683420944422\n",
      "Saving the model  0.18732898506547746 0.18727143485135436\n",
      "Epoch >>  1049 0.18727143485135436 0.03256711290267812 0.15470432194867736\n",
      "Saving the model  0.18727143485135436 0.1872135883689296\n",
      "Epoch >>  1050 0.1872135883689296 0.032562557625079584 0.1546510307438511\n",
      "Saving the model  0.1872135883689296 0.1871939372041574\n",
      "Epoch >>  1051 0.1871939372041574 0.03255874986312388 0.15463518734103446\n",
      "Saving the model  0.1871939372041574 0.1871579019702559\n",
      "Epoch >>  1052 0.1871579019702559 0.03255466464505919 0.15460323732519765\n",
      "Saving the model  0.1871579019702559 0.18709637661409168\n",
      "Epoch >>  1053 0.18709637661409168 0.03255054906026793 0.15454582755382482\n",
      "Saving the model  0.18709637661409168 0.18703833421577187\n",
      "Epoch >>  1054 0.18703833421577187 0.03254610660390921 0.1544922276118638\n",
      "Saving the model  0.18703833421577187 0.18702888590417582\n",
      "Epoch >>  1055 0.18702888590417582 0.032542671935361846 0.15448621396881532\n",
      "Saving the model  0.18702888590417582 0.18699941502161865\n",
      "Epoch >>  1056 0.18699941502161865 0.03253887462163593 0.15446054039998408\n",
      "Saving the model  0.18699941502161865 0.18693672661747035\n",
      "Epoch >>  1057 0.18693672661747035 0.03253437848339256 0.15440234813407916\n",
      "Saving the model  0.18693672661747035 0.1869050095321022\n",
      "Epoch >>  1058 0.1869050095321022 0.032530559861939784 0.1543744496701638\n",
      "Saving the model  0.1869050095321022 0.18685673811096115\n",
      "Epoch >>  1059 0.18685673811096115 0.032525806997924206 0.1543309311130383\n",
      "Saving the model  0.18685673811096115 0.18678206892342183\n",
      "Epoch >>  1060 0.18678206892342183 0.03252074252825066 0.15426132639517234\n",
      "Saving the model  0.18678206892342183 0.18674277681596432\n",
      "Epoch >>  1061 0.18674277681596432 0.03251700327216307 0.15422577354380257\n",
      "Saving the model  0.18674277681596432 0.18666595487905652\n",
      "Epoch >>  1062 0.18666595487905652 0.032512194618825256 0.1541537602602325\n",
      "Saving the model  0.18666595487905652 0.18663519777150656\n",
      "Epoch >>  1063 0.18663519777150656 0.03250847360704754 0.15412672416446016\n",
      "Saving the model  0.18663519777150656 0.18658693512966423\n",
      "Epoch >>  1064 0.18658693512966423 0.03250439931734455 0.15408253581232076\n",
      "Saving the model  0.18658693512966423 0.18652565725868914\n",
      "Epoch >>  1065 0.18652565725868914 0.03249922599234338 0.1540264312663469\n",
      "Saving the model  0.18652565725868914 0.18644460266066618\n",
      "Epoch >>  1066 0.18644460266066618 0.03249452105699146 0.15395008160367576\n",
      "Saving the model  0.18644460266066618 0.18639220192836364\n",
      "Epoch >>  1067 0.18639220192836364 0.03248993802433087 0.1539022639040338\n",
      "Saving the model  0.18639220192836364 0.18636142246555637\n",
      "Epoch >>  1068 0.18636142246555637 0.0324858747760548 0.15387554768950248\n",
      "Saving the model  0.18636142246555637 0.1863339605956227\n",
      "Epoch >>  1069 0.1863339605956227 0.03248142175514502 0.15385253884047861\n",
      "Saving the model  0.1863339605956227 0.18627906216425055\n",
      "Epoch >>  1070 0.18627906216425055 0.03247669109430199 0.15380237106994948\n",
      "Saving the model  0.18627906216425055 0.1862348305557061\n",
      "Epoch >>  1071 0.1862348305557061 0.032473010213392786 0.1537618203423143\n",
      "Saving the model  0.1862348305557061 0.18619558879552256\n",
      "Epoch >>  1072 0.18619558879552256 0.03246906808928088 0.1537265207062426\n",
      "Saving the model  0.18619558879552256 0.18618218978524276\n",
      "Epoch >>  1073 0.18618218978524276 0.032465785561008 0.15371640422423538\n",
      "Saving the model  0.18618218978524276 0.18613214227242175\n",
      "Epoch >>  1074 0.18613214227242175 0.03246137200967333 0.15367077026274872\n",
      "Saving the model  0.18613214227242175 0.1860710790414273\n",
      "Epoch >>  1075 0.1860710790414273 0.03245730466191331 0.1536137743795143\n",
      "Epoch >>  1076 0.18607341973877153 0.032454352425294125 0.15361906731347785\n",
      "Saving the model  0.1860710790414273 0.1859928635258606\n",
      "Epoch >>  1077 0.1859928635258606 0.032449893372506505 0.1535429701533544\n",
      "Saving the model  0.1859928635258606 0.1859797846028122\n",
      "Epoch >>  1078 0.1859797846028122 0.032446204326682916 0.1535335802761294\n",
      "Saving the model  0.1859797846028122 0.18595022208778095\n",
      "Epoch >>  1079 0.18595022208778095 0.0324418259808874 0.15350839610689357\n",
      "Saving the model  0.18595022208778095 0.18592415051091013\n",
      "Epoch >>  1080 0.18592415051091013 0.03243763645723449 0.15348651405367564\n",
      "Saving the model  0.18592415051091013 0.1858609836735846\n",
      "Epoch >>  1081 0.1858609836735846 0.03243308340147013 0.15342790027211456\n",
      "Saving the model  0.1858609836735846 0.18579800701282273\n",
      "Epoch >>  1082 0.18579800701282273 0.032428305208612423 0.15336970180421028\n",
      "Saving the model  0.18579800701282273 0.18575912031770278\n",
      "Epoch >>  1083 0.18575912031770278 0.03242457074746077 0.15333454957024206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.18575912031770278 0.18569738475610112\n",
      "Epoch >>  1084 0.18569738475610112 0.032419452615057257 0.1532779321410439\n",
      "Saving the model  0.18569738475610112 0.1856591749846922\n",
      "Epoch >>  1085 0.1856591749846922 0.03241557127848797 0.1532436037062042\n",
      "Saving the model  0.1856591749846922 0.18565151730516566\n",
      "Epoch >>  1086 0.18565151730516566 0.032412125299009345 0.15323939200615633\n",
      "Saving the model  0.18565151730516566 0.18560955739582888\n",
      "Epoch >>  1087 0.18560955739582888 0.032407919621332375 0.15320163777449658\n",
      "Saving the model  0.18560955739582888 0.18555136876856657\n",
      "Epoch >>  1088 0.18555136876856657 0.03240347673355255 0.15314789203501394\n",
      "Saving the model  0.18555136876856657 0.1855304679711615\n",
      "Epoch >>  1089 0.1855304679711615 0.03240057870267196 0.15312988926848947\n",
      "Saving the model  0.1855304679711615 0.18551322221296382\n",
      "Epoch >>  1090 0.18551322221296382 0.03239648743077202 0.15311673478219173\n",
      "Saving the model  0.18551322221296382 0.1854705260920629\n",
      "Epoch >>  1091 0.1854705260920629 0.03239293612435484 0.15307758996770807\n",
      "Saving the model  0.1854705260920629 0.18540828204580492\n",
      "Epoch >>  1092 0.18540828204580492 0.032389386850259584 0.1530188951955454\n",
      "Saving the model  0.18540828204580492 0.18534947571170746\n",
      "Epoch >>  1093 0.18534947571170746 0.03238493640613019 0.15296453930557732\n",
      "Saving the model  0.18534947571170746 0.18530870860180088\n",
      "Epoch >>  1094 0.18530870860180088 0.03238108358454865 0.15292762501725204\n",
      "Saving the model  0.18530870860180088 0.18525977959865064\n",
      "Epoch >>  1095 0.18525977959865064 0.03237778326706123 0.1528819963315894\n",
      "Saving the model  0.18525977959865064 0.18521569596148266\n",
      "Epoch >>  1096 0.18521569596148266 0.032373559423230634 0.15284213653825218\n",
      "Saving the model  0.18521569596148266 0.18515533616544055\n",
      "Epoch >>  1097 0.18515533616544055 0.032369314109934065 0.15278602205550662\n",
      "Saving the model  0.18515533616544055 0.18508940611590977\n",
      "Epoch >>  1098 0.18508940611590977 0.03236440088118882 0.1527250052347208\n",
      "Saving the model  0.18508940611590977 0.18502702983020383\n",
      "Epoch >>  1099 0.18502702983020383 0.0323601703534962 0.1526668594767075\n",
      "Saving the model  0.18502702983020383 0.1849727855676787\n",
      "Epoch >>  1100 0.1849727855676787 0.03235586849332576 0.15261691707435265\n",
      "Saving the model  0.1849727855676787 0.18495303263250895\n",
      "Epoch >>  1101 0.18495303263250895 0.032352080828900884 0.15260095180360772\n",
      "Saving the model  0.18495303263250895 0.1849207943571134\n",
      "Epoch >>  1102 0.1849207943571134 0.03234806039339396 0.15257273396371895\n",
      "Saving the model  0.1849207943571134 0.1848789251921886\n",
      "Epoch >>  1103 0.1848789251921886 0.03234368952456667 0.1525352356676215\n",
      "Saving the model  0.1848789251921886 0.1848320588732949\n",
      "Epoch >>  1104 0.1848320588732949 0.03233960203513807 0.15249245683815657\n",
      "Saving the model  0.1848320588732949 0.18481246812839228\n",
      "Epoch >>  1105 0.18481246812839228 0.03233549813831034 0.1524769699900816\n",
      "Saving the model  0.18481246812839228 0.18479234698127256\n",
      "Epoch >>  1106 0.18479234698127256 0.03233229006996175 0.15246005691131068\n",
      "Saving the model  0.18479234698127256 0.18472916510975337\n",
      "Epoch >>  1107 0.18472916510975337 0.032327957805222025 0.15240120730453122\n",
      "Saving the model  0.18472916510975337 0.1846861011950251\n",
      "Epoch >>  1108 0.1846861011950251 0.03232447211883597 0.1523616290761892\n",
      "Saving the model  0.1846861011950251 0.18462938917472835\n",
      "Epoch >>  1109 0.18462938917472835 0.032321006799630056 0.15230838237509847\n",
      "Saving the model  0.18462938917472835 0.1845780587667402\n",
      "Epoch >>  1110 0.1845780587667402 0.03231700307310878 0.15226105569363163\n",
      "Saving the model  0.1845780587667402 0.18453363985319382\n",
      "Epoch >>  1111 0.18453363985319382 0.0323130163122699 0.15222062354092422\n",
      "Saving the model  0.18453363985319382 0.184508842436777\n",
      "Epoch >>  1112 0.184508842436777 0.032309319777815655 0.1521995226589615\n",
      "Saving the model  0.184508842436777 0.18447207358169035\n",
      "Epoch >>  1113 0.18447207358169035 0.03230515536749669 0.15216691821419384\n",
      "Saving the model  0.18447207358169035 0.18445174735563843\n",
      "Epoch >>  1114 0.18445174735563843 0.03230150502247965 0.15215024233315896\n",
      "Saving the model  0.18445174735563843 0.18444250480787855\n",
      "Epoch >>  1115 0.18444250480787855 0.03229749266814934 0.15214501213972959\n",
      "Saving the model  0.18444250480787855 0.18440943963200393\n",
      "Epoch >>  1116 0.18440943963200393 0.03229409786529837 0.15211534176670624\n",
      "Saving the model  0.18440943963200393 0.18437098361096022\n",
      "Epoch >>  1117 0.18437098361096022 0.03228994254950151 0.15208104106145912\n",
      "Saving the model  0.18437098361096022 0.1843153347495493\n",
      "Epoch >>  1118 0.1843153347495493 0.03228676537467619 0.15202856937487363\n",
      "Epoch >>  1119 0.18432061256580481 0.032283522862336114 0.1520370897034694\n",
      "Saving the model  0.1843153347495493 0.18427059129497497\n",
      "Epoch >>  1120 0.18427059129497497 0.03227919143970673 0.15199139985526905\n",
      "Saving the model  0.18427059129497497 0.18423507975680123\n",
      "Epoch >>  1121 0.18423507975680123 0.03227545350176741 0.1519596262550346\n",
      "Saving the model  0.18423507975680123 0.1842032606677192\n",
      "Epoch >>  1122 0.1842032606677192 0.032271614445254955 0.15193164622246497\n",
      "Saving the model  0.1842032606677192 0.1841687912383429\n",
      "Epoch >>  1123 0.1841687912383429 0.03226694844500173 0.15190184279334173\n",
      "Saving the model  0.1841687912383429 0.18416582907954365\n",
      "Epoch >>  1124 0.18416582907954365 0.03226298285501603 0.15190284622452818\n",
      "Saving the model  0.18416582907954365 0.1841252310955804\n",
      "Epoch >>  1125 0.1841252310955804 0.03225827148398307 0.151866959611598\n",
      "Saving the model  0.1841252310955804 0.18410290634223853\n",
      "Epoch >>  1126 0.18410290634223853 0.03225419256891108 0.151848713773328\n",
      "Saving the model  0.18410290634223853 0.18404535652993864\n",
      "Epoch >>  1127 0.18404535652993864 0.03225012230992231 0.15179523422001676\n",
      "Saving the model  0.18404535652993864 0.1840158297411583\n",
      "Epoch >>  1128 0.1840158297411583 0.03224629361915894 0.15176953612199987\n",
      "Saving the model  0.1840158297411583 0.18396395458218584\n",
      "Epoch >>  1129 0.18396395458218584 0.03224282086516114 0.15172113371702522\n",
      "Saving the model  0.18396395458218584 0.18392337898337824\n",
      "Epoch >>  1130 0.18392337898337824 0.03223973650803549 0.1516836424753432\n",
      "Saving the model  0.18392337898337824 0.18389246221770958\n",
      "Epoch >>  1131 0.18389246221770958 0.03223581694590545 0.15165664527180459\n",
      "Saving the model  0.18389246221770958 0.18384887610205825\n",
      "Epoch >>  1132 0.18384887610205825 0.032231907033776735 0.15161696906828187\n",
      "Saving the model  0.18384887610205825 0.18384101056085725\n",
      "Epoch >>  1133 0.18384101056085725 0.032229051706252176 0.15161195885460554\n",
      "Saving the model  0.18384101056085725 0.18378923090796642\n",
      "Epoch >>  1134 0.18378923090796642 0.032225159646976156 0.1515640712609909\n",
      "Saving the model  0.18378923090796642 0.18376301463729203\n",
      "Epoch >>  1135 0.18376301463729203 0.032221803590614946 0.1515412110466777\n",
      "Saving the model  0.18376301463729203 0.1837608328633867\n",
      "Epoch >>  1136 0.1837608328633867 0.03221894868240575 0.15154188418098158\n",
      "Saving the model  0.1837608328633867 0.18373582382032433\n",
      "Epoch >>  1137 0.18373582382032433 0.03221561247086415 0.15152021134946064\n",
      "Saving the model  0.18373582382032433 0.1836833621726919\n",
      "Epoch >>  1138 0.1836833621726919 0.03221139117321001 0.15147197099948234\n",
      "Saving the model  0.1836833621726919 0.1836712454180474\n",
      "Epoch >>  1139 0.1836712454180474 0.032208145952570995 0.151463099465477\n",
      "Saving the model  0.1836712454180474 0.18362374087267272\n",
      "Epoch >>  1140 0.18362374087267272 0.032203985536061706 0.15141975533661162\n",
      "Saving the model  0.18362374087267272 0.1836030104483559\n",
      "Epoch >>  1141 0.1836030104483559 0.03220000034049439 0.1514030101078621\n",
      "Saving the model  0.1836030104483559 0.18355273640943826\n",
      "Epoch >>  1142 0.18355273640943826 0.032195842866327894 0.15135689354311085\n",
      "Saving the model  0.18355273640943826 0.18354173462342993\n",
      "Epoch >>  1143 0.18354173462342993 0.032192333754728256 0.15134940086870216\n",
      "Saving the model  0.18354173462342993 0.18347972292146617\n",
      "Epoch >>  1144 0.18347972292146617 0.03218854012150494 0.15129118279996168\n",
      "Saving the model  0.18347972292146617 0.1834515081978657\n",
      "Epoch >>  1145 0.1834515081978657 0.03218533611131626 0.15126617208655002\n",
      "Saving the model  0.1834515081978657 0.18342673116405553\n",
      "Epoch >>  1146 0.18342673116405553 0.03218157524425153 0.15124515591980467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.18342673116405553 0.18340493068686659\n",
      "Epoch >>  1147 0.18340493068686659 0.03217795633559694 0.1512269743512703\n",
      "Saving the model  0.18340493068686659 0.18336258180592063\n",
      "Epoch >>  1148 0.18336258180592063 0.03217417098512997 0.1511884108207911\n",
      "Saving the model  0.18336258180592063 0.18333097638960658\n",
      "Epoch >>  1149 0.18333097638960658 0.03217035602631907 0.15116062036328795\n",
      "Saving the model  0.18333097638960658 0.1833081711045285\n",
      "Epoch >>  1150 0.1833081711045285 0.032167218128259706 0.15114095297626942\n",
      "Saving the model  0.1833081711045285 0.18326164094525352\n",
      "Epoch >>  1151 0.18326164094525352 0.0321633423892117 0.1510982985560425\n",
      "Saving the model  0.18326164094525352 0.18323440243429132\n",
      "Epoch >>  1152 0.18323440243429132 0.03215981466995225 0.1510745877643396\n",
      "Saving the model  0.18323440243429132 0.18320789395124842\n",
      "Epoch >>  1153 0.18320789395124842 0.03215580909301879 0.15105208485823035\n",
      "Saving the model  0.18320789395124842 0.1831558816284503\n",
      "Epoch >>  1154 0.1831558816284503 0.03215218706536021 0.15100369456309082\n",
      "Saving the model  0.1831558816284503 0.18314619775217392\n",
      "Epoch >>  1155 0.18314619775217392 0.032149282236952584 0.15099691551522199\n",
      "Saving the model  0.18314619775217392 0.18309820585151593\n",
      "Epoch >>  1156 0.18309820585151593 0.03214567318008132 0.1509525326714352\n",
      "Saving the model  0.18309820585151593 0.18305599956777377\n",
      "Epoch >>  1157 0.18305599956777377 0.032142111465019614 0.1509138881027548\n",
      "Saving the model  0.18305599956777377 0.18302957141674464\n",
      "Epoch >>  1158 0.18302957141674464 0.03213857310574873 0.15089099831099642\n",
      "Saving the model  0.18302957141674464 0.1829957564561978\n",
      "Epoch >>  1159 0.1829957564561978 0.032134747371089845 0.15086100908510858\n",
      "Saving the model  0.1829957564561978 0.1829364460964448\n",
      "Epoch >>  1160 0.1829364460964448 0.03213073629382128 0.15080570980262376\n",
      "Epoch >>  1161 0.1829395700867521 0.03212780330312677 0.1508117667836256\n",
      "Saving the model  0.1829364460964448 0.18289698655868872\n",
      "Epoch >>  1162 0.18289698655868872 0.03212374447650106 0.15077324208218787\n",
      "Saving the model  0.18289698655868872 0.18284961954831236\n",
      "Epoch >>  1163 0.18284961954831236 0.03211992610412884 0.15072969344418374\n",
      "Saving the model  0.18284961954831236 0.1828132920177126\n",
      "Epoch >>  1164 0.1828132920177126 0.032116400349274335 0.15069689166843858\n",
      "Saving the model  0.1828132920177126 0.18278803332297663\n",
      "Epoch >>  1165 0.18278803332297663 0.03211288844164411 0.15067514488133288\n",
      "Saving the model  0.18278803332297663 0.18274626946980985\n",
      "Epoch >>  1166 0.18274626946980985 0.03210931571154499 0.1506369537582656\n",
      "Saving the model  0.18274626946980985 0.1827241569054552\n",
      "Epoch >>  1167 0.1827241569054552 0.032105899142352456 0.15061825776310345\n",
      "Saving the model  0.1827241569054552 0.1826776765995954\n",
      "Epoch >>  1168 0.1826776765995954 0.03210250284564788 0.15057517375394827\n",
      "Saving the model  0.1826776765995954 0.18266408234701673\n",
      "Epoch >>  1169 0.18266408234701673 0.03209887522240055 0.15056520712461702\n",
      "Saving the model  0.18266408234701673 0.1826120485212999\n",
      "Epoch >>  1170 0.1826120485212999 0.03209503047037339 0.1505170180509272\n",
      "Saving the model  0.1826120485212999 0.1825727116121225\n",
      "Epoch >>  1171 0.1825727116121225 0.032090744350163715 0.15048196726195953\n",
      "Saving the model  0.1825727116121225 0.18252216478735486\n",
      "Epoch >>  1172 0.18252216478735486 0.03208697110560528 0.15043519368175054\n",
      "Saving the model  0.18252216478735486 0.18250275606024402\n",
      "Epoch >>  1173 0.18250275606024402 0.03208337770270777 0.15041937835753721\n",
      "Saving the model  0.18250275606024402 0.18246235567805558\n",
      "Epoch >>  1174 0.18246235567805558 0.03208051918074797 0.15038183649730866\n",
      "Saving the model  0.18246235567805558 0.18240165299842265\n",
      "Epoch >>  1175 0.18240165299842265 0.03207617549114335 0.15032547750728026\n",
      "Saving the model  0.18240165299842265 0.18234869044769783\n",
      "Epoch >>  1176 0.18234869044769783 0.032071859184457215 0.15027683126324148\n",
      "Saving the model  0.18234869044769783 0.18231022774135008\n",
      "Epoch >>  1177 0.18231022774135008 0.03206786319852694 0.15024236454282422\n",
      "Saving the model  0.18231022774135008 0.1822725161040933\n",
      "Epoch >>  1178 0.1822725161040933 0.032064108357997674 0.15020840774609667\n",
      "Saving the model  0.1822725161040933 0.18222792017910755\n",
      "Epoch >>  1179 0.18222792017910755 0.03205999883848796 0.15016792134062068\n",
      "Saving the model  0.18222792017910755 0.18218338156777694\n",
      "Epoch >>  1180 0.18218338156777694 0.032056035213485226 0.15012734635429284\n",
      "Saving the model  0.18218338156777694 0.18214437026991445\n",
      "Epoch >>  1181 0.18214437026991445 0.032051902579083524 0.150092467690832\n",
      "Saving the model  0.18214437026991445 0.18211261802157605\n",
      "Epoch >>  1182 0.18211261802157605 0.032048164557669095 0.15006445346390793\n",
      "Saving the model  0.18211261802157605 0.18206194726485025\n",
      "Epoch >>  1183 0.18206194726485025 0.03204416420916869 0.15001778305568259\n",
      "Saving the model  0.18206194726485025 0.18204111935921852\n",
      "Epoch >>  1184 0.18204111935921852 0.03204145427142806 0.14999966508779145\n",
      "Saving the model  0.18204111935921852 0.1820175630073827\n",
      "Epoch >>  1185 0.1820175630073827 0.03203815398212737 0.1499794090252565\n",
      "Saving the model  0.1820175630073827 0.18199814543226112\n",
      "Epoch >>  1186 0.18199814543226112 0.03203456932536835 0.149963576106894\n",
      "Saving the model  0.18199814543226112 0.18197817566821795\n",
      "Epoch >>  1187 0.18197817566821795 0.03203049161156633 0.14994768405665282\n",
      "Saving the model  0.18197817566821795 0.18196382662367655\n",
      "Epoch >>  1188 0.18196382662367655 0.03202678100079198 0.14993704562288573\n",
      "Saving the model  0.18196382662367655 0.18191392289604758\n",
      "Epoch >>  1189 0.18191392289604758 0.03202293392492453 0.14989098897112418\n",
      "Saving the model  0.18191392289604758 0.18188227223729386\n",
      "Epoch >>  1190 0.18188227223729386 0.032019724687946054 0.14986254754934877\n",
      "Saving the model  0.18188227223729386 0.18185114011000042\n",
      "Epoch >>  1191 0.18185114011000042 0.03201598158271593 0.1498351585272854\n",
      "Saving the model  0.18185114011000042 0.181832743425287\n",
      "Epoch >>  1192 0.181832743425287 0.032013341289215805 0.14981940213607212\n",
      "Epoch >>  1193 0.18184029987837422 0.03201006085385518 0.14983023902452006\n",
      "Saving the model  0.181832743425287 0.18179788106919717\n",
      "Epoch >>  1194 0.18179788106919717 0.032006230047788534 0.14979165102140962\n",
      "Saving the model  0.18179788106919717 0.18177441684718468\n",
      "Epoch >>  1195 0.18177441684718468 0.032002758706815605 0.14977165814037002\n",
      "Saving the model  0.18177441684718468 0.18173686120756913\n",
      "Epoch >>  1196 0.18173686120756913 0.03199889032276653 0.14973797088480345\n",
      "Saving the model  0.18173686120756913 0.18168489319464504\n",
      "Epoch >>  1197 0.18168489319464504 0.031994878683345114 0.14969001451130073\n",
      "Saving the model  0.18168489319464504 0.18163734426772363\n",
      "Epoch >>  1198 0.18163734426772363 0.03199095143272839 0.14964639283499628\n",
      "Saving the model  0.18163734426772363 0.18157655912576076\n",
      "Epoch >>  1199 0.18157655912576076 0.03198641062392412 0.14959014850183755\n",
      "Saving the model  0.18157655912576076 0.18154300124171363\n",
      "Epoch >>  1200 0.18154300124171363 0.031982740315272914 0.14956026092644154\n",
      "Saving the model  0.18154300124171363 0.1815348034407304\n",
      "Epoch >>  1201 0.1815348034407304 0.031978817512063405 0.14955598592866787\n",
      "Saving the model  0.1815348034407304 0.18149613347383703\n",
      "Epoch >>  1202 0.18149613347383703 0.03197475357531956 0.14952137989851821\n",
      "Saving the model  0.18149613347383703 0.18145397396729995\n",
      "Epoch >>  1203 0.18145397396729995 0.03197099456772839 0.1494829793995722\n",
      "Saving the model  0.18145397396729995 0.18141739486135325\n",
      "Epoch >>  1204 0.18141739486135325 0.03196720565875104 0.14945018920260283\n",
      "Saving the model  0.18141739486135325 0.18138403532755276\n",
      "Epoch >>  1205 0.18138403532755276 0.03196386477316776 0.14942017055438547\n",
      "Saving the model  0.18138403532755276 0.1813482793753664\n",
      "Epoch >>  1206 0.1813482793753664 0.031959926617370585 0.14938835275799642\n",
      "Saving the model  0.1813482793753664 0.18130821108151465\n",
      "Epoch >>  1207 0.18130821108151465 0.03195593799305179 0.14935227308846338\n",
      "Saving the model  0.18130821108151465 0.1812951856538774\n",
      "Epoch >>  1208 0.1812951856538774 0.031952473263740705 0.1493427123901371\n",
      "Saving the model  0.1812951856538774 0.18123677465369836\n",
      "Epoch >>  1209 0.18123677465369836 0.03194871783628587 0.1492880568174128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.18123677465369836 0.18119544249935207\n",
      "Epoch >>  1210 0.18119544249935207 0.03194460447850381 0.1492508380208487\n",
      "Saving the model  0.18119544249935207 0.18118610501333274\n",
      "Epoch >>  1211 0.18118610501333274 0.03194148192650082 0.1492446230868324\n",
      "Saving the model  0.18118610501333274 0.18115048179939638\n",
      "Epoch >>  1212 0.18115048179939638 0.03193781083816861 0.14921267096122834\n",
      "Saving the model  0.18115048179939638 0.18113783327498742\n",
      "Epoch >>  1213 0.18113783327498742 0.031934455136260566 0.1492033781387275\n",
      "Saving the model  0.18113783327498742 0.18109809416917755\n",
      "Epoch >>  1214 0.18109809416917755 0.031930862152692745 0.14916723201648535\n",
      "Saving the model  0.18109809416917755 0.18103654273963002\n",
      "Epoch >>  1215 0.18103654273963002 0.03192722137975235 0.1491093213598783\n",
      "Saving the model  0.18103654273963002 0.18098948639279333\n",
      "Epoch >>  1216 0.18098948639279333 0.0319240418588035 0.14906544453399026\n",
      "Saving the model  0.18098948639279333 0.18094749005101077\n",
      "Epoch >>  1217 0.18094749005101077 0.031920361857181244 0.14902712819382985\n",
      "Saving the model  0.18094749005101077 0.18093654252479305\n",
      "Epoch >>  1218 0.18093654252479305 0.031917336024398564 0.14901920650039477\n",
      "Epoch >>  1219 0.18093661324821517 0.03191462860637379 0.1490219846418416\n",
      "Saving the model  0.18093654252479305 0.18093482083025123\n",
      "Epoch >>  1220 0.18093482083025123 0.03191212874850716 0.14902269208174446\n",
      "Saving the model  0.18093482083025123 0.18089676741673316\n",
      "Epoch >>  1221 0.18089676741673316 0.03190872933878903 0.14898803807794458\n",
      "Saving the model  0.18089676741673316 0.1808554854078191\n",
      "Epoch >>  1222 0.1808554854078191 0.031904795073309976 0.14895069033450956\n",
      "Saving the model  0.1808554854078191 0.18083600015776527\n",
      "Epoch >>  1223 0.18083600015776527 0.031901765653536036 0.14893423450422985\n",
      "Saving the model  0.18083600015776527 0.18079175901287628\n",
      "Epoch >>  1224 0.18079175901287628 0.03189803429620543 0.1488937247166715\n",
      "Saving the model  0.18079175901287628 0.18077895174251077\n",
      "Epoch >>  1225 0.18077895174251077 0.031894663623375175 0.1488842881191363\n",
      "Saving the model  0.18077895174251077 0.18072382630004583\n",
      "Epoch >>  1226 0.18072382630004583 0.03189029012920271 0.14883353617084366\n",
      "Saving the model  0.18072382630004583 0.18069889598487782\n",
      "Epoch >>  1227 0.18069889598487782 0.03188696733384115 0.14881192865103737\n",
      "Saving the model  0.18069889598487782 0.18068834863893038\n",
      "Epoch >>  1228 0.18068834863893038 0.031883456618250046 0.14880489202068112\n",
      "Saving the model  0.18068834863893038 0.1806680074209326\n",
      "Epoch >>  1229 0.1806680074209326 0.03187962060865585 0.14878838681227755\n",
      "Saving the model  0.1806680074209326 0.18061637443208328\n",
      "Epoch >>  1230 0.18061637443208328 0.03187539160001571 0.14874098283206846\n",
      "Saving the model  0.18061637443208328 0.18058750174741298\n",
      "Epoch >>  1231 0.18058750174741298 0.031871949415495926 0.14871555233191783\n",
      "Saving the model  0.18058750174741298 0.1805720942034672\n",
      "Epoch >>  1232 0.1805720942034672 0.031868401654462496 0.14870369254900545\n",
      "Saving the model  0.1805720942034672 0.18053467619911553\n",
      "Epoch >>  1233 0.18053467619911553 0.03186488035770087 0.14866979584141532\n",
      "Saving the model  0.18053467619911553 0.18049342949062505\n",
      "Epoch >>  1234 0.18049342949062505 0.03186131011470304 0.14863211937592263\n",
      "Saving the model  0.18049342949062505 0.18046415969935897\n",
      "Epoch >>  1235 0.18046415969935897 0.03185782688220233 0.1486063328171571\n",
      "Saving the model  0.18046415969935897 0.18044527168340646\n",
      "Epoch >>  1236 0.18044527168340646 0.03185373496345416 0.14859153671995284\n",
      "Saving the model  0.18044527168340646 0.1804178257732373\n",
      "Epoch >>  1237 0.1804178257732373 0.031850152748919454 0.14856767302431825\n",
      "Saving the model  0.1804178257732373 0.18037959028785802\n",
      "Epoch >>  1238 0.18037959028785802 0.03184619509866942 0.14853339518918912\n",
      "Epoch >>  1239 0.18039172560041444 0.03184323167169893 0.14854849392871605\n",
      "Saving the model  0.18037959028785802 0.18034172407964483\n",
      "Epoch >>  1240 0.18034172407964483 0.03183937485365299 0.14850234922599226\n",
      "Saving the model  0.18034172407964483 0.18030469127192056\n",
      "Epoch >>  1241 0.18030469127192056 0.03183595573543051 0.1484687355364905\n",
      "Saving the model  0.18030469127192056 0.180256440247292\n",
      "Epoch >>  1242 0.180256440247292 0.03183265597600192 0.14842378427129038\n",
      "Saving the model  0.180256440247292 0.18022639366033757\n",
      "Epoch >>  1243 0.18022639366033757 0.03182908087959755 0.14839731278074056\n",
      "Saving the model  0.18022639366033757 0.18016885189903012\n",
      "Epoch >>  1244 0.18016885189903012 0.03182534660752176 0.14834350529150883\n",
      "Saving the model  0.18016885189903012 0.18016564058340398\n",
      "Epoch >>  1245 0.18016564058340398 0.03182273955233232 0.14834290103107214\n",
      "Epoch >>  1246 0.18017130706732123 0.031820526857322555 0.14835078020999903\n",
      "Saving the model  0.18016564058340398 0.18013263781559172\n",
      "Epoch >>  1247 0.18013263781559172 0.03181814492593271 0.14831449288965953\n",
      "Saving the model  0.18013263781559172 0.1800944556715923\n",
      "Epoch >>  1248 0.1800944556715923 0.031814787259492716 0.14827966841210005\n",
      "Saving the model  0.1800944556715923 0.18004647340197344\n",
      "Epoch >>  1249 0.18004647340197344 0.03181110680474192 0.148235366597232\n",
      "Saving the model  0.18004647340197344 0.18000210554785756\n",
      "Epoch >>  1250 0.18000210554785756 0.03180703188900591 0.14819507365885207\n",
      "Saving the model  0.18000210554785756 0.1799774558245302\n",
      "Epoch >>  1251 0.1799774558245302 0.03180410158099483 0.14817335424353595\n",
      "Saving the model  0.1799774558245302 0.17992114541582224\n",
      "Epoch >>  1252 0.17992114541582224 0.03180080745241339 0.1481203379634094\n",
      "Saving the model  0.17992114541582224 0.17989114037096346\n",
      "Epoch >>  1253 0.17989114037096346 0.031797251371831176 0.14809388899913287\n",
      "Saving the model  0.17989114037096346 0.179840996762923\n",
      "Epoch >>  1254 0.179840996762923 0.03179292220047911 0.1480480745624445\n",
      "Saving the model  0.179840996762923 0.1798125697883529\n",
      "Epoch >>  1255 0.1798125697883529 0.03178910088488833 0.14802346890346516\n",
      "Saving the model  0.1798125697883529 0.17977856002973985\n",
      "Epoch >>  1256 0.17977856002973985 0.0317863377423287 0.14799222228741177\n",
      "Saving the model  0.17977856002973985 0.17974791552548774\n",
      "Epoch >>  1257 0.17974791552548774 0.03178308780411033 0.14796482772137803\n",
      "Saving the model  0.17974791552548774 0.17970398748542674\n",
      "Epoch >>  1258 0.17970398748542674 0.03177944458505868 0.14792454290036847\n",
      "Saving the model  0.17970398748542674 0.17967829664621046\n",
      "Epoch >>  1259 0.17967829664621046 0.03177567717659202 0.14790261946961902\n",
      "Saving the model  0.17967829664621046 0.17963972620371438\n",
      "Epoch >>  1260 0.17963972620371438 0.03177208345405298 0.14786764274966205\n",
      "Saving the model  0.17963972620371438 0.1796185361221808\n",
      "Epoch >>  1261 0.1796185361221808 0.03176925640454612 0.14784927971763517\n",
      "Saving the model  0.1796185361221808 0.17957824596722938\n",
      "Epoch >>  1262 0.17957824596722938 0.0317660188429191 0.14781222712431075\n",
      "Saving the model  0.17957824596722938 0.17953768293466524\n",
      "Epoch >>  1263 0.17953768293466524 0.031761849506314555 0.14777583342835116\n",
      "Saving the model  0.17953768293466524 0.1795137760501846\n",
      "Epoch >>  1264 0.1795137760501846 0.0317582728957549 0.14775550315443026\n",
      "Saving the model  0.1795137760501846 0.17949977562608377\n",
      "Epoch >>  1265 0.17949977562608377 0.031754757522569836 0.1477450181035145\n",
      "Saving the model  0.17949977562608377 0.17947843949018666\n",
      "Epoch >>  1266 0.17947843949018666 0.03175182693207597 0.1477266125581112\n",
      "Saving the model  0.17947843949018666 0.17945194334187536\n",
      "Epoch >>  1267 0.17945194334187536 0.03174848694914133 0.14770345639273447\n",
      "Saving the model  0.17945194334187536 0.17942428737347105\n",
      "Epoch >>  1268 0.17942428737347105 0.03174508443780655 0.1476792029356648\n",
      "Saving the model  0.17942428737347105 0.17938291009956212\n",
      "Epoch >>  1269 0.17938291009956212 0.03174178218536435 0.14764112791419787\n",
      "Saving the model  0.17938291009956212 0.17932750680419035\n",
      "Epoch >>  1270 0.17932750680419035 0.03173815369250954 0.14758935311168087\n",
      "Saving the model  0.17932750680419035 0.17931637759670963\n",
      "Epoch >>  1271 0.17931637759670963 0.03173509206171578 0.14758128553499422\n",
      "Saving the model  0.17931637759670963 0.17925594453390903\n",
      "Epoch >>  1272 0.17925594453390903 0.031731106739023 0.1475248377948865\n",
      "Saving the model  0.17925594453390903 0.1792214903878503\n",
      "Epoch >>  1273 0.1792214903878503 0.03172765454785516 0.14749383583999573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.1792214903878503 0.17920704386484615\n",
      "Epoch >>  1274 0.17920704386484615 0.03172451542737332 0.14748252843747345\n",
      "Saving the model  0.17920704386484615 0.1791623668465932\n",
      "Epoch >>  1275 0.1791623668465932 0.03172093749113065 0.1474414293554631\n",
      "Saving the model  0.1791623668465932 0.17912702204327224\n",
      "Epoch >>  1276 0.17912702204327224 0.03171748558594937 0.14740953645732352\n",
      "Saving the model  0.17912702204327224 0.17909623273528383\n",
      "Epoch >>  1277 0.17909623273528383 0.03171485374356014 0.1473813789917243\n",
      "Saving the model  0.17909623273528383 0.17907718693810784\n",
      "Epoch >>  1278 0.17907718693810784 0.03171135516760996 0.1473658317704984\n",
      "Saving the model  0.17907718693810784 0.17902669812650573\n",
      "Epoch >>  1279 0.17902669812650573 0.03170742537316091 0.14731927275334525\n",
      "Saving the model  0.17902669812650573 0.1789973638547065\n",
      "Epoch >>  1280 0.1789973638547065 0.03170341029813615 0.14729395355657085\n",
      "Saving the model  0.1789973638547065 0.17894569929480775\n",
      "Epoch >>  1281 0.17894569929480775 0.03169942393750289 0.1472462753573053\n",
      "Saving the model  0.17894569929480775 0.17890345616210623\n",
      "Epoch >>  1282 0.17890345616210623 0.031695683043674774 0.14720777311843192\n",
      "Saving the model  0.17890345616210623 0.17887409149274758\n",
      "Epoch >>  1283 0.17887409149274758 0.03169216783183095 0.14718192366091712\n",
      "Saving the model  0.17887409149274758 0.1788396764016937\n",
      "Epoch >>  1284 0.1788396764016937 0.03168892765498761 0.1471507487467067\n",
      "Saving the model  0.1788396764016937 0.17882600470689958\n",
      "Epoch >>  1285 0.17882600470689958 0.031686282950645385 0.14713972175625498\n",
      "Saving the model  0.17882600470689958 0.17879430811147592\n",
      "Epoch >>  1286 0.17879430811147592 0.03168315146126447 0.14711115665021235\n",
      "Saving the model  0.17879430811147592 0.17876851955545892\n",
      "Epoch >>  1287 0.17876851955545892 0.031679749770314666 0.14708876978514507\n",
      "Saving the model  0.17876851955545892 0.17872802712130312\n",
      "Epoch >>  1288 0.17872802712130312 0.03167638226397003 0.14705164485733385\n",
      "Saving the model  0.17872802712130312 0.17868863171665994\n",
      "Epoch >>  1289 0.17868863171665994 0.03167243403245533 0.14701619768420546\n",
      "Saving the model  0.17868863171665994 0.17866679928061657\n",
      "Epoch >>  1290 0.17866679928061657 0.03166921909896236 0.146997580181655\n",
      "Saving the model  0.17866679928061657 0.1786314685708834\n",
      "Epoch >>  1291 0.1786314685708834 0.03166603092268389 0.14696543764820028\n",
      "Saving the model  0.1786314685708834 0.17857814583373083\n",
      "Epoch >>  1292 0.17857814583373083 0.031661768988463665 0.1469163768452679\n",
      "Saving the model  0.17857814583373083 0.17854107532095673\n",
      "Epoch >>  1293 0.17854107532095673 0.031658111563522856 0.14688296375743465\n",
      "Saving the model  0.17854107532095673 0.1785203916191065\n",
      "Epoch >>  1294 0.1785203916191065 0.03165468730447874 0.14686570431462845\n",
      "Saving the model  0.1785203916191065 0.17850852200209472\n",
      "Epoch >>  1295 0.17850852200209472 0.03165096266019229 0.14685755934190317\n",
      "Saving the model  0.17850852200209472 0.1784701499444312\n",
      "Epoch >>  1296 0.1784701499444312 0.031647544780462646 0.14682260516396922\n",
      "Saving the model  0.1784701499444312 0.17842181402476232\n",
      "Epoch >>  1297 0.17842181402476232 0.03164405375355204 0.14677776027121095\n",
      "Saving the model  0.17842181402476232 0.17838475886447025\n",
      "Epoch >>  1298 0.17838475886447025 0.03164083797245082 0.1467439208920199\n",
      "Saving the model  0.17838475886447025 0.17834207417355072\n",
      "Epoch >>  1299 0.17834207417355072 0.03163745230064826 0.1467046218729028\n",
      "Saving the model  0.17834207417355072 0.17831312090138565\n",
      "Epoch >>  1300 0.17831312090138565 0.03163423651872582 0.14667888438266033\n",
      "Saving the model  0.17831312090138565 0.1783004341393637\n",
      "Epoch >>  1301 0.1783004341393637 0.03163110942795864 0.1466693247114056\n",
      "Saving the model  0.1783004341393637 0.17826184917150698\n",
      "Epoch >>  1302 0.17826184917150698 0.03162755470624001 0.14663429446526738\n",
      "Saving the model  0.17826184917150698 0.1782228414158958\n",
      "Epoch >>  1303 0.1782228414158958 0.031623721551578554 0.14659911986431762\n",
      "Saving the model  0.1782228414158958 0.17819328532833112\n",
      "Epoch >>  1304 0.17819328532833112 0.03161996743072108 0.1465733178976104\n",
      "Saving the model  0.17819328532833112 0.17816246533865673\n",
      "Epoch >>  1305 0.17816246533865673 0.03161651190716646 0.1465459534314908\n",
      "Saving the model  0.17816246533865673 0.1781120611994941\n",
      "Epoch >>  1306 0.1781120611994941 0.031612712042131355 0.14649934915736332\n",
      "Epoch >>  1307 0.1781171964867664 0.0316101800976802 0.14650701638908672\n",
      "Saving the model  0.1781120611994941 0.17808578576405695\n",
      "Epoch >>  1308 0.17808578576405695 0.03160684176487054 0.14647894399918673\n",
      "Saving the model  0.17808578576405695 0.17806070963026105\n",
      "Epoch >>  1309 0.17806070963026105 0.03160389606106773 0.14645681356919338\n",
      "Saving the model  0.17806070963026105 0.1780126629371324\n",
      "Epoch >>  1310 0.1780126629371324 0.03160028061977064 0.14641238231736167\n",
      "Saving the model  0.1780126629371324 0.17797607733786447\n",
      "Epoch >>  1311 0.17797607733786447 0.03159639951676384 0.14637967782110065\n",
      "Saving the model  0.17797607733786447 0.17792948718135296\n",
      "Epoch >>  1312 0.17792948718135296 0.03159256286909237 0.14633692431226067\n",
      "Saving the model  0.17792948718135296 0.17789455031363843\n",
      "Epoch >>  1313 0.17789455031363843 0.031589299643494655 0.14630525067014377\n",
      "Saving the model  0.17789455031363843 0.17786482682618615\n",
      "Epoch >>  1314 0.17786482682618615 0.0315863766648954 0.1462784501612908\n",
      "Saving the model  0.17786482682618615 0.17785731587682643\n",
      "Epoch >>  1315 0.17785731587682643 0.031583214017093714 0.14627410185973283\n",
      "Saving the model  0.17785731587682643 0.17783908883021565\n",
      "Epoch >>  1316 0.17783908883021565 0.03158014961651298 0.14625893921370284\n",
      "Saving the model  0.17783908883021565 0.1778158160844745\n",
      "Epoch >>  1317 0.1778158160844745 0.031576526052079 0.14623929003239572\n",
      "Saving the model  0.1778158160844745 0.1777786865489417\n",
      "Epoch >>  1318 0.1777786865489417 0.031572747737705124 0.14620593881123678\n",
      "Epoch >>  1319 0.17778096867212917 0.031569383400036045 0.14621158527209327\n",
      "Saving the model  0.1777786865489417 0.17775465422879713\n",
      "Epoch >>  1320 0.17775465422879713 0.0315661599888285 0.1461884942399687\n",
      "Epoch >>  1321 0.17776856099951793 0.03156349229276715 0.146205068706751\n",
      "Epoch >>  1322 0.17776308577920757 0.03156052234089553 0.14620256343831267\n",
      "Saving the model  0.17775465422879713 0.1777326998994516\n",
      "Epoch >>  1323 0.1777326998994516 0.03155748437040577 0.14617521552904655\n",
      "Saving the model  0.1777326998994516 0.17770380158955096\n",
      "Epoch >>  1324 0.17770380158955096 0.031554239063791706 0.14614956252575995\n",
      "Saving the model  0.17770380158955096 0.17765824613334855\n",
      "Epoch >>  1325 0.17765824613334855 0.03155094444845924 0.1461073016848902\n",
      "Saving the model  0.17765824613334855 0.17762662536957124\n",
      "Epoch >>  1326 0.17762662536957124 0.03154731654127683 0.14607930882829537\n",
      "Saving the model  0.17762662536957124 0.1775760693072884\n",
      "Epoch >>  1327 0.1775760693072884 0.031543763163955546 0.14603230614333396\n",
      "Saving the model  0.1775760693072884 0.17752778476835865\n",
      "Epoch >>  1328 0.17752778476835865 0.031540339144798035 0.1459874456235618\n",
      "Saving the model  0.17752778476835865 0.1774962064031617\n",
      "Epoch >>  1329 0.1774962064031617 0.031537054178240945 0.14595915222492203\n",
      "Saving the model  0.1774962064031617 0.17746494833664317\n",
      "Epoch >>  1330 0.17746494833664317 0.031533737990243865 0.14593121034640064\n",
      "Saving the model  0.17746494833664317 0.17740855115822585\n",
      "Epoch >>  1331 0.17740855115822585 0.03153045493123291 0.1458780962269942\n",
      "Saving the model  0.17740855115822585 0.17740097072329247\n",
      "Epoch >>  1332 0.17740097072329247 0.03152704031383019 0.1458739304094635\n",
      "Saving the model  0.17740097072329247 0.17739982484471087\n",
      "Epoch >>  1333 0.17739982484471087 0.03152400359214296 0.14587582125256918\n",
      "Saving the model  0.17739982484471087 0.1773635301868854\n",
      "Epoch >>  1334 0.1773635301868854 0.0315205429406836 0.145842987246203\n",
      "Saving the model  0.1773635301868854 0.17732274456445155\n",
      "Epoch >>  1335 0.17732274456445155 0.03151756167221531 0.1458051828922374\n",
      "Saving the model  0.17732274456445155 0.17726487795856985\n",
      "Epoch >>  1336 0.17726487795856985 0.031513850445547775 0.1457510275130232\n",
      "Saving the model  0.17726487795856985 0.17722466918287108\n",
      "Epoch >>  1337 0.17722466918287108 0.03151016099720499 0.1457145081856671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.17722466918287108 0.1771839711898471\n",
      "Epoch >>  1338 0.1771839711898471 0.031506760827418975 0.14567721036242912\n",
      "Saving the model  0.1771839711898471 0.17716916234916222\n",
      "Epoch >>  1339 0.17716916234916222 0.03150404358568361 0.14566511876347968\n",
      "Epoch >>  1340 0.1771859431162615 0.031502090955606195 0.1456838521606565\n",
      "Saving the model  0.17716916234916222 0.17715957351579636\n",
      "Epoch >>  1341 0.17715957351579636 0.031498524764296834 0.14566104875150074\n",
      "Saving the model  0.17715957351579636 0.1771242522902909\n",
      "Epoch >>  1342 0.1771242522902909 0.031495070710622665 0.1456291815796695\n",
      "Saving the model  0.1771242522902909 0.1771068445407956\n",
      "Epoch >>  1343 0.1771068445407956 0.03149163250055419 0.14561521204024266\n",
      "Saving the model  0.1771068445407956 0.1770720045938346\n",
      "Epoch >>  1344 0.1770720045938346 0.031487714505846594 0.14558429008798926\n",
      "Saving the model  0.1770720045938346 0.17703102346047483\n",
      "Epoch >>  1345 0.17703102346047483 0.03148455992535546 0.1455464635351209\n",
      "Saving the model  0.17703102346047483 0.17700936259977068\n",
      "Epoch >>  1346 0.17700936259977068 0.031481160910187225 0.14552820168958508\n",
      "Saving the model  0.17700936259977068 0.17697258055022924\n",
      "Epoch >>  1347 0.17697258055022924 0.031477567653555555 0.14549501289667527\n",
      "Saving the model  0.17697258055022924 0.17692117309243294\n",
      "Epoch >>  1348 0.17692117309243294 0.031474112917196755 0.14544706017523779\n",
      "Epoch >>  1349 0.17692368106690257 0.03147119266049141 0.1454524884064129\n",
      "Saving the model  0.17692117309243294 0.1769066253849159\n",
      "Epoch >>  1350 0.1769066253849159 0.03146736506584938 0.14543926031906795\n",
      "Saving the model  0.1769066253849159 0.17689169061239954\n",
      "Epoch >>  1351 0.17689169061239954 0.03146434031837232 0.14542735029402878\n",
      "Saving the model  0.17689169061239954 0.17685304059939383\n",
      "Epoch >>  1352 0.17685304059939383 0.03146088798842481 0.14539215261097044\n",
      "Saving the model  0.17685304059939383 0.17683013463628672\n",
      "Epoch >>  1353 0.17683013463628672 0.03145801584134452 0.14537211879494352\n",
      "Saving the model  0.17683013463628672 0.17680908529262002\n",
      "Epoch >>  1354 0.17680908529262002 0.03145510842282642 0.14535397686979493\n",
      "Saving the model  0.17680908529262002 0.17676959353402594\n",
      "Epoch >>  1355 0.17676959353402594 0.031451706254917326 0.14531788727910988\n",
      "Saving the model  0.17676959353402594 0.17672788562046401\n",
      "Epoch >>  1356 0.17672788562046401 0.03144845597829228 0.14527942964217302\n",
      "Saving the model  0.17672788562046401 0.1766867884062923\n",
      "Epoch >>  1357 0.1766867884062923 0.03144546850361827 0.1452413199026753\n",
      "Saving the model  0.1766867884062923 0.17663922946246707\n",
      "Epoch >>  1358 0.17663922946246707 0.031442097106755794 0.1451971323557126\n",
      "Saving the model  0.17663922946246707 0.17662552378099086\n",
      "Epoch >>  1359 0.17662552378099086 0.03143891432512064 0.14518660945587158\n",
      "Saving the model  0.17662552378099086 0.1765904274821733\n",
      "Epoch >>  1360 0.1765904274821733 0.03143522560608828 0.14515520187608655\n",
      "Saving the model  0.1765904274821733 0.17656061938040457\n",
      "Epoch >>  1361 0.17656061938040457 0.031432152749567614 0.14512846663083842\n",
      "Saving the model  0.17656061938040457 0.17652150040609366\n",
      "Epoch >>  1362 0.17652150040609366 0.03142927006802722 0.1450922303380677\n",
      "Saving the model  0.17652150040609366 0.17649055984008316\n",
      "Epoch >>  1363 0.17649055984008316 0.03142533721664726 0.14506522262343716\n",
      "Saving the model  0.17649055984008316 0.1764733039359355\n",
      "Epoch >>  1364 0.1764733039359355 0.031422216780784704 0.14505108715515203\n",
      "Saving the model  0.1764733039359355 0.17643357106201832\n",
      "Epoch >>  1365 0.17643357106201832 0.03141866213814762 0.14501490892387198\n",
      "Saving the model  0.17643357106201832 0.17641099044771746\n",
      "Epoch >>  1366 0.17641099044771746 0.031415528427178346 0.14499546202054042\n",
      "Saving the model  0.17641099044771746 0.17639627650408282\n",
      "Epoch >>  1367 0.17639627650408282 0.0314127781201402 0.14498349838394398\n",
      "Saving the model  0.17639627650408282 0.17637729292935636\n",
      "Epoch >>  1368 0.17637729292935636 0.0314102804976291 0.14496701243172863\n",
      "Saving the model  0.17637729292935636 0.17636491758966447\n",
      "Epoch >>  1369 0.17636491758966447 0.031407084605935096 0.14495783298373088\n",
      "Saving the model  0.17636491758966447 0.17635456758009993\n",
      "Epoch >>  1370 0.17635456758009993 0.03140439660708004 0.14495017097302135\n",
      "Saving the model  0.17635456758009993 0.17632861067152128\n",
      "Epoch >>  1371 0.17632861067152128 0.03140076385770197 0.14492784681382087\n",
      "Saving the model  0.17632861067152128 0.17629316058681435\n",
      "Epoch >>  1372 0.17629316058681435 0.031397900449055695 0.14489526013776022\n",
      "Saving the model  0.17629316058681435 0.1762418715495692\n",
      "Epoch >>  1373 0.1762418715495692 0.031393968170856566 0.14484790337871403\n",
      "Saving the model  0.1762418715495692 0.1762056546139511\n",
      "Epoch >>  1374 0.1762056546139511 0.031390207390224675 0.14481544722372783\n",
      "Saving the model  0.1762056546139511 0.1761865527876288\n",
      "Epoch >>  1375 0.1761865527876288 0.03138661479782032 0.1447999379898099\n",
      "Saving the model  0.1761865527876288 0.17614530065882564\n",
      "Epoch >>  1376 0.17614530065882564 0.031383249656397466 0.14476205100242953\n",
      "Saving the model  0.17614530065882564 0.17610062403976937\n",
      "Epoch >>  1377 0.17610062403976937 0.031380018538995434 0.14472060550077528\n",
      "Saving the model  0.17610062403976937 0.17606493916158839\n",
      "Epoch >>  1378 0.17606493916158839 0.0313768140881602 0.1446881250734295\n",
      "Saving the model  0.17606493916158839 0.1760261908091692\n",
      "Epoch >>  1379 0.1760261908091692 0.031373758401984496 0.14465243240718592\n",
      "Saving the model  0.1760261908091692 0.17602394003939006\n",
      "Epoch >>  1380 0.17602394003939006 0.031370342837262095 0.14465359720212917\n",
      "Saving the model  0.17602394003939006 0.17597863854094442\n",
      "Epoch >>  1381 0.17597863854094442 0.031366887843298843 0.14461175069764678\n",
      "Saving the model  0.17597863854094442 0.17592589398887715\n",
      "Epoch >>  1382 0.17592589398887715 0.03136367044817894 0.14456222354069928\n",
      "Saving the model  0.17592589398887715 0.175880958475476\n",
      "Epoch >>  1383 0.175880958475476 0.03136027030371619 0.14452068817176084\n",
      "Saving the model  0.175880958475476 0.1758562156279413\n",
      "Epoch >>  1384 0.1758562156279413 0.031356650711454076 0.14449956491648824\n",
      "Saving the model  0.1758562156279413 0.1758435987518843\n",
      "Epoch >>  1385 0.1758435987518843 0.03135332716562886 0.14449027158625655\n",
      "Saving the model  0.1758435987518843 0.1757962288815703\n",
      "Epoch >>  1386 0.1757962288815703 0.031349658805921506 0.14444657007564987\n",
      "Saving the model  0.1757962288815703 0.17576673605310206\n",
      "Epoch >>  1387 0.17576673605310206 0.03134598644877424 0.14442074960432896\n",
      "Saving the model  0.17576673605310206 0.17575539179829208\n",
      "Epoch >>  1388 0.17575539179829208 0.03134231187195762 0.1444130799263357\n",
      "Saving the model  0.17575539179829208 0.17572345028650624\n",
      "Epoch >>  1389 0.17572345028650624 0.03133894141640065 0.14438450887010676\n",
      "Saving the model  0.17572345028650624 0.1756844759551573\n",
      "Epoch >>  1390 0.1756844759551573 0.031335390489652316 0.14434908546550615\n",
      "Saving the model  0.1756844759551573 0.1756644382479907\n",
      "Epoch >>  1391 0.1756644382479907 0.03133242928677967 0.14433200896121212\n",
      "Saving the model  0.1756644382479907 0.1756324888080698\n",
      "Epoch >>  1392 0.1756324888080698 0.031328943275255164 0.14430354553281582\n",
      "Saving the model  0.1756324888080698 0.17562479828194988\n",
      "Epoch >>  1393 0.17562479828194988 0.031326699448963144 0.14429809883298794\n",
      "Saving the model  0.17562479828194988 0.17559730684453353\n",
      "Epoch >>  1394 0.17559730684453353 0.03132353424709911 0.14427377259743554\n",
      "Saving the model  0.17559730684453353 0.1755497253839657\n",
      "Epoch >>  1395 0.1755497253839657 0.03132042551832506 0.14422929986564187\n",
      "Saving the model  0.1755497253839657 0.17550091675158308\n",
      "Epoch >>  1396 0.17550091675158308 0.03131673953407355 0.14418417721751078\n",
      "Saving the model  0.17550091675158308 0.1754729815008047\n",
      "Epoch >>  1397 0.1754729815008047 0.03131362095339122 0.14415936054741468\n",
      "Saving the model  0.1754729815008047 0.17543539396683186\n",
      "Epoch >>  1398 0.17543539396683186 0.03131016326927396 0.1441252306975591\n",
      "Saving the model  0.17543539396683186 0.17540236322486308\n",
      "Epoch >>  1399 0.17540236322486308 0.031306866991440765 0.14409549623342338\n",
      "Saving the model  0.17540236322486308 0.17537717245725815\n",
      "Epoch >>  1400 0.17537717245725815 0.031304061317195965 0.14407311114006324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.17537717245725815 0.17534864410898726\n",
      "Epoch >>  1401 0.17534864410898726 0.031301573661747094 0.14404707044724097\n",
      "Saving the model  0.17534864410898726 0.17532582692644483\n",
      "Epoch >>  1402 0.17532582692644483 0.03129860236534494 0.14402722456110073\n",
      "Saving the model  0.17532582692644483 0.17530588662212226\n",
      "Epoch >>  1403 0.17530588662212226 0.031295221644252566 0.1440106649778706\n",
      "Saving the model  0.17530588662212226 0.17526542358987016\n",
      "Epoch >>  1404 0.17526542358987016 0.03129180730729658 0.14397361628257457\n",
      "Saving the model  0.17526542358987016 0.17525164384574823\n",
      "Epoch >>  1405 0.17525164384574823 0.03128880243865852 0.14396284140709067\n",
      "Saving the model  0.17525164384574823 0.17524566526752117\n",
      "Epoch >>  1406 0.17524566526752117 0.0312857299293552 0.14395993533816692\n",
      "Epoch >>  1407 0.17525062205446323 0.03128267780484702 0.14396794424961706\n",
      "Epoch >>  1408 0.17524881741761297 0.0312806686428278 0.14396814877478603\n",
      "Saving the model  0.17524566526752117 0.17520283080623955\n",
      "Epoch >>  1409 0.17520283080623955 0.03127720149187883 0.14392562931436156\n",
      "Saving the model  0.17520283080623955 0.1751607968580269\n",
      "Epoch >>  1410 0.1751607968580269 0.03127373105053273 0.14388706580749508\n",
      "Saving the model  0.1751607968580269 0.17512826060594358\n",
      "Epoch >>  1411 0.17512826060594358 0.031270309320273984 0.14385795128567067\n",
      "Saving the model  0.17512826060594358 0.17509354055317472\n",
      "Epoch >>  1412 0.17509354055317472 0.03126696553197612 0.14382657502119972\n",
      "Saving the model  0.17509354055317472 0.1750790568392669\n",
      "Epoch >>  1413 0.1750790568392669 0.03126452381311661 0.14381453302615146\n",
      "Saving the model  0.1750790568392669 0.17506277586484764\n",
      "Epoch >>  1414 0.17506277586484764 0.031261526392102966 0.14380124947274592\n",
      "Saving the model  0.17506277586484764 0.175030272548133\n",
      "Epoch >>  1415 0.175030272548133 0.03125767913929926 0.14377259340883494\n",
      "Saving the model  0.175030272548133 0.17499709636755828\n",
      "Epoch >>  1416 0.17499709636755828 0.03125490443273946 0.14374219193482005\n",
      "Epoch >>  1417 0.17499760424641256 0.03125205828970865 0.14374554595670508\n",
      "Saving the model  0.17499709636755828 0.1749620634394899\n",
      "Epoch >>  1418 0.1749620634394899 0.031248654495761908 0.1437134089437292\n",
      "Saving the model  0.1749620634394899 0.17492540962021316\n",
      "Epoch >>  1419 0.17492540962021316 0.031245223829629805 0.1436801857905847\n",
      "Saving the model  0.17492540962021316 0.17489657044204723\n",
      "Epoch >>  1420 0.17489657044204723 0.031242271436328805 0.14365429900571974\n",
      "Saving the model  0.17489657044204723 0.17487483072696597\n",
      "Epoch >>  1421 0.17487483072696597 0.031239151123769814 0.14363567960319745\n",
      "Saving the model  0.17487483072696597 0.17484299069256096\n",
      "Epoch >>  1422 0.17484299069256096 0.031235913090050024 0.14360707760251218\n",
      "Saving the model  0.17484299069256096 0.1748396304467503\n",
      "Epoch >>  1423 0.1748396304467503 0.031233096259741966 0.1436065341870096\n",
      "Saving the model  0.1748396304467503 0.17482519590090997\n",
      "Epoch >>  1424 0.17482519590090997 0.031230351578844885 0.14359484432206648\n",
      "Saving the model  0.17482519590090997 0.1748074369618742\n",
      "Epoch >>  1425 0.1748074369618742 0.031227046010000363 0.1435803909518752\n",
      "Saving the model  0.1748074369618742 0.17477168914460395\n",
      "Epoch >>  1426 0.17477168914460395 0.031223571743770325 0.14354811740083506\n",
      "Saving the model  0.17477168914460395 0.1747399889551619\n",
      "Epoch >>  1427 0.1747399889551619 0.031220443806026975 0.14351954514913626\n",
      "Saving the model  0.1747399889551619 0.17471764742711623\n",
      "Epoch >>  1428 0.17471764742711623 0.031216834119245678 0.14350081330787193\n",
      "Saving the model  0.17471764742711623 0.17468667202984398\n",
      "Epoch >>  1429 0.17468667202984398 0.031213827620559832 0.14347284440928562\n",
      "Saving the model  0.17468667202984398 0.17465337041269266\n",
      "Epoch >>  1430 0.17465337041269266 0.031210532705926976 0.14344283770676708\n",
      "Saving the model  0.17465337041269266 0.17463163512302796\n",
      "Epoch >>  1431 0.17463163512302796 0.031207138315143886 0.1434244968078855\n",
      "Saving the model  0.17463163512302796 0.1746292452148928\n",
      "Epoch >>  1432 0.1746292452148928 0.03120386467464956 0.14342538054024456\n",
      "Saving the model  0.1746292452148928 0.17459758001111148\n",
      "Epoch >>  1433 0.17459758001111148 0.031200499418873196 0.1433970805922397\n",
      "Saving the model  0.17459758001111148 0.17457170434020272\n",
      "Epoch >>  1434 0.17457170434020272 0.03119734418063344 0.1433743601595706\n",
      "Saving the model  0.17457170434020272 0.17454573247195143\n",
      "Epoch >>  1435 0.17454573247195143 0.031194019892077842 0.14335171257987492\n",
      "Saving the model  0.17454573247195143 0.17452194436171647\n",
      "Epoch >>  1436 0.17452194436171647 0.031191516582733215 0.14333042777898453\n",
      "Saving the model  0.17452194436171647 0.17449168782388677\n",
      "Epoch >>  1437 0.17449168782388677 0.031188525066720978 0.14330316275716698\n",
      "Saving the model  0.17449168782388677 0.17446592210421413\n",
      "Epoch >>  1438 0.17446592210421413 0.031185478723264153 0.14328044338095125\n",
      "Saving the model  0.17446592210421413 0.17444066325964416\n",
      "Epoch >>  1439 0.17444066325964416 0.031182454165267246 0.14325820909437811\n",
      "Epoch >>  1440 0.17444334807482095 0.03117967954930343 0.14326366852551872\n",
      "Saving the model  0.17444066325964416 0.17440230827456302\n",
      "Epoch >>  1441 0.17440230827456302 0.031176230835917276 0.14322607743864704\n",
      "Saving the model  0.17440230827456302 0.17438235769379729\n",
      "Epoch >>  1442 0.17438235769379729 0.03117366663440065 0.1432086910593979\n",
      "Saving the model  0.17438235769379729 0.17436075267389411\n",
      "Epoch >>  1443 0.17436075267389411 0.031170498220700192 0.1431902544531952\n",
      "Saving the model  0.17436075267389411 0.1743504021063654\n",
      "Epoch >>  1444 0.1743504021063654 0.031167866966836842 0.1431825351395298\n",
      "Saving the model  0.1743504021063654 0.17433111221323483\n",
      "Epoch >>  1445 0.17433111221323483 0.031164501310902846 0.14316661090233312\n",
      "Saving the model  0.17433111221323483 0.17430069511924992\n",
      "Epoch >>  1446 0.17430069511924992 0.031160654290694444 0.14314004082855664\n",
      "Saving the model  0.17430069511924992 0.1742704817136698\n",
      "Epoch >>  1447 0.1742704817136698 0.031158034608937655 0.14311244710473328\n",
      "Saving the model  0.1742704817136698 0.1742430799579372\n",
      "Epoch >>  1448 0.1742430799579372 0.031155266172233353 0.14308781378570498\n",
      "Saving the model  0.1742430799579372 0.17421913433452396\n",
      "Epoch >>  1449 0.17421913433452396 0.031151937945778287 0.14306719638874685\n",
      "Saving the model  0.17421913433452396 0.1741867405654555\n",
      "Epoch >>  1450 0.1741867405654555 0.031148287998701094 0.1430384525667556\n",
      "Saving the model  0.1741867405654555 0.1741806101472246\n",
      "Epoch >>  1451 0.1741806101472246 0.031145205933339252 0.14303540421388658\n",
      "Saving the model  0.1741806101472246 0.17414090981418223\n",
      "Epoch >>  1452 0.17414090981418223 0.031141468500302284 0.1429994413138811\n",
      "Saving the model  0.17414090981418223 0.17408727845190322\n",
      "Epoch >>  1453 0.17408727845190322 0.03113785425253168 0.1429494241993725\n",
      "Saving the model  0.17408727845190322 0.17405893518949866\n",
      "Epoch >>  1454 0.17405893518949866 0.0311354169305396 0.14292351825896\n",
      "Saving the model  0.17405893518949866 0.17403206159225315\n",
      "Epoch >>  1455 0.17403206159225315 0.0311325300453944 0.14289953154685978\n",
      "Saving the model  0.17403206159225315 0.17401895901058045\n",
      "Epoch >>  1456 0.17401895901058045 0.031129941229530073 0.14288901778105137\n",
      "Saving the model  0.17401895901058045 0.17398092576215293\n",
      "Epoch >>  1457 0.17398092576215293 0.031126617780067117 0.1428543079820869\n",
      "Saving the model  0.17398092576215293 0.17394655568144798\n",
      "Epoch >>  1458 0.17394655568144798 0.031123539451401522 0.14282301623004778\n",
      "Saving the model  0.17394655568144798 0.17390673999297734\n",
      "Epoch >>  1459 0.17390673999297734 0.031120235070644996 0.14278650492233366\n",
      "Saving the model  0.17390673999297734 0.17387694530267864\n",
      "Epoch >>  1460 0.17387694530267864 0.031117056595241818 0.14275988870743833\n",
      "Saving the model  0.17387694530267864 0.1738532260851337\n",
      "Epoch >>  1461 0.1738532260851337 0.03111412632201632 0.14273909976311885\n",
      "Epoch >>  1462 0.17386005247568023 0.03111200578364096 0.14274804669204072\n",
      "Saving the model  0.1738532260851337 0.17383696897983844\n",
      "Epoch >>  1463 0.17383696897983844 0.03110917892776216 0.14272779005207767\n",
      "Saving the model  0.17383696897983844 0.17380419133994346\n",
      "Epoch >>  1464 0.17380419133994346 0.031106103977133363 0.1426980873628114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.17380419133994346 0.17379230275578436\n",
      "Epoch >>  1465 0.17379230275578436 0.031103151787597354 0.14268915096818838\n",
      "Saving the model  0.17379230275578436 0.17376042248168647\n",
      "Epoch >>  1466 0.17376042248168647 0.031099661295956794 0.14266076118573098\n",
      "Saving the model  0.17376042248168647 0.17372147413456498\n",
      "Epoch >>  1467 0.17372147413456498 0.031096418317007792 0.1426250558175585\n",
      "Saving the model  0.17372147413456498 0.17370531187179183\n",
      "Epoch >>  1468 0.17370531187179183 0.03109374478506384 0.1426115670867291\n",
      "Saving the model  0.17370531187179183 0.17368121729503846\n",
      "Epoch >>  1469 0.17368121729503846 0.03109053364911928 0.1425906836459202\n",
      "Saving the model  0.17368121729503846 0.1736581007995868\n",
      "Epoch >>  1470 0.1736581007995868 0.03108730144205404 0.1425707993575337\n",
      "Saving the model  0.1736581007995868 0.17363452362717657\n",
      "Epoch >>  1471 0.17363452362717657 0.031084356957643552 0.14255016666953385\n",
      "Saving the model  0.17363452362717657 0.1736078177018411\n",
      "Epoch >>  1472 0.1736078177018411 0.031081497888894284 0.14252631981294756\n",
      "Saving the model  0.1736078177018411 0.1735798217970911\n",
      "Epoch >>  1473 0.1735798217970911 0.031078381384730378 0.14250144041236137\n",
      "Saving the model  0.1735798217970911 0.17355494703202595\n",
      "Epoch >>  1474 0.17355494703202595 0.03107557549969032 0.14247937153233634\n",
      "Saving the model  0.17355494703202595 0.17354934672636776\n",
      "Epoch >>  1475 0.17354934672636776 0.031073355913448064 0.14247599081292023\n",
      "Saving the model  0.17354934672636776 0.17352164609387727\n",
      "Epoch >>  1476 0.17352164609387727 0.03107090400207471 0.14245074209180314\n",
      "Saving the model  0.17352164609387727 0.1734840372458079\n",
      "Epoch >>  1477 0.1734840372458079 0.031067805140344133 0.14241623210546436\n",
      "Saving the model  0.1734840372458079 0.17345943551403997\n",
      "Epoch >>  1478 0.17345943551403997 0.03106507792822406 0.14239435758581645\n",
      "Saving the model  0.17345943551403997 0.17342986056172013\n",
      "Epoch >>  1479 0.17342986056172013 0.031061841131400206 0.1423680194303203\n",
      "Saving the model  0.17342986056172013 0.17340461318366332\n",
      "Epoch >>  1480 0.17340461318366332 0.03105852435831874 0.14234608882534505\n",
      "Saving the model  0.17340461318366332 0.17337797426010015\n",
      "Epoch >>  1481 0.17337797426010015 0.03105623633318927 0.14232173792691144\n",
      "Saving the model  0.17337797426010015 0.17337531842468729\n",
      "Epoch >>  1482 0.17337531842468729 0.031054026620390193 0.1423212918042977\n",
      "Saving the model  0.17337531842468729 0.17334609753971647\n",
      "Epoch >>  1483 0.17334609753971647 0.031051070023998057 0.14229502751571896\n",
      "Epoch >>  1484 0.17335523504263822 0.031048487347402395 0.1423067476952365\n",
      "Saving the model  0.17334609753971647 0.17333826779082362\n",
      "Epoch >>  1485 0.17333826779082362 0.031045239037101033 0.14229302875372324\n",
      "Saving the model  0.17333826779082362 0.17330373611446215\n",
      "Epoch >>  1486 0.17330373611446215 0.031042398158021352 0.14226133795644133\n",
      "Saving the model  0.17330373611446215 0.17327732616036676\n",
      "Epoch >>  1487 0.17327732616036676 0.031039145416824395 0.14223818074354297\n",
      "Epoch >>  1488 0.17328180629851403 0.031037074657494234 0.14224473164102028\n",
      "Epoch >>  1489 0.17327900535109614 0.031034288187908213 0.14224471716318846\n",
      "Saving the model  0.17327732616036676 0.1732547309900443\n",
      "Epoch >>  1490 0.1732547309900443 0.031031944345571223 0.14222278664447355\n",
      "Saving the model  0.1732547309900443 0.17323272222514946\n",
      "Epoch >>  1491 0.17323272222514946 0.03102851343680108 0.14220420878834872\n",
      "Saving the model  0.17323272222514946 0.17320344818177483\n",
      "Epoch >>  1492 0.17320344818177483 0.03102595569144015 0.1421774924903351\n",
      "Saving the model  0.17320344818177483 0.17317051219866536\n",
      "Epoch >>  1493 0.17317051219866536 0.031022955807061502 0.1421475563916044\n",
      "Saving the model  0.17317051219866536 0.17316909834170416\n",
      "Epoch >>  1494 0.17316909834170416 0.0310204860946958 0.14214861224700895\n",
      "Saving the model  0.17316909834170416 0.1731358970115442\n",
      "Epoch >>  1495 0.1731358970115442 0.031017157303131634 0.14211873970841313\n",
      "Saving the model  0.1731358970115442 0.17310490130978923\n",
      "Epoch >>  1496 0.17310490130978923 0.03101383922722055 0.14209106208256936\n",
      "Saving the model  0.17310490130978923 0.17307704983061628\n",
      "Epoch >>  1497 0.17307704983061628 0.031010843416636846 0.1420662064139803\n",
      "Saving the model  0.17307704983061628 0.17303927459757187\n",
      "Epoch >>  1498 0.17303927459757187 0.031008276756984983 0.1420309978405876\n",
      "Saving the model  0.17303927459757187 0.17300789302823252\n",
      "Epoch >>  1499 0.17300789302823252 0.031005360923779136 0.14200253210445424\n",
      "Saving the model  0.17300789302823252 0.17297319317815554\n",
      "Epoch >>  1500 0.17297319317815554 0.03100254095500134 0.1419706522231551\n",
      "Saving the model  0.17297319317815554 0.17293787325634305\n",
      "Epoch >>  1501 0.17293787325634305 0.030999430290143255 0.14193844296620067\n",
      "Saving the model  0.17293787325634305 0.17292427549251047\n",
      "Epoch >>  1502 0.17292427549251047 0.030996760379531845 0.14192751511297952\n",
      "Saving the model  0.17292427549251047 0.17290032328814645\n",
      "Epoch >>  1503 0.17290032328814645 0.030993807306012776 0.14190651598213436\n",
      "Saving the model  0.17290032328814645 0.17287284021843716\n",
      "Epoch >>  1504 0.17287284021843716 0.03099041023681873 0.14188242998161923\n",
      "Saving the model  0.17287284021843716 0.17286768924729137\n",
      "Epoch >>  1505 0.17286768924729137 0.030987646785412833 0.14188004246187944\n",
      "Saving the model  0.17286768924729137 0.1728415209566464\n",
      "Epoch >>  1506 0.1728415209566464 0.030984521472534634 0.14185699948411268\n",
      "Saving the model  0.1728415209566464 0.1728187681951644\n",
      "Epoch >>  1507 0.1728187681951644 0.030981505859786155 0.14183726233537916\n",
      "Saving the model  0.1728187681951644 0.17278642464690713\n",
      "Epoch >>  1508 0.17278642464690713 0.030978042187038438 0.14180838245986951\n",
      "Saving the model  0.17278642464690713 0.17276757073661123\n",
      "Epoch >>  1509 0.17276757073661123 0.030975355665491575 0.14179221507112058\n",
      "Saving the model  0.17276757073661123 0.17274751401986047\n",
      "Epoch >>  1510 0.17274751401986047 0.030972621768013322 0.14177489225184803\n",
      "Saving the model  0.17274751401986047 0.17273002851027777\n",
      "Epoch >>  1511 0.17273002851027777 0.030969381050525182 0.14176064745975334\n",
      "Saving the model  0.17273002851027777 0.17270106656255446\n",
      "Epoch >>  1512 0.17270106656255446 0.03096573512418507 0.1417353314383702\n",
      "Saving the model  0.17270106656255446 0.172698289911279\n",
      "Epoch >>  1513 0.172698289911279 0.030962391985269924 0.14173589792600988\n",
      "Saving the model  0.172698289911279 0.17268031494368447\n",
      "Epoch >>  1514 0.17268031494368447 0.030959250145489146 0.14172106479819604\n",
      "Saving the model  0.17268031494368447 0.17265188560446731\n",
      "Epoch >>  1515 0.17265188560446731 0.03095585671170836 0.14169602889275967\n",
      "Saving the model  0.17265188560446731 0.17264558075372624\n",
      "Epoch >>  1516 0.17264558075372624 0.030953225873552814 0.1416923548801742\n",
      "Saving the model  0.17264558075372624 0.1726374028851873\n",
      "Epoch >>  1517 0.1726374028851873 0.030950357979267804 0.1416870449059203\n",
      "Saving the model  0.1726374028851873 0.17261963418935172\n",
      "Epoch >>  1518 0.17261963418935172 0.03094748844974864 0.14167214573960377\n",
      "Saving the model  0.17261963418935172 0.17258431686070452\n",
      "Epoch >>  1519 0.17258431686070452 0.030943857614674292 0.14164045924603058\n",
      "Saving the model  0.17258431686070452 0.17255414282667783\n",
      "Epoch >>  1520 0.17255414282667783 0.030941070340000154 0.14161307248667823\n",
      "Saving the model  0.17255414282667783 0.1725275785717213\n",
      "Epoch >>  1521 0.1725275785717213 0.030937802835683915 0.14158977573603782\n",
      "Saving the model  0.1725275785717213 0.17250219704438746\n",
      "Epoch >>  1522 0.17250219704438746 0.030934957185764618 0.14156723985862352\n",
      "Saving the model  0.17250219704438746 0.1724816458597619\n",
      "Epoch >>  1523 0.1724816458597619 0.03093178022242688 0.14154986563733576\n",
      "Saving the model  0.1724816458597619 0.17243600754061852\n",
      "Epoch >>  1524 0.17243600754061852 0.03092835684706126 0.14150765069355814\n",
      "Saving the model  0.17243600754061852 0.17242631741375886\n",
      "Epoch >>  1525 0.17242631741375886 0.030926113896406697 0.14150020351735304\n",
      "Saving the model  0.17242631741375886 0.17238614588938897\n",
      "Epoch >>  1526 0.17238614588938897 0.0309230225562921 0.14146312333309805\n",
      "Epoch >>  1527 0.17240809119641523 0.030921214110189738 0.1414868770862266\n",
      "Saving the model  0.17238614588938897 0.17238103364171767\n",
      "Epoch >>  1528 0.17238103364171767 0.030918680262273655 0.14146235337944524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.17238103364171767 0.17235613838356909\n",
      "Epoch >>  1529 0.17235613838356909 0.030915998091907114 0.14144014029166313\n",
      "Saving the model  0.17235613838356909 0.17233195825673805\n",
      "Epoch >>  1530 0.17233195825673805 0.030912570750379557 0.14141938750635988\n",
      "Saving the model  0.17233195825673805 0.1723178368478877\n",
      "Epoch >>  1531 0.1723178368478877 0.030910029401959752 0.14140780744592948\n",
      "Saving the model  0.1723178368478877 0.1722897676475499\n",
      "Epoch >>  1532 0.1722897676475499 0.030907489332000035 0.14138227831555109\n",
      "Saving the model  0.1722897676475499 0.17226363650388682\n",
      "Epoch >>  1533 0.17226363650388682 0.03090484815836766 0.14135878834552043\n",
      "Saving the model  0.17226363650388682 0.17225699387065252\n",
      "Epoch >>  1534 0.17225699387065252 0.030901916363894333 0.1413550775067594\n",
      "Saving the model  0.17225699387065252 0.17223471106875746\n",
      "Epoch >>  1535 0.17223471106875746 0.030899335378660672 0.1413353756900979\n",
      "Saving the model  0.17223471106875746 0.172205497159355\n",
      "Epoch >>  1536 0.172205497159355 0.030896233080046263 0.14130926407930963\n",
      "Epoch >>  1537 0.17220874307969294 0.030893896637278623 0.14131484644241543\n",
      "Saving the model  0.172205497159355 0.17219253705735668\n",
      "Epoch >>  1538 0.17219253705735668 0.030890866475236374 0.1413016705821214\n",
      "Saving the model  0.17219253705735668 0.17216579735655804\n",
      "Epoch >>  1539 0.17216579735655804 0.030887736208962457 0.14127806114759656\n",
      "Saving the model  0.17216579735655804 0.17214288626910668\n",
      "Epoch >>  1540 0.17214288626910668 0.030884812785817003 0.14125807348329072\n",
      "Saving the model  0.17214288626910668 0.17212653746196804\n",
      "Epoch >>  1541 0.17212653746196804 0.030882875416849222 0.1412436620451199\n",
      "Saving the model  0.17212653746196804 0.17209939616748293\n",
      "Epoch >>  1542 0.17209939616748293 0.030879772002846785 0.14121962416463724\n",
      "Epoch >>  1543 0.17210393925090164 0.030877123689672176 0.1412268155612308\n",
      "Saving the model  0.17209939616748293 0.17208963139217137\n",
      "Epoch >>  1544 0.17208963139217137 0.03087425813764688 0.14121537325452596\n",
      "Saving the model  0.17208963139217137 0.1720587037429341\n",
      "Epoch >>  1545 0.1720587037429341 0.03087106441561535 0.14118763932732042\n",
      "Saving the model  0.1720587037429341 0.17202387204763842\n",
      "Epoch >>  1546 0.17202387204763842 0.03086818914426813 0.14115568290337205\n",
      "Saving the model  0.17202387204763842 0.17198912966981766\n",
      "Epoch >>  1547 0.17198912966981766 0.030865243118856776 0.1411238865509626\n",
      "Saving the model  0.17198912966981766 0.1719763915462971\n",
      "Epoch >>  1548 0.1719763915462971 0.030862448427207007 0.1411139431190918\n",
      "Saving the model  0.1719763915462971 0.17194634239423273\n",
      "Epoch >>  1549 0.17194634239423273 0.030859593381986634 0.1410867490122475\n",
      "Saving the model  0.17194634239423273 0.17192503102871481\n",
      "Epoch >>  1550 0.17192503102871481 0.030856575363038742 0.14106845566567747\n",
      "Saving the model  0.17192503102871481 0.1718816140159844\n",
      "Epoch >>  1551 0.1718816140159844 0.030853409915370503 0.14102820410061503\n",
      "Saving the model  0.1718816140159844 0.17185568824146588\n",
      "Epoch >>  1552 0.17185568824146588 0.03085043176187505 0.1410052564795919\n",
      "Saving the model  0.17185568824146588 0.17183321320744438\n",
      "Epoch >>  1553 0.17183321320744438 0.030848320936511145 0.14098489227093422\n",
      "Saving the model  0.17183321320744438 0.1718091534950251\n",
      "Epoch >>  1554 0.1718091534950251 0.030845567311443545 0.14096358618358282\n",
      "Saving the model  0.1718091534950251 0.17178571591398767\n",
      "Epoch >>  1555 0.17178571591398767 0.030842490927438085 0.1409432249865509\n",
      "Saving the model  0.17178571591398767 0.17177337105932777\n",
      "Epoch >>  1556 0.17177337105932777 0.030839684692262573 0.14093368636706657\n",
      "Saving the model  0.17177337105932777 0.17176358391857474\n",
      "Epoch >>  1557 0.17176358391857474 0.030837466215533498 0.1409261177030427\n",
      "Saving the model  0.17176358391857474 0.1717579805709449\n",
      "Epoch >>  1558 0.1717579805709449 0.03083479034974789 0.14092319022119856\n",
      "Saving the model  0.1717579805709449 0.17173466364660875\n",
      "Epoch >>  1559 0.17173466364660875 0.030832063061762775 0.1409026005848477\n",
      "Saving the model  0.17173466364660875 0.17170849469683416\n",
      "Epoch >>  1560 0.17170849469683416 0.030828953320549364 0.14087954137628653\n",
      "Saving the model  0.17170849469683416 0.17166517212724333\n",
      "Epoch >>  1561 0.17166517212724333 0.030825671129464074 0.1408395009977809\n",
      "Saving the model  0.17166517212724333 0.17163248394059452\n",
      "Epoch >>  1562 0.17163248394059452 0.030822846286555593 0.14080963765404053\n",
      "Saving the model  0.17163248394059452 0.1715954063515116\n",
      "Epoch >>  1563 0.1715954063515116 0.03082004716961194 0.14077535918190134\n",
      "Epoch >>  1564 0.17159647882778292 0.030817286002329664 0.1407791928254547\n",
      "Saving the model  0.1715954063515116 0.1715455734201644\n",
      "Epoch >>  1565 0.1715455734201644 0.03081387104456424 0.14073170237560165\n",
      "Saving the model  0.1715455734201644 0.17153225076005643\n",
      "Epoch >>  1566 0.17153225076005643 0.030810912418659027 0.14072133834139894\n",
      "Saving the model  0.17153225076005643 0.1714994691165215\n",
      "Epoch >>  1567 0.1714994691165215 0.03080828620713984 0.14069118290938348\n",
      "Saving the model  0.1714994691165215 0.17148252671430883\n",
      "Epoch >>  1568 0.17148252671430883 0.030805714620090602 0.1406768120942198\n",
      "Saving the model  0.17148252671430883 0.17146560876440728\n",
      "Epoch >>  1569 0.17146560876440728 0.030803239568675415 0.14066236919573322\n",
      "Saving the model  0.17146560876440728 0.1714367503911729\n",
      "Epoch >>  1570 0.1714367503911729 0.030800734209379448 0.14063601618179472\n",
      "Saving the model  0.1714367503911729 0.17139596512902452\n",
      "Epoch >>  1571 0.17139596512902452 0.030797661803078098 0.14059830332594775\n",
      "Saving the model  0.17139596512902452 0.17135472739674087\n",
      "Epoch >>  1572 0.17135472739674087 0.030794254654870255 0.14056047274187194\n",
      "Saving the model  0.17135472739674087 0.1713352791214348\n",
      "Epoch >>  1573 0.1713352791214348 0.030791652543278238 0.1405436265781577\n",
      "Saving the model  0.1713352791214348 0.17130173121383402\n",
      "Epoch >>  1574 0.17130173121383402 0.030788413610456804 0.14051331760337843\n",
      "Saving the model  0.17130173121383402 0.17128230948934545\n",
      "Epoch >>  1575 0.17128230948934545 0.03078571357731249 0.14049659591203403\n",
      "Saving the model  0.17128230948934545 0.17125822022892756\n",
      "Epoch >>  1576 0.17125822022892756 0.030782579136438334 0.14047564109249025\n",
      "Saving the model  0.17125822022892756 0.17121346480137495\n",
      "Epoch >>  1577 0.17121346480137495 0.030779821863017726 0.14043364293835842\n",
      "Saving the model  0.17121346480137495 0.17118497754334647\n",
      "Epoch >>  1578 0.17118497754334647 0.030776607411416988 0.1404083701319307\n",
      "Saving the model  0.17118497754334647 0.17115783768600407\n",
      "Epoch >>  1579 0.17115783768600407 0.030773333050531038 0.14038450463547403\n",
      "Saving the model  0.17115783768600407 0.17111442423293358\n",
      "Epoch >>  1580 0.17111442423293358 0.03077021192667558 0.14034421230625888\n",
      "Saving the model  0.17111442423293358 0.17110520964974862\n",
      "Epoch >>  1581 0.17110520964974862 0.030767691809110157 0.14033751784063922\n",
      "Saving the model  0.17110520964974862 0.17106565086551934\n",
      "Epoch >>  1582 0.17106565086551934 0.030764588897807546 0.14030106196771264\n",
      "Saving the model  0.17106565086551934 0.17101032456131834\n",
      "Epoch >>  1583 0.17101032456131834 0.03076112325675349 0.14024920130456545\n",
      "Saving the model  0.17101032456131834 0.17096676399945318\n",
      "Epoch >>  1584 0.17096676399945318 0.030758625432226534 0.14020813856722744\n",
      "Saving the model  0.17096676399945318 0.17094345839725753\n",
      "Epoch >>  1585 0.17094345839725753 0.030755657706998348 0.1401878006902602\n",
      "Saving the model  0.17094345839725753 0.1709153932883477\n",
      "Epoch >>  1586 0.1709153932883477 0.030752443095578612 0.14016295019277006\n",
      "Saving the model  0.1709153932883477 0.17089781003754284\n",
      "Epoch >>  1587 0.17089781003754284 0.03074971193156332 0.14014809810598053\n",
      "Saving the model  0.17089781003754284 0.17085969081586758\n",
      "Epoch >>  1588 0.17085969081586758 0.03074685684328445 0.1401128339725841\n",
      "Saving the model  0.17085969081586758 0.17084239910715776\n",
      "Epoch >>  1589 0.17084239910715776 0.030744057212376746 0.14009834189478187\n",
      "Saving the model  0.17084239910715776 0.17081655709323942\n",
      "Epoch >>  1590 0.17081655709323942 0.030741285293522425 0.14007527179971802\n",
      "Saving the model  0.17081655709323942 0.1708080839232594\n",
      "Epoch >>  1591 0.1708080839232594 0.0307384445458331 0.14006963937742734\n",
      "Saving the model  0.1708080839232594 0.1707900004973901\n",
      "Epoch >>  1592 0.1707900004973901 0.030735835256091127 0.1400541652413001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.1707900004973901 0.17075835952539548\n",
      "Epoch >>  1593 0.17075835952539548 0.0307328243678506 0.14002553515754568\n",
      "Saving the model  0.17075835952539548 0.17073504531717112\n",
      "Epoch >>  1594 0.17073504531717112 0.030730582668658482 0.14000446264851327\n",
      "Saving the model  0.17073504531717112 0.1707243566111522\n",
      "Epoch >>  1595 0.1707243566111522 0.030728303176308334 0.13999605343484436\n",
      "Saving the model  0.1707243566111522 0.17068743167659145\n",
      "Epoch >>  1596 0.17068743167659145 0.03072515492079222 0.13996227675579948\n",
      "Saving the model  0.17068743167659145 0.17066776362186908\n",
      "Epoch >>  1597 0.17066776362186908 0.030722175452648822 0.13994558816922034\n",
      "Saving the model  0.17066776362186908 0.1706217782267449\n",
      "Epoch >>  1598 0.1706217782267449 0.03071932260678759 0.1399024556199575\n",
      "Saving the model  0.1706217782267449 0.17058422892047242\n",
      "Epoch >>  1599 0.17058422892047242 0.030716430474406878 0.1398677984460655\n",
      "Saving the model  0.17058422892047242 0.17056423069233417\n",
      "Epoch >>  1600 0.17056423069233417 0.030714410547798 0.13984982014453598\n",
      "Saving the model  0.17056423069233417 0.17053401538719007\n",
      "Epoch >>  1601 0.17053401538719007 0.030711440882420647 0.1398225745047694\n",
      "Saving the model  0.17053401538719007 0.17052154917688184\n",
      "Epoch >>  1602 0.17052154917688184 0.030708590796226905 0.13981295838065472\n",
      "Epoch >>  1603 0.17052248518808616 0.03070598603560054 0.1398164991524854\n",
      "Saving the model  0.17052154917688184 0.17049599238670451\n",
      "Epoch >>  1604 0.17049599238670451 0.03070303325139515 0.13979295913530923\n",
      "Saving the model  0.17049599238670451 0.17046525060777795\n",
      "Epoch >>  1605 0.17046525060777795 0.030700375451029403 0.1397648751567485\n",
      "Saving the model  0.17046525060777795 0.1704397250012095\n",
      "Epoch >>  1606 0.1704397250012095 0.030697503799643363 0.13974222120156618\n",
      "Saving the model  0.1704397250012095 0.17042250322612335\n",
      "Epoch >>  1607 0.17042250322612335 0.030695077866943487 0.13972742535917956\n",
      "Saving the model  0.17042250322612335 0.17038204554804778\n",
      "Epoch >>  1608 0.17038204554804778 0.03069185306858372 0.13969019247946363\n",
      "Saving the model  0.17038204554804778 0.17035571292432572\n",
      "Epoch >>  1609 0.17035571292432572 0.030689029917226877 0.13966668300709842\n",
      "Saving the model  0.17035571292432572 0.17031431230889044\n",
      "Epoch >>  1610 0.17031431230889044 0.03068563805813218 0.13962867425075806\n",
      "Saving the model  0.17031431230889044 0.1702842217737876\n",
      "Epoch >>  1611 0.1702842217737876 0.030682995236680072 0.13960122653710721\n",
      "Saving the model  0.1702842217737876 0.17025069649725533\n",
      "Epoch >>  1612 0.17025069649725533 0.030680127012889646 0.13957056948436564\n",
      "Saving the model  0.17025069649725533 0.1702330266882642\n",
      "Epoch >>  1613 0.1702330266882642 0.030677641964874672 0.13955538472338952\n",
      "Saving the model  0.1702330266882642 0.1702062235599532\n",
      "Epoch >>  1614 0.1702062235599532 0.03067541394334689 0.139530809616606\n",
      "Saving the model  0.1702062235599532 0.17017102653683194\n",
      "Epoch >>  1615 0.17017102653683194 0.030672872914501378 0.13949815362233023\n",
      "Saving the model  0.17017102653683194 0.1701495251602084\n",
      "Epoch >>  1616 0.1701495251602084 0.03066989701262962 0.13947962814757855\n",
      "Saving the model  0.1701495251602084 0.17012218478253782\n",
      "Epoch >>  1617 0.17012218478253782 0.03066709045615186 0.1394550943263855\n",
      "Saving the model  0.17012218478253782 0.17012148072254277\n",
      "Epoch >>  1618 0.17012148072254277 0.03066453426948993 0.13945694645305257\n",
      "Saving the model  0.17012148072254277 0.1700977117605895\n",
      "Epoch >>  1619 0.1700977117605895 0.03066159035229048 0.1394361214082987\n",
      "Saving the model  0.1700977117605895 0.1700725172161982\n",
      "Epoch >>  1620 0.1700725172161982 0.030658663526650778 0.1394138536895467\n",
      "Saving the model  0.1700725172161982 0.17003208622507\n",
      "Epoch >>  1621 0.17003208622507 0.030655316487636107 0.13937676973743332\n",
      "Saving the model  0.17003208622507 0.16999324645918162\n",
      "Epoch >>  1622 0.16999324645918162 0.030653333685193743 0.13933991277398716\n",
      "Saving the model  0.16999324645918162 0.16995958355946242\n",
      "Epoch >>  1623 0.16995958355946242 0.03065104261086437 0.13930854094859724\n",
      "Saving the model  0.16995958355946242 0.16993514233232426\n",
      "Epoch >>  1624 0.16993514233232426 0.0306481949723768 0.1392869473599467\n",
      "Saving the model  0.16993514233232426 0.16991376562337257\n",
      "Epoch >>  1625 0.16991376562337257 0.03064531890173927 0.1392684467216326\n",
      "Saving the model  0.16991376562337257 0.16988648101126477\n",
      "Epoch >>  1626 0.16988648101126477 0.030642658437607842 0.1392438225736559\n",
      "Saving the model  0.16988648101126477 0.16988281467535812\n",
      "Epoch >>  1627 0.16988281467535812 0.030639929784061843 0.13924288489129505\n",
      "Saving the model  0.16988281467535812 0.16987670734835728\n",
      "Epoch >>  1628 0.16987670734835728 0.030637035287464677 0.13923967206089152\n",
      "Saving the model  0.16987670734835728 0.1698744270362027\n",
      "Epoch >>  1629 0.1698744270362027 0.03063445192795044 0.13923997510825106\n",
      "Epoch >>  1630 0.16988282092496085 0.030632319180220295 0.1392505017447392\n",
      "Saving the model  0.1698744270362027 0.1698630315025306\n",
      "Epoch >>  1631 0.1698630315025306 0.030629954038547586 0.13923307746398153\n",
      "Saving the model  0.1698630315025306 0.16984061108153617\n",
      "Epoch >>  1632 0.16984061108153617 0.03062723105501605 0.13921338002651845\n",
      "Saving the model  0.16984061108153617 0.16982535803747165\n",
      "Epoch >>  1633 0.16982535803747165 0.030624255085155167 0.13920110295231466\n",
      "Saving the model  0.16982535803747165 0.1698125808248709\n",
      "Epoch >>  1634 0.1698125808248709 0.030621218108730953 0.13919136271613836\n",
      "Saving the model  0.1698125808248709 0.16979817977833062\n",
      "Epoch >>  1635 0.16979817977833062 0.030618894145177027 0.13917928563315224\n",
      "Saving the model  0.16979817977833062 0.16977095272994364\n",
      "Epoch >>  1636 0.16977095272994364 0.030616090365140725 0.13915486236480126\n",
      "Saving the model  0.16977095272994364 0.16974952044625444\n",
      "Epoch >>  1637 0.16974952044625444 0.030613562750708152 0.13913595769554477\n",
      "Saving the model  0.16974952044625444 0.16971321191688807\n",
      "Epoch >>  1638 0.16971321191688807 0.030610340551138683 0.1391028713657476\n",
      "Saving the model  0.16971321191688807 0.1696923815554465\n",
      "Epoch >>  1639 0.1696923815554465 0.03060804186482124 0.13908433969062337\n",
      "Saving the model  0.1696923815554465 0.16967003581615842\n",
      "Epoch >>  1640 0.16967003581615842 0.0306055457941744 0.13906449002198207\n",
      "Saving the model  0.16967003581615842 0.16966278465754292\n",
      "Epoch >>  1641 0.16966278465754292 0.030603365560411985 0.13905941909712916\n",
      "Saving the model  0.16966278465754292 0.16964920093504995\n",
      "Epoch >>  1642 0.16964920093504995 0.03060047648168236 0.13904872445336575\n",
      "Saving the model  0.16964920093504995 0.16963573136563503\n",
      "Epoch >>  1643 0.16963573136563503 0.03059789468828202 0.13903783667735098\n",
      "Saving the model  0.16963573136563503 0.16960036636830858\n",
      "Epoch >>  1644 0.16960036636830858 0.030594876017231376 0.13900549035107523\n",
      "Saving the model  0.16960036636830858 0.16958183279771\n",
      "Epoch >>  1645 0.16958183279771 0.03059213364225393 0.13898969915545414\n",
      "Saving the model  0.16958183279771 0.16956328071183263\n",
      "Epoch >>  1646 0.16956328071183263 0.030589109803682207 0.13897417090814865\n",
      "Saving the model  0.16956328071183263 0.16955742635497814\n",
      "Epoch >>  1647 0.16955742635497814 0.030586097666711335 0.1389713286882653\n",
      "Saving the model  0.16955742635497814 0.1695422139850356\n",
      "Epoch >>  1648 0.1695422139850356 0.030583621865168973 0.13895859211986497\n",
      "Saving the model  0.1695422139850356 0.16952919693789978\n",
      "Epoch >>  1649 0.16952919693789978 0.03058134678504076 0.1389478501528573\n",
      "Saving the model  0.16952919693789978 0.16949843286141153\n",
      "Epoch >>  1650 0.16949843286141153 0.030578514373223207 0.13891991848818658\n",
      "Saving the model  0.16949843286141153 0.16947831085907467\n",
      "Epoch >>  1651 0.16947831085907467 0.030575890388759276 0.13890242047031356\n",
      "Saving the model  0.16947831085907467 0.16945621250718576\n",
      "Epoch >>  1652 0.16945621250718576 0.03057345745947928 0.13888275504770484\n",
      "Saving the model  0.16945621250718576 0.16944000821599367\n",
      "Epoch >>  1653 0.16944000821599367 0.03057061944195029 0.1388693887740419\n",
      "Saving the model  0.16944000821599367 0.16941118994812385\n",
      "Epoch >>  1654 0.16941118994812385 0.03056779065533702 0.13884339929278525\n",
      "Saving the model  0.16941118994812385 0.16940009448308518\n",
      "Epoch >>  1655 0.16940009448308518 0.030564893619416368 0.1388352008636672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.16940009448308518 0.16938341953600022\n",
      "Epoch >>  1656 0.16938341953600022 0.03056256705144344 0.13882085248455514\n",
      "Saving the model  0.16938341953600022 0.1693577975480296\n",
      "Epoch >>  1657 0.1693577975480296 0.030559736388033856 0.1387980611599941\n",
      "Saving the model  0.1693577975480296 0.1693339369615087\n",
      "Epoch >>  1658 0.1693339369615087 0.030557031833375468 0.13877690512813162\n",
      "Saving the model  0.1693339369615087 0.16931403001189993\n",
      "Epoch >>  1659 0.16931403001189993 0.030554222137548968 0.13875980787434927\n",
      "Saving the model  0.16931403001189993 0.1693057022529562\n",
      "Epoch >>  1660 0.1693057022529562 0.03055160008018349 0.13875410217277095\n",
      "Saving the model  0.1693057022529562 0.1692771747950725\n",
      "Epoch >>  1661 0.1692771747950725 0.03054902049668587 0.13872815429838511\n",
      "Saving the model  0.1692771747950725 0.1692649208517158\n",
      "Epoch >>  1662 0.1692649208517158 0.030546440548019856 0.13871848030369444\n",
      "Saving the model  0.1692649208517158 0.16923508762917722\n",
      "Epoch >>  1663 0.16923508762917722 0.030543986955913247 0.13869110067326265\n",
      "Saving the model  0.16923508762917722 0.1692147717244591\n",
      "Epoch >>  1664 0.1692147717244591 0.030541560277961125 0.13867321144649664\n",
      "Saving the model  0.1692147717244591 0.16920443341687658\n",
      "Epoch >>  1665 0.16920443341687658 0.030539109817285994 0.13866532359958889\n",
      "Saving the model  0.16920443341687658 0.16918536711400708\n",
      "Epoch >>  1666 0.16918536711400708 0.030537160287391514 0.138648206826614\n",
      "Saving the model  0.16918536711400708 0.16916160881995504\n",
      "Epoch >>  1667 0.16916160881995504 0.030534677305522433 0.13862693151443095\n",
      "Saving the model  0.16916160881995504 0.16912609698638367\n",
      "Epoch >>  1668 0.16912609698638367 0.03053168597210381 0.1385944110142781\n",
      "Saving the model  0.16912609698638367 0.1691081283794049\n",
      "Epoch >>  1669 0.1691081283794049 0.030528790261013704 0.1385793381183894\n",
      "Saving the model  0.1691081283794049 0.16907177289980027\n",
      "Epoch >>  1670 0.16907177289980027 0.030525699012509736 0.13854607388728868\n",
      "Saving the model  0.16907177289980027 0.1690557508039783\n",
      "Epoch >>  1671 0.1690557508039783 0.030523179152142834 0.13853257165183372\n",
      "Saving the model  0.1690557508039783 0.16905036887732988\n",
      "Epoch >>  1672 0.16905036887732988 0.030520561541366207 0.13852980733596193\n",
      "Saving the model  0.16905036887732988 0.16902686718817592\n",
      "Epoch >>  1673 0.16902686718817592 0.030517690484789053 0.13850917670338508\n",
      "Saving the model  0.16902686718817592 0.16900781660665473\n",
      "Epoch >>  1674 0.16900781660665473 0.03051490407611922 0.1384929125305339\n",
      "Saving the model  0.16900781660665473 0.16898508599629664\n",
      "Epoch >>  1675 0.16898508599629664 0.03051174601093384 0.13847333998536104\n",
      "Saving the model  0.16898508599629664 0.1689629353767956\n",
      "Epoch >>  1676 0.1689629353767956 0.030509246562756186 0.13845368881403755\n",
      "Saving the model  0.1689629353767956 0.16894526694691833\n",
      "Epoch >>  1677 0.16894526694691833 0.030506548994891507 0.138438717952025\n",
      "Saving the model  0.16894526694691833 0.16892101018324743\n",
      "Epoch >>  1678 0.16892101018324743 0.0305042315161295 0.1384167786671162\n",
      "Saving the model  0.16892101018324743 0.16891702169430836\n",
      "Epoch >>  1679 0.16891702169430836 0.030501641761390603 0.13841537993291544\n",
      "Epoch >>  1680 0.16891749716096494 0.030499009806298757 0.13841848735466386\n",
      "Saving the model  0.16891702169430836 0.1688849577494754\n",
      "Epoch >>  1681 0.1688849577494754 0.03049640936924557 0.13838854838022754\n",
      "Saving the model  0.1688849577494754 0.16886085135861464\n",
      "Epoch >>  1682 0.16886085135861464 0.03049405476463019 0.13836679659398193\n",
      "Saving the model  0.16886085135861464 0.1688354133142708\n",
      "Epoch >>  1683 0.1688354133142708 0.030491192054520024 0.1383442212597481\n",
      "Saving the model  0.1688354133142708 0.16882467605009155\n",
      "Epoch >>  1684 0.16882467605009155 0.030488799649579384 0.1383358764005093\n",
      "Saving the model  0.16882467605009155 0.1687928333174605\n",
      "Epoch >>  1685 0.1687928333174605 0.030485994286784474 0.1383068390306734\n",
      "Saving the model  0.1687928333174605 0.16876255696639603\n",
      "Epoch >>  1686 0.16876255696639603 0.030483327587944795 0.13827922937844894\n",
      "Saving the model  0.16876255696639603 0.16872791648060514\n",
      "Epoch >>  1687 0.16872791648060514 0.030480926670530012 0.1382469898100728\n",
      "Saving the model  0.16872791648060514 0.16870750921722985\n",
      "Epoch >>  1688 0.16870750921722985 0.030478219625759348 0.13822928959146819\n",
      "Saving the model  0.16870750921722985 0.16868626304286047\n",
      "Epoch >>  1689 0.16868626304286047 0.030475555963526035 0.13821070707933233\n",
      "Saving the model  0.16868626304286047 0.16865221992908008\n",
      "Epoch >>  1690 0.16865221992908008 0.03047258124688348 0.13817963868219466\n",
      "Saving the model  0.16865221992908008 0.16862469238743516\n",
      "Epoch >>  1691 0.16862469238743516 0.030469263817182554 0.13815542857025076\n",
      "Saving the model  0.16862469238743516 0.16860735557482887\n",
      "Epoch >>  1692 0.16860735557482887 0.030466671159908948 0.1381406844149184\n",
      "Saving the model  0.16860735557482887 0.16858421935152387\n",
      "Epoch >>  1693 0.16858421935152387 0.030463716579379067 0.1381205027721433\n",
      "Saving the model  0.16858421935152387 0.16855077008399366\n",
      "Epoch >>  1694 0.16855077008399366 0.030461108445704183 0.13808966163828787\n",
      "Saving the model  0.16855077008399366 0.1685414841475571\n",
      "Epoch >>  1695 0.1685414841475571 0.030458490813019868 0.13808299333453547\n",
      "Saving the model  0.1685414841475571 0.16851374933956167\n",
      "Epoch >>  1696 0.16851374933956167 0.0304561099059529 0.13805763943360705\n",
      "Saving the model  0.16851374933956167 0.16848553712202838\n",
      "Epoch >>  1697 0.16848553712202838 0.03045361623362164 0.1380319208884049\n",
      "Saving the model  0.16848553712202838 0.16846793207252111\n",
      "Epoch >>  1698 0.16846793207252111 0.030451157084420165 0.138016774988099\n",
      "Saving the model  0.16846793207252111 0.16844316943874113\n",
      "Epoch >>  1699 0.16844316943874113 0.030448646261857778 0.1379945231768814\n",
      "Saving the model  0.16844316943874113 0.16841953524229886\n",
      "Epoch >>  1700 0.16841953524229886 0.03044644988974073 0.13797308535255612\n",
      "Saving the model  0.16841953524229886 0.16841715678704436\n",
      "Epoch >>  1701 0.16841715678704436 0.03044422902621677 0.13797292776082543\n",
      "Saving the model  0.16841715678704436 0.1684056335458783\n",
      "Epoch >>  1702 0.1684056335458783 0.03044186299648987 0.1379637705493863\n",
      "Saving the model  0.1684056335458783 0.16839962150501367\n",
      "Epoch >>  1703 0.16839962150501367 0.030439628542799926 0.1379599929622119\n",
      "Saving the model  0.16839962150501367 0.1683895380088225\n",
      "Epoch >>  1704 0.1683895380088225 0.030436960223691998 0.13795257778512868\n",
      "Saving the model  0.1683895380088225 0.1683666271988031\n",
      "Epoch >>  1705 0.1683666271988031 0.030434241035730558 0.13793238616307074\n",
      "Saving the model  0.1683666271988031 0.16833283132761961\n",
      "Epoch >>  1706 0.16833283132761961 0.030431631621485513 0.13790119970613232\n",
      "Saving the model  0.16833283132761961 0.16832602200184332\n",
      "Epoch >>  1707 0.16832602200184332 0.03042920990956975 0.13789681209227167\n",
      "Saving the model  0.16832602200184332 0.16830738935603157\n",
      "Epoch >>  1708 0.16830738935603157 0.030426652579169072 0.13788073677686044\n",
      "Saving the model  0.16830738935603157 0.1682616108532819\n",
      "Epoch >>  1709 0.1682616108532819 0.030423998244122653 0.13783761260915706\n",
      "Epoch >>  1710 0.16826388289381436 0.030421914392853106 0.13784196850095906\n",
      "Saving the model  0.1682616108532819 0.16824786611550668\n",
      "Epoch >>  1711 0.16824786611550668 0.030419495705288322 0.13782837041021612\n",
      "Saving the model  0.16824786611550668 0.1682427584729222\n",
      "Epoch >>  1712 0.1682427584729222 0.030417066930372105 0.1378256915425478\n",
      "Saving the model  0.1682427584729222 0.16822047647817626\n",
      "Epoch >>  1713 0.16822047647817626 0.030415055954842205 0.13780542052333178\n",
      "Saving the model  0.16822047647817626 0.1681961487886029\n",
      "Epoch >>  1714 0.1681961487886029 0.030412211010322654 0.13778393777827821\n",
      "Saving the model  0.1681961487886029 0.1681671520070297\n",
      "Epoch >>  1715 0.1681671520070297 0.030409735840851153 0.13775741616617676\n",
      "Saving the model  0.1681671520070297 0.168145795275435\n",
      "Epoch >>  1716 0.168145795275435 0.030407275220947532 0.13773852005448572\n",
      "Saving the model  0.168145795275435 0.16811923796365424\n",
      "Epoch >>  1717 0.16811923796365424 0.030404857565764627 0.13771438039788814\n",
      "Saving the model  0.16811923796365424 0.16810470933060206\n",
      "Epoch >>  1718 0.16810470933060206 0.03040232756582248 0.1377023817647779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.16810470933060206 0.16809656532727302\n",
      "Epoch >>  1719 0.16809656532727302 0.030399955129066222 0.13769661019820525\n",
      "Saving the model  0.16809656532727302 0.1680846513090117\n",
      "Epoch >>  1720 0.1680846513090117 0.03039758752646602 0.13768706378254408\n",
      "Saving the model  0.1680846513090117 0.16808311851004806\n",
      "Epoch >>  1721 0.16808311851004806 0.030395415685725412 0.13768770282432083\n",
      "Saving the model  0.16808311851004806 0.1680828488534788\n",
      "Epoch >>  1722 0.1680828488534788 0.030393021194420347 0.1376898276590566\n",
      "Saving the model  0.1680828488534788 0.16806784040998687\n",
      "Epoch >>  1723 0.16806784040998687 0.03039026639061709 0.13767757401936767\n",
      "Saving the model  0.16806784040998687 0.16806516759203383\n",
      "Epoch >>  1724 0.16806516759203383 0.030387810053709767 0.1376773575383218\n",
      "Saving the model  0.16806516759203383 0.1680444187023032\n",
      "Epoch >>  1725 0.1680444187023032 0.030385344992500677 0.13765907370980043\n",
      "Saving the model  0.1680444187023032 0.16803627868082321\n",
      "Epoch >>  1726 0.16803627868082321 0.030382953588090154 0.137653325092731\n",
      "Saving the model  0.16803627868082321 0.16800573574510821\n",
      "Epoch >>  1727 0.16800573574510821 0.030380238044199627 0.1376254977009066\n",
      "Saving the model  0.16800573574510821 0.16797431681701852\n",
      "Epoch >>  1728 0.16797431681701852 0.03037748954752717 0.1375968272694893\n",
      "Saving the model  0.16797431681701852 0.16795135040655582\n",
      "Epoch >>  1729 0.16795135040655582 0.030374572973360593 0.13757677743319316\n",
      "Saving the model  0.16795135040655582 0.16792100680764346\n",
      "Epoch >>  1730 0.16792100680764346 0.030371657606412875 0.13754934920122835\n",
      "Saving the model  0.16792100680764346 0.16791526740685964\n",
      "Epoch >>  1731 0.16791526740685964 0.030369290661778927 0.1375459767450784\n",
      "Saving the model  0.16791526740685964 0.16788502328047092\n",
      "Epoch >>  1732 0.16788502328047092 0.030366359560083232 0.1375186637203853\n",
      "Saving the model  0.16788502328047092 0.16787672478625526\n",
      "Epoch >>  1733 0.16787672478625526 0.03036405384824172 0.13751267093801128\n",
      "Saving the model  0.16787672478625526 0.16787127171186284\n",
      "Epoch >>  1734 0.16787127171186284 0.030361887597419944 0.13750938411444064\n",
      "Saving the model  0.16787127171186284 0.1678624428329524\n",
      "Epoch >>  1735 0.1678624428329524 0.03035971735096394 0.13750272548198617\n",
      "Saving the model  0.1678624428329524 0.16784155602538692\n",
      "Epoch >>  1736 0.16784155602538692 0.030357356988815885 0.13748419903656875\n",
      "Epoch >>  1737 0.16784171515177232 0.030354978229360133 0.13748673692240987\n",
      "Saving the model  0.16784155602538692 0.16781116645414926\n",
      "Epoch >>  1738 0.16781116645414926 0.030352416980710954 0.13745874947343611\n",
      "Saving the model  0.16781116645414926 0.16778658328519716\n",
      "Epoch >>  1739 0.16778658328519716 0.030349500795612633 0.13743708248958253\n",
      "Saving the model  0.16778658328519716 0.16776438605817273\n",
      "Epoch >>  1740 0.16776438605817273 0.030346644572692396 0.13741774148547842\n",
      "Saving the model  0.16776438605817273 0.16774292794643983\n",
      "Epoch >>  1741 0.16774292794643983 0.030344644055254718 0.13739828389118308\n",
      "Saving the model  0.16774292794643983 0.16772087937770283\n",
      "Epoch >>  1742 0.16772087937770283 0.030342024220861272 0.1373788551568396\n",
      "Saving the model  0.16772087937770283 0.16771875286352897\n",
      "Epoch >>  1743 0.16771875286352897 0.03033984525860922 0.13737890760491817\n",
      "Saving the model  0.16771875286352897 0.16769000753940225\n",
      "Epoch >>  1744 0.16769000753940225 0.03033707741927346 0.1373529301201274\n",
      "Saving the model  0.16769000753940225 0.16765903631101917\n",
      "Epoch >>  1745 0.16765903631101917 0.030334832148348014 0.13732420416266983\n",
      "Saving the model  0.16765903631101917 0.16763588911684432\n",
      "Epoch >>  1746 0.16763588911684432 0.03033221099640276 0.13730367812044011\n",
      "Saving the model  0.16763588911684432 0.16760706636122244\n",
      "Epoch >>  1747 0.16760706636122244 0.030329178250485377 0.13727788811073557\n",
      "Saving the model  0.16760706636122244 0.16759780325257098\n",
      "Epoch >>  1748 0.16759780325257098 0.030326953304597684 0.1372708499479721\n",
      "Saving the model  0.16759780325257098 0.16757279913530937\n",
      "Epoch >>  1749 0.16757279913530937 0.030324525613090077 0.137248273522218\n",
      "Saving the model  0.16757279913530937 0.16755066843368166\n",
      "Epoch >>  1750 0.16755066843368166 0.030322398842306513 0.13722826959137407\n",
      "Saving the model  0.16755066843368166 0.16751957061359177\n",
      "Epoch >>  1751 0.16751957061359177 0.03031940933247682 0.13720016128111376\n",
      "Saving the model  0.16751957061359177 0.1674945351587502\n",
      "Epoch >>  1752 0.1674945351587502 0.030316721097892376 0.13717781406085663\n",
      "Saving the model  0.1674945351587502 0.16748191865625037\n",
      "Epoch >>  1753 0.16748191865625037 0.030314331243040886 0.1371675874132083\n",
      "Saving the model  0.16748191865625037 0.1674556233004413\n",
      "Epoch >>  1754 0.1674556233004413 0.03031211588890166 0.13714350741153827\n",
      "Saving the model  0.1674556233004413 0.16743226671746506\n",
      "Epoch >>  1755 0.16743226671746506 0.03030944925954436 0.13712281745791927\n",
      "Saving the model  0.16743226671746506 0.16740721559371\n",
      "Epoch >>  1756 0.16740721559371 0.03030715291333213 0.13710006268037664\n",
      "Saving the model  0.16740721559371 0.16740513156358539\n",
      "Epoch >>  1757 0.16740513156358539 0.030304456108863825 0.13710067545472043\n",
      "Saving the model  0.16740513156358539 0.16736745614112267\n",
      "Epoch >>  1758 0.16736745614112267 0.030302358087013523 0.1370650980541079\n",
      "Saving the model  0.16736745614112267 0.16735154071694894\n",
      "Epoch >>  1759 0.16735154071694894 0.030299886795106645 0.13705165392184127\n",
      "Saving the model  0.16735154071694894 0.1673444615366886\n",
      "Epoch >>  1760 0.1673444615366886 0.03029773783207215 0.13704672370461532\n",
      "Saving the model  0.1673444615366886 0.1673231171816033\n",
      "Epoch >>  1761 0.1673231171816033 0.030295465298723345 0.13702765188287888\n",
      "Saving the model  0.1673231171816033 0.1673061612213995\n",
      "Epoch >>  1762 0.1673061612213995 0.03029318580097965 0.13701297542041843\n",
      "Saving the model  0.1673061612213995 0.1672613864433401\n",
      "Epoch >>  1763 0.1672613864433401 0.03029034996610187 0.1369710364772371\n",
      "Saving the model  0.1672613864433401 0.16722105071423024\n",
      "Epoch >>  1764 0.16722105071423024 0.030287671113931817 0.13693337960029722\n",
      "Saving the model  0.16722105071423024 0.1672002223215739\n",
      "Epoch >>  1765 0.1672002223215739 0.030285679324629854 0.13691454299694286\n",
      "Saving the model  0.1672002223215739 0.16718118718961464\n",
      "Epoch >>  1766 0.16718118718961464 0.030283157075472206 0.13689803011414126\n",
      "Saving the model  0.16718118718961464 0.16715560433229593\n",
      "Epoch >>  1767 0.16715560433229593 0.030280746814700932 0.13687485751759385\n",
      "Saving the model  0.16715560433229593 0.16714049705239456\n",
      "Epoch >>  1768 0.16714049705239456 0.030278618283992666 0.1368618787684009\n",
      "Saving the model  0.16714049705239456 0.16713356848432664\n",
      "Epoch >>  1769 0.16713356848432664 0.030276141284648138 0.1368574271996777\n",
      "Saving the model  0.16713356848432664 0.16710883680107788\n",
      "Epoch >>  1770 0.16710883680107788 0.030273846682133444 0.13683499011894404\n",
      "Saving the model  0.16710883680107788 0.16707933119448493\n",
      "Epoch >>  1771 0.16707933119448493 0.03027095885601432 0.1368083723384702\n",
      "Saving the model  0.16707933119448493 0.1670492262605138\n",
      "Epoch >>  1772 0.1670492262605138 0.030268317149823008 0.13678090911069046\n",
      "Saving the model  0.1670492262605138 0.16702781119105176\n",
      "Epoch >>  1773 0.16702781119105176 0.030266489449351484 0.13676132174169964\n",
      "Saving the model  0.16702781119105176 0.16701410669182742\n",
      "Epoch >>  1774 0.16701410669182742 0.030264173245625237 0.1367499334462019\n",
      "Saving the model  0.16701410669182742 0.16700219945137268\n",
      "Epoch >>  1775 0.16700219945137268 0.030261581199101766 0.13674061825227066\n",
      "Saving the model  0.16700219945137268 0.16697813060898758\n",
      "Epoch >>  1776 0.16697813060898758 0.030259744689329973 0.1367183859196573\n",
      "Saving the model  0.16697813060898758 0.16696956424316392\n",
      "Epoch >>  1777 0.16696956424316392 0.030257154886492908 0.13671240935667076\n",
      "Saving the model  0.16696956424316392 0.16693346302087333\n",
      "Epoch >>  1778 0.16693346302087333 0.030254609467112583 0.13667885355376028\n",
      "Saving the model  0.16693346302087333 0.1669177422722084\n",
      "Epoch >>  1779 0.1669177422722084 0.030252091116140425 0.1366656511560673\n",
      "Saving the model  0.1669177422722084 0.16690654006158157\n",
      "Epoch >>  1780 0.16690654006158157 0.030250228910407472 0.1366563111511735\n",
      "Saving the model  0.16690654006158157 0.1668938458994571\n",
      "Epoch >>  1781 0.1668938458994571 0.030248246356039413 0.13664559954341707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.1668938458994571 0.1668662931348427\n",
      "Epoch >>  1782 0.1668662931348427 0.0302456341323236 0.13662065900251852\n",
      "Saving the model  0.1668662931348427 0.16685097375653757\n",
      "Epoch >>  1783 0.16685097375653757 0.03024300816643408 0.13660796559010302\n",
      "Saving the model  0.16685097375653757 0.16683654643470308\n",
      "Epoch >>  1784 0.16683654643470308 0.030240909770175222 0.13659563666452737\n",
      "Saving the model  0.16683654643470308 0.16680797849368595\n",
      "Epoch >>  1785 0.16680797849368595 0.030237828978598065 0.13657014951508725\n",
      "Saving the model  0.16680797849368595 0.16679240100441053\n",
      "Epoch >>  1786 0.16679240100441053 0.030235373539192752 0.13655702746521722\n",
      "Saving the model  0.16679240100441053 0.16676650529141715\n",
      "Epoch >>  1787 0.16676650529141715 0.030232705764868476 0.13653379952654815\n",
      "Saving the model  0.16676650529141715 0.1667456975341388\n",
      "Epoch >>  1788 0.1667456975341388 0.03023015046763528 0.13651554706650298\n",
      "Saving the model  0.1667456975341388 0.16671906091449018\n",
      "Epoch >>  1789 0.16671906091449018 0.03022755259410587 0.13649150832038398\n",
      "Saving the model  0.16671906091449018 0.16670823185968173\n",
      "Epoch >>  1790 0.16670823185968173 0.03022507748630267 0.13648315437337874\n",
      "Saving the model  0.16670823185968173 0.1666961731147884\n",
      "Epoch >>  1791 0.1666961731147884 0.03022309617046519 0.1364730769443228\n",
      "Saving the model  0.1666961731147884 0.1666624724047961\n",
      "Epoch >>  1792 0.1666624724047961 0.030220850361447782 0.13644162204334798\n",
      "Saving the model  0.1666624724047961 0.1666480123210243\n",
      "Epoch >>  1793 0.1666480123210243 0.03021831321208683 0.13642969910893699\n",
      "Saving the model  0.1666480123210243 0.16663172675721366\n",
      "Epoch >>  1794 0.16663172675721366 0.030215955396866067 0.13641577136034727\n",
      "Saving the model  0.16663172675721366 0.16660696754131407\n",
      "Epoch >>  1795 0.16660696754131407 0.030213754378706034 0.13639321316260744\n",
      "Saving the model  0.16660696754131407 0.16657627781324472\n",
      "Epoch >>  1796 0.16657627781324472 0.030211063523151203 0.136365214290093\n",
      "Saving the model  0.16657627781324472 0.16656320610745207\n",
      "Epoch >>  1797 0.16656320610745207 0.030208987935115398 0.1363542181723362\n",
      "Saving the model  0.16656320610745207 0.16653484842463362\n",
      "Epoch >>  1798 0.16653484842463362 0.03020636200630815 0.13632848641832498\n",
      "Saving the model  0.16653484842463362 0.16652641475230323\n",
      "Epoch >>  1799 0.16652641475230323 0.030203968950668323 0.13632244580163455\n",
      "Saving the model  0.16652641475230323 0.1664884578428314\n",
      "Epoch >>  1800 0.1664884578428314 0.030201262185530008 0.13628719565730113\n",
      "Saving the model  0.1664884578428314 0.1664778735606649\n",
      "Epoch >>  1801 0.1664778735606649 0.03019930672963558 0.13627856683102887\n",
      "Saving the model  0.1664778735606649 0.16646593329575116\n",
      "Epoch >>  1802 0.16646593329575116 0.030197224062070316 0.13626870923368045\n",
      "Saving the model  0.16646593329575116 0.1664557993579838\n",
      "Epoch >>  1803 0.1664557993579838 0.030195369287662605 0.13626043007032088\n",
      "Saving the model  0.1664557993579838 0.1664377936318406\n",
      "Epoch >>  1804 0.1664377936318406 0.03019288803527276 0.1362449055965675\n",
      "Saving the model  0.1664377936318406 0.16640780084510973\n",
      "Epoch >>  1805 0.16640780084510973 0.030190184534485822 0.13621761631062362\n",
      "Saving the model  0.16640780084510973 0.16639792050256025\n",
      "Epoch >>  1806 0.16639792050256025 0.030187669114144666 0.13621025138841517\n",
      "Saving the model  0.16639792050256025 0.16638604162367146\n",
      "Epoch >>  1807 0.16638604162367146 0.03018517416320303 0.13620086746046797\n",
      "Saving the model  0.16638604162367146 0.16636280081995208\n",
      "Epoch >>  1808 0.16636280081995208 0.030182514046908145 0.13618028677304317\n",
      "Saving the model  0.16636280081995208 0.16634471756823774\n",
      "Epoch >>  1809 0.16634471756823774 0.030180113263552976 0.13616460430468408\n",
      "Saving the model  0.16634471756823774 0.1663285281424334\n",
      "Epoch >>  1810 0.1663285281424334 0.030177461593525613 0.136151066548907\n",
      "Saving the model  0.1663285281424334 0.16629795752320847\n",
      "Epoch >>  1811 0.16629795752320847 0.030174987171166377 0.13612297035204135\n",
      "Saving the model  0.16629795752320847 0.1662732686693581\n",
      "Epoch >>  1812 0.1662732686693581 0.030172800674657562 0.13610046799469974\n",
      "Saving the model  0.1662732686693581 0.16625470670450904\n",
      "Epoch >>  1813 0.16625470670450904 0.030170603695279158 0.1360841030092287\n",
      "Saving the model  0.16625470670450904 0.1662262672774505\n",
      "Epoch >>  1814 0.1662262672774505 0.030168494899201842 0.13605777237824757\n",
      "Saving the model  0.1662262672774505 0.16620323052790673\n",
      "Epoch >>  1815 0.16620323052790673 0.03016591676949363 0.13603731375841177\n",
      "Saving the model  0.16620323052790673 0.1661950490403084\n",
      "Epoch >>  1816 0.1661950490403084 0.030163468401865363 0.13603158063844176\n",
      "Saving the model  0.1661950490403084 0.16616484679262625\n",
      "Epoch >>  1817 0.16616484679262625 0.030160736308097343 0.13600411048452757\n",
      "Saving the model  0.16616484679262625 0.16613193446059463\n",
      "Epoch >>  1818 0.16613193446059463 0.030158309411339266 0.13597362504925406\n",
      "Saving the model  0.16613193446059463 0.1661115003192294\n",
      "Epoch >>  1819 0.1661115003192294 0.030155743907781533 0.1359557564114469\n",
      "Saving the model  0.1661115003192294 0.1660877352677184\n",
      "Epoch >>  1820 0.1660877352677184 0.030153312809811962 0.13593442245790546\n",
      "Saving the model  0.1660877352677184 0.166054692445734\n",
      "Epoch >>  1821 0.166054692445734 0.030150705424160137 0.13590398702157297\n",
      "Saving the model  0.166054692445734 0.16603505166771285\n",
      "Epoch >>  1822 0.16603505166771285 0.03014823942792 0.13588681223979213\n",
      "Saving the model  0.16603505166771285 0.1660119353596516\n",
      "Epoch >>  1823 0.1660119353596516 0.03014556525892936 0.13586637010072122\n",
      "Saving the model  0.1660119353596516 0.16598014721887158\n",
      "Epoch >>  1824 0.16598014721887158 0.030142925567899333 0.13583722165097104\n",
      "Saving the model  0.16598014721887158 0.16596418407615077\n",
      "Epoch >>  1825 0.16596418407615077 0.030140602510922307 0.13582358156522717\n",
      "Saving the model  0.16596418407615077 0.16593990689245194\n",
      "Epoch >>  1826 0.16593990689245194 0.030138100361393708 0.13580180653105692\n",
      "Saving the model  0.16593990689245194 0.16590636012027837\n",
      "Epoch >>  1827 0.16590636012027837 0.03013560668669089 0.1357707534335863\n",
      "Saving the model  0.16590636012027837 0.16588022240336256\n",
      "Epoch >>  1828 0.16588022240336256 0.03013348984689012 0.13574673255647113\n",
      "Saving the model  0.16588022240336256 0.1658609071646507\n",
      "Epoch >>  1829 0.1658609071646507 0.030130797185804064 0.1357301099788452\n",
      "Saving the model  0.1658609071646507 0.16583113513485187\n",
      "Epoch >>  1830 0.16583113513485187 0.030128023488783934 0.13570311164606663\n",
      "Saving the model  0.16583113513485187 0.16581595563324728\n",
      "Epoch >>  1831 0.16581595563324728 0.030125363263820606 0.13569059236942524\n",
      "Saving the model  0.16581595563324728 0.16578854640786958\n",
      "Epoch >>  1832 0.16578854640786958 0.030122915505086435 0.13566563090278175\n",
      "Saving the model  0.16578854640786958 0.1657608468674287\n",
      "Epoch >>  1833 0.1657608468674287 0.030120902376867233 0.13563994449055977\n",
      "Saving the model  0.1657608468674287 0.16573887054469805\n",
      "Epoch >>  1834 0.16573887054469805 0.03011871199183114 0.13562015855286524\n",
      "Saving the model  0.16573887054469805 0.16571858752389373\n",
      "Epoch >>  1835 0.16571858752389373 0.030116197846779522 0.13560238967711263\n",
      "Saving the model  0.16571858752389373 0.16568622202914285\n",
      "Epoch >>  1836 0.16568622202914285 0.03011361318970088 0.1355726088394402\n",
      "Saving the model  0.16568622202914285 0.1656669514663007\n",
      "Epoch >>  1837 0.1656669514663007 0.030110933193996794 0.13555601827230226\n",
      "Saving the model  0.1656669514663007 0.1656451470329387\n",
      "Epoch >>  1838 0.1656451470329387 0.030108827264149568 0.13553631976878758\n",
      "Saving the model  0.1656451470329387 0.16562391663446008\n",
      "Epoch >>  1839 0.16562391663446008 0.030106885461645746 0.1355170311728127\n",
      "Saving the model  0.16562391663446008 0.16560260598423773\n",
      "Epoch >>  1840 0.16560260598423773 0.030104019305592433 0.13549858667864367\n",
      "Saving the model  0.16560260598423773 0.16558037184298477\n",
      "Epoch >>  1841 0.16558037184298477 0.030101712932835478 0.1354786589101477\n",
      "Saving the model  0.16558037184298477 0.16556437811626804\n",
      "Epoch >>  1842 0.16556437811626804 0.030099304750727043 0.13546507336553923\n",
      "Saving the model  0.16556437811626804 0.16553619343013506\n",
      "Epoch >>  1843 0.16553619343013506 0.030097225459743058 0.13543896797039032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.16553619343013506 0.16552398006007382\n",
      "Epoch >>  1844 0.16552398006007382 0.03009528692796282 0.13542869313210928\n",
      "Saving the model  0.16552398006007382 0.16551361929880598\n",
      "Epoch >>  1845 0.16551361929880598 0.030093302982087372 0.13542031631671667\n",
      "Saving the model  0.16551361929880598 0.16548605249640788\n",
      "Epoch >>  1846 0.16548605249640788 0.030090729378743866 0.13539532311766225\n",
      "Saving the model  0.16548605249640788 0.16545738266582508\n",
      "Epoch >>  1847 0.16545738266582508 0.03008822767847264 0.13536915498735075\n",
      "Saving the model  0.16545738266582508 0.16544636286671574\n",
      "Epoch >>  1848 0.16544636286671574 0.03008607818313255 0.13536028468358133\n",
      "Saving the model  0.16544636286671574 0.16542969614767492\n",
      "Epoch >>  1849 0.16542969614767492 0.030083888503461373 0.13534580764421145\n",
      "Saving the model  0.16542969614767492 0.16542964317556663\n",
      "Epoch >>  1850 0.16542964317556663 0.030082204226701926 0.13534743894886267\n",
      "Saving the model  0.16542964317556663 0.16540687172923715\n",
      "Epoch >>  1851 0.16540687172923715 0.03007968186625251 0.13532718986298273\n",
      "Saving the model  0.16540687172923715 0.16539125971366184\n",
      "Epoch >>  1852 0.16539125971366184 0.030077491529772103 0.1353137681838877\n",
      "Saving the model  0.16539125971366184 0.16537929993695621\n",
      "Epoch >>  1853 0.16537929993695621 0.030075384851492654 0.1353039150854616\n",
      "Saving the model  0.16537929993695621 0.16536844928897457\n",
      "Epoch >>  1854 0.16536844928897457 0.030072612116578613 0.13529583717239432\n",
      "Saving the model  0.16536844928897457 0.16534630716718574\n",
      "Epoch >>  1855 0.16534630716718574 0.030069938353083886 0.13527636881410038\n",
      "Saving the model  0.16534630716718574 0.16533160307766656\n",
      "Epoch >>  1856 0.16533160307766656 0.030067738943721903 0.13526386413394328\n",
      "Saving the model  0.16533160307766656 0.165305576835093\n",
      "Epoch >>  1857 0.165305576835093 0.030065117926288024 0.13524045890880368\n",
      "Saving the model  0.165305576835093 0.16528179608209054\n",
      "Epoch >>  1858 0.16528179608209054 0.030062821054993756 0.13521897502709512\n",
      "Saving the model  0.16528179608209054 0.1652627731785512\n",
      "Epoch >>  1859 0.1652627731785512 0.030061031597597057 0.13520174158095288\n",
      "Saving the model  0.1652627731785512 0.16522685744863452\n",
      "Epoch >>  1860 0.16522685744863452 0.030058594966540366 0.1351682624820932\n",
      "Saving the model  0.16522685744863452 0.16520479928373877\n",
      "Epoch >>  1861 0.16520479928373877 0.03005652278713251 0.1351482764966052\n",
      "Saving the model  0.16520479928373877 0.16519372536964844\n",
      "Epoch >>  1862 0.16519372536964844 0.03005451065240805 0.13513921471723922\n",
      "Saving the model  0.16519372536964844 0.16518618260157772\n",
      "Epoch >>  1863 0.16518618260157772 0.03005241010433299 0.1351337724972438\n",
      "Saving the model  0.16518618260157772 0.16516427936057726\n",
      "Epoch >>  1864 0.16516427936057726 0.03005016367187702 0.13511411568869935\n",
      "Saving the model  0.16516427936057726 0.16515519600330386\n",
      "Epoch >>  1865 0.16515519600330386 0.03004826387740153 0.13510693212590152\n",
      "Saving the model  0.16515519600330386 0.1651209343789695\n",
      "Epoch >>  1866 0.1651209343789695 0.03004551888637505 0.13507541549259341\n",
      "Saving the model  0.1651209343789695 0.16511489392982787\n",
      "Epoch >>  1867 0.16511489392982787 0.030043159837228283 0.13507173409259854\n",
      "Saving the model  0.16511489392982787 0.1650997898509752\n",
      "Epoch >>  1868 0.1650997898509752 0.030040654888070655 0.13505913496290367\n",
      "Saving the model  0.1650997898509752 0.1650793335102961\n",
      "Epoch >>  1869 0.1650793335102961 0.03003809548154924 0.13504123802874599\n",
      "Saving the model  0.1650793335102961 0.165057849240656\n",
      "Epoch >>  1870 0.165057849240656 0.030035656885919502 0.13502219235473553\n",
      "Saving the model  0.165057849240656 0.16502854200231076\n",
      "Epoch >>  1871 0.16502854200231076 0.030033409548219654 0.13499513245409028\n",
      "Saving the model  0.16502854200231076 0.16500564309084728\n",
      "Epoch >>  1872 0.16500564309084728 0.030031178428737607 0.13497446466210913\n",
      "Saving the model  0.16500564309084728 0.1649861134703133\n",
      "Epoch >>  1873 0.1649861134703133 0.03002933310427435 0.1349567803660383\n",
      "Saving the model  0.1649861134703133 0.16497535685616702\n",
      "Epoch >>  1874 0.16497535685616702 0.030026864711484223 0.13494849214468213\n",
      "Saving the model  0.16497535685616702 0.16496928017366805\n",
      "Epoch >>  1875 0.16496928017366805 0.03002508823623342 0.1349441919374338\n",
      "Saving the model  0.16496928017366805 0.16495615606991143\n",
      "Epoch >>  1876 0.16495615606991143 0.03002303696090514 0.13493311910900568\n",
      "Saving the model  0.16495615606991143 0.16494220920048408\n",
      "Epoch >>  1877 0.16494220920048408 0.030020967748102558 0.1349212414523808\n",
      "Saving the model  0.16494220920048408 0.16492475142280977\n",
      "Epoch >>  1878 0.16492475142280977 0.0300187952337117 0.13490595618909737\n",
      "Saving the model  0.16492475142280977 0.16490154285549802\n",
      "Epoch >>  1879 0.16490154285549802 0.030016339141095184 0.13488520371440232\n",
      "Saving the model  0.16490154285549802 0.16487841379211154\n",
      "Epoch >>  1880 0.16487841379211154 0.030014105715870362 0.13486430807624064\n",
      "Saving the model  0.16487841379211154 0.16485686590440496\n",
      "Epoch >>  1881 0.16485686590440496 0.030011736759261394 0.13484512914514307\n",
      "Saving the model  0.16485686590440496 0.1648384977725046\n",
      "Epoch >>  1882 0.1648384977725046 0.03000958283890684 0.13482891493359722\n",
      "Saving the model  0.1648384977725046 0.16481427957197067\n",
      "Epoch >>  1883 0.16481427957197067 0.03000745739558716 0.13480682217638304\n",
      "Saving the model  0.16481427957197067 0.16479099258571278\n",
      "Epoch >>  1884 0.16479099258571278 0.030005331778124374 0.13478566080758794\n",
      "Saving the model  0.16479099258571278 0.16476915798950553\n",
      "Epoch >>  1885 0.16476915798950553 0.03000330780188228 0.13476585018762283\n",
      "Saving the model  0.16476915798950553 0.1647415510792877\n",
      "Epoch >>  1886 0.1647415510792877 0.030001222508744697 0.13474032857054244\n",
      "Saving the model  0.1647415510792877 0.16470466568963427\n",
      "Epoch >>  1887 0.16470466568963427 0.0299990516780599 0.13470561401157397\n",
      "Saving the model  0.16470466568963427 0.16468096312528047\n",
      "Epoch >>  1888 0.16468096312528047 0.0299966482970263 0.13468431482825402\n",
      "Saving the model  0.16468096312528047 0.16465508505563511\n",
      "Epoch >>  1889 0.16465508505563511 0.029994068443277216 0.1346610166123577\n",
      "Saving the model  0.16465508505563511 0.16463672116787273\n",
      "Epoch >>  1890 0.16463672116787273 0.029991483717364185 0.13464523745050871\n",
      "Saving the model  0.16463672116787273 0.16461565821627722\n",
      "Epoch >>  1891 0.16461565821627722 0.029989028165113552 0.13462663005116332\n",
      "Saving the model  0.16461565821627722 0.16459079733285034\n",
      "Epoch >>  1892 0.16459079733285034 0.029986827835739808 0.13460396949711015\n",
      "Saving the model  0.16459079733285034 0.1645742535735441\n",
      "Epoch >>  1893 0.1645742535735441 0.029984290022248852 0.13458996355129477\n",
      "Saving the model  0.1645742535735441 0.16454880005456562\n",
      "Epoch >>  1894 0.16454880005456562 0.029981969744620213 0.134566830309945\n",
      "Saving the model  0.16454880005456562 0.16453138450648033\n",
      "Epoch >>  1895 0.16453138450648033 0.02997979816384277 0.13455158634263734\n",
      "Saving the model  0.16453138450648033 0.16451323002325957\n",
      "Epoch >>  1896 0.16451323002325957 0.02997727593423205 0.13453595408902724\n",
      "Saving the model  0.16451323002325957 0.164485617281979\n",
      "Epoch >>  1897 0.164485617281979 0.029974890152968534 0.1345107271290102\n",
      "Saving the model  0.164485617281979 0.16447071606137428\n",
      "Epoch >>  1898 0.16447071606137428 0.029972479409035864 0.13449823665233795\n",
      "Saving the model  0.16447071606137428 0.16445191863311243\n",
      "Epoch >>  1899 0.16445191863311243 0.029970400805841978 0.13448151782727014\n",
      "Saving the model  0.16445191863311243 0.16441502670433195\n",
      "Epoch >>  1900 0.16441502670433195 0.02996786075517714 0.13444716594915423\n",
      "Saving the model  0.16441502670433195 0.16439406398621687\n",
      "Epoch >>  1901 0.16439406398621687 0.02996530053870537 0.134428763447511\n",
      "Saving the model  0.16439406398621687 0.1643812456269746\n",
      "Epoch >>  1902 0.1643812456269746 0.029962993637863748 0.13441825198911073\n",
      "Saving the model  0.1643812456269746 0.16436134842748895\n",
      "Epoch >>  1903 0.16436134842748895 0.02996054974751236 0.13440079867997629\n",
      "Saving the model  0.16436134842748895 0.1643421318152773\n",
      "Epoch >>  1904 0.1643421318152773 0.029957955668649148 0.13438417614662762\n",
      "Saving the model  0.1643421318152773 0.16431440674215878\n",
      "Epoch >>  1905 0.16431440674215878 0.02995513690988008 0.13435926983227828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.16431440674215878 0.1642908735711097\n",
      "Epoch >>  1906 0.1642908735711097 0.02995267090606278 0.1343382026650463\n",
      "Saving the model  0.1642908735711097 0.16427208658131734\n",
      "Epoch >>  1907 0.16427208658131734 0.029950415606917715 0.1343216709743993\n",
      "Saving the model  0.16427208658131734 0.1642344088120942\n",
      "Epoch >>  1908 0.1642344088120942 0.029948139490650078 0.13428626932144375\n",
      "Saving the model  0.1642344088120942 0.16421304886039093\n",
      "Epoch >>  1909 0.16421304886039093 0.02994583141374947 0.13426721744664122\n",
      "Saving the model  0.16421304886039093 0.16420074360716866\n",
      "Epoch >>  1910 0.16420074360716866 0.029943403244559373 0.134257340362609\n",
      "Saving the model  0.16420074360716866 0.164172839674842\n",
      "Epoch >>  1911 0.164172839674842 0.029940979126005497 0.1342318605488359\n",
      "Saving the model  0.164172839674842 0.1641541820727984\n",
      "Epoch >>  1912 0.1641541820727984 0.029939070779220478 0.13421511129357713\n",
      "Saving the model  0.1641541820727984 0.16412542600747113\n",
      "Epoch >>  1913 0.16412542600747113 0.029936662197137736 0.13418876381033282\n",
      "Saving the model  0.16412542600747113 0.16410729938218885\n",
      "Epoch >>  1914 0.16410729938218885 0.029934443469627127 0.1341728559125612\n",
      "Saving the model  0.16410729938218885 0.16410382371493124\n",
      "Epoch >>  1915 0.16410382371493124 0.02993274705102307 0.13417107666390737\n",
      "Saving the model  0.16410382371493124 0.16408735907871985\n",
      "Epoch >>  1916 0.16408735907871985 0.0299301917269304 0.13415716735178884\n",
      "Saving the model  0.16408735907871985 0.16407125934180575\n",
      "Epoch >>  1917 0.16407125934180575 0.02992788163432672 0.1341433777074784\n",
      "Saving the model  0.16407125934180575 0.16405261880653355\n",
      "Epoch >>  1918 0.16405261880653355 0.029925723619882178 0.1341268951866508\n",
      "Saving the model  0.16405261880653355 0.1640248109816537\n",
      "Epoch >>  1919 0.1640248109816537 0.029923235802379267 0.13410157517927387\n",
      "Saving the model  0.1640248109816537 0.1640197371994212\n",
      "Epoch >>  1920 0.1640197371994212 0.029921016676975866 0.13409872052244481\n",
      "Saving the model  0.1640197371994212 0.16399713627099624\n",
      "Epoch >>  1921 0.16399713627099624 0.029918862956742946 0.13407827331425293\n",
      "Saving the model  0.16399713627099624 0.1639865421652189\n",
      "Epoch >>  1922 0.1639865421652189 0.029916808621069668 0.13406973354414914\n",
      "Saving the model  0.1639865421652189 0.16396939492532933\n",
      "Epoch >>  1923 0.16396939492532933 0.029915009170859975 0.13405438575446949\n",
      "Saving the model  0.16396939492532933 0.16396592042772049\n",
      "Epoch >>  1924 0.16396592042772049 0.02991305743534192 0.13405286299237892\n",
      "Saving the model  0.16396592042772049 0.16394431400816917\n",
      "Epoch >>  1925 0.16394431400816917 0.02991016710487859 0.13403414690329102\n",
      "Epoch >>  1926 0.16394609731776932 0.029907872605386437 0.13403822471238322\n",
      "Saving the model  0.16394431400816917 0.16393828451789053\n",
      "Epoch >>  1927 0.16393828451789053 0.02990606784157748 0.13403221667631343\n",
      "Saving the model  0.16393828451789053 0.1639175524286798\n",
      "Epoch >>  1928 0.1639175524286798 0.02990402588890412 0.134013526539776\n",
      "Saving the model  0.1639175524286798 0.1638946232623828\n",
      "Epoch >>  1929 0.1638946232623828 0.029901554556055473 0.13399306870632777\n",
      "Saving the model  0.1638946232623828 0.16386648534993967\n",
      "Epoch >>  1930 0.16386648534993967 0.02989922074328641 0.13396726460665365\n",
      "Saving the model  0.16386648534993967 0.16384322939217424\n",
      "Epoch >>  1931 0.16384322939217424 0.029896535200972407 0.13394669419120228\n",
      "Saving the model  0.16384322939217424 0.16381527649187638\n",
      "Epoch >>  1932 0.16381527649187638 0.029894160904217645 0.13392111558765923\n",
      "Saving the model  0.16381527649187638 0.16379435856798089\n",
      "Epoch >>  1933 0.16379435856798089 0.029891902494420988 0.1339024560735605\n",
      "Saving the model  0.16379435856798089 0.1637683243430311\n",
      "Epoch >>  1934 0.1637683243430311 0.029889497142993753 0.13387882720003813\n",
      "Saving the model  0.1637683243430311 0.16374660967470445\n",
      "Epoch >>  1935 0.16374660967470445 0.029887347361910364 0.13385926231279485\n",
      "Saving the model  0.16374660967470445 0.16372599993378323\n",
      "Epoch >>  1936 0.16372599993378323 0.029885234208921092 0.13384076572486256\n",
      "Saving the model  0.16372599993378323 0.16371070248091424\n",
      "Epoch >>  1937 0.16371070248091424 0.02988293230933866 0.13382777017157602\n",
      "Saving the model  0.16371070248091424 0.16369379244047777\n",
      "Epoch >>  1938 0.16369379244047777 0.02988041855256806 0.1338133738879103\n",
      "Saving the model  0.16369379244047777 0.16366558443320092\n",
      "Epoch >>  1939 0.16366558443320092 0.02987816275783293 0.13378742167536814\n",
      "Saving the model  0.16366558443320092 0.16365719873037576\n",
      "Epoch >>  1940 0.16365719873037576 0.02987615638503782 0.13378104234533825\n",
      "Saving the model  0.16365719873037576 0.16363166150731634\n",
      "Epoch >>  1941 0.16363166150731634 0.029873909932031525 0.13375775157528494\n",
      "Saving the model  0.16363166150731634 0.16361070583583548\n",
      "Epoch >>  1942 0.16361070583583548 0.029871981537764013 0.13373872429807165\n",
      "Saving the model  0.16361070583583548 0.16358503031913074\n",
      "Epoch >>  1943 0.16358503031913074 0.029869510155954047 0.13371552016317695\n",
      "Saving the model  0.16358503031913074 0.16356333219737726\n",
      "Epoch >>  1944 0.16356333219737726 0.029866755600485653 0.13369657659689185\n",
      "Saving the model  0.16356333219737726 0.16356000402575113\n",
      "Epoch >>  1945 0.16356000402575113 0.029865139950886164 0.1336948640748652\n",
      "Saving the model  0.16356000402575113 0.16353750929511807\n",
      "Epoch >>  1946 0.16353750929511807 0.029863284768602807 0.13367422452651553\n",
      "Saving the model  0.16353750929511807 0.1635224998930527\n",
      "Epoch >>  1947 0.1635224998930527 0.029860916913972392 0.13366158297908062\n",
      "Saving the model  0.1635224998930527 0.1635069527866172\n",
      "Epoch >>  1948 0.1635069527866172 0.029858925898451964 0.1336480268881657\n",
      "Saving the model  0.1635069527866172 0.16348518912421697\n",
      "Epoch >>  1949 0.16348518912421697 0.029856676835992954 0.13362851228822456\n",
      "Saving the model  0.16348518912421697 0.16345298290068755\n",
      "Epoch >>  1950 0.16345298290068755 0.029854366469310487 0.13359861643137777\n",
      "Saving the model  0.16345298290068755 0.16342965822955244\n",
      "Epoch >>  1951 0.16342965822955244 0.029851943178239783 0.13357771505131313\n",
      "Saving the model  0.16342965822955244 0.16341439100606955\n",
      "Epoch >>  1952 0.16341439100606955 0.029849873469399126 0.13356451753667098\n",
      "Saving the model  0.16341439100606955 0.1633927662516434\n",
      "Epoch >>  1953 0.1633927662516434 0.029847316066886367 0.13354545018475755\n",
      "Saving the model  0.1633927662516434 0.1633827947902451\n",
      "Epoch >>  1954 0.1633827947902451 0.029845149555983944 0.13353764523426198\n",
      "Saving the model  0.1633827947902451 0.16336678718460282\n",
      "Epoch >>  1955 0.16336678718460282 0.02984301764125568 0.13352376954334794\n",
      "Epoch >>  1956 0.1633673829754592 0.029841327381608437 0.13352605559385164\n",
      "Saving the model  0.16336678718460282 0.16335607130533294\n",
      "Epoch >>  1957 0.16335607130533294 0.029839429397932264 0.13351664190740145\n",
      "Saving the model  0.16335607130533294 0.16333581290227622\n",
      "Epoch >>  1958 0.16333581290227622 0.029837251274513445 0.1334985616277636\n",
      "Saving the model  0.16333581290227622 0.16333030406606783\n",
      "Epoch >>  1959 0.16333030406606783 0.029834883029487554 0.13349542103658113\n",
      "Saving the model  0.16333030406606783 0.16331634870653533\n",
      "Epoch >>  1960 0.16331634870653533 0.02983278662420212 0.1334835620823344\n",
      "Saving the model  0.16331634870653533 0.16330065123164741\n",
      "Epoch >>  1961 0.16330065123164741 0.029830749083932684 0.13346990214771615\n",
      "Saving the model  0.16330065123164741 0.16328084517794178\n",
      "Epoch >>  1962 0.16328084517794178 0.02982867819715142 0.13345216698079174\n",
      "Saving the model  0.16328084517794178 0.1632609801053441\n",
      "Epoch >>  1963 0.1632609801053441 0.029827085419859616 0.1334338946854858\n",
      "Saving the model  0.1632609801053441 0.16324307004575905\n",
      "Epoch >>  1964 0.16324307004575905 0.029824969146597033 0.13341810089916317\n",
      "Saving the model  0.16324307004575905 0.16322972810554937\n",
      "Epoch >>  1965 0.16322972810554937 0.029823027481495623 0.13340670062405496\n",
      "Saving the model  0.16322972810554937 0.1632119078948265\n",
      "Epoch >>  1966 0.1632119078948265 0.029821356836374695 0.13339055105845302\n",
      "Saving the model  0.1632119078948265 0.1631950118885243\n",
      "Epoch >>  1967 0.1631950118885243 0.02981908072077904 0.1333759311677467\n",
      "Saving the model  0.1631950118885243 0.16317728267771328\n",
      "Epoch >>  1968 0.16317728267771328 0.02981683837499391 0.13336044430272098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  0.16317728267771328 0.16315955315510638\n",
      "Epoch >>  1969 0.16315955315510638 0.029814832887617573 0.13334472026749036\n",
      "Saving the model  0.16315955315510638 0.1631339159047995\n",
      "Epoch >>  1970 0.1631339159047995 0.02981246296084187 0.1333214529439591\n",
      "Saving the model  0.1631339159047995 0.1631178545584501\n",
      "Epoch >>  1971 0.1631178545584501 0.029810694125298465 0.13330716043315272\n",
      "Saving the model  0.1631178545584501 0.16308716133322343\n",
      "Epoch >>  1972 0.16308716133322343 0.029808214634457247 0.13327894669876703\n",
      "Saving the model  0.16308716133322343 0.16306406704141035\n",
      "Epoch >>  1973 0.16306406704141035 0.02980599590201721 0.13325807113939422\n",
      "Saving the model  0.16306406704141035 0.16304649845697256\n",
      "Epoch >>  1974 0.16304649845697256 0.0298036871324261 0.13324281132454763\n",
      "Saving the model  0.16304649845697256 0.16301595672147842\n",
      "Epoch >>  1975 0.16301595672147842 0.02980141641677684 0.13321454030470262\n",
      "Epoch >>  1976 0.1630239261816834 0.029799659378758017 0.1332242668029266\n",
      "Saving the model  0.16301595672147842 0.16301277228395664\n",
      "Epoch >>  1977 0.16301277228395664 0.029798344321171615 0.13321442796278662\n",
      "Saving the model  0.16301277228395664 0.1629966120232909\n",
      "Epoch >>  1978 0.1629966120232909 0.02979597871641927 0.13320063330687318\n",
      "Saving the model  0.1629966120232909 0.1629777436769668\n",
      "Epoch >>  1979 0.1629777436769668 0.029793914904376877 0.13318382877259122\n",
      "Saving the model  0.1629777436769668 0.16294969719932806\n",
      "Epoch >>  1980 0.16294969719932806 0.02979131797503145 0.1331583792242978\n",
      "Saving the model  0.16294969719932806 0.1629377788722132\n",
      "Epoch >>  1981 0.1629377788722132 0.029789220762776517 0.13314855810943785\n",
      "Saving the model  0.1629377788722132 0.16290955082056613\n",
      "Epoch >>  1982 0.16290955082056613 0.02978697112564962 0.1331225796949175\n",
      "Saving the model  0.16290955082056613 0.16289314890294845\n",
      "Epoch >>  1983 0.16289314890294845 0.029784620057064056 0.1331085288458853\n",
      "Saving the model  0.16289314890294845 0.16287660108568774\n",
      "Epoch >>  1984 0.16287660108568774 0.02978248909947477 0.13309411198621374\n",
      "Saving the model  0.16287660108568774 0.16285482567956316\n",
      "Epoch >>  1985 0.16285482567956316 0.029780614484087305 0.13307421119547638\n",
      "Saving the model  0.16285482567956316 0.1628434093805976\n",
      "Epoch >>  1986 0.1628434093805976 0.029778551245388137 0.1330648581352101\n",
      "Saving the model  0.1628434093805976 0.16282160749385224\n",
      "Epoch >>  1987 0.16282160749385224 0.029776385894803997 0.1330452215990489\n",
      "Saving the model  0.16282160749385224 0.1628111136358865\n",
      "Epoch >>  1988 0.1628111136358865 0.029774404519041626 0.13303670911684556\n",
      "Saving the model  0.1628111136358865 0.16280062227954398\n",
      "Epoch >>  1989 0.16280062227954398 0.029771905862093977 0.13302871641745073\n",
      "Saving the model  0.16280062227954398 0.16276788712220694\n",
      "Epoch >>  1990 0.16276788712220694 0.0297694871768806 0.13299839994532706\n",
      "Saving the model  0.16276788712220694 0.16275924901847008\n",
      "Epoch >>  1991 0.16275924901847008 0.029767407015631155 0.1329918420028395\n",
      "Saving the model  0.16275924901847008 0.1627533169790666\n",
      "Epoch >>  1992 0.1627533169790666 0.029766024618950903 0.13298729236011628\n",
      "Saving the model  0.1627533169790666 0.162719994412071\n",
      "Epoch >>  1993 0.162719994412071 0.0297637151635149 0.13295627924855677\n",
      "Saving the model  0.162719994412071 0.16269479505059414\n",
      "Epoch >>  1994 0.16269479505059414 0.029761824436342205 0.13293297061425258\n",
      "Saving the model  0.16269479505059414 0.16267909913316184\n",
      "Epoch >>  1995 0.16267909913316184 0.029759601680900905 0.13291949745226145\n",
      "Saving the model  0.16267909913316184 0.1626518391423558\n",
      "Epoch >>  1996 0.1626518391423558 0.02975725025147706 0.13289458889087927\n",
      "Saving the model  0.1626518391423558 0.16264308989182968\n",
      "Epoch >>  1997 0.16264308989182968 0.029755260205667832 0.13288782968616222\n",
      "Saving the model  0.16264308989182968 0.16263109677025403\n",
      "Epoch >>  1998 0.16263109677025403 0.029753370690764357 0.13287772607949\n",
      "Saving the model  0.16263109677025403 0.1626072083186213\n",
      "Epoch >>  1999 0.1626072083186213 0.029751037693677998 0.1328561706249437\n"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION Training Loop\n",
    "\n",
    "loss_hist1  = Averager()\n",
    "loss_hist2  = Averager()\n",
    "loss_hist3  = Averager()\n",
    "\n",
    "\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 4\n",
    "counter    = 0\n",
    "model.train()\n",
    "prev_min = 1000\n",
    "\n",
    "for epoch in range(0, 2000):\n",
    "    for t1 in train_data_loader:\n",
    "        new_images  = torch.Tensor(t1['img']).to(device)\n",
    "        attr_target = t1['attr'].to(device)\n",
    "        cate_target = t1['cate'].to(device)\n",
    "\n",
    "        out1, out2  = model(new_images)\n",
    "        cate_target = torch.reshape(cate_target, [batch_size])\n",
    "        #print(out1.shape, out2.shape, cate_target.shape, attr_target.shape)\n",
    "\n",
    "        loss1      = 5*bce_loss(out1, attr_target)\n",
    "        loss2      = ce_loss(out2,  cate_target)\n",
    "\n",
    "        losses     = loss1 + loss2 #sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        counter =  counter+1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for t1 in val_data_loader:\n",
    "            new_images  = torch.Tensor(t1['img']).to(device)\n",
    "            attr_target = t1['attr'].to(device)\n",
    "            cate_target = t1['cate'].to(device)\n",
    "\n",
    "            out1, out2  = model(new_images)\n",
    "            cate_target = torch.reshape(cate_target, [batch_size])\n",
    "            #print(out1.shape, out2.shape, cate_target.shape, attr_target.shape)\n",
    "\n",
    "            loss1      = bce_loss(out1, attr_target)\n",
    "            loss2      = ce_loss(out2,  cate_target)\n",
    "\n",
    "            losses     = loss1 + loss2\n",
    "\n",
    "            loss_hist1.send(loss1.data.item())\n",
    "            loss_hist2.send(loss2.data.item())\n",
    "            loss_hist3.send(losses.data.item())\n",
    "    \n",
    "    if loss_hist3.value < prev_min:\n",
    "        print('Saving the model ', prev_min, loss_hist3.value)\n",
    "        torch.save(model.state_dict(), 'newdataset_model4.pth')\n",
    "        prev_min = loss_hist3.value\n",
    "    \n",
    "    print('Epoch >> ', epoch, loss_hist3.value, loss_hist1.value, loss_hist2.value)\n",
    "\n",
    "#a = next(dloader)\n",
    "#print(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [4] [[  2 129 175 179 180 181]] [ 21 129 175 179 181]\n",
      "Predicted:     outerwear [['black' 'longsleeves' 'coat' 'nobutton' 'robe' 'trench']]\n",
      "Ground Truth:  ['outerwear'] ['navyblue' 'longsleeves' 'coat' 'nobutton' 'trench']\n"
     ]
    }
   ],
   "source": [
    "# [STAR] New Fashion Dataset Testing on a single image\n",
    "\n",
    "cate_list = np.array(['accessories', 'bottoms' ,'dresses', 'footwear' ,'outerwear', 'tops'])\n",
    "attr_list = np.array(['totebag', 'beige', 'black', 'brown', 'darkred', 'green', 'grey', 'lightpink', 'multicolor', 'offwhite', 'orange', 'pink', 'purple', 'yellow', 'clutchbag', 'silver', 'white', 'neckscarf', 'golden', 'lightblue', 'lightgreen', 'navyblue', 'red', 'redfloral', 'layerednecklace', 'cream', 'ecru', 'hoops', 'rosegold', 'crossbody', 'blue', 'mustard', 'skinnybelt', 'navy', 'tan', 'statementbelt', 'burgundy', 'camel', 'darkbrown', 'chainnecklace', 'statementnecklace', 'teardropearrings', 'strawtote', 'camelbrown', 'scrunchie', 'blackwhite', 'headband', 'olive', 'crushbag', 'beltbag', 'blackvirgin', 'bucketbag', 'backpack', 'khakigreen', 'leopard', 'rosepink', 'minibag', 'socks', 'beanie', 'buckethat', 'fedora', 'ivory', 'olivegreen', 'jeans', 'long', 'lightdenim', 'mediumdenim', 'darkdenim', 'regular', 'lightblack', 'ankle', 'frayed', 'boyfriend', 'bootcut', 'distressed', 'skinny', 'straight', 'wide', 'highrise', 'midrise', 'lowrise', 'pant', 'blackcheck', 'maroon', 'greycheck', 'darkgrey', 'browncheck', 'greyblue', 'legging', 'plum', 'skyblue', 'loose', 'metallicblack', 'bluefloral', 'trouser', 'darkgreen', 'wideleg', 'pinkfloral', 'darkdenimblue', 'skirts', 'aline', 'high', 'denimblue', 'oatmeal', 'asymmetrical', 'brownfloral', 'mettalicpink', 'blackfloral', 'greyfloral', 'pleated', 'blush', 'slit', 'tulle', 'wrap', 'creamfloral', 'maxi', 'greenfloral', 'yellowfloral', 'mini', 'taupe', 'khaki', 'knee', 'midi', 'tank', 'sleeveless', 'dustypink', 'short', 'shortsleeves', 'puff', 'longsleeves', 'whitefloral', 'lightpurple', 'tflength', 'oneshoulder', 'strapless', 'turtleneck', 'lightgrey', 'fitandflare', 'openback', 'lightskyblue', 'ruched', 'slip', 'sweater', 'tea', 'midcalfboots', 'kneehighboots', 'pumps', 'combatboots', 'chelseaboots', 'flats', 'wedges', 'mules', 'darkblue', 'platformsandals', 'blockheelsandals', 'classicsneakers', 'retrorunning', 'lowtopsneakers', 'hightopsneakers', 'crocs', 'slides', 'turquoice', 'slippers', 'platformsneakers', 'slingbacksandals', 'loafers', 'booties', 'blazer', 'collarless', 'doublebreasted', 'onebutton', 'oversized', 'anthracitegrey', 'singlebreasted', 'midnightblue', 'coat', 'peacoat', 'button', 'quilted', 'nobutton', 'robe', 'trench', 'teddy', 'jacket', 'denim', 'moto', 'puffer', 'withoutsleeves', 'shearling', 'crewneck', 'tight', 'collared', 'cardigan', 'vneck', 'crop', 'square', 'tshirt', 'mock', 'blouse', 'smocked', 'lonsleeves'])\n",
    "        \n",
    "        \n",
    "model.load_state_dict(torch.load('newdataset_model4.pth'))\n",
    "model.eval()\n",
    "\n",
    "index = random.randint(0, len(d2))\n",
    "t1    = d2[index]\n",
    "\n",
    "new_images  = torch.Tensor(np.expand_dims(t1['img'], 0)).to(device)\n",
    "attr_target = t1['attr'].to(device)\n",
    "cate_target = t1['cate'].to(device)\n",
    "        \n",
    "out1, out2  = model(new_images)\n",
    "        \n",
    "out1 = torch.sigmoid(out1)\n",
    "out2 = torch.softmax(out2, axis=1)\n",
    "\n",
    "out1 = out1.data.cpu().numpy().flatten()\n",
    "out2 = out2.data.cpu().numpy().flatten()\n",
    "\n",
    "out1[out1 < 0.5] = 0\n",
    "out1 = np.array(out1.flatten())\n",
    "\n",
    "attr_index         = np.array(np.nonzero(out1))\n",
    "attr_ground_index  = np.array(np.nonzero(t1['attr']).flatten())\n",
    "\n",
    "cate_index         = np.argmax(out2)\n",
    "cate_ground_index  = t1['cate'].data.cpu().numpy()#[0][0]\n",
    "\n",
    "print(cate_index, cate_ground_index, attr_index, attr_ground_index)\n",
    "print(\"Predicted:    \", cate_list[cate_index],        attr_list[attr_index])\n",
    "print(\"Ground Truth: \", cate_list[cate_ground_index], attr_list[attr_ground_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/129_Socks/socks6.jpg\n",
      "torch.Size([3, 224, 164])\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/129_Socks/socks6.jpg\n",
      "torch.Size([3, 224, 164])\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "t1    = d2[index]\n",
    "print(t1['img'].shape)\n",
    "print(d2[index]['img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/129_Socks/socks6.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f626bab15d0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(d2[index]['img'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 224)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('/media/yu-hao/WindowsData/FashionNewDataset/Accessories/129_Socks/socks6.JPG').convert('RGB')\n",
    "width, height  = img.size\n",
    "new_width  = width//2\n",
    "new_height = height//2\n",
    "\n",
    "img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "#elif path.exists(self.img_list[idx].replace('.jpg', ''))\n",
    "\n",
    "#print('Original Image size is ', width, height)\n",
    "# Very Important\n",
    "# For getting the cropped and resized region of interest image\n",
    "img.thumbnail((224, 224), Image.ANTIALIAS)\n",
    "\n",
    "img.show()\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 164)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f626bb36c50>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = t1['img'].data.numpy()\n",
    "print(p1.shape)\n",
    "plt.imshow(p1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/img/Embroidered_Woven_Dress/img_00000015.jpg\n",
      "Original Image size is  200 300\n",
      "40 [40]\n",
      "Predicted:     Dress [['solid' 'long_sleeve' 'mini_length' 'crew_neckline' 'cotton' 'loose']]\n",
      "Ground Truth:  ['Dress'] ['solid' 'long_sleeve' 'mini_length' 'no_neckline' 'cotton' 'loose']\n"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION Testing on a single image\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "model.load_state_dict(torch.load('fashion_cate_attr_resnet50_single_linear.pth'))\n",
    "model.eval()\n",
    "\n",
    "index = random.randint(0, len(d2))\n",
    "t1    = d2[index]\n",
    "\n",
    "new_images  = torch.Tensor(np.expand_dims(t1['img'], 0)).to(device)\n",
    "attr_target = t1['attr'].to(device)\n",
    "cate_target = t1['cate'].to(device)\n",
    "        \n",
    "out1, out2  = model(new_images)\n",
    "        \n",
    "out1 = torch.sigmoid(out1)\n",
    "out2 = torch.softmax(out2, axis=1)\n",
    "\n",
    "out1 = out1.data.cpu().numpy().flatten()\n",
    "out2 = out2.data.cpu().numpy().flatten()\n",
    "\n",
    "out1[out1 < 0.5] = 0\n",
    "out1 = np.array(out1.flatten())\n",
    "\n",
    "attr_index         = np.array(np.nonzero(out1))\n",
    "attr_ground_index  = np.array(np.nonzero(t1['attr']).flatten())\n",
    "\n",
    "cate_index         = np.argmax(out2)\n",
    "cate_ground_index  = t1['cate'].data.cpu().numpy()#[0][0]\n",
    "\n",
    "print(cate_index, cate_ground_index)\n",
    "print(\"Predicted:    \", cate_list[cate_index], attr_list[attr_index])\n",
    "print(\"Ground Truth: \", cate_list[cate_ground_index], attr_list[attr_ground_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Predicted:     Jumpsuit ['striped' 'pleated' 'sleeveless' 'maxi_length' 'no_dress' 'v_neckline'\n",
      " 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "1 Predicted:     Jumpsuit ['striped' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "2 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "3 Predicted:     Jumpsuit ['striped' 'pleated' 'sleeveless' 'maxi_length' 'cotton' 'conventional']\n",
      "---------------------\n",
      "4 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "5 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "6 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "7 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "8 Predicted:     Cutoffs ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "9 Predicted:     Blazer ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "10 Predicted:     Blazer ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "11 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "12 Predicted:     Coat ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "13 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "14 Predicted:     Top ['solid' 'long_sleeve' 'no_dress' 'no_neckline']\n",
      "---------------------\n",
      "15 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "16 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'conventional']\n",
      "---------------------\n",
      "17 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "18 Predicted:     Culottes ['pleated' 'long_sleeve' 'no_dress' 'cotton' 'loose']\n",
      "---------------------\n",
      "19 Predicted:     Blouse ['striped' 'pleated' 'long_sleeve' 'no_dress' 'chiffon' 'loose']\n",
      "---------------------\n",
      "20 Predicted:     Jeggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "21 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "22 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'denim' 'conventional']\n",
      "---------------------\n",
      "23 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "24 Predicted:     Button-Down ['graphic' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "25 Predicted:     Sweatshorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "26 Predicted:     Blouse ['floral' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "27 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "28 Predicted:     Blouse ['graphic' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "29 Predicted:     Dress ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "30 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "31 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "32 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "33 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "34 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "35 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "36 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "37 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "38 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "39 Predicted:     Cardigan ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'no_neckline' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "40 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "41 Predicted:     Hoodie ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "42 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "43 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "44 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "45 Predicted:     Sweater ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "46 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton']\n",
      "---------------------\n",
      "47 Predicted:     Sweater ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "48 Predicted:     Sweater ['embroidered' 'solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit'\n",
      " 'loose' 'conventional']\n",
      "---------------------\n",
      "49 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim']\n",
      "---------------------\n",
      "50 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "51 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "52 Predicted:     Blouse ['pleated' 'solid' 'long_sleeve' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "53 Predicted:     Tee ['solid' 'sleeveless' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "54 Predicted:     Tee ['graphic' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "55 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "56 Predicted:     Tank ['graphic' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'loose']\n",
      "---------------------\n",
      "57 Predicted:     Joggers ['graphic' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "58 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "59 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "60 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "61 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "62 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "63 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'conventional']\n",
      "---------------------\n",
      "64 Predicted:     Dress ['solid' 'short_sleeve' 'maxi_length' 'crew_neckline' 'chiffon'\n",
      " 'conventional']\n",
      "---------------------\n",
      "65 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'conventional']\n",
      "---------------------\n",
      "66 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "67 Predicted:     Dress ['striped' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "68 Predicted:     Sweater ['solid' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "69 Predicted:     Hoodie ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "70 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'loose']\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Predicted:     Dress ['sleeveless' 'maxi_length' 'no_neckline' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "72 Predicted:     Tank ['sleeveless' 'no_dress' 'crew_neckline' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "73 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "74 Predicted:     Sweater ['solid' 'sleeveless' 'no_dress' 'crew_neckline' 'no_neckline' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "75 Predicted:     Dress ['sleeveless' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "76 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "77 Predicted:     Tee ['solid' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "78 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "79 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'leather' 'tight']\n",
      "---------------------\n",
      "80 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "81 Predicted:     Blazer ['solid' 'long_sleeve' 'no_dress' 'cotton' 'leather' 'conventional']\n",
      "---------------------\n",
      "82 Predicted:     Blouse ['striped' 'pleated' 'long_sleeve' 'no_dress' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "83 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim']\n",
      "---------------------\n",
      "84 Predicted:     Tee ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'v_neckline' 'no_neckline'\n",
      " 'cotton' 'conventional']\n",
      "---------------------\n",
      "85 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "86 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "87 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "88 Predicted:     Dress ['striped' 'sleeveless' 'mini_length' 'no_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "89 Predicted:     Blouse ['solid' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "90 Predicted:     Dress ['striped' 'short_sleeve' 'mini_length' 'v_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "91 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "92 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "93 Predicted:     Sweatpants ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "94 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "95 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "96 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "97 Predicted:     Tee ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "98 Predicted:     Blouse ['pleated' 'sleeveless' 'no_dress' 'no_neckline' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "99 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "100 Predicted:     Dress ['pleated' 'sleeveless' 'maxi_length' 'no_neckline' 'chiffon' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "101 Predicted:     Tee ['solid' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "102 Predicted:     Blouse ['floral' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "103 Predicted:     Dress ['solid' 'mini_length' 'cotton' 'tight']\n",
      "---------------------\n",
      "104 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "105 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "106 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'conventional']\n",
      "---------------------\n",
      "107 Predicted:     Tee ['solid' 'short_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "108 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'leather' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "109 Predicted:     Jacket ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "110 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "111 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "112 Predicted:     Tee ['long_sleeve' 'no_dress' 'crew_neckline' 'loose' 'conventional']\n",
      "---------------------\n",
      "113 Predicted:     Cardigan ['solid' 'long_sleeve' 'short_sleeve' 'no_dress' 'v_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "114 Predicted:     Jeggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "115 Predicted:     Sweater ['solid' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "116 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim']\n",
      "---------------------\n",
      "117 Predicted:     Blouse ['floral' 'sleeveless' 'maxi_length' 'no_dress' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "118 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "119 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "120 Predicted:     Blouse ['floral' 'long_sleeve' 'no_dress' 'crew_neckline' 'chiffon' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "121 Predicted:     Jacket ['solid' 'long_sleeve' 'no_dress' 'denim' 'conventional']\n",
      "---------------------\n",
      "122 Predicted:     Blazer ['graphic' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "123 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "124 Predicted:     Blouse ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'conventional']\n",
      "---------------------\n",
      "125 Predicted:     Blouse ['pleated' 'long_sleeve' 'no_dress' 'chiffon' 'loose' 'conventional']\n",
      "---------------------\n",
      "126 Predicted:     Blouse ['solid' 'short_sleeve' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "127 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "128 Predicted:     Dress ['solid' 'sleeveless' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "129 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "130 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'chiffon' 'cotton' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "131 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "132 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "133 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "134 Predicted:     Dress ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "135 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "136 Predicted:     Dress ['graphic' 'long_sleeve' 'mini_length' 'v_neckline' 'cotton']\n",
      "---------------------\n",
      "137 Predicted:     Dress ['graphic' 'long_sleeve' 'mini_length' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "138 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "139 Predicted:     Sweatshorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "140 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "141 Predicted:     Jumpsuit ['solid' 'sleeveless' 'no_dress' 'v_neckline' 'no_neckline' 'denim'\n",
      " 'cotton' 'conventional']\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 Predicted:     Tee ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "143 Predicted:     Tee ['solid' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "144 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "145 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "146 Predicted:     Shorts ['floral' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "147 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "148 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "149 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "150 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "151 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "152 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "153 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "154 Predicted:     Dress ['embroidered' 'sleeveless' 'mini_length' 'no_neckline' 'chiffon'\n",
      " 'conventional']\n",
      "---------------------\n",
      "155 Predicted:     Culottes ['striped' 'pleated' 'sleeveless' 'no_dress' 'no_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "156 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "157 Predicted:     Shorts ['striped' 'pleated' 'long_sleeve' 'no_dress' 'v_neckline' 'no_neckline'\n",
      " 'cotton' 'conventional']\n",
      "---------------------\n",
      "158 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'conventional']\n",
      "---------------------\n",
      "159 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "160 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "161 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "162 Predicted:     Dress ['solid' 'long_sleeve' 'no_dress' 'denim' 'conventional']\n",
      "---------------------\n",
      "163 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "164 Predicted:     Joggers ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'no_neckline'\n",
      " 'conventional']\n",
      "---------------------\n",
      "165 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "166 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "167 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'denim' 'conventional']\n",
      "---------------------\n",
      "168 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "169 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'no_neckline' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "170 Predicted:     Shorts ['solid' 'no_dress' 'no_neckline' 'cotton' 'loose' 'conventional']\n",
      "---------------------\n",
      "171 Predicted:     Blazer ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'v_neckline' 'cotton']\n",
      "---------------------\n",
      "172 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "173 Predicted:     Tee ['solid' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "174 Predicted:     Sweater ['solid' 'long_sleeve' 'sleeveless' 'no_dress' 'no_neckline' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "175 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-e779f68bd4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mnew_images\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#print(new_images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION VALIDATION LOOP\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "model.load_state_dict(torch.load('fashion_cate_attr_resnet50_single_linear.pth'))\n",
    "\n",
    "loss_hist1  = Averager()\n",
    "loss_hist2  = Averager()\n",
    "loss_hist3  = Averager()\n",
    "\n",
    "\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 1\n",
    "counter    = 0\n",
    "prev_min   = 1000\n",
    "\n",
    "val_data_loader   = build_dataloader(d3, 1, False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "cat_array_result  = []\n",
    "attr_array_result = []\n",
    "\n",
    "img_fraction = 0.50\n",
    "fontsize     = 17\n",
    "txt          = \"Hello World\"\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for t1 in val_data_loader:\n",
    "        new_images  = torch.Tensor(t1['img']).to(device)\n",
    "        #print(new_images.shape)\n",
    "        \n",
    "        #attr_target = t1['attr'].to(device)\n",
    "        #cate_target = t1['cate'].to(device)\n",
    "        \n",
    "        #print(t1['attr'])\n",
    "        #print(t1['cate'])\n",
    "        \n",
    "        #temp_img = np.array(t1['img'])[0]\n",
    "        #print(t1['imgpath'])\n",
    "        temp_img = Image.open(t1['imgpath'][0]).convert('RGB')\n",
    "        #np.moveaxis(temp_img, 0, 2)\n",
    "        #print('Image shape is ', temp_img.shape)\n",
    "        \n",
    "        img_save = temp_img#Image.fromarray(temp_img, 'RGB')\n",
    "        \n",
    "        out1, out2  = model(new_images)\n",
    "        \n",
    "        out1 = torch.sigmoid(out1)\n",
    "        out2 = torch.softmax(out2, axis=1)\n",
    "        \n",
    "        out1 = out1.data.cpu().numpy().flatten()\n",
    "        out2 = out2.data.cpu().numpy().flatten()\n",
    "        \n",
    "        out1[out1 < 0.5] = 0\n",
    "        out1 = np.array(out1.flatten())\n",
    "        \n",
    "        attr_index         = np.array(np.nonzero(out1)[0])\n",
    "        #attr_ground_index  = np.array(np.nonzero(t1['attr'][0]).flatten())\n",
    "        \n",
    "        cate_index         = np.argmax(out2)\n",
    "        #cate_ground_index  = t1['cate'].data.cpu().numpy()[0][0]\n",
    "        \n",
    "        #print(cate_index, cate_ground_index)\n",
    "        print(counter, \"Predicted:    \", cate_list[cate_index], attr_list[attr_index])\n",
    "        #print(\"Ground Truth: \", cate_list[cate_ground_index], attr_list[attr_ground_index])\n",
    "        print('---------------------')\n",
    "        \n",
    "        txt = cate_list[cate_index]\n",
    "        txt = txt+'\\n'+ \"\\n\".join( attr_list[attr_index])\n",
    "        \n",
    "        cat_array_result.append(cate_list[cate_index])\n",
    "        attr_array_result.append(attr_list[attr_index])\n",
    "        \n",
    "        while font.getsize(txt)[0] < img_fraction*img_save.size[0]:\n",
    "            # iterate until the text size is just larger than the criteria\n",
    "            fontsize += 1\n",
    "            font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
    "        \n",
    "        #nt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 15)\n",
    "        d  = ImageDraw.Draw(img_save)\n",
    "        d.text((10,10), txt,  fill=(0, 0, 0), font=font)\n",
    "        img_save.save('/home/yu-hao/SEMISUNET/SHARE_RESULTS/'+str(counter)+'.png')\n",
    "        \n",
    "        counter = counter+1\n",
    "        \n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portion of image width you want text width to be\n",
    "\n",
    "img_fraction = 0.50\n",
    "fontsize     = 11\n",
    "txt          = \"Hello World\"\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
    "while font.getsize(txt)[0] < img_fraction*img_save.size[0]:\n",
    "    # iterate until the text size is just larger than the criteria\n",
    "    fontsize += 1\n",
    "    font = ImageFont.truetype(\"arial.ttf\", fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Code to Create the New dataset text file\n",
    "\n",
    "\n",
    "a  = glob.glob('/media/yu-hao/WindowsData/FashionNewDataset/**/*.csv', recursive=True)\n",
    "\n",
    "\n",
    "h = {}\n",
    "count = 0\n",
    "for t in a:\n",
    "    #print(t)\n",
    "    f = open(t).read().split('\\n')[1:]\n",
    "    \n",
    "    for l in f:\n",
    "        temp = l.split(',')[2:]\n",
    "        temp = [x for x in temp if x]\n",
    "        \n",
    "        for l in temp:\n",
    "            if l in h:\n",
    "                h[l] = h[l]+1\n",
    "            else:\n",
    "                h[l] = 1\n",
    "#print(h)\n",
    "\n",
    "hnew = {}\n",
    "for k in h:\n",
    "    if h[k] >= 10:\n",
    "        hnew[k] = h[k]\n",
    "\n",
    "#print(hnew)\n",
    "\n",
    "\n",
    "count         = 0\n",
    "imagepathlist = []\n",
    "imagecatlist  = []\n",
    "imageattrlist = []\n",
    "newdataset    = []\n",
    "\n",
    "for t in a:\n",
    "    f               = open(t).read().split('\\n')[1:]\n",
    "    imagefolderpath = \"/\".join(t.split('/')[:-1])\n",
    "    \n",
    "    for l in f:\n",
    "        temp = l.split(',')\n",
    "        temp = [x for x in temp if x]\n",
    "        \n",
    "        for k in temp:\n",
    "            if k in hnew:\n",
    "                if '.jpg' not in temp[0]:\n",
    "                    imagename =  temp[0]+'.jpg'\n",
    "                else:\n",
    "                    imagename =  temp[0]\n",
    "                \n",
    "                imagepath = imagefolderpath+\"/\"+imagename\n",
    "                \n",
    "                category   = temp[1]\n",
    "                attributes = temp[2:]\n",
    "                \n",
    "                imagepathlist.append(imagepath)\n",
    "                imagecatlist.append(category)\n",
    "                imageattrlist.append(attributes)\n",
    "                \n",
    "                #print(imagepath)\n",
    "                #print(category, attributes)\n",
    "                \n",
    "                newdataset.append(imagepath+','+category+\",\"+\",\".join(attributes))\n",
    "\n",
    "newdataset = \"\\n\".join(newdataset)\n",
    "tp1 = open('newdataset.txt', 'w')\n",
    "tp1.write(newdataset)\n",
    "tp1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8373\n",
      "[6309 1557 7212 ... 6936 4053 6960]\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/70_Robe/robe10.jpg,outerwear,coat,robe,longsleeves,nobutton,green\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For creating the Train, Validation and Test splits from the New Dataset\n",
    "\n",
    "#Uncomment to Run\n",
    "\n",
    "# images = np.array(open('newdataset.txt', 'r').read().split('\\n')[:-1])\n",
    "# print(len(images))\n",
    "\n",
    "# shuffleindex = np.array(range(len(images)))\n",
    "# random.shuffle(shuffleindex)\n",
    "# print(shuffleindex)\n",
    "\n",
    "# trainidx = np.array(shuffleindex[:6000])\n",
    "# validx   = np.array(shuffleindex[6000:7000])\n",
    "# testidx  = np.array(shuffleindex[7000:])\n",
    "\n",
    "# train_images = images[trainidx]\n",
    "# val_images   = images[validx]\n",
    "# test_images  = images[testidx]\n",
    "\n",
    "# print(train_images[0])\n",
    "\n",
    "\n",
    "# f = open('newdataset_train.txt', 'w')\n",
    "# f.write('\\n'.join(train_images))\n",
    "# f.close()\n",
    "\n",
    "# f = open('newdataset_val.txt', 'w')\n",
    "# f.write('\\n'.join(val_images))\n",
    "# f.close()\n",
    "\n",
    "# f = open('newdataset_test.txt', 'w')\n",
    "# f.write('\\n'.join(test_images))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8428\n",
      "[7346  615 6863 ... 7967 1764 3294]\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora21.png (516, 711, 3) 951\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora22.png (507, 694, 3) 953\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora23.png (435, 545, 3) 954\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora24.png (494, 542, 3) 955\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora25.png (381, 537, 3) 957\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora26.png (453, 676, 3) 959\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora27.png (384, 546, 3) 961\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora28.png (337, 405, 3) 962\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora29.png (381, 425, 3) 964\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Accessories/133_Fedora/fedora30.png (412, 438, 3) 966\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Hemline/34_Long/long7.png (620, 343, 3) 992\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut2.png (625, 397, 3) 1390\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut3.png (621, 366, 3) 1395\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut4.png (627, 315, 3) 1400\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut5.png (617, 304, 3) 1405\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut6.png (621, 317, 3) 1410\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Silhouette/27_Bootcut/bootcut8.png (607, 332, 3) 1420\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Waistline/31_Highrise/highrise2.png (472, 358, 3) 1889\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Jeans/Waistline/32_MidRise/midrise20.png (599, 325, 3) 2098\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline1.png (611, 595, 3) 3132\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline2.png (392, 337, 3) 3136\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline3.png (678, 675, 3) 3140\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline4.png (613, 609, 3) 3144\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline5.png (711, 588, 3) 3148\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline6.png (655, 598, 3) 3152\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline7.png (581, 589, 3) 3156\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline8.png (612, 471, 3) 3160\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline9.png (337, 318, 3) 3164\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline10.png (526, 467, 3) 3168\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline11.png (566, 499, 3) 3172\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline12.png (368, 298, 3) 3175\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline13.png (403, 331, 3) 3179\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline14.png (670, 595, 3) 3182\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline15.png (604, 608, 3) 3186\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline16.png (200, 180, 3) 3189\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline17.png (838, 588, 3) 3192\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline18.png (420, 417, 3) 3196\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline19.png (485, 471, 3) 3199\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/1_Aline/aline20.png (716, 597, 3) 3202\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/3_Pleated/pleated1.png (669, 587, 3) 3278\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/3_Pleated/pleated2.png (351, 361, 3) 3282\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/3_Pleated/pleated5.png (322, 381, 3) 3292\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/3_Pleated/pleated6.png (837, 578, 3) 3296\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/4_Slit/slit7.png (218, 218, 3) 3372\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/4_Slit/slit8.png (373, 181, 3) 3376\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Silhouettes/4_Slit/slit9.png (268, 303, 3) 3380\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/10_Maxi/maxi12.png (590, 335, 3) 3620\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini1.png (472, 444, 3) 3650\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini2.png (388, 339, 3) 3654\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini3.png (454, 416, 3) 3658\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini4.png (507, 499, 3) 3662\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini5.png (388, 313, 3) 3666\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini6.png (498, 470, 3) 3670\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini7.png (499, 488, 3) 3673\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini8.png (423, 410, 3) 3676\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini9.png (489, 494, 3) 3679\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini10.png (504, 452, 3) 3683\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini11.png (516, 418, 3) 3686\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini12.png (658, 574, 3) 3689\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini13.png (602, 594, 3) 3692\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini14.png (618, 589, 3) 3696\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini15.png (464, 428, 3) 3700\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini16.png (479, 436, 3) 3704\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini17.png (503, 447, 3) 3707\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini18.png (525, 605, 3) 3710\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini19.png (537, 536, 3) 3714\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/7_Mini/mini20.png (473, 508, 3) 3718\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee1.png (830, 595, 3) 3722\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee2.png (814, 602, 3) 3726\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee3.png (761, 597, 3) 3730\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee4.png (603, 411, 3) 3734\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee5.png (586, 475, 3) 3738\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee6.png (818, 570, 3) 3741\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee7.png (587, 380, 3) 3745\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee8.png (528, 452, 3) 3748\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee9.png (281, 277, 3) 3752\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee10.png (319, 274, 3) 3756\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee11.png (613, 455, 3) 3760\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee12.png (346, 280, 3) 3763\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee13.png (603, 393, 3) 3766\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee14.png (620, 475, 3) 3769\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee15.png (617, 479, 3) 3773\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee16.png (331, 275, 3) 3776\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee17.png (373, 318, 3) 3779\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee18.png (600, 404, 3) 3783\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee19.png (835, 592, 3) 3786\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/8_Knee/knee20.png (574, 380, 3) 3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/9_Midi/midi5.png (432, 358, 3) 3807\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/9_Midi/midi6.png (426, 296, 3) 3810\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/Slength/9_Midi/midi13.png (593, 417, 3) 3837\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high1.png (650, 668, 3) 3865\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high2.png (655, 586, 3) 3869\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high3.png (377, 294, 3) 3873\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high4.png (707, 602, 3) 3877\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high5.png (677, 477, 3) 3880\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high6.png (543, 384, 3) 3883\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high7.png (584, 493, 3) 3886\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high8.png (380, 456, 3) 3889\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high9.png (468, 500, 3) 3893\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high11.png (695, 588, 3) 3900\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high15.png (648, 567, 3) 3913\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Bottoms/Skirts/S_waistline/11_High/high18.png (663, 568, 3) 3924\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot1.png (593, 393, 3) 4802\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot2.png (598, 415, 3) 4803\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot3.png (504, 399, 3) 4805\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot4.png (506, 397, 3) 4807\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot5.png (560, 330, 3) 4809\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot6.png (406, 336, 3) 4811\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot7.png (638, 353, 3) 4813\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot8.png (838, 609, 3) 4815\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot9.png (593, 434, 3) 4817\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/101_Kneehighboots/kneehighboot10.png (617, 502, 3) 4819\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/102_Pumps/pump12.png (439, 610, 3) 4880\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat1.png (460, 664, 3) 4985\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat2.png (498, 669, 3) 4987\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat3.png (636, 707, 3) 4989\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat4.png (661, 713, 3) 4991\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat5.png (346, 564, 3) 4993\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat6.png (362, 603, 3) 4995\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat7.png (342, 710, 3) 4996\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat8.png (444, 649, 3) 4998\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat9.png (308, 523, 3) 5000\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/105_Flats/flat10.png (681, 504, 3) 5002\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule24.png (514, 679, 3) 5128\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule25.png (479, 678, 3) 5130\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule26.png (494, 683, 3) 5131\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule27.png (539, 694, 3) 5133\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule28.png (541, 704, 3) 5134\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule29.png (489, 730, 3) 5135\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule30.png (258, 422, 3) 5137\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule31.png (524, 411, 3) 5139\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule32.png (530, 379, 3) 5141\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule33.png (353, 407, 3) 5143\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule34.png (436, 710, 3) 5145\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/107_Mules/mule35.png (525, 662, 3) 5147\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal1.png (481, 538, 3) 5149\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal2.png (496, 500, 3) 5151\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal3.png (227, 390, 3) 5153\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal4.png (499, 612, 3) 5155\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal5.png (489, 473, 3) 5157\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal6.png (446, 472, 3) 5159\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal7.png (788, 765, 3) 5161\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal8.png (469, 521, 3) 5163\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal9.png (464, 525, 3) 5165\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal10.png (255, 375, 3) 5167\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal11.png (301, 372, 3) 5169\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal12.png (718, 575, 3) 5171\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal13.png (534, 643, 3) 5173\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal14.png (553, 642, 3) 5175\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal15.png (426, 460, 3) 5176\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal16.png (431, 502, 3) 5177\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal17.png (410, 458, 3) 5179\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal18.png (411, 422, 3) 5181\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal19.png (403, 422, 3) 5183\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Footwear/108_Platformsandals/platformsandal20.png (443, 467, 3) 5185\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/68_Peacoat/peacoat11.png (781, 549, 3) 6175\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/68_Peacoat/peacoat14.png (570, 499, 3) 6188\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted1.png (678, 559, 3) 6220\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted2.png (686, 591, 3) 6225\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted3.png (674, 569, 3) 6230\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted4.png (665, 581, 3) 6235\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted5.png (650, 579, 3) 6239\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted6.png (649, 569, 3) 6244\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted7.png (530, 620, 3) 6249\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted8.png (567, 458, 3) 6254\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted9.png (546, 469, 3) 6259\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted10.png (591, 455, 3) 6264\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted11.png (574, 465, 3) 6269\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted12.png (644, 581, 3) 6274\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted13.png (647, 586, 3) 6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted14.png (632, 586, 3) 6284\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted15.png (640, 606, 3) 6288\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted16.png (650, 608, 3) 6293\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted17.png (724, 417, 3) 6297\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted18.png (671, 656, 3) 6302\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted19.png (736, 492, 3) 6307\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/69_Quilted/quilted20.png (601, 531, 3) 6312\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy1.png (468, 474, 3) 6521\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy2.png (518, 383, 3) 6526\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy3.png (665, 364, 3) 6531\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy4.png (641, 380, 3) 6536\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy5.png (683, 382, 3) 6541\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy6.png (670, 382, 3) 6546\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy7.png (609, 439, 3) 6551\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy8.png (607, 428, 3) 6556\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy9.png (618, 431, 3) 6561\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy10.png (582, 427, 3) 6566\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy11.png (578, 432, 3) 6571\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy12.png (562, 430, 3) 6576\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy13.png (572, 427, 3) 6581\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy14.png (641, 387, 3) 6586\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy15.png (642, 356, 3) 6591\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy16.png (657, 392, 3) 6595\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy17.png (595, 439, 3) 6600\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy18.png (677, 357, 3) 6605\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy19.png (679, 365, 3) 6610\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Coat/72_Teddy/teddy20.png (612, 444, 3) 6615\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim1.png (733, 584, 3) 6619\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim2.png (730, 655, 3) 6623\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim3.png (448, 433, 3) 6627\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim4.png (639, 685, 3) 6631\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim5.png (700, 705, 3) 6635\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim6.png (593, 484, 3) 6639\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim7.png (626, 493, 3) 6643\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim8.png (624, 487, 3) 6646\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim9.png (602, 490, 3) 6650\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim10.png (634, 481, 3) 6654\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim11.png (603, 486, 3) 6658\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim12.png (614, 478, 3) 6662\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim13.png (587, 493, 3) 6666\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim14.png (641, 504, 3) 6670\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim15.png (540, 503, 3) 6674\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim16.png (594, 502, 3) 6678\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim17.png (632, 454, 3) 6682\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim18.png (601, 448, 3) 6686\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim19.png (679, 568, 3) 6690\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/64_Denim/denim20.png (530, 503, 3) 6694\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto1.png (594, 496, 3) 6698\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto2.png (575, 496, 3) 6702\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto3.png (854, 889, 3) 6706\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto4.png (458, 390, 3) 6709\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto5.png (449, 449, 3) 6713\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto6.png (557, 415, 3) 6717\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto7.png (464, 383, 3) 6721\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto8.png (573, 497, 3) 6725\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto9.png (818, 625, 3) 6729\n",
      "/media/yu-hao/WindowsData/FashionNewDataset/Outerwear/Jacket/65_Moto/moto10.png (557, 527, 3) 6733\n"
     ]
    }
   ],
   "source": [
    "# [STAR] Code to read the entries in New dataset and print image shape etc.\n",
    "\n",
    "images = open('newdataset.txt', 'r').read().split('\\n')[:-1]\n",
    "print(len(images))\n",
    "\n",
    "shuffleindex = np.array(range(len(images)))\n",
    "random.shuffle(shuffleindex)\n",
    "print(shuffleindex)\n",
    "\n",
    "trainidx = shuffleindex[:6000]\n",
    "validx   = shuffleindex[6000:7000]\n",
    "testidx  = shuffleindex[7000:]\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "all_shapesx = []\n",
    "all_shapesy = []\n",
    "\n",
    "for index, t in enumerate(images):\n",
    "    temp = t.split(',')\n",
    "    p    = temp[0].replace('.jpg', '.JPG')\n",
    "    c    = temp[1]\n",
    "    a    = temp[2:]\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        p     = p.replace('.JPG', '.png')\n",
    "        image = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image is not None:\n",
    "            #pass\n",
    "            print(p, image.shape, index)\n",
    "            im1 = Image.open(p)\n",
    "            im1 = im1.convert('RGB')\n",
    "            im1.save(p.replace('.png', '.JPG'))\n",
    "        else:\n",
    "            print('Big error ', p)\n",
    "\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    #image /= 255.0\n",
    "    \n",
    "    #print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f6272222c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272222bd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62729e1450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d6d310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d6d890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d6ddd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d76390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d768d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d76e10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d7d390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d7d890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d7ddd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d84350>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d7d410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d767d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d84090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d84ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d84050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d0f590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d0fad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d0f110>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d17590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d0f750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d844d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d17890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d17ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d1f310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d1f850>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d1fd90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d27310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d27850>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d27d90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d276d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d1f590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d843d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d30090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d30a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d30f10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d39550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d39a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d39f10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d42550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d39ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d84950>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d425d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d42cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ccb2d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ccb790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ccbcd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd42d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd4790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd4cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd4690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ccb390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d30550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cdd410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cdd950>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cdde90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ce5410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ce5950>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ce5e90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ce5a10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cdd490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd4450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ced5d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cedc10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cf6090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cf66d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cf6c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cff090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cff6d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cf6250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cd4d50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cff450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cff050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c873d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c87910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c87e50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c8f3d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c8f910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c8fe50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c8f990>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c87490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ced190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c98610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c98b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c98d90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ca2610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ca2b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ca2d90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271caa610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ca26d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cedb10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271caa6d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271caad10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cb4310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cb47d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cb4d10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cbb310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cbb7d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cbbd10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cbb3d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cb4c90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ca2110>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cc2550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cc2a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cc2f10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c4d550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c4da90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c4df10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c4d210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cc2210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271cbbc90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ced390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d17750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c550d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c55ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c55410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c60590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c60ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272d39310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272cdec10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272cb26d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272c7b250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272c44190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272d7d690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272bc8c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272b123d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272ad9310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272c44550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272d2db50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272aad190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272a52a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272a31c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62729fc3d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62729c2310>,\n",
       "  <matplotlib.axis.XTick at 0x7f627297ee50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272948610>,\n",
       "  <matplotlib.axis.XTick at 0x7f62729b5b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272b0a790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272890190>,\n",
       "  <matplotlib.axis.XTick at 0x7f62728570d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272bff910>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723c8f90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723cde90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723d4cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723dbb10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723d4190>,\n",
       "  <matplotlib.axis.XTick at 0x7f62728b3310>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723e2210>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723ea050>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723eac10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723f0f90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723f7e90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723fdcd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272404b10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723fd5d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723eab10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62728cb910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272391210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272399510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272399c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f627239fad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723a6dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723acc10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723b2a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723ac090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272391c90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723b95d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723c2510>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723c2c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272349ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f627234edd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272355c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f627235ca50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272355510>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723c2a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723916d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f627236a510>,\n",
       "  <matplotlib.axis.XTick at 0x7f627236acd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272371ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272376ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f627237e910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272384750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272309590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272384090>,\n",
       "  <matplotlib.axis.XTick at 0x7f627236a3d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272311510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272311cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272319ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272320ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272326910>,\n",
       "  <matplotlib.axis.XTick at 0x7f627232c750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272333590>,\n",
       "  <matplotlib.axis.XTick at 0x7f627232c050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272319590>,\n",
       "  <matplotlib.axis.XTick at 0x7f627236a090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272341050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272341c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722c8f90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722cee90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722d5cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722dbb10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722e2950>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722db590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272341e50>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722e9510>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722e9c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c60090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c4d150>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c55610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272516410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c67250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271d6d290>,\n",
       "  <matplotlib.axis.XTick at 0x7f62722e9410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c67690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c67dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c02410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c02a10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c02690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b89650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b89c50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b91290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b89510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c67890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b91710>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b91d10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b99350>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b99950>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b997d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b9f590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b9fb90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b9f650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b99210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b994d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62723b2dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271c67350>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ba6750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ba6d50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bae390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bae990>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bae810>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ba6dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6272311090>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bb6410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bb6a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bb6dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bbd690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bbdc90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bc42d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bc48d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bc4ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bbd750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bc4250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b4d510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b4db10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b53190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b53750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b53d50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b59390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b59990>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b532d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bbdb50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b59e10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b62450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b62a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b62dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b6a690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b6ac90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b722d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b62ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b59250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b72650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b72dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b78410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b78a10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b78690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b7f650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b7fc50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b09290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b7f510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b72710>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b09710>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b09d10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b0f350>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b0f950>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b0f7d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b16590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b16b90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b16650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b0f410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b78050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b1e6d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b1ecd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b25310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b25910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b25f10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b2b550>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b2bb50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b25490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b09790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b2b250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b34610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b34c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b3b250>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b3b850>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b3be50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b42490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b3b1d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b2be10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b426d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b42a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aca5d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271acabd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad1290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad1810>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad1e10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad8450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad1790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b3b310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad88d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ad8ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae0510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae0b10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae6190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae6750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae6d50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae6450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ae0490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b42350>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aed890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aede90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271af64d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271af6ad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271afe1d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271afe710>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271afed10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271afe290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aedb90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a85210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a857d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a85dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a8d410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a8da10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a8d690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a94650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a8d050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a85690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271b42a10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271bc4e50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a94590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a9d290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a9d810>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a9de10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aa3450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aa3a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aa3dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a9d510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a85890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aab510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271aabb10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab2190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab2750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab2d50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab8390>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab20d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab2610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab8150>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab88d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ac25d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ac2bd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a49290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a49810>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a49e10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a4f450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a49790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab8a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a4f8d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a4fed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a57510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a57b10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a5f190>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a5f750>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a5fd50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a5f450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a57490>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271ab8450>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a65890>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a65e90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a6c4d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a6cad0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a741d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a74710>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a74d10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a74290>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a65b90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a7d210>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a7d7d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a7ddd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a83410>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a83a10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a83690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a0b650>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a83050>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a83590>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a0b8d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a131d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a13790>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a13d90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a193d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a199d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a19f10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a21610>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a196d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a19b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a21a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a21e10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a296d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a29cd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a2f310>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a2f910>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a2ff10>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a2f3d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a29850>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a38510>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a38a50>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a38dd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a3f690>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a3fc90>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719c62d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719c68d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719c6ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719c6850>,\n",
       "  <matplotlib.axis.XTick at 0x7f6271a38910>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719cd410>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719cd990>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719cd810>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719d55d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719d5bd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719dc290>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719dc810>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719dce10>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719d5b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719cd350>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719e3350>,\n",
       "  <matplotlib.axis.XTick at 0x7f62719e3950>],\n",
       " [Text(0, 0, 'babypink'),\n",
       "  Text(0, 0, 'cornflowerblue'),\n",
       "  Text(0, 0, 'lavenderpurple'),\n",
       "  Text(0, 0, 'opyumred'),\n",
       "  Text(0, 0, 'bluered'),\n",
       "  Text(0, 0, 'silverblack'),\n",
       "  Text(0, 0, 'blackgold'),\n",
       "  Text(0, 0, 'goldblack'),\n",
       "  Text(0, 0, 'goldpurple'),\n",
       "  Text(0, 0, 'pinkrhodium'),\n",
       "  Text(0, 0, 'silvergold'),\n",
       "  Text(0, 0, 'ballerinapink'),\n",
       "  Text(0, 0, 'brightorange'),\n",
       "  Text(0, 0, 'deepbeige'),\n",
       "  Text(0, 0, 'lightbeige'),\n",
       "  Text(0, 0, 'mottygrey'),\n",
       "  Text(0, 0, 'softbeige'),\n",
       "  Text(0, 0, 'yellowgrey'),\n",
       "  Text(0, 0, 'muddygreen'),\n",
       "  Text(0, 0, 'rustbrown'),\n",
       "  Text(0, 0, 'crystal'),\n",
       "  Text(0, 0, 'goldenwhite'),\n",
       "  Text(0, 0, 'pearlwhite'),\n",
       "  Text(0, 0, 'silverred'),\n",
       "  Text(0, 0, 'goldengreen'),\n",
       "  Text(0, 0, 'lightmustard'),\n",
       "  Text(0, 0, 'naturalbrown'),\n",
       "  Text(0, 0, 'copperbrown'),\n",
       "  Text(0, 0, 'ivorywhite'),\n",
       "  Text(0, 0, 'turquoiseblue'),\n",
       "  Text(0, 0, 'blushpink'),\n",
       "  Text(0, 0, 'fluorescentpink'),\n",
       "  Text(0, 0, 'jadegreen'),\n",
       "  Text(0, 0, 'rustred'),\n",
       "  Text(0, 0, 'terracotapink'),\n",
       "  Text(0, 0, 'crimson'),\n",
       "  Text(0, 0, 'bluejade'),\n",
       "  Text(0, 0, 'camouflage'),\n",
       "  Text(0, 0, 'beigeblack'),\n",
       "  Text(0, 0, 'blackolive'),\n",
       "  Text(0, 0, 'mossbrown'),\n",
       "  Text(0, 0, 'redblack'),\n",
       "  Text(0, 0, 'darkbeige'),\n",
       "  Text(0, 0, 'charcoalgrey'),\n",
       "  Text(0, 0, 'crimsonred'),\n",
       "  Text(0, 0, 'eggplantred'),\n",
       "  Text(0, 0, 'magentapink'),\n",
       "  Text(0, 0, 'neonorange'),\n",
       "  Text(0, 0, 'sugarbrown'),\n",
       "  Text(0, 0, 'tawnybrown'),\n",
       "  Text(0, 0, 'prussianblue'),\n",
       "  Text(0, 0, 'emoryblue'),\n",
       "  Text(0, 0, 'midblue'),\n",
       "  Text(0, 0, 'medumdenim'),\n",
       "  Text(0, 0, 'navybluecheck'),\n",
       "  Text(0, 0, 'greygreen'),\n",
       "  Text(0, 0, 'blackplaid'),\n",
       "  Text(0, 0, 'bluecheck'),\n",
       "  Text(0, 0, 'snakish'),\n",
       "  Text(0, 0, 'greencheck'),\n",
       "  Text(0, 0, 'bluegrey'),\n",
       "  Text(0, 0, 'olivegrey'),\n",
       "  Text(0, 0, 'darkmaroon'),\n",
       "  Text(0, 0, 'pinkzebra'),\n",
       "  Text(0, 0, 'moss'),\n",
       "  Text(0, 0, 'redblackplaid'),\n",
       "  Text(0, 0, 'cinnamonbrown'),\n",
       "  Text(0, 0, 'millitarygreen'),\n",
       "  Text(0, 0, 'greenplaid'),\n",
       "  Text(0, 0, 'blackcream'),\n",
       "  Text(0, 0, 'tawnyport'),\n",
       "  Text(0, 0, 'ston'),\n",
       "  Text(0, 0, 'oxblood'),\n",
       "  Text(0, 0, 'mettalicblue'),\n",
       "  Text(0, 0, 'palegrey'),\n",
       "  Text(0, 0, 'berry'),\n",
       "  Text(0, 0, 'lightpinkfloral'),\n",
       "  Text(0, 0, 'deepamber'),\n",
       "  Text(0, 0, 'brownplaid'),\n",
       "  Text(0, 0, 'bluesilver'),\n",
       "  Text(0, 0, 'purplefloral'),\n",
       "  Text(0, 0, 'nero'),\n",
       "  Text(0, 0, 'dexter'),\n",
       "  Text(0, 0, 'cinnamon'),\n",
       "  Text(0, 0, 'dazzlingblue'),\n",
       "  Text(0, 0, 'lightbeigecheck'),\n",
       "  Text(0, 0, 'tobacco'),\n",
       "  Text(0, 0, 'blackwhitestripe'),\n",
       "  Text(0, 0, 'indigo'),\n",
       "  Text(0, 0, 'indigowhite'),\n",
       "  Text(0, 0, 'powderpink'),\n",
       "  Text(0, 0, 'paperwhite'),\n",
       "  Text(0, 0, 'lightdenimblue'),\n",
       "  Text(0, 0, 'softecru'),\n",
       "  Text(0, 0, 'harborwaves'),\n",
       "  Text(0, 0, 'slate'),\n",
       "  Text(0, 0, 'sagegreen'),\n",
       "  Text(0, 0, 'lightredfloral'),\n",
       "  Text(0, 0, 'paledenimblue'),\n",
       "  Text(0, 0, 'blackredfloral'),\n",
       "  Text(0, 0, 'orchid'),\n",
       "  Text(0, 0, 'emerald'),\n",
       "  Text(0, 0, 'sapphireblue'),\n",
       "  Text(0, 0, 'mustardyellow'),\n",
       "  Text(0, 0, 'flourescentgreen'),\n",
       "  Text(0, 0, 'lightgreenfloral'),\n",
       "  Text(0, 0, 'whitebluefloral'),\n",
       "  Text(0, 0, 'brwonfloral'),\n",
       "  Text(0, 0, 'charcolgrey'),\n",
       "  Text(0, 0, 'woddenbrown'),\n",
       "  Text(0, 0, 'blew'),\n",
       "  Text(0, 0, 'blackbeige'),\n",
       "  Text(0, 0, 'darkredfloral'),\n",
       "  Text(0, 0, 'blackblue'),\n",
       "  Text(0, 0, 'skybluefloral'),\n",
       "  Text(0, 0, 'offwhitefloral'),\n",
       "  Text(0, 0, 'armygreen'),\n",
       "  Text(0, 0, 'chalkwhite'),\n",
       "  Text(0, 0, 'fuschiapink'),\n",
       "  Text(0, 0, 'taupbrown'),\n",
       "  Text(0, 0, 'almondbeige'),\n",
       "  Text(0, 0, 'sepiapink'),\n",
       "  Text(0, 0, 'tufflebrown'),\n",
       "  Text(0, 0, 'anthracite'),\n",
       "  Text(0, 0, 'balletpink'),\n",
       "  Text(0, 0, 'paralinebrown'),\n",
       "  Text(0, 0, 'shamrockgreen'),\n",
       "  Text(0, 0, 'taupegrey'),\n",
       "  Text(0, 0, 'beigegold'),\n",
       "  Text(0, 0, 'caramelbrown'),\n",
       "  Text(0, 0, 'ivoryblack'),\n",
       "  Text(0, 0, 'irongrey'),\n",
       "  Text(0, 0, 'hazelnutbrown'),\n",
       "  Text(0, 0, 'latte'),\n",
       "  Text(0, 0, 'royalgreen'),\n",
       "  Text(0, 0, 'sugarbeige'),\n",
       "  Text(0, 0, 'maleblue'),\n",
       "  Text(0, 0, 'redsatin'),\n",
       "  Text(0, 0, 'flamingo'),\n",
       "  Text(0, 0, 'amaranthpink'),\n",
       "  Text(0, 0, 'fluorescent'),\n",
       "  Text(0, 0, 'chocolate'),\n",
       "  Text(0, 0, 'cobaltblue'),\n",
       "  Text(0, 0, 'limezest'),\n",
       "  Text(0, 0, 'navywhite'),\n",
       "  Text(0, 0, 'candypink'),\n",
       "  Text(0, 0, 'flamered'),\n",
       "  Text(0, 0, 'nudepink'),\n",
       "  Text(0, 0, 'silverblue'),\n",
       "  Text(0, 0, 'metallicsilver'),\n",
       "  Text(0, 0, 'saphireblue'),\n",
       "  Text(0, 0, 'inkblue'),\n",
       "  Text(0, 0, 'sand'),\n",
       "  Text(0, 0, 'bonewhite'),\n",
       "  Text(0, 0, 'bluepinstripe'),\n",
       "  Text(0, 0, 'flamingopink'),\n",
       "  Text(0, 0, 'pistachiogreen'),\n",
       "  Text(0, 0, 'sky'),\n",
       "  Text(0, 0, 'electricblue'),\n",
       "  Text(0, 0, 'etro'),\n",
       "  Text(0, 0, 'antiquepink'),\n",
       "  Text(0, 0, 'beigewhite'),\n",
       "  Text(0, 0, 'bluesilk'),\n",
       "  Text(0, 0, 'persianred'),\n",
       "  Text(0, 0, 'blackwhitecheck'),\n",
       "  Text(0, 0, 'greysilk'),\n",
       "  Text(0, 0, 'multicolorcheck'),\n",
       "  Text(0, 0, 'multicolorgragon'),\n",
       "  Text(0, 0, 'navybluevirgin'),\n",
       "  Text(0, 0, 'navyvirgin'),\n",
       "  Text(0, 0, 'neutralblendplaid'),\n",
       "  Text(0, 0, 'neutralvirgin'),\n",
       "  Text(0, 0, 'pinksoba'),\n",
       "  Text(0, 0, 'redvirgin'),\n",
       "  Text(0, 0, 'sandvirgin'),\n",
       "  Text(0, 0, 'whitestriped'),\n",
       "  Text(0, 0, 'beigevirgin'),\n",
       "  Text(0, 0, 'lightarmygreen'),\n",
       "  Text(0, 0, 'bronzebrown'),\n",
       "  Text(0, 0, 'brownplaidcheck'),\n",
       "  Text(0, 0, 'samelbrown'),\n",
       "  Text(0, 0, 'cuminbrown'),\n",
       "  Text(0, 0, 'redgreycheck'),\n",
       "  Text(0, 0, 'claret'),\n",
       "  Text(0, 0, 'greysnake'),\n",
       "  Text(0, 0, 'khakibrown'),\n",
       "  Text(0, 0, 'plaidcheckbrown'),\n",
       "  Text(0, 0, 'blackpink'),\n",
       "  Text(0, 0, 'silvermetallic'),\n",
       "  Text(0, 0, 'camelnude'),\n",
       "  Text(0, 0, 'lightrosepink'),\n",
       "  Text(0, 0, 'beigebrown'),\n",
       "  Text(0, 0, 'creamyneonyellow'),\n",
       "  Text(0, 0, 'creamvirgin'),\n",
       "  Text(0, 0, 'greenbeige'),\n",
       "  Text(0, 0, 'shortsleevesshortsleeves'),\n",
       "  Text(0, 0, 'redwhite'),\n",
       "  Text(0, 0, 'blackgrey'),\n",
       "  Text(0, 0, 'mudgreen'),\n",
       "  Text(0, 0, 'checkwhite'),\n",
       "  Text(0, 0, 'lightyellow'),\n",
       "  Text(0, 0, 'blackgreen'),\n",
       "  Text(0, 0, 'darkpurple'),\n",
       "  Text(0, 0, 'snake'),\n",
       "  Text(0, 0, 'cognacbrown'),\n",
       "  Text(0, 0, 'gold'),\n",
       "  Text(0, 0, 'cherryred'),\n",
       "  Text(0, 0, 'lilacpurple'),\n",
       "  Text(0, 0, 'diamond'),\n",
       "  Text(0, 0, 'neonpink'),\n",
       "  Text(0, 0, 'royalblue'),\n",
       "  Text(0, 0, 'dustyblue'),\n",
       "  Text(0, 0, 'pastelpink'),\n",
       "  Text(0, 0, 'yellowblack'),\n",
       "  Text(0, 0, 'bluewhite'),\n",
       "  Text(0, 0, 'poppink'),\n",
       "  Text(0, 0, 'sandbeige'),\n",
       "  Text(0, 0, 'browncheck'),\n",
       "  Text(0, 0, 'greyblue'),\n",
       "  Text(0, 0, 'plum'),\n",
       "  Text(0, 0, 'metallicgrey'),\n",
       "  Text(0, 0, 'metallicblack'),\n",
       "  Text(0, 0, 'darkdenimblue'),\n",
       "  Text(0, 0, 'oatmeal'),\n",
       "  Text(0, 0, 'mettalicpink'),\n",
       "  Text(0, 0, 'burgundyfloral'),\n",
       "  Text(0, 0, 'blush'),\n",
       "  Text(0, 0, 'creamfloral'),\n",
       "  Text(0, 0, 'taupe'),\n",
       "  Text(0, 0, 'chestnutbrown'),\n",
       "  Text(0, 0, 'goldenyellow'),\n",
       "  Text(0, 0, 'greywhite'),\n",
       "  Text(0, 0, 'yelloe'),\n",
       "  Text(0, 0, 'midpink'),\n",
       "  Text(0, 0, 'metallicblue'),\n",
       "  Text(0, 0, 'rosegolden'),\n",
       "  Text(0, 0, 'babyblue'),\n",
       "  Text(0, 0, 'silvertone'),\n",
       "  Text(0, 0, 'deepblue'),\n",
       "  Text(0, 0, 'brownblack'),\n",
       "  Text(0, 0, 'lemon'),\n",
       "  Text(0, 0, 'metallicpink'),\n",
       "  Text(0, 0, 'palegold'),\n",
       "  Text(0, 0, 'anthracitegrey'),\n",
       "  Text(0, 0, 'midnightblue'),\n",
       "  Text(0, 0, 'withoutsleeves'),\n",
       "  Text(0, 0, 'pinkblack'),\n",
       "  Text(0, 0, 'emeraldgreen'),\n",
       "  Text(0, 0, 'lilac'),\n",
       "  Text(0, 0, 'hotpink'),\n",
       "  Text(0, 0, 'goldenblack'),\n",
       "  Text(0, 0, 'camelbrown'),\n",
       "  Text(0, 0, 'blackvirgin'),\n",
       "  Text(0, 0, 'mintgreen'),\n",
       "  Text(0, 0, 'blackcheck'),\n",
       "  Text(0, 0, 'greycheck'),\n",
       "  Text(0, 0, 'pinkfloral'),\n",
       "  Text(0, 0, 'khaki'),\n",
       "  Text(0, 0, 'lightbrown'),\n",
       "  Text(0, 0, 'dustypink'),\n",
       "  Text(0, 0, 'darkpink'),\n",
       "  Text(0, 0, 'darkblue'),\n",
       "  Text(0, 0, 'turquoice'),\n",
       "  Text(0, 0, 'palepink'),\n",
       "  Text(0, 0, 'tan'),\n",
       "  Text(0, 0, 'rosepink'),\n",
       "  Text(0, 0, 'tanbrown'),\n",
       "  Text(0, 0, 'greenfloral'),\n",
       "  Text(0, 0, 'lightskyblue'),\n",
       "  Text(0, 0, 'whitegold'),\n",
       "  Text(0, 0, 'mustard'),\n",
       "  Text(0, 0, 'olive'),\n",
       "  Text(0, 0, 'chocolatebrown'),\n",
       "  Text(0, 0, 'denimblue'),\n",
       "  Text(0, 0, 'yellowfloral'),\n",
       "  Text(0, 0, 'khakigreen'),\n",
       "  Text(0, 0, 'maroon'),\n",
       "  Text(0, 0, 'greyfloral'),\n",
       "  Text(0, 0, 'lightpurple'),\n",
       "  Text(0, 0, 'rosegold'),\n",
       "  Text(0, 0, 'bluefloral'),\n",
       "  Text(0, 0, 'lightgrey'),\n",
       "  Text(0, 0, 'navy'),\n",
       "  Text(0, 0, 'darkbrown'),\n",
       "  Text(0, 0, 'darkgreen'),\n",
       "  Text(0, 0, 'brownfloral'),\n",
       "  Text(0, 0, 'redfloral'),\n",
       "  Text(0, 0, 'burgundy'),\n",
       "  Text(0, 0, 'leopard'),\n",
       "  Text(0, 0, 'darkred'),\n",
       "  Text(0, 0, 'camel'),\n",
       "  Text(0, 0, 'offwhite'),\n",
       "  Text(0, 0, 'lightgreen'),\n",
       "  Text(0, 0, 'whitefloral'),\n",
       "  Text(0, 0, 'skyblue'),\n",
       "  Text(0, 0, 'orange'),\n",
       "  Text(0, 0, 'purple'),\n",
       "  Text(0, 0, 'neckscarf'),\n",
       "  Text(0, 0, 'layerednecklace'),\n",
       "  Text(0, 0, 'skinnybelt'),\n",
       "  Text(0, 0, 'statementbelt'),\n",
       "  Text(0, 0, 'strawtote'),\n",
       "  Text(0, 0, 'crushbag'),\n",
       "  Text(0, 0, 'distressed'),\n",
       "  Text(0, 0, 'lowrise'),\n",
       "  Text(0, 0, 'legging'),\n",
       "  Text(0, 0, 'trouser'),\n",
       "  Text(0, 0, 'wideleg'),\n",
       "  Text(0, 0, 'asymmetrical'),\n",
       "  Text(0, 0, 'pleated'),\n",
       "  Text(0, 0, 'slit'),\n",
       "  Text(0, 0, 'tulle'),\n",
       "  Text(0, 0, 'wrap'),\n",
       "  Text(0, 0, 'maxi'),\n",
       "  Text(0, 0, 'tank'),\n",
       "  Text(0, 0, 'short'),\n",
       "  Text(0, 0, 'tflength'),\n",
       "  Text(0, 0, 'strapless'),\n",
       "  Text(0, 0, 'turtleneck'),\n",
       "  Text(0, 0, 'fitandflare'),\n",
       "  Text(0, 0, 'ruched'),\n",
       "  Text(0, 0, 'slip'),\n",
       "  Text(0, 0, 'sweater'),\n",
       "  Text(0, 0, 'tea'),\n",
       "  Text(0, 0, 'platformsandals'),\n",
       "  Text(0, 0, 'collarless'),\n",
       "  Text(0, 0, 'onebutton'),\n",
       "  Text(0, 0, 'peacoat'),\n",
       "  Text(0, 0, 'quilted'),\n",
       "  Text(0, 0, 'trench'),\n",
       "  Text(0, 0, 'teddy'),\n",
       "  Text(0, 0, 'denim'),\n",
       "  Text(0, 0, 'ivory'),\n",
       "  Text(0, 0, 'lightblack'),\n",
       "  Text(0, 0, 'clutchbag'),\n",
       "  Text(0, 0, 'olivegreen'),\n",
       "  Text(0, 0, 'oneshoulder'),\n",
       "  Text(0, 0, 'classicsneakers'),\n",
       "  Text(0, 0, 'shearling'),\n",
       "  Text(0, 0, 'tight'),\n",
       "  Text(0, 0, 'blackwhite'),\n",
       "  Text(0, 0, 'backpack'),\n",
       "  Text(0, 0, 'socks'),\n",
       "  Text(0, 0, 'buckethat'),\n",
       "  Text(0, 0, 'bootcut'),\n",
       "  Text(0, 0, 'blackfloral'),\n",
       "  Text(0, 0, 'midcalfboots'),\n",
       "  Text(0, 0, 'pumps'),\n",
       "  Text(0, 0, 'combatboots'),\n",
       "  Text(0, 0, 'chelseaboots'),\n",
       "  Text(0, 0, 'wedges'),\n",
       "  Text(0, 0, 'blockheelsandals'),\n",
       "  Text(0, 0, 'retrorunning'),\n",
       "  Text(0, 0, 'lowtopsneakers'),\n",
       "  Text(0, 0, 'hightopsneakers'),\n",
       "  Text(0, 0, 'slides'),\n",
       "  Text(0, 0, 'slippers'),\n",
       "  Text(0, 0, 'platformsneakers'),\n",
       "  Text(0, 0, 'slingbacksandals'),\n",
       "  Text(0, 0, 'loafers'),\n",
       "  Text(0, 0, 'booties'),\n",
       "  Text(0, 0, 'doublebreasted'),\n",
       "  Text(0, 0, 'robe'),\n",
       "  Text(0, 0, 'lonsleeves'),\n",
       "  Text(0, 0, 'lightpink'),\n",
       "  Text(0, 0, 'boyfriend'),\n",
       "  Text(0, 0, 'darkgrey'),\n",
       "  Text(0, 0, 'midi'),\n",
       "  Text(0, 0, 'crop'),\n",
       "  Text(0, 0, 'totebag'),\n",
       "  Text(0, 0, 'hoops'),\n",
       "  Text(0, 0, 'crossbody'),\n",
       "  Text(0, 0, 'chainnecklace'),\n",
       "  Text(0, 0, 'statementnecklace'),\n",
       "  Text(0, 0, 'teardropearrings'),\n",
       "  Text(0, 0, 'scrunchie'),\n",
       "  Text(0, 0, 'headband'),\n",
       "  Text(0, 0, 'beltbag'),\n",
       "  Text(0, 0, 'bucketbag'),\n",
       "  Text(0, 0, 'minibag'),\n",
       "  Text(0, 0, 'beanie'),\n",
       "  Text(0, 0, 'skinny'),\n",
       "  Text(0, 0, 'knee'),\n",
       "  Text(0, 0, 'crocs'),\n",
       "  Text(0, 0, 'puffer'),\n",
       "  Text(0, 0, 'blouse'),\n",
       "  Text(0, 0, 'smocked'),\n",
       "  Text(0, 0, 'ecru'),\n",
       "  Text(0, 0, 'wide'),\n",
       "  Text(0, 0, 'singlebreasted'),\n",
       "  Text(0, 0, 'cardigan'),\n",
       "  Text(0, 0, 'fedora'),\n",
       "  Text(0, 0, 'moto'),\n",
       "  Text(0, 0, 'mini'),\n",
       "  Text(0, 0, 'tshirt'),\n",
       "  Text(0, 0, 'yellow'),\n",
       "  Text(0, 0, 'kneehighboots'),\n",
       "  Text(0, 0, 'flats'),\n",
       "  Text(0, 0, 'mules'),\n",
       "  Text(0, 0, 'cream'),\n",
       "  Text(0, 0, 'aline'),\n",
       "  Text(0, 0, 'openback'),\n",
       "  Text(0, 0, 'frayed'),\n",
       "  Text(0, 0, 'loose'),\n",
       "  Text(0, 0, 'mock'),\n",
       "  Text(0, 0, 'straight'),\n",
       "  Text(0, 0, 'oversized'),\n",
       "  Text(0, 0, 'nobutton'),\n",
       "  Text(0, 0, 'button'),\n",
       "  Text(0, 0, 'collared'),\n",
       "  Text(0, 0, 'green'),\n",
       "  Text(0, 0, 'golden'),\n",
       "  Text(0, 0, 'silver'),\n",
       "  Text(0, 0, 'red'),\n",
       "  Text(0, 0, 'square'),\n",
       "  Text(0, 0, 'midrise'),\n",
       "  Text(0, 0, 'navyblue'),\n",
       "  Text(0, 0, 'long'),\n",
       "  Text(0, 0, 'vneck'),\n",
       "  Text(0, 0, 'shortsleeves'),\n",
       "  Text(0, 0, 'grey'),\n",
       "  Text(0, 0, 'pink'),\n",
       "  Text(0, 0, 'beige'),\n",
       "  Text(0, 0, 'lightdenim'),\n",
       "  Text(0, 0, 'jacket'),\n",
       "  Text(0, 0, 'lightblue'),\n",
       "  Text(0, 0, 'multicolor'),\n",
       "  Text(0, 0, 'coat'),\n",
       "  Text(0, 0, 'darkdenim'),\n",
       "  Text(0, 0, 'mediumdenim'),\n",
       "  Text(0, 0, 'puff'),\n",
       "  Text(0, 0, 'blazer'),\n",
       "  Text(0, 0, 'highrise'),\n",
       "  Text(0, 0, 'brown'),\n",
       "  Text(0, 0, 'pant'),\n",
       "  Text(0, 0, 'crewneck'),\n",
       "  Text(0, 0, 'ankle'),\n",
       "  Text(0, 0, 'sleeveless'),\n",
       "  Text(0, 0, 'blue'),\n",
       "  Text(0, 0, 'regular'),\n",
       "  Text(0, 0, 'white'),\n",
       "  Text(0, 0, 'skirts'),\n",
       "  Text(0, 0, 'high'),\n",
       "  Text(0, 0, 'jeans'),\n",
       "  Text(0, 0, 'black'),\n",
       "  Text(0, 0, 'longsleeves')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWhUlEQVR4nO3df7Ad5X3f8fcXYYPNjzEUQWWJWmSqSSwyBVMNjUOcusEJatNUJDUddVyP4uLSpsQTM824Ip1xRFIlZJp67DbGLXVaa2K7ikLqQYGOx1guddMm4KsYAxLICATiRkK6yPwGCf349o999rmrq3N1z733HF0kvV8zZ3b3Oc/uPrtnz37O/ro3MhNJkgDOmOsGSJLeOgwFSVJlKEiSKkNBklQZCpKk6sy5bgDARRddlIsXL57rZkjSSWXz5s3PZ+b8QU7zLREKixcvZmRkZK6bIUknlYh4ZtDT9PSRJKkyFCRJlaEgSaoMBUlSZShIkipDQZJUGQqSpMpQkCRVhoIkqTIUJGmOLF5971w34RiGgiSpMhQkSZWhIEmqDAVJUtVXKETEuyLiroh4PCIei4j3R8SFEXFfRDxRuhd06t8aEdsjYltEXDe85kuSBqnfI4XPAV/PzB8BrgAeA1YDmzJzCbCpDBMRS4GVwOXAcuCOiJg36IZLkgZvylCIiPOBnwR+HyAz38zMF4EVwLpSbR1wfelfAazPzAOZuQPYDlw96IZLkgavnyOFHwLGgP8WEd+NiC9GxDnAJZm5G6B0Ly71FwLPdsYfLWVHiYibImIkIkbGxsZmtRCSpMHoJxTOBK4CvpCZ7wNeo5wqmkT0KMtjCjLvzMxlmbls/vyB/otRSdIM9RMKo8BoZj5Qhu+iCYk9EbEAoHT3dupf2hl/EbBrMM2VJA3TlKGQmc8Bz0bED5eia4GtwEZgVSlbBdxd+jcCKyPirIi4DFgCPDjQVkuShuLMPut9AvhKRLwdeAr4GE2gbIiIG4GdwA0AmbklIjbQBMch4ObMPDzwlkuSBq6vUMjMh4BlPd66dpL6a4G1s2iXJGkO+ESzJKkyFCRJlaEgSaoMBUlSZShIkipDQZJUGQqSpMpQkCRVhoIkqTIUJEmVoSBJqgwFSVJlKEiSKkNBklQZCpKkylCQJFWGgiSpMhQkSZWhIEmqDAVJUmUoSJIqQ0GSVBkKkqTKUJAkVX2FQkQ8HRGPRMRDETFSyi6MiPsi4onSvaBT/9aI2B4R2yLiumE1XpI0WNM5Uvg7mXllZi4rw6uBTZm5BNhUhomIpcBK4HJgOXBHRMwbYJslSUMym9NHK4B1pX8dcH2nfH1mHsjMHcB24OpZzEeSdIL0GwoJfCMiNkfETaXskszcDVC6F5fyhcCznXFHS9lRIuKmiBiJiJGxsbGZtV6SNFBn9lnvmszcFREXA/dFxOPHqRs9yvKYgsw7gTsBli1bdsz7kqQTr68jhczcVbp7ga/RnA7aExELAEp3b6k+ClzaGX0RsGtQDZYkDc+UoRAR50TEeW0/8DPAo8BGYFWptgq4u/RvBFZGxFkRcRmwBHhw0A2XJA1eP6ePLgG+FhFt/a9m5tcj4jvAhoi4EdgJ3ACQmVsiYgOwFTgE3JyZh4fSeknSQE0ZCpn5FHBFj/J9wLWTjLMWWDvr1kmSTiifaJYkVYaCJKkyFCRJlaEgSaoMBUlSZShIkipDQZJUGQqSpMpQkCRVhoIkqTIUJEmVoSBJqgwFSVJlKEiSKkNBklQZCpKkylCQJFWGgiSpMhQkSZWhIEmqDAVJUmUoSJIqQ0GSVBkKkqSq71CIiHkR8d2IuKcMXxgR90XEE6V7QafurRGxPSK2RcR1w2i4JGnwpnOk8CvAY53h1cCmzFwCbCrDRMRSYCVwObAcuCMi5g2muZKkYeorFCJiEfCzwBc7xSuAdaV/HXB9p3x9Zh7IzB3AduDqwTRXkjRM/R4pfBb4FHCkU3ZJZu4GKN2LS/lC4NlOvdFSdpSIuCkiRiJiZGxsbNoNlyQN3pShEBF/H9ibmZv7nGb0KMtjCjLvzMxlmbls/vz5fU5akjRMZ/ZR5xrgH0TE3wPOBs6PiC8DeyJiQWbujogFwN5SfxS4tDP+ImDXIBstSRqOKY8UMvPWzFyUmYtpLiB/KzP/CbARWFWqrQLuLv0bgZURcVZEXAYsAR4ceMslSQPXz5HCZG4HNkTEjcBO4AaAzNwSERuArcAh4ObMPDzrlkqShm5aoZCZ9wP3l/59wLWT1FsLrJ1l2yRJJ5hPNEuSKkNBklQZCpKkylCQJFWGgiSpMhQkSZWhIEmqDAVJUmUoSJIqQ0GSVBkKkqTKUJAkVYaCJKkyFCRJlaEgSaoMBUlSZShIkipDQZJUGQqSpMpQkCRVhoIkqTIUJGkOLF5971w3oSdDQZJUGQqSpGrKUIiIsyPiwYj4XkRsiYjbSvmFEXFfRDxRuhd0xrk1IrZHxLaIuG6YCyBJGpx+jhQOAD+VmVcAVwLLI+LHgNXApsxcAmwqw0TEUmAlcDmwHLgjIuYNo/GSpMGaMhSy8WoZfFt5JbACWFfK1wHXl/4VwPrMPJCZO4DtwNUDbbUkaSj6uqYQEfMi4iFgL3BfZj4AXJKZuwFK9+JSfSHwbGf00VI2cZo3RcRIRIyMjY3NZhkkSQPSVyhk5uHMvBJYBFwdET96nOrRaxI9pnlnZi7LzGXz58/vr7WSpKGa1t1HmfkicD/NtYI9EbEAoHT3lmqjwKWd0RYBu2bdUknS0PVz99H8iHhX6X8H8CHgcWAjsKpUWwXcXfo3Aisj4qyIuAxYAjw46IZLkgbvzD7qLADWlTuIzgA2ZOY9EfFnwIaIuBHYCdwAkJlbImIDsBU4BNycmYeH03xJ0iBNGQqZ+TDwvh7l+4BrJxlnLbB21q2TJJ1QPtEsSaoMBUlSZShIkipDQZJUGQqSpMpQkCRVhoIkqTIUJEmVoSBJqgwFSVJlKEiSKkNBklQZCpKkylCQJFWGgiSpMhQkSZWhIEmqDAVJUmUoSJIqQ0GSVBkKkqTKUJCkE2zx6nvnugmTMhQkSZWhIEmqpgyFiLg0Iv5XRDwWEVsi4ldK+YURcV9EPFG6F3TGuTUitkfEtoi4bpgLIEkanH6OFA4B/yoz3wv8GHBzRCwFVgObMnMJsKkMU95bCVwOLAfuiIh5w2i8JJ1M3srXElpThkJm7s7Mvyj9rwCPAQuBFcC6Um0dcH3pXwGsz8wDmbkD2A5cPeiGS5IGb1rXFCJiMfA+4AHgkszcDU1wABeXaguBZzujjZayidO6KSJGImJkbGxs+i2XJA1c36EQEecCfwx8MjNfPl7VHmV5TEHmnZm5LDOXzZ8/v99mSJKGqK9QiIi30QTCVzLzf5TiPRGxoLy/ANhbykeBSzujLwJ2Daa5kqRh6ufuowB+H3gsMz/TeWsjsKr0rwLu7pSvjIizIuIyYAnw4OCaLEkaljP7qHMN8FHgkYh4qJT9GnA7sCEibgR2AjcAZOaWiNgAbKW5c+nmzDw88JZLkgZuylDIzD+l93UCgGsnGWctsHYW7ZIkzQGfaJYkVYaCJKkyFCRJlaEgSUN2Mvx5i5ahIEmqDAVJUmUoSJIqQ0GSVBkKkjQkJ9MF5pahIEmqDAVJUmUoSJIqQ0GSVBkKkqTKUJAkVYaCJKkyFCRJlaEgSaoMBUkagpPxaWYwFCRJHYaCJKkyFCRJlaEgSarOnOsGSNKp5GS9wNya8kghIv5rROyNiEc7ZRdGxH0R8UTpXtB579aI2B4R2yLiumE1XJI0eP2cPvoSsHxC2WpgU2YuATaVYSJiKbASuLyMc0dEzBtYayVJQzVlKGTmt4EfTCheAawr/euA6zvl6zPzQGbuALYDVw+orZKkIZvpNYVLMnM3QGbujoiLS/lC4M879UZLmSSd0k72awmtQd99FD3KsmfFiJsiYiQiRsbGxgbcDEnSTMw0FPZExAKA0t1bykeBSzv1FgG7ek0gM+/MzGWZuWz+/PkzbIYkzb1T5SgBZn76aCOwCri9dO/ulH81Ij4DvBtYAjw420ZK0lvRqRQGrSlDISL+O/BB4KKIGAV+nSYMNkTEjcBO4AaAzNwSERuArcAh4ObMPDyktkvSnDkVAwH6CIXM/MeTvHXtJPXXAmtn0yhJ0tzwz1xIkipDQZJUGQqSpMpQkKRpOFUvMLcMBUlSZShIUh9O9SOElqEgSaoMBUlSZShIkipDQZKO43S5ltDyfzRLUg+nWxi0PFKQpAlO10AAQ0GS1GEoSFLH6XyUAF5TkCTAMGgZCpJOa4bB0Tx9JOm0ZSAcy1CQdNoxDCZnKEg6LSxefa9h0AevKUg6pRkE02MoSBqoxavv5enbf3bKnXFbZ2K3H7MZV8dnKEiniRO1k9bJzWsK0inOX9CaDkNBOkUZBpoJQ0GSVA3tmkJELAc+B8wDvpiZtw9rXtLp6HhHAp7b10wNJRQiYh7weeCngVHgOxGxMTO3DmN+0qmiu6P3DhvNhWEdKVwNbM/MpwAiYj2wAhhKKJzI29lmMu5c3Xo31/N7K66bk+mzkOZCZObgJxrxYWB5Zn68DH8U+FuZ+cudOjcBN5XBHwa2zWKWlwGvlP7zSn+/3ZmMM5txT/X5nUxtPdXndzK19XReNwDPMzPvycz5Mxy3p2FdaI4eZUelT2bemZnLyuu8Tv+0X8DZNCv1+U5/v92ZjOP8To22nurzO5naejqvm+dnsf8baCDA8EJhFLi0M7wI2DWkeUmSBmRYofAdYElEXBYRbwdWAhuHNC9J0oDMW7NmzcAnumbNmiO33XbbE8BXgE8AX87MPx74jIrbbrvtvcDXgM3A66W/3+5MxpnNuKf6/E6mtp7q8zuZ2no6r5vNa9as2cxbxFAuNEuSTk4+0SxJqgwFSdK4zJz2C3h1mvV/AtgPLAYeLWXrgReBpcAamltWEzhcXs8Bh4AjwG3Al4Angb00F7Lb+ps74x0p/UeAF4DPAgc703yD5nmIZ4F/D4wBj9Kc29vdmWb72t+ZXrd84vDE1xtlftnpJvBmp529pjHVdLuvQz26Rzrz73c63Ve7nnq9d2RCve57r/Zo13SW50hZ15PNO4Gne7T1UPl8u/M90ln+w+X9I8BLpc7rPdo8ndd0lqnfaR7stDOBX+q892gf03+TY7epbv/+UmfiNEZK98Bx2tuu372dddrrc+q1Te8r832lU9b9nF7vlP9FZ/rdz7e7DG3/C4x/j/aVNh6aMP5k37Huumn3Da+V8Q906rT7hjdptp3uuG8CDzG+Hb1Wxn2ps54P0Dywm8C3OsvQLnfbzt3Adpp94WbgAWBpZ9/5i8DvdYbXAL8B3DWTfXc/rxN9pDCv078aGC1/+uKjnfLXgMeBb5fh7jMPv9tjmj8o3UOdukFzD3Cr3RgPAd8D/gT4j51xAd7WY9ov9mhDO683J5Rlp/9sxm/BPdIpf5Xxo7P9PcY7NGGahzv9+yaZXztOdOq/1GP8yXTbN7F+t23dddAuQzvuwxPqTVyOiXLC8AGadf36cdq3qEf5q8CfTijr7nig2ebasjNotq/k6O1jOm1t18ORiRVnYV6ZXrv+3z5JvYOdNnXn3277Bztl3c/r7Yzv1Lou6kyv17NF0Pw4g+ZBq3a6vfYbvcbfQrO+u9rPA2DPcaazhaN34K9z9Gf6Wqn7vdKe9kdRa+I66pa36+mNUme0dLvb7V/SrJ/DHL287bpaUobPoNn+2+/zSxzrvDLey2U+byvL0wbI2TSf0V8H/igzt0bEMX9tIiKizPvVzPxwj/kMxIwuNEfEq8C/BD4FvIdm4cZovtwBnA/8l8xcGxF3AT/H5Bu6JGl63gR+mebH9UKacDkD+AZwBTCf5ofk36DZL2+g+WE1D/jNzPzDySY80yOFM4B/A1xbGrQEeAb4q6VBXwJu6dRvA+FA6U6W4pKkY4/q2qPIrwH30Bxt/BzN0fI84Crg48B1wG8B59AExxpgObArM6/IzB8Fvn68Gc80FOYBd9Gcfvkt4H6agDgfuARYC7wrIt5dytrD+fbQsE01SdKxJp6Oa0+9f4AmAILmSGEPzf70p4FraParn6C5RnMO8F7gEeBDEfE7EfGBzOx1iquazY45gY/QHKb8TZpzwnsYP1d7APgwzZ+7aC9WPc74BSBJOt31On9/uFPe7i8Pdeq3+9iP0+xnHwbeQbM/fgX425l5JfCvgW2Z+X2affQjwG9HxKeP16CZhsJh4B8BC2juSjiP5q6e95T3PwL8Gc2ft1hYGnwGzTmtMzj6YpMkna56XaA/g6NvmjnI+E0xO2j+iB7ArwI/Djycmb9DEw7n0hwhALwLeEc5Y/N6Zn6Z5madq47boFlcaL6Z5iLHX6O5iv9NmnNcO2nuvPkYcC/N6aSkuZLfXj2XJM3MyzQ/xJ+hORPzMs1t9luBn6E5Y3OY5sf4/6P5c0P/juaI4yDwS5k5MunUh3Wva+e+2sWUZxM6ZeeW7lU0gfLjNOfAfoLmFrNHGb93918A/xn4tzS3jj1Nc+H668DBzr2736A5PfUssK8zr4/Q3L72KZqjmjdokvQRmtvOrqE5BHuTo+/1/2RZuf+U8XuTD5Q67T3Mz5c6+8pyvljq/gC4g+Z+4hfLh/UhmucsjjB+X/QPShvuL9P+WKl7Ls0FpPZ5i8dK9/+UeR8CvlWWbxHwFM1F/o/T3Or2JM3/mHi9LO9y4Ps0v0DeWdbjS8AHgfeX956nuTngneW9l8t83sn4PeF/pXxm7Xo6AvwacCXNxvYnZX1sA+4EvsD4rXe3lPXU3q/9XZofEIeB3Z3P63zgbsafG9lXlns/49vND5Xh/eXzebnU30fzg6S9ffFF4D8wfvry+tK+IzTbye6yrnYxfoj+LM0/iRopbdsFfLq8/1Ol/uLyue1k/KaJf0az/R4CnqDZTr8M/Gb57MaAZTTneJ+jOcwfo9lunyrra1/53B+n2UY+U8peKJ/ZB4A/KMvzv2m+MzuAf9hpyw6af4N7LvDu0pb/SfO9SuDXgXU029n7y7pdTfMHK/fTPBP022U5PlvW9z3AtaX//5bl+IWy3H9Q1tWnSzt/stT7ZHn/HJrt7PvAfyplVzL+Pf494J+X4YvKZ/JImcbKMu+lZX3sB/4c+PnS5s/RbOcJ/OoU+6FLyjppt9+Hy/ofpfnuHab5DnyTZvu5jWa7XVKW7wtl/p8u7dlKsx3so7kt+pYy7WfKfF6j2d+MAFdNsv8Lmv3ELcPeD09rnz1HofBVmoc/Xikb+OPl1T6wspfmi94+cHaodHcAf5fmQvYR4J7jhULZcLoPyLQ7g51M/XBR+1xDt6x9cOdAebUPHD3J+IMv7Q7/K8CPML5znzi/12iC70BZ3hfKMkyc345OO7r3bD9Q1uHTZWN9g/H7/W8o673dIT9Xyj5U3n+x1G/bv58meJ4sZSOMPwD2OL0ffDpYpvuXnbrtcj5V2rWzx3jt/fjt8H7gdzvbxp4J9dvbnZ+g2W6eYfyho3YddcN8slf3M2jD9mCnvH3vJZovertMr5R5Hirj7OLY7aJtZ7c9e0u3fWDpOZofIu32fIAmCNoHz9rxbqXZgXbb/AzNdvT8hOXez/j21bbjmzTX+T7P+A+dw4xv879IEwovMv5Dp7vttA/SvUBzJ8v3ae6dbz+fdufcbcdBmm3t8+X9dnrbyjgfpPkB1H6vHqb5Hm+meR5paanfPiz2ZKnzbZrt/PnOuC+UevfS/KBrl+ujU+yHNk/yuXW/a88x/kDaS4z/WGw/h+/Q/Ej6jbLMbZisp/mhMvEhwKeAW3u05Raa7+5Wmv3EO+c6CLov/yCeJKnytlBJUmUoSJIqQ0GSVBkKkqTKUJAkVf8f6ZnxWRruXZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For plotting the histogram of the dataset attributes\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "h = {k: v for k, v in sorted(h.items(), key=lambda item: item[1])}\n",
    "\n",
    "#h = sorted(h, key=h.get)\n",
    "#print(sortlist)\n",
    "\n",
    "ticks = range(len(h))\n",
    "plt.bar(ticks, h.values(), align='center')\n",
    "plt.xticks(ticks, h.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_array_result = '\\n'.join([str(x) for x in cat_array_result])\n",
    "attr_array_result = '\\n'.join([str(x) for x in attr_array_result])\n",
    "\n",
    "f = open(\"cat_array_result.txt\", \"w\")\n",
    "f.write(cat_array_result)\n",
    "f.close()\n",
    "\n",
    "f = open(\"attr_array_result.txt\", \"w\")\n",
    "f.write(attr_array_result)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "\n",
    "train_cate_path = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_cate.txt\"\n",
    "train_attr_path = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_attr.txt\"\n",
    "\n",
    "\n",
    "img_list = open(img_list_path).read()\n",
    "img_list = img_list.split(\"\\n\")[:-1]\n",
    "\n",
    "print(len(img_list))\n",
    "basepath = \"\"\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    #print(img_list[i])\n",
    "    img_path = basepath+\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/\"+img_list[i]\n",
    "    \n",
    "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    #print(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    image /= 255.0\n",
    "    \n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6197 img/Wifey_Graphic_Muscle_Tee/img_00000018.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "img_list_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "\n",
    "img_list = open(img_list_path).read()\n",
    "img_list = img_list.split(\"\\n\")[:-1]\n",
    "\n",
    "#print(img_list)\n",
    "index = random.randint(0, 10000)\n",
    "print(index, img_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
