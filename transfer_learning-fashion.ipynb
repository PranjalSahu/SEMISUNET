{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] All the Imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import csv\n",
    "from scipy import ndimage, misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     2,
     9,
     29,
     53
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Attribute and Category Model\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "class MyAttrCateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model    = models.resnet18(pretrained=True)\n",
    "        self.model.fc = Identity()\n",
    "        \n",
    "        #self.attr_layer = nn.Sequential(nn.Linear(512, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 26, bias=False)\n",
    "        #                               )\n",
    "        \n",
    "        #self.cate_layer = nn.Sequential(nn.Linear(512, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 50, bias=False))\n",
    "        self.attr_layer = nn.Linear(512, 26)\n",
    "        self.cate_layer = nn.Linear(512, 50)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1     = self.model(x)\n",
    "        attr_out = self.attr_layer(out1)\n",
    "        cate_out = self.cate_layer(out1)\n",
    "        #cate_out = torch.flatten(cate_out)\n",
    "        return attr_out, cate_out\n",
    "\n",
    "class MyAttrCateModel50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model    = models.resnet50(pretrained=True)\n",
    "        self.model.fc = Identity()\n",
    "        \n",
    "        #self.attr_layer = nn.Sequential(nn.Linear(2048, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 26, bias=False))\n",
    "        #self.cate_layer = nn.Sequential(nn.Linear(2048, 128, bias=False), \n",
    "        #                                nn.ReLU(inplace=True),\n",
    "        #                                nn.Linear(128, 50, bias=False))\n",
    "        self.attr_layer = nn.Linear(2048, 26)\n",
    "        self.cate_layer = nn.Linear(2048, 50)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1     = self.model(x)\n",
    "        attr_out = self.attr_layer(out1)\n",
    "        cate_out = self.cate_layer(out1)\n",
    "        #cate_out = torch.flatten(cate_out)\n",
    "        return attr_out, cate_out\n",
    "#model  = MyAttrCateModel()\n",
    "# x      = torch.randn(1, 3, 224, 224)\n",
    "# output = model(x)\n",
    "# print(output[0].shape, output[1].shape)\n",
    "\n",
    "#print(model)\n",
    "#model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEMP Code to Read the BP images\n",
    "\n",
    "# images = glob.glob('/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/**/*.png', recursive=True)\n",
    "# #print(images)\n",
    "# filtered_images  = []\n",
    "# counter          = 0\n",
    "\n",
    "# for m in images:\n",
    "#     #if 'Top' in m or 'Bottom' in m :\n",
    "#         #continue\n",
    "#     filtered_images.append(m[64:])\n",
    "# valid_dataset = \"\\n\".join(filtered_images)\n",
    "\n",
    "# f = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/newval.txt\", \"w\")\n",
    "# f.write(valid_dataset)\n",
    "# f.close()\n",
    "\n",
    "# #print(filtered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] Data Loaders for Fashion Dataset\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class AttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r')\n",
    "        self.img_list = [x.strip() for x in fp]\n",
    "\n",
    "        # read attribute labels and category annotations\n",
    "        self.labels = np.loadtxt(label_file, dtype=np.float32)\n",
    "\n",
    "        # read categories\n",
    "        self.categories = []\n",
    "        catefn = open(cate_file).readlines()\n",
    "        for i, line in enumerate(catefn):\n",
    "            self.categories.append(line.strip('\\n'))\n",
    "\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        print(os.path.join(self.img_path, self.img_list[idx]))\n",
    "        img = Image.open(os.path.join(self.img_path,\n",
    "                                      self.img_list[idx])).convert('RGB')\n",
    "\n",
    "        width, height  = img.size\n",
    "        print('Original Image size is ', width, height)\n",
    "        # Very Important\n",
    "        # For getting the cropped and resized region of interest image\n",
    "        img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "        img   = self.transform(img)\n",
    "\n",
    "        label    = torch.from_numpy(self.labels[idx])\n",
    "        cate     = torch.LongTensor([int(self.categories[idx]) - 1])\n",
    "\n",
    "        data = {'img': img, 'attr': label, 'cate': cate}\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "\n",
    "class ValidAttrDataset(Dataset):\n",
    "    CLASSES = None\n",
    "    \n",
    "    def __init__(self,\n",
    "                 img_path,\n",
    "                 img_file,\n",
    "                 label_file,\n",
    "                 cate_file,\n",
    "                 bbox_file,\n",
    "                 landmark_file,\n",
    "                 img_size,\n",
    "                 idx2id=None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "        # read img names\n",
    "        fp = open(img_file, 'r').read().split('\\n')\n",
    "        self.img_list = fp#[x.strip() for x in fp]\n",
    "        \n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def get_basic_item(self, idx):\n",
    "        print(os.path.join(self.img_path, self.img_list[idx]))\n",
    "        img = Image.open(os.path.join(self.img_path,\n",
    "                                      self.img_list[idx])).convert('RGB')\n",
    "        \n",
    "        width, height  = img.size\n",
    "        img.resize((width//2, height//2))\n",
    "        width, height  = img.size\n",
    "        \n",
    "        print('Original Image size is ', width, height)\n",
    "        # Very Important\n",
    "        # For getting the cropped and resized region of interest image\n",
    "        img.thumbnail(self.img_size, Image.ANTIALIAS)\n",
    "        img   = self.transform(img)\n",
    "\n",
    "        #label    = torch.from_numpy(self.labels[idx])\n",
    "        #cate     = torch.LongTensor([int(self.categories[idx]) - 1])\n",
    "\n",
    "        data = {'img': img}#, 'attr': label, 'cate': cate}\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_basic_item(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "img_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/\"\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "label_file = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_attr.txt\"\n",
    "cate_file  = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_cate.txt\"\n",
    "img_size   = [224, 224]\n",
    "#img_size   = [256, 256]\n",
    "\n",
    "landmark_file = None\n",
    "bbox_file     = None\n",
    "\n",
    "d1 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val.txt\"\n",
    "label_file = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val_attr.txt\"\n",
    "cate_file  = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/val_cate.txt\"\n",
    "\n",
    "d2 = AttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "img_path   = \"/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/\"\n",
    "img_file   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/newval.txt\"\n",
    "\n",
    "d3 = ValidAttrDataset(img_path, img_file, label_file, cate_file, bbox_file, landmark_file, img_size, idx2id=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_dataloader(dataset, batch_size, shuffle):\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=False)\n",
    "    return data_loader\n",
    "\n",
    "train_data_loader = build_dataloader(d1, 4, True)\n",
    "val_data_loader   = build_dataloader(d2, 4, False)\n",
    "\n",
    "model  = MyAttrCateModel50()\n",
    "#model  = MyAttrCateModel()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "params       = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer    = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0001)\n",
    "lr_scheduler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anorak' 'Blazer' 'Blouse' 'Bomber' 'Button-Down' 'Cardigan' 'Flannel'\n",
      " 'Halter' 'Henley' 'Hoodie' 'Jacket' 'Jersey' 'Parka' 'Peacoat' 'Poncho'\n",
      " 'Sweater' 'Tank' 'Tee' 'Top' 'Turtleneck' 'Capris' 'Chinos' 'Culottes'\n",
      " 'Cutoffs' 'Gauchos' 'Jeans' 'Jeggings' 'Jodhpurs' 'Joggers' 'Leggings'\n",
      " 'Sarong' 'Shorts' 'Skirt' 'Sweatpants' 'Sweatshorts' 'Trunks' 'Caftan'\n",
      " 'Cape' 'Coat' 'Coverup' 'Dress' 'Jumpsuit' 'Kaftan' 'Kimono' 'Nightdress'\n",
      " 'Onesie' 'Robe' 'Romper' 'Shirtdress' 'Sundress']\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For loading the labels and categories etc.\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "print(cate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 1 - 10 Styles/Style 6/Style 6.png\n",
      "Original Image size is  359 553\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, len(d3))\n",
    "temp  = d3[index]\n",
    "#print(temp['cate'])\n",
    "\n",
    "#attr_index = np.nonzero(temp['attr'].data.numpy())[0]#temp['attr'].data.numpy().astype('int')\n",
    "#cate_index = temp['cate'].data.numpy()\n",
    "#print(attr_index)\n",
    "#print(cate_index)\n",
    "#.astype('int')\n",
    "\n",
    "temp = temp['img'].data.numpy()\n",
    "#print(temp.shape)\n",
    "temp = np.moveaxis(temp, 0, -1)\n",
    "#print(temp.shape)\n",
    "\n",
    "plt.imshow(temp)\n",
    "#print(attr_index)\n",
    "#print(cate_index)\n",
    "\n",
    "#print(cate_list[cate_index])\n",
    "#print(attr_list[attr_index])\n",
    "\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     16
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model  1000 2.4690650403499603\n",
      "Epoch >>  0 2.4690650403499603 0.32421635499596596 2.1448486886024476\n",
      "Saving the model  2.4690650403499603 2.373939606845379\n",
      "Epoch >>  1 2.373939606845379 0.31374691185355186 2.0601926976144314\n",
      "Saving the model  2.373939606845379 2.3202684246699015\n",
      "Epoch >>  2 2.3202684246699015 0.30673006669680275 2.0135383597215015\n",
      "Saving the model  2.3202684246699015 2.2755222101211547\n",
      "Epoch >>  3 2.2755222101211547 0.30178153750672937 1.973740673787892\n",
      "Saving the model  2.2755222101211547 2.2398026696681974\n",
      "Epoch >>  4 2.2398026696681974 0.29681208066642284 1.9429905903697013\n",
      "Saving the model  2.2398026696681974 2.2018027129968005\n",
      "Epoch >>  5 2.2018027129968005 0.29308239939560493 1.9087203140258788\n",
      "Saving the model  2.2018027129968005 2.1711222874947955\n",
      "Epoch >>  6 2.1711222874947955 0.28941710267961024 1.8817051849365234\n",
      "Saving the model  2.1711222874947955 2.153285289078951\n",
      "Epoch >>  7 2.153285289078951 0.2868471268117428 1.8664381622076034\n",
      "Saving the model  2.153285289078951 2.135865389426549\n",
      "Epoch >>  8 2.135865389426549 0.2842484169221587 1.851616972251071\n",
      "Saving the model  2.135865389426549 2.1149369722485543\n",
      "Epoch >>  9 2.1149369722485543 0.28134267535656693 1.8335942965477705\n",
      "Saving the model  2.1149369722485543 2.101907019880685\n",
      "Epoch >>  10 2.101907019880685 0.27947684413194657 1.8224301753179593\n",
      "Saving the model  2.101907019880685 2.090149658605456\n",
      "Epoch >>  11 2.090149658605456 0.277443344703565 1.8127063132822514\n",
      "Saving the model  2.090149658605456 2.0732043799024362\n",
      "Epoch >>  12 2.0732043799024362 0.27551290557017694 1.7976914735619838\n",
      "Saving the model  2.0732043799024362 2.0549905264760766\n",
      "Epoch >>  13 2.0549905264760766 0.2733542219134314 1.7816363036738976\n",
      "Saving the model  2.0549905264760766 2.0444173907121024\n",
      "Epoch >>  14 2.0444173907121024 0.2717562915146351 1.7726610983202855\n",
      "Saving the model  2.0444173907121024 2.0353985581882297\n",
      "Epoch >>  15 2.0353985581882297 0.2702349261185154 1.7651636309912428\n",
      "Saving the model  2.0353985581882297 2.025412896086188\n",
      "Epoch >>  16 2.025412896086188 0.2690408923398046 1.7563720026656109\n",
      "Saving the model  2.025412896086188 2.0146809496978917\n",
      "Epoch >>  17 2.0146809496978917 0.26770484342343276 1.7469761052239272\n",
      "Saving the model  2.0146809496978917 2.0062699213843596\n",
      "Epoch >>  18 2.0062699213843596 0.26678396702048024 1.7394859533945197\n",
      "Saving the model  2.0062699213843596 1.9971171260893346\n",
      "Epoch >>  19 1.9971171260893346 0.2658590360552073 1.731258089067042\n",
      "Saving the model  1.9971171260893346 1.9872653544346492\n",
      "Epoch >>  20 1.9872653544346492 0.2645203344843217 1.7227450189959435\n",
      "Saving the model  1.9872653544346492 1.9801208103732628\n",
      "Epoch >>  21 1.9801208103732628 0.2635547732534734 1.7165660361363129\n"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION Training Loop\n",
    "\n",
    "loss_hist1  = Averager()\n",
    "loss_hist2  = Averager()\n",
    "loss_hist3  = Averager()\n",
    "\n",
    "\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 4\n",
    "counter    = 0\n",
    "model.train()\n",
    "prev_min = 1000\n",
    "\n",
    "for epoch in range(100):\n",
    "    for t1 in train_data_loader:\n",
    "        new_images  = torch.Tensor(t1['img']).to(device)\n",
    "        attr_target = t1['attr'].to(device)\n",
    "        cate_target = t1['cate'].to(device)\n",
    "\n",
    "        out1, out2  = model(new_images)\n",
    "        cate_target = torch.reshape(cate_target, [batch_size])\n",
    "        #print(out1.shape, out2.shape, cate_target.shape, attr_target.shape)\n",
    "\n",
    "        loss1      = 5*bce_loss(out1, attr_target)\n",
    "        loss2      = ce_loss(out2,  cate_target)\n",
    "\n",
    "        losses     = loss1 + loss2 #sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        counter =  counter+1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for t1 in val_data_loader:\n",
    "            new_images  = torch.Tensor(t1['img']).to(device)\n",
    "            attr_target = t1['attr'].to(device)\n",
    "            cate_target = t1['cate'].to(device)\n",
    "\n",
    "            out1, out2  = model(new_images)\n",
    "            cate_target = torch.reshape(cate_target, [batch_size])\n",
    "            #print(out1.shape, out2.shape, cate_target.shape, attr_target.shape)\n",
    "\n",
    "            loss1      = bce_loss(out1, attr_target)\n",
    "            loss2      = ce_loss(out2,  cate_target)\n",
    "\n",
    "            losses     = loss1 + loss2\n",
    "\n",
    "            loss_hist1.send(loss1.data.item())\n",
    "            loss_hist2.send(loss2.data.item())\n",
    "            loss_hist3.send(losses.data.item())\n",
    "    \n",
    "    if loss_hist3.value < prev_min:\n",
    "        print('Saving the model ', prev_min, loss_hist3.value)\n",
    "        torch.save(model.state_dict(), 'fashion_cate_attr_resnet50_single_linear_equalweight.pth')\n",
    "        prev_min = loss_hist3.value\n",
    "    \n",
    "    print('Epoch >> ', epoch, loss_hist3.value, loss_hist1.value, loss_hist2.value)\n",
    "\n",
    "#a = next(dloader)\n",
    "#print(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/img/Embroidered_Woven_Dress/img_00000015.jpg\n",
      "Original Image size is  200 300\n",
      "40 [40]\n",
      "Predicted:     Dress [['solid' 'long_sleeve' 'mini_length' 'crew_neckline' 'cotton' 'loose']]\n",
      "Ground Truth:  ['Dress'] ['solid' 'long_sleeve' 'mini_length' 'no_neckline' 'cotton' 'loose']\n"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION Testing on a single image\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "model.load_state_dict(torch.load('fashion_cate_attr_resnet50_single_linear.pth'))\n",
    "model.eval()\n",
    "\n",
    "index = random.randint(0, len(d2))\n",
    "t1    = d2[index]\n",
    "\n",
    "new_images  = torch.Tensor(np.expand_dims(t1['img'], 0)).to(device)\n",
    "attr_target = t1['attr'].to(device)\n",
    "cate_target = t1['cate'].to(device)\n",
    "        \n",
    "out1, out2  = model(new_images)\n",
    "        \n",
    "out1 = torch.sigmoid(out1)\n",
    "out2 = torch.softmax(out2, axis=1)\n",
    "\n",
    "out1 = out1.data.cpu().numpy().flatten()\n",
    "out2 = out2.data.cpu().numpy().flatten()\n",
    "\n",
    "out1[out1 < 0.5] = 0\n",
    "out1 = np.array(out1.flatten())\n",
    "\n",
    "attr_index         = np.array(np.nonzero(out1))\n",
    "attr_ground_index  = np.array(np.nonzero(t1['attr']).flatten())\n",
    "\n",
    "cate_index         = np.argmax(out2)\n",
    "cate_ground_index  = t1['cate'].data.cpu().numpy()#[0][0]\n",
    "\n",
    "print(cate_index, cate_ground_index)\n",
    "print(\"Predicted:    \", cate_list[cate_index], attr_list[attr_index])\n",
    "print(\"Ground Truth: \", cate_list[cate_ground_index], attr_list[attr_ground_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 28/Style 28.png\n",
      "Original Image size is  370 629\n",
      "0 Predicted:     Jumpsuit ['striped' 'sleeveless' 'maxi_length' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 28/Representative Images/Tops - Dress Option 2.png\n",
      "Original Image size is  297 468\n",
      "1 Predicted:     Dress ['striped' 'sleeveless' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 28/Representative Images/Footwear - Heels.png\n",
      "Original Image size is  714 600\n",
      "2 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 28/Representative Images/Tops - Dress Option 1.png\n",
      "Original Image size is  446 614\n",
      "3 Predicted:     Shorts ['striped' 'sleeveless' 'no_dress' 'v_neckline' 'no_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 22/Style 22.png\n",
      "Original Image size is  341 637\n",
      "4 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 22/Representative Images/Tops - Options 2.png\n",
      "Original Image size is  423 309\n",
      "5 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 22/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  513 684\n",
      "6 Predicted:     Sweater ['floral' 'solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 22/Representative Images/Outerwear Option 3.png\n",
      "Original Image size is  618 694\n",
      "7 Predicted:     Top ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'loose']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 22/Representative Images/Jeans Option 1.png\n",
      "Original Image size is  172 384\n",
      "8 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 26/Style 26.png\n",
      "Original Image size is  380 541\n",
      "9 Predicted:     Jeans ['solid' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 26/Representative Images/Outerwear - Option 2.png\n",
      "Original Image size is  252 449\n",
      "10 Predicted:     Coat ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 26/Representative Images/Bottoms - Jeans.png\n",
      "Original Image size is  361 634\n",
      "11 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 26/Representative Images/Outerwear - Option 3.png\n",
      "Original Image size is  475 723\n",
      "12 Predicted:     Blazer ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 26/Representative Images/Footwear - Heels.png\n",
      "Original Image size is  698 733\n",
      "13 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Style 24.png\n",
      "Original Image size is  556 750\n",
      "14 Predicted:     Top ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'cotton']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Bottoms - Jeans option 1.png\n",
      "Original Image size is  496 900\n",
      "15 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  572 584\n",
      "16 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Footwear option 2.png\n",
      "Original Image size is  419 526\n",
      "17 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Tops - Option 2.png\n",
      "Original Image size is  660 663\n",
      "18 Predicted:     Culottes ['pleated' 'sleeveless' 'no_dress' 'no_neckline' 'chiffon' 'cotton'\n",
      " 'loose' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Tops - Option 3.png\n",
      "Original Image size is  653 679\n",
      "19 Predicted:     Dress ['striped' 'pleated' 'long_sleeve' 'mini_length' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Bottoms - Jeans option 2.png\n",
      "Original Image size is  413 636\n",
      "20 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 24/Representative Images/Footwear option 1.png\n",
      "Original Image size is  507 581\n",
      "21 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Style 27.png\n",
      "Original Image size is  376 567\n",
      "22 Predicted:     Blouse ['graphic' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Bottoms - Jeans Option 2.png\n",
      "Original Image size is  390 556\n",
      "23 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Tops - Options 3.png\n",
      "Original Image size is  287 288\n",
      "24 Predicted:     Blouse ['graphic' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Footwear - Option 2.png\n",
      "Original Image size is  463 631\n",
      "25 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  476 604\n",
      "26 Predicted:     Dress ['graphic' 'long_sleeve' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Footwear - Option 1.png\n",
      "Original Image size is  354 493\n",
      "27 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 27/Representative Images/Tops - Option 2.png\n",
      "Original Image size is  593 377\n",
      "28 Predicted:     Button-Down ['graphic' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Style 30.png\n",
      "Original Image size is  570 750\n",
      "29 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Representative Images/Accessory - Clutch.png\n",
      "Original Image size is  647 501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  580 485\n",
      "31 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Representative Images/Tops - Option 2.png\n",
      "Original Image size is  417 547\n",
      "32 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Representative Images/Tops - Option 3.png\n",
      "Original Image size is  678 695\n",
      "33 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 30/Representative Images/Bottoms - Skirt.png\n",
      "Original Image size is  865 764\n",
      "34 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Style 29.png\n",
      "Original Image size is  356 666\n",
      "35 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Representative Images/Footwear - Option 2.png\n",
      "Original Image size is  599 496\n",
      "36 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Representative Images/Bottoms - Jeans option 1.png\n",
      "Original Image size is  278 390\n",
      "37 Predicted:     Jeggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  707 755\n",
      "38 Predicted:     Tee ['solid' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Representative Images/Footwear - Option 3.png\n",
      "Original Image size is  534 425\n",
      "39 Predicted:     Jacket ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 29/Representative Images/Bottoms - Jeans option 2.png\n",
      "Original Image size is  350 500\n",
      "40 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Style 21.png\n",
      "Original Image size is  344 639\n",
      "41 Predicted:     Blouse ['striped' 'solid' 'long_sleeve' 'no_dress' 'no_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Jeans.png\n",
      "Original Image size is  392 667\n",
      "42 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Accessory Option 1.png\n",
      "Original Image size is  596 544\n",
      "43 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Footwear Option 1.png\n",
      "Original Image size is  371 381\n",
      "44 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Tops option 3.png\n",
      "Original Image size is  494 589\n",
      "45 Predicted:     Sweater ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Footwear Option 2.png\n",
      "Original Image size is  641 577\n",
      "46 Predicted:     Tank ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Tops option 1.png\n",
      "Original Image size is  319 227\n",
      "47 Predicted:     Sweater ['striped' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 21/Representative Images/Tops option 2.png\n",
      "Original Image size is  630 631\n",
      "48 Predicted:     Sweater ['embroidered' 'solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 25/Style 25.png\n",
      "Original Image size is  514 751\n",
      "49 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 25/Representative Images/Bottoms - Jeans.png\n",
      "Original Image size is  445 838\n",
      "50 Predicted:     Joggers ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 25/Representative Images/Footwear - Heels.png\n",
      "Original Image size is  568 712\n",
      "51 Predicted:     Shorts ['sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 25/Representative Images/Tops - Long Sleeve.png\n",
      "Original Image size is  671 910\n",
      "52 Predicted:     Skirt ['pleated' 'sleeveless' 'no_dress' 'no_neckline' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 23/Style 23.png\n",
      "Original Image size is  527 801\n",
      "53 Predicted:     Tee ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 23/Representative Images/Tops - Crop top option 2.png\n",
      "Original Image size is  710 472\n",
      "54 Predicted:     Tee ['graphic' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 23/Representative Images/Tops - Crop top option 1.png\n",
      "Original Image size is  547 372\n",
      "55 Predicted:     Tee ['graphic' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 23/Representative Images/Tops - Crop top option 3.png\n",
      "Original Image size is  537 415\n",
      "56 Predicted:     Tank ['graphic' 'sleeveless' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 3 - 10 Styles/Style 23/Representative Images/Bottoms - Option 2.png\n",
      "Original Image size is  421 649\n",
      "57 Predicted:     Skirt ['sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Style 16.png\n",
      "Original Image size is  397 671\n",
      "58 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Accessory Option 1.png\n",
      "Original Image size is  626 747\n",
      "59 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Footwear Option 1.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image size is  551 494\n",
      "60 Predicted:     Skirt ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Footwear Option 2.png\n",
      "Original Image size is  317 457\n",
      "61 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Bottoms - Jeans.png\n",
      "Original Image size is  326 551\n",
      "62 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Accessory Option 2.png\n",
      "Original Image size is  315 484\n",
      "63 Predicted:     Blouse ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 16/Representative Images/Tops - Blush Tee.png\n",
      "Original Image size is  506 654\n",
      "64 Predicted:     Tee ['solid' 'short_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Style 11.png\n",
      "Original Image size is  431 749\n",
      "65 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Tops - Blue Blouse.png\n",
      "Original Image size is  795 681\n",
      "66 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'v_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Accessory - Bag 3.png\n",
      "Original Image size is  418 498\n",
      "67 Predicted:     Tank ['striped' 'long_sleeve' 'short_sleeve' 'no_dress' 'crew_neckline'\n",
      " 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Footwear - Flat Sandals.png\n",
      "Original Image size is  476 320\n",
      "68 Predicted:     Tee ['solid' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Accessory - Bag 1.png\n",
      "Original Image size is  607 607\n",
      "69 Predicted:     Hoodie ['striped' 'long_sleeve' 'crew_neckline' 'cotton' 'loose' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Bottoms - Wide leg pants Option 1.png\n",
      "Original Image size is  470 790\n",
      "70 Predicted:     Culottes ['sleeveless' 'no_dress' 'no_neckline' 'cotton' 'loose' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Bottoms - Wide leg pants Option 2.png\n",
      "Original Image size is  477 667\n",
      "71 Predicted:     Dress ['sleeveless' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 11/Representative Images/Accessory - Bag 2.png\n",
      "Original Image size is  553 635\n",
      "72 Predicted:     Hoodie ['striped' 'mini_length' 'crew_neckline' 'cotton' 'loose' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 13/Style 13.png\n",
      "Original Image size is  461 750\n",
      "73 Predicted:     Dress ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 13/Representative Images/Tops - Option 1.png\n",
      "Original Image size is  427 682\n",
      "74 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 13/Representative Images/Accessory - Sneakers low top.png\n",
      "Original Image size is  677 528\n",
      "75 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 13/Representative Images/Bottoms - Shorts.png\n",
      "Original Image size is  285 226\n",
      "76 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 13/Representative Images/Tops - Option 2.png\n",
      "Original Image size is  479 366\n",
      "77 Predicted:     Shorts ['solid' 'short_sleeve' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 12/Style 12.png\n",
      "Original Image size is  400 681\n",
      "78 Predicted:     Coat ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 12/Representative Images/Footwear - Knee front boots.png\n",
      "Original Image size is  367 597\n",
      "79 Predicted:     Leggings ['solid' 'sleeveless' 'mini_length' 'no_dress' 'no_neckline' 'leather'\n",
      " 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 12/Representative Images/Tops - Belted Dress.png\n",
      "Original Image size is  411 666\n",
      "80 Predicted:     Dress ['solid' 'mini_length' 'crew_neckline' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Style 17.png\n",
      "Original Image size is  527 792\n",
      "81 Predicted:     Blouse ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Tops Option 2.png\n",
      "Original Image size is  932 796\n",
      "82 Predicted:     Blouse ['striped' 'pleated' 'long_sleeve' 'no_dress' 'crew_neckline' 'chiffon'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Bottoms - Jeans - Option 2.png\n",
      "Original Image size is  482 690\n",
      "83 Predicted:     Jeggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Tops - Ribbed Henley Option 1.png\n",
      "Original Image size is  446 360\n",
      "84 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Bottoms - Jeans - Option 1.png\n",
      "Original Image size is  224 549\n",
      "85 Predicted:     Jeans ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'denim' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Tops Option 3.png\n",
      "Original Image size is  509 438\n",
      "86 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 17/Representative Images/Accessory - Fedora.png\n",
      "Original Image size is  511 595\n",
      "87 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 18/Style 18.png\n",
      "Original Image size is  521 792\n",
      "88 Predicted:     Dress ['striped' 'mini_length' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 18/Representative Images/Footwear - High top converse.png\n",
      "Original Image size is  499 397\n",
      "89 Predicted:     Jacket ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 18/Representative Images/Tops - Dress.png\n",
      "Original Image size is  515 586\n",
      "90 Predicted:     Dress ['striped' 'sleeveless' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 18/Representative Images/Accessory - Fedora.png\n",
      "Original Image size is  462 346\n",
      "91 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Style 14.png\n",
      "Original Image size is  448 754\n",
      "92 Predicted:     Tee ['solid' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Representative Images/Footwear Option 1.png\n",
      "Original Image size is  543 750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Representative Images/Bottoms - Skirt option 2(1).png\n",
      "Original Image size is  525 503\n",
      "94 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Representative Images/Footwear Option 2.png\n",
      "Original Image size is  455 586\n",
      "95 Predicted:     Leggings ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Representative Images/Outerwear - Option 1.png\n",
      "Original Image size is  550 652\n",
      "96 Predicted:     Cardigan ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'knit' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 14/Representative Images/Bottoms - Skirt option 2.png\n",
      "Original Image size is  619 776\n",
      "97 Predicted:     Tee ['solid' 'no_dress' 'crew_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 19/Style 19.png\n",
      "Original Image size is  422 668\n",
      "98 Predicted:     Skirt ['pleated' 'sleeveless' 'no_dress' 'no_neckline' 'chiffon' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 19/Representative Images/Footwear - White low top sneakers.png\n",
      "Original Image size is  437 444\n",
      "99 Predicted:     Sweater ['solid' 'long_sleeve' 'no_dress' 'crew_neckline' 'no_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 19/Representative Images/Bottoms - Skirt.png\n",
      "Original Image size is  413 645\n",
      "100 Predicted:     Dress ['pleated' 'sleeveless' 'maxi_length' 'no_neckline' 'chiffon' 'loose'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 19/Representative Images/Tops - Tee.png\n",
      "Original Image size is  444 538\n",
      "101 Predicted:     Tee ['solid' 'long_sleeve' 'no_dress' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Style 15.png\n",
      "Original Image size is  507 819\n",
      "102 Predicted:     Dress ['long_sleeve' 'short_sleeve' 'mini_length' 'crew_neckline' 'cotton'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Tops - Dress option 1.png\n",
      "Original Image size is  342 455\n",
      "103 Predicted:     Dress ['solid' 'long_sleeve' 'mini_length' 'crew_neckline' 'cotton' 'tight']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Footwear Option 1.png\n",
      "Original Image size is  502 348\n",
      "104 Predicted:     Shorts ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'tight'\n",
      " 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Footwear Option 2.png\n",
      "Original Image size is  381 266\n",
      "105 Predicted:     Dress ['solid' 'sleeveless' 'no_dress' 'no_neckline' 'cotton' 'conventional']\n",
      "---------------------\n",
      "/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Tops - Dress option 2.png\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Tops - Dress option 2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-97c61df3480b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mnew_images\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print(new_images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-5781a00da105>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_basic_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-5781a00da105>\u001b[0m in \u001b[0;36mget_basic_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         img = Image.open(os.path.join(self.img_path,\n\u001b[0;32m--> 111\u001b[0;31m                                       self.img_list[idx])).convert('RGB')\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2929\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 2931\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2932\u001b[0m     )\n\u001b[1;32m   2933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/home/yu-hao/Downloads/30 Styles-20210216T225758Z-001/30 Styles/Batch 2 - 10 Styles/Style 15/Representative Images/Tops - Dress option 2.png'"
     ]
    }
   ],
   "source": [
    "# [STAR] MMFASHION VALIDATION LOOP\n",
    "\n",
    "attr_list = []\n",
    "attr_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_attr_cloth.txt\").read().split('\\n')\n",
    "for t in attr_list_file[2:-1]:\n",
    "    attr_list.append(t.split()[0])\n",
    "attr_list = np.array(attr_list)\n",
    "\n",
    "cate_list = []\n",
    "cate_list_file = open(\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/list_category_cloth.txt\").read().split('\\n')\n",
    "for t in cate_list_file[2:-1]:\n",
    "    cate_list.append(t.split()[0])\n",
    "cate_list = np.array(cate_list)\n",
    "\n",
    "model.load_state_dict(torch.load('fashion_cate_attr_resnet50_single_linear.pth'))\n",
    "\n",
    "loss_hist1  = Averager()\n",
    "loss_hist2  = Averager()\n",
    "loss_hist3  = Averager()\n",
    "\n",
    "\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 1\n",
    "counter    = 0\n",
    "prev_min = 1000\n",
    "\n",
    "val_data_loader   = build_dataloader(d3, 1, False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t1 in val_data_loader:\n",
    "        new_images  = torch.Tensor(t1['img']).to(device)\n",
    "        #print(new_images.shape)\n",
    "        \n",
    "        #attr_target = t1['attr'].to(device)\n",
    "        #cate_target = t1['cate'].to(device)\n",
    "        \n",
    "        #print(t1['attr'])\n",
    "        #print(t1['cate'])\n",
    "        \n",
    "        out1, out2  = model(new_images)\n",
    "        \n",
    "        out1 = torch.sigmoid(out1)\n",
    "        out2 = torch.softmax(out2, axis=1)\n",
    "        \n",
    "        out1 = out1.data.cpu().numpy().flatten()\n",
    "        out2 = out2.data.cpu().numpy().flatten()\n",
    "        \n",
    "        out1[out1 < 0.5] = 0\n",
    "        out1 = np.array(out1.flatten())\n",
    "        \n",
    "        attr_index         = np.array(np.nonzero(out1)[0])\n",
    "        #attr_ground_index  = np.array(np.nonzero(t1['attr'][0]).flatten())\n",
    "        \n",
    "        cate_index         = np.argmax(out2)\n",
    "        #cate_ground_index  = t1['cate'].data.cpu().numpy()[0][0]\n",
    "        \n",
    "        #print(cate_index, cate_ground_index)\n",
    "        print(counter, \"Predicted:    \", cate_list[cate_index], attr_list[attr_index])\n",
    "        #print(\"Ground Truth: \", cate_list[cate_ground_index], attr_list[attr_ground_index])\n",
    "        print('---------------------')\n",
    "        \n",
    "        counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "print(len(d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "\n",
    "train_cate_path = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_cate.txt\"\n",
    "train_attr_path = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train_attr.txt\"\n",
    "\n",
    "\n",
    "img_list = open(img_list_path).read()\n",
    "img_list = img_list.split(\"\\n\")[:-1]\n",
    "\n",
    "print(len(img_list))\n",
    "basepath = \"\"\n",
    "\n",
    "for i in tqdm(range(len(img_list))):\n",
    "    #print(img_list[i])\n",
    "    img_path = basepath+\"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Img/\"+img_list[i]\n",
    "    \n",
    "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    #print(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    image /= 255.0\n",
    "    \n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6197 img/Wifey_Graphic_Muscle_Tee/img_00000018.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "img_list_path   = \"/media/yu-hao/WindowsData/MMFASHION-DATASET/CategoryandAttributePredictionBenchmark/Anno_fine/train.txt\"\n",
    "\n",
    "img_list = open(img_list_path).read()\n",
    "img_list = img_list.split(\"\\n\")[:-1]\n",
    "\n",
    "#print(img_list)\n",
    "index = random.randint(0, 10000)\n",
    "print(index, img_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
