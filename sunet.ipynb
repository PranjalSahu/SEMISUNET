{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "import csv\n",
    "from scipy import ndimage, misc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "\n",
    "from skimage.measure import label\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "\n",
    "import functools\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "np.random.seed(0)\n",
    "#torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     11,
     28,
     39,
     66,
     74,
     135,
     223,
     356,
     480,
     543
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Pytorch Models for training\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class SUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes  = n_classes\n",
    "        self.bilinear   = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.4)\n",
    "        self.dp2 = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "       \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "        \n",
    "        x  = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN_old(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=256, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.bilinear = bilinear\n",
    "        self.n_classes = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        self.lsgn_a = nn.GroupNorm(128,256)\n",
    "    \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h = torch.unsqueeze(hidden,0)\n",
    "        \n",
    "        embedded = input\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        hidden_bilstm = h[0]\n",
    "        \n",
    "        \n",
    "        hidden_bilinn =  hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "    \n",
    "        hidden_bilinn = self.lsgn_a(hidden_bilinn)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden_bilinn), 1)), dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        attn_weights  = self.lsgn_a(attn_weights)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "   #     print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "  #      print('The output shape is : ',output.shape)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    " #      print('The output shape after is : ',output.shape)\n",
    "        \n",
    "    \n",
    "        hidden_bi = hidden_bilinn.unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #print(\"output and hidden before lstm \",output.shape,hidden_bi.shape)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        output = self.lsgn_a(output)\n",
    "        \n",
    "       #output = self.lsgn_a(output)\n",
    "    \n",
    "        return output,hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "\n",
    "############### MAIN MODEL ##############\n",
    "class UNetDoubleSmallGroupNormdifferent_old(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(128,256)\n",
    "        \n",
    "        self.lsgn2 = nn.GroupNorm(64,256)\n",
    "        \n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        #print('x5 shape is :',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,256,256])\n",
    "\n",
    "        lstm = nn.LSTM(256,256,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "                \n",
    "        #print('xlst',xlst.shape)    \n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        \n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        \n",
    "        #print(hidden)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        \n",
    "        \n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,256,256))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "    \n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,256,16,16])\n",
    "        \n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    " \n",
    "        \n",
    "        \n",
    "        x5 = self.lsgn2(x5)\n",
    "        \n",
    "        ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallGroupNormdifferent(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        super(UNetDoubleSmallGroupNormdifferent, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc     = DoubleConv(n_channels, 16)\n",
    "        self.down1   = Down(16, 32)\n",
    "        self.downnew = Down(16,16)\n",
    "        self.down2   = Down(32, 64)\n",
    "        self.down3   = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4   = Down(128, 256 // factor) \n",
    "        self.upsam   = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        self.down5 = Down(128,256)\n",
    "        self.ups3  = nn.ConvTranspose2d(1 , 1, kernel_size=2, stride=2)\n",
    "        self.ups4  = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        #self.out_sigmoid = nn.Sigmoid()\n",
    "        self.out_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lsgn1 = nn.GroupNorm(64,128)\n",
    "        \n",
    "        self.lsgn2 = nn.GroupNorm(64,1024)\n",
    "        \n",
    "        self.gn1 = nn.GroupNorm(8, 16)\n",
    "        self.gn2 = nn.GroupNorm(16, 32)\n",
    "        self.gn3 = nn.GroupNorm(32, 64)\n",
    "        self.gn4 = nn.GroupNorm(64, 128)\n",
    "        self.gn5 = nn.GroupNorm(32, 64)\n",
    "        self.gn6 = nn.GroupNorm(16, 32)\n",
    "        self.gn7 = nn.GroupNorm(8, 16)\n",
    "        self.gn8 = nn.GroupNorm(4,8)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        #x = self.upsam()\n",
    "        \n",
    "        x1 = self.inc(x)\n",
    "        x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "        x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "        x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "        x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        #x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        #print('x5:',x5.shape)\n",
    "        \n",
    "        xlst = x5.reshape([4,128,1024])\n",
    "        \n",
    "\n",
    "        lstm = nn.LSTM(1024,1024,batch_first= True,bidirectional=True,num_layers=1).cuda()\n",
    "        \n",
    "        xlst = self.lsgn1(xlst)\n",
    "        ylst = lstm(xlst)\n",
    "        \n",
    "        f = np.asarray(ylst)\n",
    "        \n",
    "        h  = torch.cuda.FloatTensor(ylst[0])\n",
    "        h = torch.squeeze(h)\n",
    "        \n",
    "        encoder_o = f[0]\n",
    "        \n",
    "        a = np.zeros((4,128,1024))\n",
    "        #a = ndarray((4,128,1024))\n",
    "\n",
    "        a = torch.from_numpy(a)\n",
    "        a.cuda()\n",
    "        \n",
    "        for i in range(4):\n",
    "            oo,b = attn_decoder1.forward(xlst,h[i],encoder_o[i])\n",
    "            oo = self.lsgn2(oo)\n",
    "            a[i] = oo\n",
    "        \n",
    "            \n",
    "        a = a.unsqueeze(0)\n",
    "        a = a.reshape([4,128,32,32])\n",
    "        \n",
    "        \n",
    "        \n",
    "        x5 = a  \n",
    "        x5 = x5.cuda()\n",
    "        \n",
    "        \n",
    "        x5 = x5.type(torch.cuda.FloatTensor)\n",
    "        x5 = self.lsgn1(x5)\n",
    "        \n",
    "        #x5 = self.ups4(x5)\n",
    "    \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "        x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        x = self.gn7(x)\n",
    "\n",
    "        #x = self.downnew(x)\n",
    "        \n",
    "        #out    = self.out_softmax(logits)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class UNetDoubleSmallWithoutGN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes,bilinear=True):\n",
    "        \n",
    "        super(UNetDoubleSmallWithoutGN, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc   = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "       # x1 = self.gn1(x1)\n",
    "       \n",
    "        x2 = self.down1(x1)\n",
    "       # x2 = self.gn2(x2)\n",
    "       \n",
    "        x3 = self.down2(x2)\n",
    "       # x3 = self.gn3(x3)\n",
    "       \n",
    "        x4 = self.down3(x3)\n",
    "       # x4 = self.gn4(x4)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        #x5 = torch.squeeze(x5)\n",
    "        x5 = self.down5(x5)\n",
    "        #x5 = self.down6(x5)\n",
    "        \n",
    "        ups4     = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        upsconv4 = DoubleConv(256,128)\n",
    "        ups4 = ups4.cuda()\n",
    "        \n",
    "        opt = ups4(x5)\n",
    "        \n",
    "        x5 = opt\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        #x = self.gn5(x)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       # x = self.gn6(x)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        #x = self.gn7(x)\n",
    "       \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        #out    = self.out_softmax(logits)\n",
    "        return logits\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=128, bilinear=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.bilinear = bilinear\n",
    "        self.n_classes = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.attn2 = nn.Linear(1024,128)\n",
    "        \n",
    "        self.attn_24 = nn.Linear(self.hidden_size*4, self.hidden_size*2)\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.attn_combine_bilstm = nn.Linear(3072, 1024)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(1024, 1024)\n",
    "        self.out = nn.Linear(1024, 1024)\n",
    "       # self.hidden = nn.Parameter(torch.randn(4,256,256).cuda()),nn.Parameter(torch.randn(4,256,256).cuda())\n",
    "       \n",
    "        self.lsgn_a = nn.GroupNorm(512,1024)\n",
    "        \n",
    "        self.lsgn_in = nn.GroupNorm(64,128)\n",
    "    \n",
    "        self.down5 = Down(128,256)\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "                \n",
    "        self.ups4 = nn.ConvTranspose2d(256 , 256 // 2, kernel_size=2, stride=2)\n",
    "        self.upsconv4 = DoubleConv(256,128)\n",
    "\n",
    "        self.lstm = nn.LSTM(256,256,batch_first=False,bidirectional=True,num_layers=1).cuda()\n",
    "    \n",
    "    def forward(self, input,hidden,encoder_outputs):\n",
    "        \n",
    "        h = torch.unsqueeze(hidden,0)\n",
    "        embedded = input\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = self.lsgn_in(embedded)\n",
    "        hidden_bilstm = h[0]\n",
    "        hidden_bilinn =  hidden_bilstm\n",
    "        \n",
    "        hidden_bilinn = self.attn(hidden_bilinn)\n",
    "        \n",
    "        #print('hidden bilinn shape:',hidden_bilinn.shape)\n",
    "    \n",
    "        hidden_bilinn = self.lsgn_a(hidden_bilinn)\n",
    "        #print(hidden_bilinn.shape)\n",
    "        \n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden_bilinn), 1)), dim=1)\n",
    "        attn_weights  = self.lsgn_a(attn_weights)\n",
    "        attn_weights  = self.attn2(attn_weights)\n",
    "        attn_weights = self.lsgn_in(attn_weights)\n",
    "        \n",
    "        #print(attn_weights.unsqueeze(0).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "    \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        #print('attn_applied: encoder outputs',attn_applied[0].shape,encoder_outputs[0].shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        #print('The output shape is : ',output.shape)\n",
    "        \n",
    "        output = self.attn_combine_bilstm(output).unsqueeze(0)\n",
    "        \n",
    "        #print('The output shape after is : ',output.shape)\n",
    "        \n",
    "    \n",
    "        hidden_bi = hidden_bilinn.unsqueeze(0)\n",
    "        output    = F.relu(output)\n",
    "        output    = self.lsgn_in(output)\n",
    "        \n",
    "        #print(\"output and hidden before lstm \",output.shape,hidden_bi.shape)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden_bi)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        output = self.lsgn_a(output)\n",
    "        return output,hidden\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(4, 256, self.hidden_size, device=device)\n",
    "#model = SUNet(1, 1)\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     21,
     43,
     50,
     59,
     90,
     114,
     145,
     155,
     179,
     202,
     225,
     253,
     265,
     296,
     362,
     435,
     472,
     490
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For training different models for comparison on MOSMEDDATA dataset\n",
    "\n",
    "import skimage\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID_MOSCOW/COVID_MOSCOW/COVID19_1110/'\n",
    "basepath_models  = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID_MOSCOW/COVID_MOSCOW/COVID19_1110/models/single_models/'\n",
    "\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = F.sigmoid(pred)\n",
    "    \n",
    "    pred   = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        #output[output > 0.5]= 1\n",
    "        #output[output < 0.5]= 0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_predictions(models, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        models[i].eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(5):\n",
    "            output = models[k].forward(x)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.data.cpu().numpy()\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_sum = np.zeros(outputs[0].shape, dtype='float16')\n",
    "        for k in range(5):\n",
    "            output_sum = output_sum+outputs[k]\n",
    "        output_sum = output_sum/5.0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output_sum[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_filtered(valx, valy):\n",
    "    valxf = []\n",
    "    valyf = []\n",
    "    \n",
    "    for i in range(valx.shape[0]):\n",
    "        if np.count_nonzero(valy[i]) > 0:\n",
    "            valxf.append(valx[i])\n",
    "            valyf.append(valy[i])\n",
    "    return np.array(valxf), np.array(valyf)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion, trainx, trainy):\n",
    "    loss_array = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def prepare_batch(batch_size, k_means, trainx_l, trainy_l, h):\n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(int(batch_size/2)):\n",
    "        idx = random.randint(0, trainx_l.shape[0]-1)\n",
    "        c   = k_means.predict(np.reshape(trainx_l[idx].astype('float32'), [1, 512*512]))[0]\n",
    "        \n",
    "        a.append(trainx_l[idx])\n",
    "        b.append(trainy_l[idx])\n",
    "        \n",
    "        idx = random.randint(0, len(h[c])-1)\n",
    "        t1  = np.expand_dims(np.load(h[c][idx]), 0)\n",
    "        t2  = np.expand_dims(np.load(h[c][idx].replace('-x', '-y')), 0)\n",
    "        \n",
    "        a.append(t1)\n",
    "        b.append(t2)\n",
    "   \n",
    "    a1 = np.array(a).astype('float16')\n",
    "    b1 = np.array(b).astype('float16')\n",
    "   \n",
    "    return a1, b1\n",
    "\n",
    "def store_cluster_slices(model_teacher, k_means, version):\n",
    "    epoch_array = np.arange(79)\n",
    "    all_labels  = []\n",
    "    step_size   = 10 \n",
    "    count       = 0\n",
    "    \n",
    "    for epoch in epoch_array:\n",
    "        temp_index               = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "        trainx, trainx_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "        trainy                   = get_prediction(model_teacher, trainx)\n",
    "        \n",
    "        #trainy = np.load('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/PREDICTION-NUMPY/'+str(epoch)+'.npy')\n",
    "        trainy = np.reshape(trainy, [trainy.shape[0], 512*512])\n",
    "        #print(epoch, trainy.shape, trainx.shape)\n",
    "        \n",
    "        l1     = k_means.predict(trainy)\n",
    "        \n",
    "        for jt, t in enumerate(l1):\n",
    "            temp  = np.reshape(trainy[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-y.npy', temp)\n",
    "            \n",
    "            temp  = np.reshape(trainx[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-x.npy', temp)\n",
    "            \n",
    "            count = count+1\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_hash(version):\n",
    "    all_cluster_files = glob.glob('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/*.npy')\n",
    "    print('Version ', version, 'File name counts ', len(all_cluster_files))\n",
    "    filename_hash = {}\n",
    "    for i in range(50):\n",
    "        filename_hash[i] = []\n",
    "\n",
    "    for t in all_cluster_files:\n",
    "        filename_hash[int(t.split('/')[-1].split('-')[0])].append(t)\n",
    "    \n",
    "    return filename_hash\n",
    "\n",
    "def get_all_covid_lesions(valx, valy, lesion_size):\n",
    "    lesion_shapes_x = []\n",
    "    lesion_shapes_y = []\n",
    "    \n",
    "    for i in range(valy.shape[0]):\n",
    "        tx           = valx[i, 0]\n",
    "        blobs        = valy[i, 0]\n",
    "        blobs_labels = skimage.measure.label(blobs, background=0)\n",
    "        propsa       = skimage.measure.regionprops(blobs_labels)\n",
    "        \n",
    "        for k in range(len(propsa)):\n",
    "            temp = (blobs_labels == propsa[k].label).astype('uint8')\n",
    "            \n",
    "            temp_size = np.count_nonzero(temp.flatten().astype('uint8'))\n",
    "            if temp_size < lesion_size and temp_size > 5:\n",
    "                slice_x, slice_y = ndimage.find_objects(temp == 1)[0]\n",
    "                \n",
    "                roi_y = 1-temp[slice_x, slice_y]\n",
    "                roi_x = tx[slice_x, slice_y]*temp[slice_x, slice_y]\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x)\n",
    "                lesion_shapes_y.append(roi_y)\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x.T)\n",
    "                lesion_shapes_y.append(roi_y.T)\n",
    "                \n",
    "                lesion_shapes_x.append(np.rot90(roi_x, 180))\n",
    "                lesion_shapes_y.append(np.rot90(roi_y, 180))\n",
    "    \n",
    "    return lesion_shapes_x, lesion_shapes_y\n",
    "\n",
    "def get_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            i,j = np.nonzero(mask[t])\n",
    "            \n",
    "            index = random.randint(0, len(i)-1)\n",
    "            \n",
    "            i = i[index]\n",
    "            j = j[index]\n",
    "            \n",
    "            lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "            \n",
    "            lesion_x     = lesion_shapes_x[lesion_index]\n",
    "            lesion_y     = lesion_shapes_y[lesion_index]\n",
    "            \n",
    "            sx     = int(lesion_x.shape[0]/2)\n",
    "            sy     = int(lesion_x.shape[1]/2)\n",
    "            \n",
    "            if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                m1         = m1*mask[t]\n",
    "                m1[m1 > 0] = 1\n",
    "\n",
    "                x_array.append(np.expand_dims(st,          axis=0))\n",
    "                x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "\n",
    "                count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_multiple_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            #segmen\n",
    "            ipl, jpl = np.nonzero(mask[t])\n",
    "            \n",
    "            lesion_count = random.randint(0, 5)\n",
    "            temp_count   = 0\n",
    "            \n",
    "            while(temp_count < lesion_count):\n",
    "                index = random.randint(0, len(ipl)-1)\n",
    "\n",
    "                i = ipl[index]\n",
    "                j = jpl[index]\n",
    "\n",
    "                lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "\n",
    "                lesion_x     = lesion_shapes_x[lesion_index]\n",
    "                lesion_y     = lesion_shapes_y[lesion_index]\n",
    "\n",
    "                sx     = int(lesion_x.shape[0]/2)\n",
    "                sy     = int(lesion_x.shape[1]/2)\n",
    "\n",
    "                if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                    m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                    m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                    m1         = m1*mask[t]\n",
    "                    m1[m1 > 0] = 1\n",
    "                    segmentation_mask[t] = m1\n",
    "                    temp_count           = temp_count + 1\n",
    "            \n",
    "            x_array.append(np.expand_dims(st,          axis=0))\n",
    "            x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "            \n",
    "            count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def plot_figure_slope(model_save_name):\n",
    "    N = 2\n",
    "    a = val_dice_array1#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = train_dice_array1#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = test_dice_array1#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    temp  = 0\n",
    "    slope = 0\n",
    "    #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "    for i in range(1, len(a)):\n",
    "        if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "            temp  = i#np.argmax(a)\n",
    "            slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "            #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "\n",
    "def plot_figure(model_save_name):\n",
    "    a = list(val_dice_array)#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = list(train_dice_array)#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = list(test_dice_array)#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    #a.insert(0, 0)\n",
    "    #b.insert(0, 0)\n",
    "    #c.insert(0, 0)\n",
    "#     temp  = 0\n",
    "#     slope = 0\n",
    "#     #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "#     for i in range(1, len(a)):\n",
    "#         if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "#             temp  = i#np.argmax(a)\n",
    "#             slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "#             #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    # Take arg max for semi model\n",
    "    temp = np.argmax(a)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    #plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "test_ids       = np.load(basepath+'TEST.npy')\n",
    "unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "nocovid_ids    = np.load(basepath+'NOCOVID.npy')\n",
    "\n",
    "\n",
    "unlabelled_ids     = unlabelled_ids\n",
    "train_ids          = train_ids[:4]\n",
    "val_ids            = val_ids\n",
    "test_ids           = test_ids\n",
    "\n",
    "trainx_l, trainy_l = read_training_data(train_ids)\n",
    "valx, valy         = read_training_data(val_ids)\n",
    "testx, testy       = read_training_data(test_ids)\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "            \n",
    "prev_max        = -1000\n",
    "model_student   = SUNet(1, 1)\n",
    "model_student.cuda()\n",
    "\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0001)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "\n",
    "\n",
    "val_dice_array   = []\n",
    "train_dice_array = []\n",
    "test_dice_array  = []\n",
    "\n",
    "trainx, trainy   = sort_data(trainx_l, trainy_l)\n",
    "total_epochs = 100\n",
    "\n",
    "\n",
    "teacher_dice_array = []\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch%10 ==1:\n",
    "        print(epoch)\n",
    "\n",
    "    train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy)\n",
    "    \n",
    "    val_dice      = evaluate_result(model_student, valx, valy)\n",
    "    student_dice1 = evaluate_result(model_student, trainx, trainy)\n",
    "    \n",
    "    \n",
    "    train_dice_array.append(np.mean(student_dice1))\n",
    "    val_dice_array.append(np.mean(val_dice))\n",
    "    \n",
    "    model_save_name = \"tmi-compare-sunet\"\n",
    "    \n",
    "    if np.mean(val_dice) > prev_max:\n",
    "        print(\"Step %d  Dice %.5f > %f  Train Dice %f \" % (epoch, np.mean(val_dice), prev_max, np.mean(student_dice1)))\n",
    "        prev_max     = np.mean(val_dice)\n",
    "        torch.save(model_student.state_dict(), basepath_models+model_save_name+'-'+str(epoch)+\".pt\")\n",
    "\n",
    "    #np.save(model_save_name+'_train.npy',      train_dice_array)\n",
    "    #np.save(model_save_name+'_validation.npy', val_dice_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     21,
     43,
     50,
     59,
     90,
     114,
     145,
     155,
     179,
     199,
     232,
     255,
     283,
     295,
     326,
     392,
     465,
     502,
     520,
     562,
     616
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1, 512, 512) (5, 1, 512, 512) (48, 1, 512, 512)\n",
      "Step 0  Val Dice 0.38641, Train Dice 0.334668, Test Dice 0.337660\n",
      "1\n",
      "Step 2  Val Dice 0.39514, Train Dice 0.392259, Test Dice 0.425920\n",
      "Step 3  Val Dice 0.46319, Train Dice 0.464655, Test Dice 0.502105\n",
      "Step 4  Val Dice 0.58911, Train Dice 0.582315, Test Dice 0.616705\n",
      "Step 5  Val Dice 0.61803, Train Dice 0.609297, Test Dice 0.643027\n",
      "Step 6  Val Dice 0.66260, Train Dice 0.653285, Test Dice 0.672730\n",
      "Step 7  Val Dice 0.66764, Train Dice 0.665725, Test Dice 0.681237\n",
      "Step 9  Val Dice 0.69188, Train Dice 0.683809, Test Dice 0.694649\n",
      "Step 10  Val Dice 0.69737, Train Dice 0.684531, Test Dice 0.699895\n",
      "11\n",
      "Step 12  Val Dice 0.71199, Train Dice 0.703339, Test Dice 0.710210\n",
      "Step 13  Val Dice 0.71687, Train Dice 0.707096, Test Dice 0.723844\n",
      "Step 14  Val Dice 0.71963, Train Dice 0.707066, Test Dice 0.723194\n",
      "Step 16  Val Dice 0.72872, Train Dice 0.727326, Test Dice 0.742997\n",
      "Step 17  Val Dice 0.73806, Train Dice 0.725543, Test Dice 0.730326\n",
      "Step 20  Val Dice 0.74444, Train Dice 0.740602, Test Dice 0.752499\n",
      "21\n",
      "Step 21  Val Dice 0.74779, Train Dice 0.744927, Test Dice 0.752250\n",
      "Step 23  Val Dice 0.75167, Train Dice 0.753420, Test Dice 0.751249\n",
      "Step 24  Val Dice 0.75472, Train Dice 0.758877, Test Dice 0.753995\n",
      "Step 26  Val Dice 0.75806, Train Dice 0.762068, Test Dice 0.754922\n",
      "Step 27  Val Dice 0.75915, Train Dice 0.767588, Test Dice 0.764984\n",
      "Step 28  Val Dice 0.75974, Train Dice 0.760403, Test Dice 0.745290\n",
      "31\n",
      "Step 31  Val Dice 0.76294, Train Dice 0.769591, Test Dice 0.740880\n",
      "Step 33  Val Dice 0.77042, Train Dice 0.764044, Test Dice 0.750212\n",
      "Step 39  Val Dice 0.77199, Train Dice 0.793483, Test Dice 0.761996\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For training different models for comparison on COVID-19 dataset using LSTM Model\n",
    "\n",
    "import skimage\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/home/yu-hao/SEMISUNET/Dataset/'\n",
    "basepath_models  = '/home/yu-hao/SEMISUNET/Dataset/models/'\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = F.sigmoid(pred)\n",
    "    \n",
    "    pred   = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 4\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        #output[output > 0.5]= 1\n",
    "        #output[output < 0.5]= 0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_predictions(models, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        models[i].eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(5):\n",
    "            output = models[k].forward(x)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.data.cpu().numpy()\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_sum = np.zeros(outputs[0].shape, dtype='float16')\n",
    "        for k in range(5):\n",
    "            output_sum = output_sum+outputs[k]\n",
    "        output_sum = output_sum/5.0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output_sum[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_filtered(valx, valy):\n",
    "    valxf = []\n",
    "    valyf = []\n",
    "    \n",
    "    for i in range(valx.shape[0]):\n",
    "        if np.count_nonzero(valy[i]) > 0:\n",
    "            valxf.append(valx[i])\n",
    "            valyf.append(valy[i])\n",
    "    return np.array(valxf), np.array(valyf)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 4\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def evaluate_result_new(pred, valy):\n",
    "    val_dice       = []\n",
    "    batch_size     = 4\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        output = pred[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y      = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        \n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            t1 = scipy.ndimage.zoom(output[0, 0].astype('uint8'), 0.6875, order=0)\n",
    "            t2 = scipy.ndimage.zoom(y[0, 0].astype('uint8'),      0.6875, order=0)\n",
    "            #print(t1.shape, t2.shape)\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    \n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "    \n",
    "    idx    = np.random.permutation(trainx.shape[0])\n",
    "    trainx = trainx[idx]\n",
    "    trainy = trainy[idx]\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def prepare_batch(batch_size, k_means, trainx_l, trainy_l, h):\n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(int(batch_size/2)):\n",
    "        idx = random.randint(0, trainx_l.shape[0]-1)\n",
    "        c   = k_means.predict(np.reshape(trainx_l[idx].astype('float32'), [1, 512*512]))[0]\n",
    "        \n",
    "        a.append(trainx_l[idx])\n",
    "        b.append(trainy_l[idx])\n",
    "        \n",
    "        idx = random.randint(0, len(h[c])-1)\n",
    "        t1  = np.expand_dims(np.load(h[c][idx]), 0)\n",
    "        t2  = np.expand_dims(np.load(h[c][idx].replace('-x', '-y')), 0)\n",
    "        \n",
    "        a.append(t1)\n",
    "        b.append(t2)\n",
    "   \n",
    "    a1 = np.array(a).astype('float16')\n",
    "    b1 = np.array(b).astype('float16')\n",
    "   \n",
    "    return a1, b1\n",
    "\n",
    "def store_cluster_slices(model_teacher, k_means, version):\n",
    "    epoch_array = np.arange(79)\n",
    "    all_labels  = []\n",
    "    step_size   = 10 \n",
    "    count       = 0\n",
    "    \n",
    "    for epoch in epoch_array:\n",
    "        temp_index               = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "        trainx, trainx_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "        trainy                   = get_prediction(model_teacher, trainx)\n",
    "        \n",
    "        #trainy = np.load('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/PREDICTION-NUMPY/'+str(epoch)+'.npy')\n",
    "        trainy = np.reshape(trainy, [trainy.shape[0], 512*512])\n",
    "        #print(epoch, trainy.shape, trainx.shape)\n",
    "        \n",
    "        l1     = k_means.predict(trainy)\n",
    "        \n",
    "        for jt, t in enumerate(l1):\n",
    "            temp  = np.reshape(trainy[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-y.npy', temp)\n",
    "            \n",
    "            temp  = np.reshape(trainx[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-x.npy', temp)\n",
    "            \n",
    "            count = count+1\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_hash(version):\n",
    "    all_cluster_files = glob.glob('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/*.npy')\n",
    "    print('Version ', version, 'File name counts ', len(all_cluster_files))\n",
    "    filename_hash = {}\n",
    "    for i in range(50):\n",
    "        filename_hash[i] = []\n",
    "\n",
    "    for t in all_cluster_files:\n",
    "        filename_hash[int(t.split('/')[-1].split('-')[0])].append(t)\n",
    "    \n",
    "    return filename_hash\n",
    "\n",
    "def get_all_covid_lesions(valx, valy, lesion_size):\n",
    "    lesion_shapes_x = []\n",
    "    lesion_shapes_y = []\n",
    "    \n",
    "    for i in range(valy.shape[0]):\n",
    "        tx           = valx[i, 0]\n",
    "        blobs        = valy[i, 0]\n",
    "        blobs_labels = skimage.measure.label(blobs, background=0)\n",
    "        propsa       = skimage.measure.regionprops(blobs_labels)\n",
    "        \n",
    "        for k in range(len(propsa)):\n",
    "            temp = (blobs_labels == propsa[k].label).astype('uint8')\n",
    "            \n",
    "            temp_size = np.count_nonzero(temp.flatten().astype('uint8'))\n",
    "            if temp_size < lesion_size and temp_size > 5:\n",
    "                slice_x, slice_y = ndimage.find_objects(temp == 1)[0]\n",
    "                \n",
    "                roi_y = 1-temp[slice_x, slice_y]\n",
    "                roi_x = tx[slice_x, slice_y]*temp[slice_x, slice_y]\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x)\n",
    "                lesion_shapes_y.append(roi_y)\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x.T)\n",
    "                lesion_shapes_y.append(roi_y.T)\n",
    "                \n",
    "                lesion_shapes_x.append(np.rot90(roi_x, 180))\n",
    "                lesion_shapes_y.append(np.rot90(roi_y, 180))\n",
    "    \n",
    "    return lesion_shapes_x, lesion_shapes_y\n",
    "\n",
    "def get_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            i,j = np.nonzero(mask[t])\n",
    "            \n",
    "            index = random.randint(0, len(i)-1)\n",
    "            \n",
    "            i = i[index]\n",
    "            j = j[index]\n",
    "            \n",
    "            lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "            \n",
    "            lesion_x     = lesion_shapes_x[lesion_index]\n",
    "            lesion_y     = lesion_shapes_y[lesion_index]\n",
    "            \n",
    "            sx     = int(lesion_x.shape[0]/2)\n",
    "            sy     = int(lesion_x.shape[1]/2)\n",
    "            \n",
    "            if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                m1         = m1*mask[t]\n",
    "                m1[m1 > 0] = 1\n",
    "\n",
    "                x_array.append(np.expand_dims(st,          axis=0))\n",
    "                x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "\n",
    "                count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_multiple_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            #segmen\n",
    "            ipl, jpl = np.nonzero(mask[t])\n",
    "            \n",
    "            lesion_count = random.randint(0, 5)\n",
    "            temp_count   = 0\n",
    "            \n",
    "            while(temp_count < lesion_count):\n",
    "                index = random.randint(0, len(ipl)-1)\n",
    "\n",
    "                i = ipl[index]\n",
    "                j = jpl[index]\n",
    "\n",
    "                lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "\n",
    "                lesion_x     = lesion_shapes_x[lesion_index]\n",
    "                lesion_y     = lesion_shapes_y[lesion_index]\n",
    "\n",
    "                sx     = int(lesion_x.shape[0]/2)\n",
    "                sy     = int(lesion_x.shape[1]/2)\n",
    "\n",
    "                if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                    m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                    m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                    m1         = m1*mask[t]\n",
    "                    m1[m1 > 0] = 1\n",
    "                    segmentation_mask[t] = m1\n",
    "                    temp_count           = temp_count + 1\n",
    "            \n",
    "            x_array.append(np.expand_dims(st,          axis=0))\n",
    "            x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "            \n",
    "            count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def plot_figure_slope(model_save_name):\n",
    "    N = 2\n",
    "    a = val_dice_array1#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = train_dice_array1#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = test_dice_array1#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    temp  = 0\n",
    "    slope = 0\n",
    "    #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "    for i in range(1, len(a)):\n",
    "        if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "            temp  = i#np.argmax(a)\n",
    "            slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "            #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "\n",
    "def plot_figure(model_save_name):\n",
    "    a = list(val_dice_array)#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = list(train_dice_array)#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = list(test_dice_array)#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    #a.insert(0, 0)\n",
    "    #b.insert(0, 0)\n",
    "    #c.insert(0, 0)\n",
    "#     temp  = 0\n",
    "#     slope = 0\n",
    "#     #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "#     for i in range(1, len(a)):\n",
    "#         if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "#             temp  = i#np.argmax(a)\n",
    "#             slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "#             #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    # Take arg max for semi model\n",
    "    temp = np.argmax(a)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    #plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def train_model1(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "        #x2 = model.forward(x)        \n",
    "        #print(x2.shape)\n",
    "        \n",
    "#         lstm = nn.LSTM(512*512,512*512,batchfirst=True)\n",
    "#         hidden = (torch.randn(1, 512, 512), torch.randn(1, 512, 512))\n",
    "#         outlstm = lstm(x, hidden)\n",
    "#         n = np.asarray(outlstm)\n",
    "  \n",
    "        print(i, x.shape[0])\n",
    "        \n",
    "        if(x.shape[0]!= 4):\n",
    "            break\n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        y = np.expand_dims(y, 1)\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def train_model2(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    #batch_size = 4\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        \n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "  \n",
    "        if(x.shape[0]!=4):\n",
    "            break\n",
    "            \n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        y = np.expand_dims(y, 1)\n",
    "\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "# train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "# val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "# test_ids       = np.load(basepath+'TEST.npy')\n",
    "# unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "# nocovid_ids    = np.load(basepath+'NOCOVID.npy')\n",
    "\n",
    "\n",
    "# unlabelled_ids     = unlabelled_ids\n",
    "# train_ids          = train_ids[:4]\n",
    "# val_ids            = val_ids\n",
    "# test_ids           = test_ids\n",
    "\n",
    "trainx_l = np.load(basepath+'train_x.npy')/255.0\n",
    "trainy_l = np.load(basepath+'train_y.npy')\n",
    "trainy_l[trainy_l > 0] = 1\n",
    "\n",
    "train_size    = 45\n",
    "valx          = trainx_l[train_size:]\n",
    "valy          = trainy_l[train_size:]\n",
    "\n",
    "trainx_l = trainx_l[:train_size]\n",
    "trainy_l = trainy_l[:train_size]\n",
    "\n",
    "testx = np.load(basepath+'test_x.npy')/255.0\n",
    "testy = np.load(basepath+'test_y.npy')\n",
    "testy[testy > 0] = 1\n",
    "\n",
    "\n",
    "trainx_l1 = np.zeros([trainx_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valx1     = np.zeros([valx.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testx1    = np.zeros([testx.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "trainy_l1 = np.zeros([trainy_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valy1     = np.zeros([valy.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testy1    = np.zeros([testy.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "\n",
    "for i in range(trainx_l.shape[0]):\n",
    "    trainx_l1[i, 0] = scipy.ndimage.zoom(trainx_l[i], 2, order=3)\n",
    "    trainy_l1[i, 0] = scipy.ndimage.zoom(trainy_l[i], 2, order=0)\n",
    "\n",
    "for i in range(valx.shape[0]):\n",
    "    valx1[i, 0] = scipy.ndimage.zoom(valx[i], 2, order=3)\n",
    "    valy1[i, 0] = scipy.ndimage.zoom(valy[i], 2, order=0)\n",
    "\n",
    "for i in range(testx.shape[0]):\n",
    "    testx1[i, 0] = scipy.ndimage.zoom(testx[i], 2, order=3)\n",
    "    testy1[i, 0] = scipy.ndimage.zoom(testy[i], 2, order=0)\n",
    "\n",
    "\n",
    "trainx_l = trainx_l1\n",
    "trainy_l = trainy_l1\n",
    "valx     = valx1\n",
    "valy     = valy1\n",
    "testx    = testx1\n",
    "testy    = testy1\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "attn_decoder1 = AttnDecoderRNN(256, 256, dropout_p=0.45)\n",
    "attn_decoder1.cuda()\n",
    "\n",
    "prev_max        = -1000\n",
    "model_student   = UNetDoubleSmallGroupNormdifferent(1, 1)\n",
    "model_student.cuda()\n",
    "\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0001)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "\n",
    "optimizer_attn_w  = optim.Adam(attn_decoder1.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "val_dice_array   = []\n",
    "train_dice_array = []\n",
    "test_dice_array  = []\n",
    "\n",
    "trainx, trainy   = sort_data(trainx_l, trainy_l)\n",
    "total_epochs = 1000\n",
    "\n",
    "\n",
    "# trainx = np.expand_dims(trainx, axis=1)\n",
    "# trainy = np.expand_dims(trainy, axis=1)\n",
    "\n",
    "# valx   = np.expand_dims(valx, axis=1)\n",
    "# valy   = np.expand_dims(valy, axis=1)\n",
    "\n",
    "# testx  = np.expand_dims(testx, axis=1)\n",
    "# testy  = np.expand_dims(testy, axis=1)\n",
    "\n",
    "teacher_dice_array = []\n",
    "test_dice_array    = []\n",
    "\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch%10 ==1:\n",
    "        print(epoch)\n",
    "    #train_model1(model, optimizer, criterion, trainx, trainy, augment=False)\n",
    "    train_loss    = train_model2(model_student, 4, optimizer_student, criterion, trainx, trainy, False)\n",
    "    #train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\n",
    "    \n",
    "    pred      = get_prediction(model_student, valx)\n",
    "    val_dice1 = evaluate_result_new(pred, valy)\n",
    "    #print(pred.shape, len(val_dice1), valy.shape)\n",
    "    \n",
    "    pred          = get_prediction(model_student, testx)\n",
    "    student_dice2 = evaluate_result_new(pred, testy)\n",
    "    #print(pred.shape, len(student_dice2), testy.shape)\n",
    "    \n",
    "    #val_dice      = evaluate_result(model_student, valx,   valy)\n",
    "    student_dice1 = evaluate_result(model_student, trainx, trainy)\n",
    "    #student_dice2 = evaluate_result(model_student, testx,  testy)\n",
    "    \n",
    "    \n",
    "    train_dice_array.append(np.mean(student_dice1))\n",
    "    val_dice_array.append(np.mean(val_dice1))\n",
    "    test_dice_array.append(np.mean(student_dice2))\n",
    "\n",
    "    model_save_name = \"ipmi-attentionlstm-covid19\"\n",
    "    \n",
    "    if np.mean(val_dice1) > prev_max:\n",
    "        print(\"Step %d  Val Dice %.5f, Train Dice %f, Test Dice %f\" % (epoch, np.mean(val_dice1), np.mean(student_dice1), np.mean(student_dice2)))\n",
    "        prev_max     = np.mean(val_dice1)\n",
    "        torch.save(model_student.state_dict(), basepath_models+model_save_name+'-6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4,128,1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     22,
     44,
     51,
     60,
     91,
     115,
     146,
     156,
     180,
     200,
     233,
     256,
     284,
     296,
     327,
     393,
     466,
     503,
     521,
     563,
     617
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1, 512, 512) (5, 1, 512, 512) (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 0  Val Dice 0.40847, Train Dice 0.406240, Test Dice 0.550675\n",
      "1\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 1  Val Dice 0.52611, Train Dice 0.538528, Test Dice 0.641904\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 2  Val Dice 0.61439, Train Dice 0.608030, Test Dice 0.689462\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 3  Val Dice 0.69659, Train Dice 0.647938, Test Dice 0.715573\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 5  Val Dice 0.70109, Train Dice 0.670300, Test Dice 0.733683\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 6  Val Dice 0.71339, Train Dice 0.679548, Test Dice 0.740670\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 7  Val Dice 0.72831, Train Dice 0.712592, Test Dice 0.751639\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 8  Val Dice 0.74446, Train Dice 0.714466, Test Dice 0.756919\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 9  Val Dice 0.75278, Train Dice 0.715105, Test Dice 0.758331\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "11\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 12  Val Dice 0.77352, Train Dice 0.744654, Test Dice 0.740789\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "21\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "Step 22  Val Dice 0.77722, Train Dice 0.818739, Test Dice 0.775160\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n",
      "(5, 1, 512, 512) 5 (5, 1, 512, 512)\n",
      "(48, 1, 512, 512) 5 (48, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For training different models for comparison on COVID-19 dataset using SU-Net Model\n",
    "\n",
    "import skimage\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/home/yu-hao/SEMISUNET/Dataset/'\n",
    "basepath_models  = '/home/yu-hao/SEMISUNET/Dataset/models/'\n",
    "\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = F.sigmoid(pred)\n",
    "    \n",
    "    pred   = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        #output[output > 0.5]= 1\n",
    "        #output[output < 0.5]= 0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_predictions(models, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        models[i].eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(5):\n",
    "            output = models[k].forward(x)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.data.cpu().numpy()\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_sum = np.zeros(outputs[0].shape, dtype='float16')\n",
    "        for k in range(5):\n",
    "            output_sum = output_sum+outputs[k]\n",
    "        output_sum = output_sum/5.0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output_sum[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_filtered(valx, valy):\n",
    "    valxf = []\n",
    "    valyf = []\n",
    "    \n",
    "    for i in range(valx.shape[0]):\n",
    "        if np.count_nonzero(valy[i]) > 0:\n",
    "            valxf.append(valx[i])\n",
    "            valyf.append(valy[i])\n",
    "    return np.array(valxf), np.array(valyf)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def evaluate_result_new(pred, valy):\n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        output = pred[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y      = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        \n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            t1 = scipy.ndimage.zoom(output[0, 0].astype('uint8'), 0.6875, order=0)\n",
    "            t2 = scipy.ndimage.zoom(y[0, 0].astype('uint8'),      0.6875, order=0)\n",
    "            #print(t1.shape, t2.shape)\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    \n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "    \n",
    "    idx    = np.random.permutation(trainx.shape[0])\n",
    "    trainx = trainx[idx]\n",
    "    trainy = trainy[idx]\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def prepare_batch(batch_size, k_means, trainx_l, trainy_l, h):\n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(int(batch_size/2)):\n",
    "        idx = random.randint(0, trainx_l.shape[0]-1)\n",
    "        c   = k_means.predict(np.reshape(trainx_l[idx].astype('float32'), [1, 512*512]))[0]\n",
    "        \n",
    "        a.append(trainx_l[idx])\n",
    "        b.append(trainy_l[idx])\n",
    "        \n",
    "        idx = random.randint(0, len(h[c])-1)\n",
    "        t1  = np.expand_dims(np.load(h[c][idx]), 0)\n",
    "        t2  = np.expand_dims(np.load(h[c][idx].replace('-x', '-y')), 0)\n",
    "        \n",
    "        a.append(t1)\n",
    "        b.append(t2)\n",
    "   \n",
    "    a1 = np.array(a).astype('float16')\n",
    "    b1 = np.array(b).astype('float16')\n",
    "   \n",
    "    return a1, b1\n",
    "\n",
    "def store_cluster_slices(model_teacher, k_means, version):\n",
    "    epoch_array = np.arange(79)\n",
    "    all_labels  = []\n",
    "    step_size   = 10 \n",
    "    count       = 0\n",
    "    \n",
    "    for epoch in epoch_array:\n",
    "        temp_index               = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "        trainx, trainx_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "        trainy                   = get_prediction(model_teacher, trainx)\n",
    "        \n",
    "        #trainy = np.load('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/PREDICTION-NUMPY/'+str(epoch)+'.npy')\n",
    "        trainy = np.reshape(trainy, [trainy.shape[0], 512*512])\n",
    "        #print(epoch, trainy.shape, trainx.shape)\n",
    "        \n",
    "        l1     = k_means.predict(trainy)\n",
    "        \n",
    "        for jt, t in enumerate(l1):\n",
    "            temp  = np.reshape(trainy[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-y.npy', temp)\n",
    "            \n",
    "            temp  = np.reshape(trainx[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-x.npy', temp)\n",
    "            \n",
    "            count = count+1\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_hash(version):\n",
    "    all_cluster_files = glob.glob('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/*.npy')\n",
    "    print('Version ', version, 'File name counts ', len(all_cluster_files))\n",
    "    filename_hash = {}\n",
    "    for i in range(50):\n",
    "        filename_hash[i] = []\n",
    "\n",
    "    for t in all_cluster_files:\n",
    "        filename_hash[int(t.split('/')[-1].split('-')[0])].append(t)\n",
    "    \n",
    "    return filename_hash\n",
    "\n",
    "def get_all_covid_lesions(valx, valy, lesion_size):\n",
    "    lesion_shapes_x = []\n",
    "    lesion_shapes_y = []\n",
    "    \n",
    "    for i in range(valy.shape[0]):\n",
    "        tx           = valx[i, 0]\n",
    "        blobs        = valy[i, 0]\n",
    "        blobs_labels = skimage.measure.label(blobs, background=0)\n",
    "        propsa       = skimage.measure.regionprops(blobs_labels)\n",
    "        \n",
    "        for k in range(len(propsa)):\n",
    "            temp = (blobs_labels == propsa[k].label).astype('uint8')\n",
    "            \n",
    "            temp_size = np.count_nonzero(temp.flatten().astype('uint8'))\n",
    "            if temp_size < lesion_size and temp_size > 5:\n",
    "                slice_x, slice_y = ndimage.find_objects(temp == 1)[0]\n",
    "                \n",
    "                roi_y = 1-temp[slice_x, slice_y]\n",
    "                roi_x = tx[slice_x, slice_y]*temp[slice_x, slice_y]\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x)\n",
    "                lesion_shapes_y.append(roi_y)\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x.T)\n",
    "                lesion_shapes_y.append(roi_y.T)\n",
    "                \n",
    "                lesion_shapes_x.append(np.rot90(roi_x, 180))\n",
    "                lesion_shapes_y.append(np.rot90(roi_y, 180))\n",
    "    \n",
    "    return lesion_shapes_x, lesion_shapes_y\n",
    "\n",
    "def get_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            i,j = np.nonzero(mask[t])\n",
    "            \n",
    "            index = random.randint(0, len(i)-1)\n",
    "            \n",
    "            i = i[index]\n",
    "            j = j[index]\n",
    "            \n",
    "            lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "            \n",
    "            lesion_x     = lesion_shapes_x[lesion_index]\n",
    "            lesion_y     = lesion_shapes_y[lesion_index]\n",
    "            \n",
    "            sx     = int(lesion_x.shape[0]/2)\n",
    "            sy     = int(lesion_x.shape[1]/2)\n",
    "            \n",
    "            if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                m1         = m1*mask[t]\n",
    "                m1[m1 > 0] = 1\n",
    "\n",
    "                x_array.append(np.expand_dims(st,          axis=0))\n",
    "                x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "\n",
    "                count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_multiple_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            #segmen\n",
    "            ipl, jpl = np.nonzero(mask[t])\n",
    "            \n",
    "            lesion_count = random.randint(0, 5)\n",
    "            temp_count   = 0\n",
    "            \n",
    "            while(temp_count < lesion_count):\n",
    "                index = random.randint(0, len(ipl)-1)\n",
    "\n",
    "                i = ipl[index]\n",
    "                j = jpl[index]\n",
    "\n",
    "                lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "\n",
    "                lesion_x     = lesion_shapes_x[lesion_index]\n",
    "                lesion_y     = lesion_shapes_y[lesion_index]\n",
    "\n",
    "                sx     = int(lesion_x.shape[0]/2)\n",
    "                sy     = int(lesion_x.shape[1]/2)\n",
    "\n",
    "                if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                    m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                    m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                    m1         = m1*mask[t]\n",
    "                    m1[m1 > 0] = 1\n",
    "                    segmentation_mask[t] = m1\n",
    "                    temp_count           = temp_count + 1\n",
    "            \n",
    "            x_array.append(np.expand_dims(st,          axis=0))\n",
    "            x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "            \n",
    "            count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def plot_figure_slope(model_save_name):\n",
    "    N = 2\n",
    "    a = val_dice_array1#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = train_dice_array1#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = test_dice_array1#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    temp  = 0\n",
    "    slope = 0\n",
    "    #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "    for i in range(1, len(a)):\n",
    "        if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "            temp  = i#np.argmax(a)\n",
    "            slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "            #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "\n",
    "def plot_figure(model_save_name):\n",
    "    a = list(val_dice_array)#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = list(train_dice_array)#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = list(test_dice_array)#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    #a.insert(0, 0)\n",
    "    #b.insert(0, 0)\n",
    "    #c.insert(0, 0)\n",
    "#     temp  = 0\n",
    "#     slope = 0\n",
    "#     #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "#     for i in range(1, len(a)):\n",
    "#         if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "#             temp  = i#np.argmax(a)\n",
    "#             slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "#             #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    # Take arg max for semi model\n",
    "    temp = np.argmax(a)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    #plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def train_model1(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "        #x2 = model.forward(x)        \n",
    "        #print(x2.shape)\n",
    "        \n",
    "#         lstm = nn.LSTM(512*512,512*512,batchfirst=True)\n",
    "#         hidden = (torch.randn(1, 512, 512), torch.randn(1, 512, 512))\n",
    "#         outlstm = lstm(x, hidden)\n",
    "#         n = np.asarray(outlstm)\n",
    "  \n",
    "        print(i, x.shape[0])\n",
    "        \n",
    "        if(x.shape[0]!= 4):\n",
    "            break\n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        y = np.expand_dims(y, 1)\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def train_model2(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    #batch_size = 4\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        \n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "  \n",
    "        if(x.shape[0]!=4):\n",
    "            break\n",
    "            \n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        \n",
    "\n",
    "        y = np.expand_dims(y, 1)\n",
    "\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "# train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "# val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "# test_ids       = np.load(basepath+'TEST.npy')\n",
    "# unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "# nocovid_ids    = np.load(basepath+'NOCOVID.npy')\n",
    "\n",
    "\n",
    "# unlabelled_ids     = unlabelled_ids\n",
    "# train_ids          = train_ids[:4]\n",
    "# val_ids            = val_ids\n",
    "# test_ids           = test_ids\n",
    "\n",
    "trainx_l = np.load(basepath+'train_x.npy')/255.0\n",
    "trainy_l = np.load(basepath+'train_y.npy')\n",
    "trainy_l[trainy_l > 0] = 1\n",
    "\n",
    "#index    = np.random.permutation(trainx_l.shape[0])\n",
    "#trainx_l = trainx_l[index]\n",
    "#trainy_l = trainy_l[index]\n",
    "\n",
    "train_size    = 45\n",
    "valx = trainx_l[train_size:]\n",
    "valy = trainy_l[train_size:]\n",
    "\n",
    "trainx_l = trainx_l[:train_size]\n",
    "trainy_l = trainy_l[:train_size]\n",
    "\n",
    "testx = np.load(basepath+'test_x.npy')/255.0\n",
    "testy = np.load(basepath+'test_y.npy')\n",
    "testy[testy > 0] = 1\n",
    "\n",
    "\n",
    "trainx_l1 = np.zeros([trainx_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valx1     = np.zeros([valx.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testx1    = np.zeros([testx.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "trainy_l1 = np.zeros([trainy_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valy1     = np.zeros([valy.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testy1    = np.zeros([testy.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "\n",
    "for i in range(trainx_l.shape[0]):\n",
    "    trainx_l1[i, 0] = scipy.ndimage.zoom(trainx_l[i], 2, order=3)\n",
    "    trainy_l1[i, 0] = scipy.ndimage.zoom(trainy_l[i], 2, order=0)\n",
    "\n",
    "for i in range(valx.shape[0]):\n",
    "    valx1[i, 0] = scipy.ndimage.zoom(valx[i], 2, order=3)\n",
    "    valy1[i, 0] = scipy.ndimage.zoom(valy[i], 2, order=0)\n",
    "\n",
    "for i in range(testx.shape[0]):\n",
    "    testx1[i, 0] = scipy.ndimage.zoom(testx[i], 2, order=3)\n",
    "    testy1[i, 0] = scipy.ndimage.zoom(testy[i], 2, order=0)\n",
    "\n",
    "\n",
    "trainx_l = trainx_l1\n",
    "trainy_l = trainy_l1\n",
    "valx = valx1\n",
    "valy = valy1\n",
    "testx = testx1\n",
    "testy = testy1\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "prev_max        = -1000\n",
    "model_student   = SUNet(1, 1)\n",
    "model_student.cuda()\n",
    "\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0001)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "\n",
    "val_dice_array   = []\n",
    "train_dice_array = []\n",
    "test_dice_array  = []\n",
    "\n",
    "trainx, trainy   = trainx_l, trainy_l\n",
    "trainx, trainy   = sort_data(trainx_l, trainy_l)\n",
    "total_epochs = 30\n",
    "\n",
    "\n",
    "# trainx = np.expand_dims(trainx, axis=1)\n",
    "# trainy = np.expand_dims(trainy, axis=1)\n",
    "\n",
    "# valx   = np.expand_dims(valx, axis=1)\n",
    "# valy   = np.expand_dims(valy, axis=1)\n",
    "\n",
    "# testx  = np.expand_dims(testx, axis=1)\n",
    "# testy  = np.expand_dims(testy, axis=1)\n",
    "\n",
    "teacher_dice_array = []\n",
    "test_dice_array    = []\n",
    "\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch%10 ==1:\n",
    "        print(epoch)\n",
    "    #train_model1(model, optimizer, criterion, trainx, trainy, augment=False)\n",
    "    train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\n",
    "    #train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\n",
    "    \n",
    "    pred      = get_prediction(model_student, valx)\n",
    "    val_dice1 = evaluate_result_new(pred, valy)\n",
    "    print(pred.shape, len(val_dice1), valy.shape)\n",
    "    \n",
    "    pred          = get_prediction(model_student, testx)\n",
    "    student_dice2 = evaluate_result_new(pred, testy)\n",
    "    print(pred.shape, len(student_dice2), testy.shape)\n",
    "    \n",
    "    #val_dice      = evaluate_result(model_student, valx,   valy)\n",
    "    student_dice1 = evaluate_result(model_student, trainx, trainy)\n",
    "    #student_dice2 = evaluate_result(model_student, testx,  testy)\n",
    "    \n",
    "    \n",
    "    train_dice_array.append(np.mean(student_dice1))\n",
    "    val_dice_array.append(np.mean(val_dice1))\n",
    "    test_dice_array.append(np.mean(student_dice2))\n",
    "\n",
    "    model_save_name = \"ipmi-sunet-covid19\"\n",
    "    \n",
    "    if np.mean(val_dice1) > prev_max:\n",
    "        print(\"Step %d  Val Dice %.5f, Train Dice %f, Test Dice %f\" % (epoch, np.mean(val_dice1), np.mean(student_dice1), np.mean(student_dice2)))\n",
    "        prev_max     = np.mean(val_dice1)\n",
    "        torch.save(model_student.state_dict(), basepath_models+model_save_name+'-6.pt')\n",
    "\n",
    "    #np.save(model_save_name+'_train.npy',      train_dice_array)\n",
    "    #np.save(model_save_name+'_validation.npy', val_dice_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 2 GN\n",
    "# (45, 1, 512, 512) (5, 1, 512, 512) (48, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.00000, Train Dice 0.000000, Test Dice 0.000000\n",
    "# 1\n",
    "# Step 6  Val Dice 0.05016, Train Dice 0.118959, Test Dice 0.103342\n",
    "# Step 7  Val Dice 0.31815, Train Dice 0.349599, Test Dice 0.307122\n",
    "# Step 8  Val Dice 0.63631, Train Dice 0.543914, Test Dice 0.578809\n",
    "# Step 9  Val Dice 0.68335, Train Dice 0.621097, Test Dice 0.635156\n",
    "# Step 10  Val Dice 0.69556, Train Dice 0.637887, Test Dice 0.651901\n",
    "# 11\n",
    "# Step 13  Val Dice 0.70388, Train Dice 0.646838, Test Dice 0.665426\n",
    "# Step 14  Val Dice 0.70715, Train Dice 0.654906, Test Dice 0.670942\n",
    "# Step 20  Val Dice 0.71351, Train Dice 0.662403, Test Dice 0.674490\n",
    "# 21\n",
    "# Step 21  Val Dice 0.71357, Train Dice 0.668946, Test Dice 0.669391\n",
    "# Step 24  Val Dice 0.72196, Train Dice 0.666852, Test Dice 0.682729\n",
    "# Step 27  Val Dice 0.72361, Train Dice 0.687283, Test Dice 0.683081\n",
    "# Step 30  Val Dice 0.73600, Train Dice 0.696675, Test Dice 0.692754\n",
    "# 31\n",
    "# Step 36  Val Dice 0.73605, Train Dice 0.702647, Test Dice 0.666775\n",
    "# Step 37  Val Dice 0.75148, Train Dice 0.710645, Test Dice 0.671546\n",
    "# 41\n",
    "# Step 44  Val Dice 0.75176, Train Dice 0.713824, Test Dice 0.652402\n",
    "# Step 45  Val Dice 0.76012, Train Dice 0.744207, Test Dice 0.689487\n",
    "# Step 46  Val Dice 0.77758, Train Dice 0.743573, Test Dice 0.683576\n",
    "# 51\n",
    "# 61\n",
    "# Step 61  Val Dice 0.77897, Train Dice 0.743691, Test Dice 0.692439\n",
    "# Step 65  Val Dice 0.77912, Train Dice 0.763989, Test Dice 0.692671\n",
    "# Step 66  Val Dice 0.77998, Train Dice 0.783560, Test Dice 0.706940\n",
    "# 71\n",
    "# 81\n",
    "# Step 81  Val Dice 0.78727, Train Dice 0.797163, Test Dice 0.701257\n",
    "\n",
    "# 4 GN\n",
    "# (45, 1, 512, 512) (5, 1, 512, 512) (48, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.00000, Train Dice 0.000000, Test Dice 0.000001\n",
    "# 1\n",
    "# Step 4  Val Dice 0.11335, Train Dice 0.059222, Test Dice 0.060365\n",
    "# Step 5  Val Dice 0.52040, Train Dice 0.461123, Test Dice 0.436235\n",
    "# Step 6  Val Dice 0.68600, Train Dice 0.626483, Test Dice 0.622587\n",
    "# Step 9  Val Dice 0.70716, Train Dice 0.667402, Test Dice 0.657514\n",
    "# Step 10  Val Dice 0.72560, Train Dice 0.686944, Test Dice 0.671868\n",
    "# 11\n",
    "# Step 13  Val Dice 0.73194, Train Dice 0.692215, Test Dice 0.660874\n",
    "# Step 14  Val Dice 0.74235, Train Dice 0.701571, Test Dice 0.671201\n",
    "# Step 16  Val Dice 0.74756, Train Dice 0.704440, Test Dice 0.683192\n",
    "# Step 19  Val Dice 0.75899, Train Dice 0.710249, Test Dice 0.669616\n",
    "# Step 20  Val Dice 0.76912, Train Dice 0.744263, Test Dice 0.689958\n",
    "# 21\n",
    "# Step 28  Val Dice 0.77397, Train Dice 0.765428, Test Dice 0.692351\n",
    "# 31\n",
    "# Step 33  Val Dice 0.77443, Train Dice 0.785372, Test Dice 0.709192\n",
    "# Step 38  Val Dice 0.78444, Train Dice 0.792295, Test Dice 0.686179\n",
    "# 41\n",
    "# Step 41  Val Dice 0.78921, Train Dice 0.781758, Test Dice 0.687306\n",
    "# 51\n",
    "# 61\n",
    "# 71\n",
    "# 81\n",
    "# 91\n",
    "# 101\n",
    "# 111\n",
    "# 121\n",
    "# 131\n",
    "# 141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Sort\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.00027, Train Dice 0.001213, Test Dice 0.001755\n",
    "# 1\n",
    "# Step 7  Val Dice 0.00382, Train Dice 0.076572, Test Dice 0.054568\n",
    "# Step 8  Val Dice 0.31308, Train Dice 0.248025, Test Dice 0.250341\n",
    "# Step 9  Val Dice 0.60493, Train Dice 0.452303, Test Dice 0.445337\n",
    "# Step 10  Val Dice 0.70992, Train Dice 0.664974, Test Dice 0.652485\n",
    "# 11\n",
    "# Step 11  Val Dice 0.73933, Train Dice 0.652466, Test Dice 0.646877\n",
    "# Step 12  Val Dice 0.74122, Train Dice 0.713898, Test Dice 0.702860\n",
    "# Step 13  Val Dice 0.76766, Train Dice 0.722366, Test Dice 0.689882\n",
    "# Step 19  Val Dice 0.77753, Train Dice 0.765109, Test Dice 0.718724\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78552, Train Dice 0.778215, Test Dice 0.698430\n",
    "# Step 22  Val Dice 0.78576, Train Dice 0.762371, Test Dice 0.676977\n",
    "# Step 27  Val Dice 0.79172, Train Dice 0.801648, Test Dice 0.696595\n",
    "\n",
    "# Non sort\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.47310, Train Dice 0.414437, Test Dice 0.457420\n",
    "# 1\n",
    "# Step 1  Val Dice 0.62207, Train Dice 0.525722, Test Dice 0.565086\n",
    "# Step 2  Val Dice 0.62731, Train Dice 0.539318, Test Dice 0.562520\n",
    "# Step 3  Val Dice 0.66079, Train Dice 0.576287, Test Dice 0.590151\n",
    "# Step 5  Val Dice 0.66563, Train Dice 0.573630, Test Dice 0.571538\n",
    "# Step 6  Val Dice 0.69991, Train Dice 0.634576, Test Dice 0.628347\n",
    "# Step 7  Val Dice 0.72765, Train Dice 0.634495, Test Dice 0.625526\n",
    "# Step 8  Val Dice 0.74690, Train Dice 0.681710, Test Dice 0.675751\n",
    "# 11\n",
    "# Step 11  Val Dice 0.76492, Train Dice 0.708205, Test Dice 0.687793\n",
    "# Step 14  Val Dice 0.77187, Train Dice 0.736016, Test Dice 0.693092\n",
    "# Step 16  Val Dice 0.78225, Train Dice 0.737534, Test Dice 0.680775\n",
    "# 21\n",
    "# Step 23  Val Dice 0.79977, Train Dice 0.783781, Test Dice 0.695209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "code_folding": [
     0,
     22,
     44,
     51,
     60,
     91,
     115,
     146,
     156,
     180,
     213,
     236,
     264,
     276,
     307,
     373,
     446,
     483,
     501,
     543,
     597
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1, 512, 512) (5, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
      "Step 0  Val Dice 0.77634, Train Dice 0.153924, Test Dice 0.723316\n",
      "1\n",
      "Step 1  Val Dice 0.76877, Train Dice 0.116518, Test Dice 0.705424\n",
      "Step 2  Val Dice 0.73067, Train Dice 0.094445, Test Dice 0.683303\n",
      "Step 3  Val Dice 0.77280, Train Dice 0.142163, Test Dice 0.717842\n",
      "Step 4  Val Dice 0.77123, Train Dice 0.139559, Test Dice 0.715836\n",
      "Step 5  Val Dice 0.77141, Train Dice 0.139238, Test Dice 0.715969\n",
      "Step 6  Val Dice 0.77118, Train Dice 0.139625, Test Dice 0.715823\n",
      "Step 7  Val Dice 0.77121, Train Dice 0.136001, Test Dice 0.715501\n",
      "Step 8  Val Dice 0.77273, Train Dice 0.143900, Test Dice 0.715735\n",
      "Step 9  Val Dice 0.77085, Train Dice 0.139977, Test Dice 0.715868\n",
      "Step 10  Val Dice 0.77275, Train Dice 0.135950, Test Dice 0.714477\n",
      "11\n",
      "Step 11  Val Dice 0.77103, Train Dice 0.145491, Test Dice 0.716586\n",
      "Step 12  Val Dice 0.77145, Train Dice 0.137945, Test Dice 0.714228\n",
      "Step 13  Val Dice 0.77043, Train Dice 0.137131, Test Dice 0.716093\n",
      "Step 14  Val Dice 0.76861, Train Dice 0.141842, Test Dice 0.714246\n",
      "Step 15  Val Dice 0.77357, Train Dice 0.145900, Test Dice 0.716719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-843088dd69fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;31m#train_model1(model, optimizer, criterion, trainx, trainy, augment=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m     \u001b[0;31m#train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-843088dd69fe>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, batch_size, optimizer, criterion, trainx, trainy, augment)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mloss_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# [STAR] Semi-supervised training SU-Net Model\n",
    "\n",
    "import skimage\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/'\n",
    "basepath_models  = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/models/'\n",
    "\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = F.sigmoid(pred)\n",
    "    \n",
    "    pred   = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, datax):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(datax)//batch_size):\n",
    "        x = datax[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        #output[output > 0.5]= 1\n",
    "        #output[output < 0.5]= 0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_predictions(models, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        models[i].eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(5):\n",
    "            output = models[k].forward(x)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.data.cpu().numpy()\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_sum = np.zeros(outputs[0].shape, dtype='float16')\n",
    "        for k in range(5):\n",
    "            output_sum = output_sum+outputs[k]\n",
    "        output_sum = output_sum/5.0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output_sum[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_filtered(valx, valy):\n",
    "    valxf = []\n",
    "    valyf = []\n",
    "    \n",
    "    for i in range(valx.shape[0]):\n",
    "        if np.count_nonzero(valy[i]) > 0:\n",
    "            valxf.append(valx[i])\n",
    "            valyf.append(valy[i])\n",
    "    return np.array(valxf), np.array(valyf)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "    \n",
    "    idx    = np.random.permutation(trainx.shape[0])\n",
    "    trainx = trainx[idx]\n",
    "    trainy = trainy[idx]\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def prepare_batch(batch_size, k_means, trainx_l, trainy_l, h):\n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(int(batch_size/2)):\n",
    "        idx = random.randint(0, trainx_l.shape[0]-1)\n",
    "        c   = k_means.predict(np.reshape(trainx_l[idx].astype('float32'), [1, 512*512]))[0]\n",
    "        \n",
    "        a.append(trainx_l[idx])\n",
    "        b.append(trainy_l[idx])\n",
    "        \n",
    "        idx = random.randint(0, len(h[c])-1)\n",
    "        t1  = np.expand_dims(np.load(h[c][idx]), 0)\n",
    "        t2  = np.expand_dims(np.load(h[c][idx].replace('-x', '-y')), 0)\n",
    "        \n",
    "        a.append(t1)\n",
    "        b.append(t2)\n",
    "   \n",
    "    a1 = np.array(a).astype('float16')\n",
    "    b1 = np.array(b).astype('float16')\n",
    "   \n",
    "    return a1, b1\n",
    "\n",
    "def store_cluster_slices(model_teacher, k_means, version):\n",
    "    epoch_array = np.arange(79)\n",
    "    all_labels  = []\n",
    "    step_size   = 10 \n",
    "    count       = 0\n",
    "    \n",
    "    for epoch in epoch_array:\n",
    "        temp_index               = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "        trainx, trainx_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "        trainy                   = get_prediction(model_teacher, trainx)\n",
    "        \n",
    "        #trainy = np.load('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/PREDICTION-NUMPY/'+str(epoch)+'.npy')\n",
    "        trainy = np.reshape(trainy, [trainy.shape[0], 512*512])\n",
    "        #print(epoch, trainy.shape, trainx.shape)\n",
    "        \n",
    "        l1     = k_means.predict(trainy)\n",
    "        \n",
    "        for jt, t in enumerate(l1):\n",
    "            temp  = np.reshape(trainy[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-y.npy', temp)\n",
    "            \n",
    "            temp  = np.reshape(trainx[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-x.npy', temp)\n",
    "            \n",
    "            count = count+1\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_hash(version):\n",
    "    all_cluster_files = glob.glob('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/*.npy')\n",
    "    print('Version ', version, 'File name counts ', len(all_cluster_files))\n",
    "    filename_hash = {}\n",
    "    for i in range(50):\n",
    "        filename_hash[i] = []\n",
    "\n",
    "    for t in all_cluster_files:\n",
    "        filename_hash[int(t.split('/')[-1].split('-')[0])].append(t)\n",
    "    \n",
    "    return filename_hash\n",
    "\n",
    "def get_all_covid_lesions(valx, valy, lesion_size):\n",
    "    lesion_shapes_x = []\n",
    "    lesion_shapes_y = []\n",
    "    \n",
    "    for i in range(valy.shape[0]):\n",
    "        tx           = valx[i, 0]\n",
    "        blobs        = valy[i, 0]\n",
    "        blobs_labels = skimage.measure.label(blobs, background=0)\n",
    "        propsa       = skimage.measure.regionprops(blobs_labels)\n",
    "        \n",
    "        for k in range(len(propsa)):\n",
    "            temp = (blobs_labels == propsa[k].label).astype('uint8')\n",
    "            \n",
    "            temp_size = np.count_nonzero(temp.flatten().astype('uint8'))\n",
    "            if temp_size < lesion_size and temp_size > 5:\n",
    "                slice_x, slice_y = ndimage.find_objects(temp == 1)[0]\n",
    "                \n",
    "                roi_y = 1-temp[slice_x, slice_y]\n",
    "                roi_x = tx[slice_x, slice_y]*temp[slice_x, slice_y]\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x)\n",
    "                lesion_shapes_y.append(roi_y)\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x.T)\n",
    "                lesion_shapes_y.append(roi_y.T)\n",
    "                \n",
    "                lesion_shapes_x.append(np.rot90(roi_x, 180))\n",
    "                lesion_shapes_y.append(np.rot90(roi_y, 180))\n",
    "    \n",
    "    return lesion_shapes_x, lesion_shapes_y\n",
    "\n",
    "def get_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            i,j = np.nonzero(mask[t])\n",
    "            \n",
    "            index = random.randint(0, len(i)-1)\n",
    "            \n",
    "            i = i[index]\n",
    "            j = j[index]\n",
    "            \n",
    "            lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "            \n",
    "            lesion_x     = lesion_shapes_x[lesion_index]\n",
    "            lesion_y     = lesion_shapes_y[lesion_index]\n",
    "            \n",
    "            sx     = int(lesion_x.shape[0]/2)\n",
    "            sy     = int(lesion_x.shape[1]/2)\n",
    "            \n",
    "            if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                m1         = m1*mask[t]\n",
    "                m1[m1 > 0] = 1\n",
    "\n",
    "                x_array.append(np.expand_dims(st,          axis=0))\n",
    "                x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "\n",
    "                count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_multiple_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            #segmen\n",
    "            ipl, jpl = np.nonzero(mask[t])\n",
    "            \n",
    "            lesion_count = random.randint(0, 5)\n",
    "            temp_count   = 0\n",
    "            \n",
    "            while(temp_count < lesion_count):\n",
    "                index = random.randint(0, len(ipl)-1)\n",
    "\n",
    "                i = ipl[index]\n",
    "                j = jpl[index]\n",
    "\n",
    "                lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "\n",
    "                lesion_x     = lesion_shapes_x[lesion_index]\n",
    "                lesion_y     = lesion_shapes_y[lesion_index]\n",
    "\n",
    "                sx     = int(lesion_x.shape[0]/2)\n",
    "                sy     = int(lesion_x.shape[1]/2)\n",
    "\n",
    "                if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                    m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                    m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                    m1         = m1*mask[t]\n",
    "                    m1[m1 > 0] = 1\n",
    "                    segmentation_mask[t] = m1\n",
    "                    temp_count           = temp_count + 1\n",
    "            \n",
    "            x_array.append(np.expand_dims(st,          axis=0))\n",
    "            x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "            \n",
    "            count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def plot_figure_slope(model_save_name):\n",
    "    N = 2\n",
    "    a = val_dice_array1#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = train_dice_array1#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = test_dice_array1#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    temp  = 0\n",
    "    slope = 0\n",
    "    #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "    for i in range(1, len(a)):\n",
    "        if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "            temp  = i#np.argmax(a)\n",
    "            slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "            #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "\n",
    "def plot_figure(model_save_name):\n",
    "    a = list(val_dice_array)#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = list(train_dice_array)#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = list(test_dice_array)#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    #a.insert(0, 0)\n",
    "    #b.insert(0, 0)\n",
    "    #c.insert(0, 0)\n",
    "#     temp  = 0\n",
    "#     slope = 0\n",
    "#     #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "#     for i in range(1, len(a)):\n",
    "#         if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "#             temp  = i#np.argmax(a)\n",
    "#             slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "#             #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    # Take arg max for semi model\n",
    "    temp = np.argmax(a)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    #plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def train_model1(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "        #x2 = model.forward(x)        \n",
    "        #print(x2.shape)\n",
    "        \n",
    "#         lstm = nn.LSTM(512*512,512*512,batchfirst=True)\n",
    "#         hidden = (torch.randn(1, 512, 512), torch.randn(1, 512, 512))\n",
    "#         outlstm = lstm(x, hidden)\n",
    "#         n = np.asarray(outlstm)\n",
    "  \n",
    "        print(i, x.shape[0])\n",
    "        \n",
    "        if(x.shape[0]!= 4):\n",
    "            break\n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        y = np.expand_dims(y, 1)\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def train_model2(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    #batch_size = 4\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        \n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "  \n",
    "        if(x.shape[0]!=4):\n",
    "            break\n",
    "            \n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        \n",
    "\n",
    "        y = np.expand_dims(y, 1)\n",
    "\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "# train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "# val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "# test_ids       = np.load(basepath+'TEST.npy')\n",
    "# unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "# nocovid_ids    = np.load(basepath+'NOCOVID.npy')\n",
    "\n",
    "\n",
    "# unlabelled_ids     = unlabelled_ids\n",
    "# train_ids          = train_ids[:4]\n",
    "# val_ids            = val_ids\n",
    "# test_ids           = test_ids\n",
    "\n",
    "trainx_l = np.load(basepath+'train_x.npy')/255.0\n",
    "trainy_l = np.load(basepath+'train_y.npy')\n",
    "trainy_l[trainy_l > 0] = 1\n",
    "\n",
    "train_size    = 45\n",
    "valx = trainx_l[train_size:]\n",
    "valy = trainy_l[train_size:]\n",
    "\n",
    "trainx_l = trainx_l[:train_size]\n",
    "trainy_l = trainy_l[:train_size]\n",
    "\n",
    "testx = np.load(basepath+'test_x.npy')/255.0\n",
    "testy = np.load(basepath+'test_y.npy')\n",
    "testy[testy > 0] = 1\n",
    "\n",
    "unlabelledx_l = np.load(basepath+'unlabelled_x.npy')/255.0\n",
    "\n",
    "\n",
    "trainx_l1 = np.zeros([trainx_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valx1     = np.zeros([valx.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testx1    = np.zeros([testx.shape[0], 1, 512, 512],    dtype='float16')\n",
    "unlabelledx1    = np.zeros([unlabelledx_l.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "trainy_l1 = np.zeros([trainy_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valy1     = np.zeros([valy.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testy1    = np.zeros([testy.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "for i in range(trainx_l.shape[0]):\n",
    "    trainx_l1[i, 0] = scipy.ndimage.zoom(trainx_l[i], 2, order=3)\n",
    "    trainy_l1[i, 0] = scipy.ndimage.zoom(trainy_l[i], 2, order=0)\n",
    "\n",
    "for i in range(valx.shape[0]):\n",
    "    valx1[i, 0] = scipy.ndimage.zoom(valx[i], 2, order=3)\n",
    "    valy1[i, 0] = scipy.ndimage.zoom(valy[i], 2, order=0)\n",
    "\n",
    "for i in range(testx.shape[0]):\n",
    "    testx1[i, 0] = scipy.ndimage.zoom(testx[i], 2, order=3)\n",
    "    testy1[i, 0] = scipy.ndimage.zoom(testy[i], 2, order=0)\n",
    "\n",
    "for i in range(unlabelledx1.shape[0]):\n",
    "    unlabelledx1[i, 0] = scipy.ndimage.zoom(unlabelledx_l[i], 2, order=3)\n",
    "    #testy1[i, 0] = scipy.ndimage.zoom(unlabelledy1[i], 2, order=0)\n",
    "\n",
    "model_student   = SUNet(1, 1)\n",
    "model_student.cuda()\n",
    "p1         = torch.load(basepath_models+\"tmi-compare-sunet-covid19-30.pt\")\n",
    "model_student.load_state_dict(p1)\n",
    "\n",
    "\n",
    "unlabelledy1 = get_prediction(model_student, unlabelledx1)\n",
    "\n",
    "trainx_l = trainx_l1\n",
    "trainy_l = trainy_l1\n",
    "valx = valx1\n",
    "valy = valy1\n",
    "testx = testx1\n",
    "testy = testy1\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape, unlabelledy1.shape)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "prev_max        = -1000\n",
    "model_student   = SUNet(1, 1)\n",
    "model_student.cuda()\n",
    "p1         = torch.load(basepath_models+\"tmi-compare-sunet-covid19-30.pt\")\n",
    "model_student.load_state_dict(p1)\n",
    "\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0001)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "#criterion          = nn.MSELoss()\n",
    "\n",
    "val_dice_array   = []\n",
    "train_dice_array = []\n",
    "test_dice_array  = []\n",
    "\n",
    "#trainy[trainy > 0.5] = 1\n",
    "#trainy[trainy < 0.5] = 0\n",
    "total_epochs     = 1000\n",
    "#trainx, trainy   = sort_data(trainx, trainy)\n",
    "\n",
    "trainx = trainx#[800:]\n",
    "trainy = trainy#[800:]\n",
    "# trainx = np.expand_dims(trainx, axis=1)\n",
    "# trainy = np.expand_dims(trainy, axis=1)\n",
    "\n",
    "# valx   = np.expand_dims(valx, axis=1)\n",
    "# valy   = np.expand_dims(valy, axis=1)\n",
    "\n",
    "# testx  = np.expand_dims(testx, axis=1)\n",
    "# testy  = np.expand_dims(testy, axis=1)\n",
    "\n",
    "teacher_dice_array = []\n",
    "test_dice_array    = []\n",
    "\n",
    "index        = np.random.permutation(np.arange(len(unlabelledx1)))\n",
    "unlabelledx1 = unlabelledx1[index]\n",
    "unlabelledy1 = unlabelledy1[index]\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch%10 ==1:\n",
    "        print(epoch)\n",
    "    \n",
    "    # Re-generate pseudo labels again\n",
    "    if epoch%5 == 0:\n",
    "        step_size        = len(unlabelledx1)//20-1\n",
    "        inputx           = unlabelledx1#[0:(1+epoch%20)*step_size]\n",
    "        unlabelledy1     = get_prediction(model_student, inputx)\n",
    "        #unlabelledy1[unlabelledy1 < 0.5] = 0\n",
    "        #unlabelledy1[unlabelledy1 > 0.5] = 1\n",
    "        trainx_l1        = inputx#np.concatenate([trainx_l, inputx], axis=0)\n",
    "        trainy_l1        = unlabelledy1#np.concatenate([trainy_l, unlabelledy1], axis=0)\n",
    "        trainx, trainy   = sort_data(trainx_l1, trainy_l1)\n",
    "    \n",
    "    #train_model1(model, optimizer, criterion, trainx, trainy, augment=False)\n",
    "    train_loss    = train_model(model_student, 4, optimizer_student, criterion, trainx, trainy, False)\n",
    "    #train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\n",
    "    \n",
    "    val_dice      = evaluate_result(model_student, valx,   valy)\n",
    "    student_dice1 = evaluate_result(model_student, trainx, trainy)\n",
    "    student_dice2 = evaluate_result(model_student, testx,  testy)\n",
    "    \n",
    "    \n",
    "    train_dice_array.append(np.mean(student_dice1))\n",
    "    val_dice_array.append(np.mean(val_dice))\n",
    "    test_dice_array.append(np.mean(student_dice2))\n",
    "    \n",
    "    \n",
    "    model_save_name = \"tmi-compare-sunet-covid19-semi\"\n",
    "    \n",
    "    #if np.mean(val_dice) > prev_max:\n",
    "    print(\"Step %d  Val Dice %.5f, Train Dice %f, Test Dice %f\" % (epoch, np.mean(val_dice), np.mean(student_dice1), np.mean(student_dice2)))\n",
    "    prev_max     = np.mean(val_dice)\n",
    "    torch.save(model_student.state_dict(), basepath_models+model_save_name+'-'+str(epoch)+\".pt\")\n",
    "\n",
    "    #np.save(model_save_name+'_train.npy',      train_dice_array)\n",
    "    #np.save(model_save_name+'_validation.npy', val_dice_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1, 512, 512) (316, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(inputx.shape, unlabelledy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Without threshdoling\n",
    "\n",
    "# Non-Iterative Without threshdoling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Without Thresholding SU-Net covid-19\n",
    "\n",
    "# All\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.76960, Train Dice 0.086486, Test Dice 0.695945\n",
    "# 1\n",
    "# Step 1  Val Dice 0.76680, Train Dice 0.088690, Test Dice 0.678503\n",
    "# Step 2  Val Dice 0.75676, Train Dice 0.090160, Test Dice 0.709546\n",
    "# Step 3  Val Dice 0.76640, Train Dice 0.085630, Test Dice 0.672755\n",
    "# Step 4  Val Dice 0.75804, Train Dice 0.096443, Test Dice 0.722479\n",
    "# Step 5  Val Dice 0.76218, Train Dice 0.092003, Test Dice 0.719346\n",
    "# Step 6  Val Dice 0.78326, Train Dice 0.089921, Test Dice 0.710196\n",
    "# Step 7  Val Dice 0.74530, Train Dice 0.100489, Test Dice 0.725772\n",
    "# Step 8  Val Dice 0.76933, Train Dice 0.096645, Test Dice 0.724160\n",
    "# Step 9  Val Dice 0.77539, Train Dice 0.081607, Test Dice 0.671963\n",
    "# Step 10  Val Dice 0.78023, Train Dice 0.089463, Test Dice 0.706236\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78315, Train Dice 0.086977, Test Dice 0.705594\n",
    "# Step 12  Val Dice 0.78709, Train Dice 0.093157, Test Dice 0.710461\n",
    "# Step 13  Val Dice 0.69627, Train Dice 0.062377, Test Dice 0.568129\n",
    "# Step 14  Val Dice 0.77469, Train Dice 0.096401, Test Dice 0.727789\n",
    "# Step 15  Val Dice 0.77551, Train Dice 0.092316, Test Dice 0.700556\n",
    "# Step 16  Val Dice 0.77993, Train Dice 0.085810, Test Dice 0.697788\n",
    "# Step 17  Val Dice 0.78453, Train Dice 0.094763, Test Dice 0.720082\n",
    "# Step 18  Val Dice 0.79124, Train Dice 0.092550, Test Dice 0.709006\n",
    "# Step 19  Val Dice 0.78343, Train Dice 0.091609, Test Dice 0.709662\n",
    "# Step 20  Val Dice 0.78500, Train Dice 0.093218, Test Dice 0.714936\n",
    "# 21\n",
    "# Step 21  Val Dice 0.77866, Train Dice 0.089802, Test Dice 0.697119\n",
    "# Step 22  Val Dice 0.77554, Train Dice 0.096152, Test Dice 0.716012\n",
    "# Step 23  Val Dice 0.78234, Train Dice 0.092014, Test Dice 0.712717\n",
    "# Step 24  Val Dice 0.78059, Train Dice 0.095741, Test Dice 0.716026\n",
    "# Step 25  Val Dice 0.78056, Train Dice 0.096267, Test Dice 0.716681\n",
    "# Step 26  Val Dice 0.77195, Train Dice 0.087644, Test Dice 0.690997\n",
    "# Step 27  Val Dice 0.77858, Train Dice 0.098494, Test Dice 0.723717\n",
    "# Step 28  Val Dice 0.78784, Train Dice 0.091096, Test Dice 0.705478\n",
    "# Step 29  Val Dice 0.78401, Train Dice 0.093413, Test Dice 0.702934\n",
    "# Step 30  Val Dice 0.77420, Train Dice 0.087512, Test Dice 0.673745\n",
    "# 31\n",
    "# Step 31  Val Dice 0.78071, Train Dice 0.091674, Test Dice 0.709491\n",
    "# Step 32  Val Dice 0.78643, Train Dice 0.088662, Test Dice 0.701180\n",
    "# Step 33  Val Dice 0.78092, Train Dice 0.090681, Test Dice 0.687806\n",
    "# Step 34  Val Dice 0.78879, Train Dice 0.093551, Test Dice 0.709777\n",
    "# Step 35  Val Dice 0.78320, Train Dice 0.095863, Test Dice 0.711491\n",
    "# Step 36  Val Dice 0.78647, Train Dice 0.092875, Test Dice 0.707001\n",
    "# Step 37  Val Dice 0.78129, Train Dice 0.094385, Test Dice 0.710185\n",
    "# Step 38  Val Dice 0.78459, Train Dice 0.091607, Test Dice 0.699432\n",
    "# Step 39  Val Dice 0.76512, Train Dice 0.099071, Test Dice 0.720157\n",
    "# Step 40  Val Dice 0.78041, Train Dice 0.095752, Test Dice 0.708487\n",
    "# 41\n",
    "# Step 41  Val Dice 0.77891, Train Dice 0.096113, Test Dice 0.708067\n",
    "# Step 42  Val Dice 0.78342, Train Dice 0.096345, Test Dice 0.714913\n",
    "# Step 43  Val Dice 0.77716, Train Dice 0.096061, Test Dice 0.713501\n",
    "# Step 44  Val Dice 0.77556, Train Dice 0.095669, Test Dice 0.715358\n",
    "# Step 45  Val Dice 0.78359, Train Dice 0.094337, Test Dice 0.697413\n",
    "# Step 46  Val Dice 0.78133, Train Dice 0.094720, Test Dice 0.702655\n",
    "# Step 47  Val Dice 0.77036, Train Dice 0.096502, Test Dice 0.711313\n",
    "# Step 48  Val Dice 0.78490, Train Dice 0.094728, Test Dice 0.693549\n",
    "# Step 49  Val Dice 0.78311, Train Dice 0.095501, Test Dice 0.697564\n",
    "# Step 50  Val Dice 0.78698, Train Dice 0.094604, Test Dice 0.696109\n",
    "# 51\n",
    "# Step 51  Val Dice 0.76679, Train Dice 0.089120, Test Dice 0.700028\n",
    "# Step 52  Val Dice 0.77652, Train Dice 0.093872, Test Dice 0.704631\n",
    "# Step 53  Val Dice 0.78068, Train Dice 0.094548, Test Dice 0.700081\n",
    "# Step 54  Val Dice 0.77043, Train Dice 0.096046, Test Dice 0.698489\n",
    "# Step 55  Val Dice 0.78204, Train Dice 0.095159, Test Dice 0.707760\n",
    "# Step 56  Val Dice 0.77453, Train Dice 0.096047, Test Dice 0.705782\n",
    "# Step 57  Val Dice 0.79178, Train Dice 0.093507, Test Dice 0.703230\n",
    "# Step 58  Val Dice 0.77803, Train Dice 0.096408, Test Dice 0.699404\n",
    "# Step 59  Val Dice 0.78115, Train Dice 0.094943, Test Dice 0.703442\n",
    "# Step 60  Val Dice 0.78245, Train Dice 0.093809, Test Dice 0.687335\n",
    "# 61\n",
    "# Step 61  Val Dice 0.77171, Train Dice 0.094787, Test Dice 0.698197\n",
    "# Step 62  Val Dice 0.77956, Train Dice 0.095218, Test Dice 0.701594\n",
    "# Step 63  Val Dice 0.78030, Train Dice 0.097245, Test Dice 0.698260\n",
    "\n",
    "# 200\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.74634, Train Dice 0.096919, Test Dice 0.692648\n",
    "# 1\n",
    "# Step 1  Val Dice 0.75567, Train Dice 0.113393, Test Dice 0.714680\n",
    "# Step 2  Val Dice 0.76548, Train Dice 0.085316, Test Dice 0.660143\n",
    "# Step 3  Val Dice 0.78061, Train Dice 0.094858, Test Dice 0.687344\n",
    "# Step 4  Val Dice 0.77420, Train Dice 0.109518, Test Dice 0.722472\n",
    "# Step 5  Val Dice 0.76873, Train Dice 0.106067, Test Dice 0.678752\n",
    "# Step 6  Val Dice 0.77391, Train Dice 0.109509, Test Dice 0.717850\n",
    "# Step 7  Val Dice 0.78515, Train Dice 0.098746, Test Dice 0.702177\n",
    "# Step 8  Val Dice 0.79146, Train Dice 0.102465, Test Dice 0.716334\n",
    "# Step 9  Val Dice 0.78303, Train Dice 0.102859, Test Dice 0.710842\n",
    "# Step 10  Val Dice 0.79075, Train Dice 0.097922, Test Dice 0.701302\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78602, Train Dice 0.105189, Test Dice 0.715962\n",
    "# Step 12  Val Dice 0.78620, Train Dice 0.103557, Test Dice 0.713915\n",
    "# Step 13  Val Dice 0.78869, Train Dice 0.099656, Test Dice 0.708253\n",
    "# Step 14  Val Dice 0.78398, Train Dice 0.105993, Test Dice 0.717645\n",
    "# Step 15  Val Dice 0.78865, Train Dice 0.100477, Test Dice 0.713139\n",
    "# Step 16  Val Dice 0.78464, Train Dice 0.102017, Test Dice 0.711767\n",
    "# Step 17  Val Dice 0.77246, Train Dice 0.094232, Test Dice 0.672174\n",
    "# Step 18  Val Dice 0.78583, Train Dice 0.098426, Test Dice 0.697059\n",
    "# Step 19  Val Dice 0.76829, Train Dice 0.092097, Test Dice 0.701564\n",
    "# Step 20  Val Dice 0.78649, Train Dice 0.101227, Test Dice 0.710348\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78889, Train Dice 0.101472, Test Dice 0.705186\n",
    "# Step 22  Val Dice 0.78545, Train Dice 0.106239, Test Dice 0.715938\n",
    "# Step 23  Val Dice 0.78612, Train Dice 0.103149, Test Dice 0.716769\n",
    "# Step 24  Val Dice 0.78571, Train Dice 0.100187, Test Dice 0.701511\n",
    "# Step 25  Val Dice 0.79013, Train Dice 0.101526, Test Dice 0.716037\n",
    "# Step 26  Val Dice 0.78934, Train Dice 0.104168, Test Dice 0.717593\n",
    "# Step 27  Val Dice 0.78702, Train Dice 0.105027, Test Dice 0.702148\n",
    "# Step 28  Val Dice 0.75876, Train Dice 0.112148, Test Dice 0.731801\n",
    "# Step 29  Val Dice 0.77488, Train Dice 0.107388, Test Dice 0.714125\n",
    "# Step 30  Val Dice 0.78428, Train Dice 0.100493, Test Dice 0.696862\n",
    "# 31\n",
    "# Step 31  Val Dice 0.78336, Train Dice 0.104836, Test Dice 0.707322\n",
    "# Step 32  Val Dice 0.78407, Train Dice 0.103721, Test Dice 0.709621\n",
    "# Step 33  Val Dice 0.78611, Train Dice 0.104923, Test Dice 0.713980\n",
    "# Step 34  Val Dice 0.78941, Train Dice 0.105856, Test Dice 0.718466\n",
    "# Step 35  Val Dice 0.78648, Train Dice 0.102528, Test Dice 0.711470\n",
    "# Step 36  Val Dice 0.79251, Train Dice 0.104248, Test Dice 0.709666\n",
    "# Step 37  Val Dice 0.79069, Train Dice 0.106425, Test Dice 0.715234\n",
    "# Step 38  Val Dice 0.78394, Train Dice 0.101496, Test Dice 0.700881\n",
    "# Step 39  Val Dice 0.77843, Train Dice 0.105345, Test Dice 0.715907\n",
    "\n",
    "#400\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.75230, Train Dice 0.101206, Test Dice 0.650249\n",
    "# 1\n",
    "# Step 1  Val Dice 0.76599, Train Dice 0.106628, Test Dice 0.693211\n",
    "# Step 2  Val Dice 0.77040, Train Dice 0.103857, Test Dice 0.671344\n",
    "# Step 3  Val Dice 0.77045, Train Dice 0.122281, Test Dice 0.718886\n",
    "# Step 4  Val Dice 0.78309, Train Dice 0.105207, Test Dice 0.681917\n",
    "# Step 5  Val Dice 0.77282, Train Dice 0.116804, Test Dice 0.699086\n",
    "# Step 6  Val Dice 0.78173, Train Dice 0.117289, Test Dice 0.704573\n",
    "# Step 7  Val Dice 0.77906, Train Dice 0.106698, Test Dice 0.700022\n",
    "# Step 8  Val Dice 0.76877, Train Dice 0.122936, Test Dice 0.720944\n",
    "# Step 9  Val Dice 0.76531, Train Dice 0.108972, Test Dice 0.695032\n",
    "# Step 10  Val Dice 0.76762, Train Dice 0.109099, Test Dice 0.702491\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78665, Train Dice 0.117951, Test Dice 0.714834\n",
    "# Step 12  Val Dice 0.76575, Train Dice 0.098176, Test Dice 0.654575\n",
    "# Step 13  Val Dice 0.77748, Train Dice 0.112553, Test Dice 0.695828\n",
    "# Step 14  Val Dice 0.78206, Train Dice 0.119942, Test Dice 0.718196\n",
    "# Step 15  Val Dice 0.77613, Train Dice 0.119922, Test Dice 0.711672\n",
    "# Step 16  Val Dice 0.78377, Train Dice 0.124576, Test Dice 0.727247\n",
    "# Step 17  Val Dice 0.79024, Train Dice 0.111336, Test Dice 0.700918\n",
    "# Step 18  Val Dice 0.78263, Train Dice 0.118029, Test Dice 0.710809\n",
    "# Step 19  Val Dice 0.77670, Train Dice 0.120491, Test Dice 0.717174\n",
    "# Step 20  Val Dice 0.78638, Train Dice 0.112238, Test Dice 0.696694\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78196, Train Dice 0.120038, Test Dice 0.719291\n",
    "# Step 22  Val Dice 0.78028, Train Dice 0.115958, Test Dice 0.716562\n",
    "# Step 23  Val Dice 0.78073, Train Dice 0.120539, Test Dice 0.700957\n",
    "# Step 24  Val Dice 0.79044, Train Dice 0.108482, Test Dice 0.696392\n",
    "# Step 25  Val Dice 0.79283, Train Dice 0.113291, Test Dice 0.703540\n",
    "\n",
    "#800\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.73472, Train Dice 0.158629, Test Dice 0.682844\n",
    "# 1\n",
    "# Step 1  Val Dice 0.77439, Train Dice 0.158773, Test Dice 0.696564\n",
    "# Step 2  Val Dice 0.77997, Train Dice 0.140926, Test Dice 0.671849\n",
    "# Step 3  Val Dice 0.78561, Train Dice 0.148026, Test Dice 0.691112\n",
    "# Step 4  Val Dice 0.75413, Train Dice 0.150734, Test Dice 0.694628\n",
    "# Step 5  Val Dice 0.78264, Train Dice 0.155732, Test Dice 0.690054\n",
    "# Step 6  Val Dice 0.78519, Train Dice 0.150693, Test Dice 0.697227\n",
    "# Step 7  Val Dice 0.77686, Train Dice 0.153245, Test Dice 0.695094\n",
    "# Step 8  Val Dice 0.78195, Train Dice 0.150747, Test Dice 0.687839\n",
    "# Step 9  Val Dice 0.78251, Train Dice 0.144772, Test Dice 0.685603\n",
    "# Step 10  Val Dice 0.77868, Train Dice 0.160324, Test Dice 0.706527\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78995, Train Dice 0.158198, Test Dice 0.714903\n",
    "# Step 12  Val Dice 0.78065, Train Dice 0.155356, Test Dice 0.704081\n",
    "# Step 13  Val Dice 0.78358, Train Dice 0.154340, Test Dice 0.696042\n",
    "# Step 14  Val Dice 0.76411, Train Dice 0.161165, Test Dice 0.715797\n",
    "# Step 15  Val Dice 0.78057, Train Dice 0.139103, Test Dice 0.679545\n",
    "# Step 16  Val Dice 0.76315, Train Dice 0.128445, Test Dice 0.647859\n",
    "# Step 17  Val Dice 0.78328, Train Dice 0.156562, Test Dice 0.705554\n",
    "# Step 18  Val Dice 0.78794, Train Dice 0.152850, Test Dice 0.695145\n",
    "# Step 19  Val Dice 0.77639, Train Dice 0.155153, Test Dice 0.706256\n",
    "# Step 20  Val Dice 0.78459, Train Dice 0.154809, Test Dice 0.688036\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78294, Train Dice 0.160343, Test Dice 0.702798\n",
    "# Step 22  Val Dice 0.78745, Train Dice 0.159909, Test Dice 0.703682\n",
    "# Step 23  Val Dice 0.77172, Train Dice 0.160035, Test Dice 0.709891\n",
    "# Step 24  Val Dice 0.78460, Train Dice 0.161159, Test Dice 0.704819\n",
    "# Step 25  Val Dice 0.77785, Train Dice 0.162993, Test Dice 0.703123\n",
    "# Step 26  Val Dice 0.77868, Train Dice 0.158767, Test Dice 0.701666\n",
    "# Step 27  Val Dice 0.78560, Train Dice 0.158326, Test Dice 0.701601\n",
    "# Step 28  Val Dice 0.78494, Train Dice 0.160455, Test Dice 0.700043\n",
    "# Step 29  Val Dice 0.77863, Train Dice 0.161924, Test Dice 0.704310\n",
    "# Step 30  Val Dice 0.77325, Train Dice 0.155435, Test Dice 0.711685\n",
    "# 31\n",
    "# Step 31  Val Dice 0.78218, Train Dice 0.158349, Test Dice 0.700234\n",
    "# Step 32  Val Dice 0.78080, Train Dice 0.160715, Test Dice 0.703748\n",
    "# Step 33  Val Dice 0.75618, Train Dice 0.169156, Test Dice 0.709846\n",
    "# Step 34  Val Dice 0.78608, Train Dice 0.163116, Test Dice 0.702327\n",
    "# Step 35  Val Dice 0.78041, Train Dice 0.157568, Test Dice 0.698863\n",
    "# Step 36  Val Dice 0.76975, Train Dice 0.162500, Test Dice 0.705656\n",
    "# Step 37  Val Dice 0.78092, Train Dice 0.160537, Test Dice 0.697503\n",
    "# Step 38  Val Dice 0.76285, Train Dice 0.162233, Test Dice 0.703796\n",
    "# Step 39  Val Dice 0.77286, Train Dice 0.155182, Test Dice 0.701541\n",
    "# Step 40  Val Dice 0.74728, Train Dice 0.167308, Test Dice 0.702444\n",
    "# 41\n",
    "# Step 41  Val Dice 0.77444, Train Dice 0.147631, Test Dice 0.697188\n",
    "# Step 42  Val Dice 0.76702, Train Dice 0.152582, Test Dice 0.685949\n",
    "# Step 43  Val Dice 0.77300, Train Dice 0.159889, Test Dice 0.706163\n",
    "# Step 44  Val Dice 0.78632, Train Dice 0.157277, Test Dice 0.693421\n",
    "# Step 45  Val Dice 0.77941, Train Dice 0.159846, Test Dice 0.699474\n",
    "# Step 46  Val Dice 0.77754, Train Dice 0.158413, Test Dice 0.701419\n",
    "# Step 47  Val Dice 0.77798, Train Dice 0.160258, Test Dice 0.701154\n",
    "# Step 48  Val Dice 0.77523, Train Dice 0.161263, Test Dice 0.700899\n",
    "# Step 49  Val Dice 0.78511, Train Dice 0.157999, Test Dice 0.698246\n",
    "# Step 50  Val Dice 0.77813, Train Dice 0.154543, Test Dice 0.687816\n",
    "# 51\n",
    "# Step 51  Val Dice 0.78417, Train Dice 0.162000, Test Dice 0.715313\n",
    "# Step 52  Val Dice 0.77703, Train Dice 0.159766, Test Dice 0.703580\n",
    "# Step 53  Val Dice 0.77336, Train Dice 0.160172, Test Dice 0.699686\n",
    "# Step 54  Val Dice 0.78281, Train Dice 0.163251, Test Dice 0.709982\n",
    "# Step 55  Val Dice 0.78064, Train Dice 0.161610, Test Dice 0.707715\n",
    "# Step 56  Val Dice 0.78012, Train Dice 0.158705, Test Dice 0.701075\n",
    "# Step 57  Val Dice 0.78000, Train Dice 0.160328, Test Dice 0.707254\n",
    "# Step 58  Val Dice 0.76357, Train Dice 0.161788, Test Dice 0.712207\n",
    "# Step 59  Val Dice 0.78163, Train Dice 0.160422, Test Dice 0.705630\n",
    "# Step 60  Val Dice 0.79046, Train Dice 0.159068, Test Dice 0.698817\n",
    "# 61\n",
    "# Step 61  Val Dice 0.77617, Train Dice 0.163711, Test Dice 0.711225\n",
    "# Step 62  Val Dice 0.77744, Train Dice 0.159166, Test Dice 0.700734\n",
    "# Step 63  Val Dice 0.77947, Train Dice 0.155888, Test Dice 0.689236\n",
    "# Step 64  Val Dice 0.77474, Train Dice 0.158871, Test Dice 0.689761\n",
    "# Step 65  Val Dice 0.78543, Train Dice 0.159414, Test Dice 0.691674\n",
    "# Step 66  Val Dice 0.77809, Train Dice 0.162082, Test Dice 0.712904\n",
    "# Step 67  Val Dice 0.77671, Train Dice 0.156939, Test Dice 0.692184\n",
    "# Step 68  Val Dice 0.77810, Train Dice 0.154502, Test Dice 0.688168\n",
    "# Step 69  Val Dice 0.77309, Train Dice 0.165298, Test Dice 0.696385\n",
    "# Step 70  Val Dice 0.76865, Train Dice 0.164778, Test Dice 0.708567\n",
    "# 71\n",
    "# Step 71  Val Dice 0.78432, Train Dice 0.162739, Test Dice 0.698329\n",
    "# Step 72  Val Dice 0.78146, Train Dice 0.160001, Test Dice 0.702032\n",
    "# Step 73  Val Dice 0.77527, Train Dice 0.163756, Test Dice 0.700365\n",
    "# Step 74  Val Dice 0.77433, Train Dice 0.159215, Test Dice 0.699333\n",
    "# Step 75  Val Dice 0.77814, Train Dice 0.158537, Test Dice 0.708614\n",
    "# Step 76  Val Dice 0.75127, Train Dice 0.165263, Test Dice 0.702319\n",
    "# Step 77  Val Dice 0.77775, Train Dice 0.159492, Test Dice 0.692634\n",
    "# Step 78  Val Dice 0.77805, Train Dice 0.159919, Test Dice 0.706456\n",
    "# Step 79  Val Dice 0.77529, Train Dice 0.159668, Test Dice 0.697030\n",
    "# Step 80  Val Dice 0.76399, Train Dice 0.155411, Test Dice 0.703061\n",
    "# 81\n",
    "# Step 81  Val Dice 0.76684, Train Dice 0.160488, Test Dice 0.698145\n",
    "# Step 82  Val Dice 0.78520, Train Dice 0.162197, Test Dice 0.702477\n",
    "# Step 83  Val Dice 0.77797, Train Dice 0.161070, Test Dice 0.703510\n",
    "# Step 84  Val Dice 0.78670, Train Dice 0.160445, Test Dice 0.699961\n",
    "# Step 85  Val Dice 0.76111, Train Dice 0.163970, Test Dice 0.704226\n",
    "# Step 86  Val Dice 0.78016, Train Dice 0.159273, Test Dice 0.690556\n",
    "# Step 87  Val Dice 0.78416, Train Dice 0.156192, Test Dice 0.706431\n",
    "# Step 88  Val Dice 0.77545, Train Dice 0.162959, Test Dice 0.705520\n",
    "# Step 89  Val Dice 0.76866, Train Dice 0.158873, Test Dice 0.704616\n",
    "# Step 90  Val Dice 0.77719, Train Dice 0.159607, Test Dice 0.691359\n",
    "# 91\n",
    "# Step 91  Val Dice 0.77205, Train Dice 0.164002, Test Dice 0.706259\n",
    "# Step 92  Val Dice 0.77632, Train Dice 0.160584, Test Dice 0.705630\n",
    "# Step 93  Val Dice 0.77371, Train Dice 0.159083, Test Dice 0.698607\n",
    "# Step 94  Val Dice 0.76756, Train Dice 0.164419, Test Dice 0.706719\n",
    "# Step 95  Val Dice 0.77081, Train Dice 0.159339, Test Dice 0.703790\n",
    "# Step 96  Val Dice 0.77320, Train Dice 0.163854, Test Dice 0.710185\n",
    "# Step 97  Val Dice 0.77556, Train Dice 0.158653, Test Dice 0.691929\n",
    "# Step 98  Val Dice 0.77168, Train Dice 0.158688, Test Dice 0.704049\n",
    "# Step 99  Val Dice 0.77142, Train Dice 0.159484, Test Dice 0.715179\n",
    "# Step 100  Val Dice 0.77337, Train Dice 0.161956, Test Dice 0.703735\n",
    "# 101\n",
    "# Step 101  Val Dice 0.73038, Train Dice 0.183402, Test Dice 0.702264\n",
    "# Step 102  Val Dice 0.77282, Train Dice 0.162253, Test Dice 0.704131\n",
    "# Step 103  Val Dice 0.77421, Train Dice 0.162338, Test Dice 0.706616\n",
    "# Step 104  Val Dice 0.77688, Train Dice 0.161807, Test Dice 0.706532\n",
    "# Step 105  Val Dice 0.77261, Train Dice 0.161099, Test Dice 0.707236\n",
    "# Step 106  Val Dice 0.77175, Train Dice 0.162355, Test Dice 0.704611\n",
    "# Step 107  Val Dice 0.77589, Train Dice 0.162206, Test Dice 0.702425\n",
    "# Step 108  Val Dice 0.77110, Train Dice 0.163021, Test Dice 0.707839\n",
    "# Step 109  Val Dice 0.77608, Train Dice 0.161230, Test Dice 0.702473\n",
    "# Step 110  Val Dice 0.77247, Train Dice 0.161850, Test Dice 0.710297\n",
    "# 111\n",
    "# Step 111  Val Dice 0.77066, Train Dice 0.163042, Test Dice 0.699049\n",
    "# Step 112  Val Dice 0.77082, Train Dice 0.162564, Test Dice 0.704643\n",
    "# Step 113  Val Dice 0.76954, Train Dice 0.161856, Test Dice 0.704986\n",
    "# Step 114  Val Dice 0.77910, Train Dice 0.161205, Test Dice 0.702903\n",
    "# Step 115  Val Dice 0.77267, Train Dice 0.162246, Test Dice 0.706734\n",
    "# Step 116  Val Dice 0.77346, Train Dice 0.160302, Test Dice 0.708507\n",
    "# Step 117  Val Dice 0.77591, Train Dice 0.159704, Test Dice 0.702253\n",
    "# Step 118  Val Dice 0.77394, Train Dice 0.162043, Test Dice 0.703634\n",
    "# Step 119  Val Dice 0.77039, Train Dice 0.162210, Test Dice 0.704716\n",
    "# Step 120  Val Dice 0.77719, Train Dice 0.163004, Test Dice 0.706754\n",
    "# 121\n",
    "# Step 121  Val Dice 0.77787, Train Dice 0.160327, Test Dice 0.706900\n",
    "# Step 122  Val Dice 0.77371, Train Dice 0.159102, Test Dice 0.711457\n",
    "# Step 123  Val Dice 0.77295, Train Dice 0.161424, Test Dice 0.712470\n",
    "# Step 124  Val Dice 0.77383, Train Dice 0.162578, Test Dice 0.700667\n",
    "# Step 125  Val Dice 0.77084, Train Dice 0.160966, Test Dice 0.708993\n",
    "# Step 126  Val Dice 0.76856, Train Dice 0.162428, Test Dice 0.704068\n",
    "# Step 127  Val Dice 0.77078, Train Dice 0.164852, Test Dice 0.706414\n",
    "# Step 128  Val Dice 0.76885, Train Dice 0.159765, Test Dice 0.703725\n",
    "# Step 129  Val Dice 0.76403, Train Dice 0.163013, Test Dice 0.709086\n",
    "# Step 130  Val Dice 0.76809, Train Dice 0.163498, Test Dice 0.709258\n",
    "# 131\n",
    "# Step 131  Val Dice 0.77495, Train Dice 0.161948, Test Dice 0.706331\n",
    "# Step 132  Val Dice 0.77681, Train Dice 0.162651, Test Dice 0.703723\n",
    "# Step 133  Val Dice 0.77393, Train Dice 0.160274, Test Dice 0.703047\n",
    "# Step 134  Val Dice 0.76649, Train Dice 0.164786, Test Dice 0.706821\n",
    "# Step 135  Val Dice 0.77381, Train Dice 0.160812, Test Dice 0.705146\n",
    "# Step 136  Val Dice 0.77072, Train Dice 0.161100, Test Dice 0.700972\n",
    "# Step 137  Val Dice 0.76634, Train Dice 0.162437, Test Dice 0.708003\n",
    "# Step 138  Val Dice 0.77422, Train Dice 0.160117, Test Dice 0.700464\n",
    "# Step 139  Val Dice 0.76924, Train Dice 0.164877, Test Dice 0.708603\n",
    "# Step 140  Val Dice 0.76390, Train Dice 0.161334, Test Dice 0.704529\n",
    "# 141\n",
    "# Step 141  Val Dice 0.75862, Train Dice 0.164848, Test Dice 0.713014\n",
    "# Step 142  Val Dice 0.76736, Train Dice 0.164371, Test Dice 0.712200\n",
    "# Step 143  Val Dice 0.77384, Train Dice 0.161893, Test Dice 0.709951\n",
    "# Step 144  Val Dice 0.77002, Train Dice 0.160455, Test Dice 0.701017\n",
    "# Step 145  Val Dice 0.76955, Train Dice 0.163930, Test Dice 0.708132\n",
    "# Step 146  Val Dice 0.77213, Train Dice 0.165353, Test Dice 0.710433\n",
    "# Step 147  Val Dice 0.78176, Train Dice 0.157316, Test Dice 0.703405\n",
    "# Step 148  Val Dice 0.75424, Train Dice 0.161609, Test Dice 0.693865\n",
    "# Step 149  Val Dice 0.76669, Train Dice 0.162693, Test Dice 0.706027\n",
    "# Step 150  Val Dice 0.76764, Train Dice 0.164047, Test Dice 0.710010\n",
    "# 151\n",
    "# Step 151  Val Dice 0.76441, Train Dice 0.164585, Test Dice 0.710081\n",
    "# Step 152  Val Dice 0.77203, Train Dice 0.162795, Test Dice 0.707566\n",
    "# Step 153  Val Dice 0.76495, Train Dice 0.164155, Test Dice 0.711998\n",
    "# Step 154  Val Dice 0.77009, Train Dice 0.161733, Test Dice 0.706287\n",
    "# Step 155  Val Dice 0.77051, Train Dice 0.162807, Test Dice 0.709780\n",
    "# Step 156  Val Dice 0.77300, Train Dice 0.162444, Test Dice 0.705059\n",
    "# Step 157  Val Dice 0.77055, Train Dice 0.162842, Test Dice 0.710097\n",
    "# Step 158  Val Dice 0.76739, Train Dice 0.165268, Test Dice 0.706852\n",
    "# Step 159  Val Dice 0.77439, Train Dice 0.159844, Test Dice 0.708793\n",
    "# Step 160  Val Dice 0.76340, Train Dice 0.163652, Test Dice 0.710601\n",
    "# 161\n",
    "# Step 161  Val Dice 0.76216, Train Dice 0.161676, Test Dice 0.710788\n",
    "# Step 162  Val Dice 0.76665, Train Dice 0.163545, Test Dice 0.708288\n",
    "# Step 163  Val Dice 0.77840, Train Dice 0.158248, Test Dice 0.703766\n",
    "# Step 164  Val Dice 0.78200, Train Dice 0.162928, Test Dice 0.711251\n",
    "# Step 165  Val Dice 0.77412, Train Dice 0.162459, Test Dice 0.709979\n",
    "# Step 166  Val Dice 0.76889, Train Dice 0.164704, Test Dice 0.711782\n",
    "# Step 167  Val Dice 0.77335, Train Dice 0.162509, Test Dice 0.708134\n",
    "# Step 168  Val Dice 0.77608, Train Dice 0.161484, Test Dice 0.701428\n",
    "# Step 169  Val Dice 0.77266, Train Dice 0.161525, Test Dice 0.701135\n",
    "# Step 170  Val Dice 0.76588, Train Dice 0.160495, Test Dice 0.702298\n",
    "# 171\n",
    "# Step 171  Val Dice 0.76808, Train Dice 0.162319, Test Dice 0.708672\n",
    "# Step 172  Val Dice 0.76495, Train Dice 0.163092, Test Dice 0.705336\n",
    "# Step 173  Val Dice 0.76196, Train Dice 0.164560, Test Dice 0.704434\n",
    "# Step 174  Val Dice 0.76284, Train Dice 0.164377, Test Dice 0.710436\n",
    "# Step 175  Val Dice 0.76522, Train Dice 0.162297, Test Dice 0.707675\n",
    "# Step 176  Val Dice 0.76615, Train Dice 0.162111, Test Dice 0.705661\n",
    "# Step 177  Val Dice 0.76521, Train Dice 0.164285, Test Dice 0.713988\n",
    "# Step 178  Val Dice 0.76398, Train Dice 0.161138, Test Dice 0.706503\n",
    "# Step 179  Val Dice 0.76494, Train Dice 0.161360, Test Dice 0.710854\n",
    "# Step 180  Val Dice 0.77108, Train Dice 0.163868, Test Dice 0.703167\n",
    "# 181\n",
    "# Step 181  Val Dice 0.75966, Train Dice 0.161909, Test Dice 0.711061\n",
    "# Step 182  Val Dice 0.75337, Train Dice 0.160714, Test Dice 0.695118\n",
    "# Step 183  Val Dice 0.76706, Train Dice 0.162692, Test Dice 0.708214\n",
    "# Step 184  Val Dice 0.76813, Train Dice 0.162671, Test Dice 0.709678\n",
    "# Step 185  Val Dice 0.76173, Train Dice 0.164606, Test Dice 0.707886\n",
    "# Step 186  Val Dice 0.77323, Train Dice 0.163052, Test Dice 0.705707\n",
    "# Step 187  Val Dice 0.76878, Train Dice 0.160789, Test Dice 0.705204\n",
    "# Step 188  Val Dice 0.77197, Train Dice 0.161332, Test Dice 0.699585\n",
    "# Step 189  Val Dice 0.76593, Train Dice 0.163027, Test Dice 0.709010\n",
    "# Step 190  Val Dice 0.76379, Train Dice 0.161841, Test Dice 0.706333\n",
    "# 191\n",
    "# Step 191  Val Dice 0.77081, Train Dice 0.162536, Test Dice 0.707980\n",
    "# Step 192  Val Dice 0.76141, Train Dice 0.163704, Test Dice 0.708480\n",
    "# Step 193  Val Dice 0.77741, Train Dice 0.162015, Test Dice 0.703964\n",
    "# Step 194  Val Dice 0.76675, Train Dice 0.162514, Test Dice 0.706532\n",
    "# Step 195  Val Dice 0.76238, Train Dice 0.161868, Test Dice 0.710264\n",
    "# Step 196  Val Dice 0.76863, Train Dice 0.160202, Test Dice 0.703000\n",
    "# Step 197  Val Dice 0.76850, Train Dice 0.162388, Test Dice 0.710206\n",
    "# Step 198  Val Dice 0.76343, Train Dice 0.162942, Test Dice 0.709720\n",
    "# Step 199  Val Dice 0.76458, Train Dice 0.163672, Test Dice 0.706510\n",
    "# Step 200  Val Dice 0.74916, Train Dice 0.160629, Test Dice 0.703690\n",
    "# 201\n",
    "# Step 201  Val Dice 0.76985, Train Dice 0.162949, Test Dice 0.707944\n",
    "# Step 202  Val Dice 0.76873, Train Dice 0.160163, Test Dice 0.704747\n",
    "# Step 203  Val Dice 0.76528, Train Dice 0.164013, Test Dice 0.710100\n",
    "# Step 204  Val Dice 0.76553, Train Dice 0.161751, Test Dice 0.703714\n",
    "# Step 205  Val Dice 0.76475, Train Dice 0.164584, Test Dice 0.710440\n",
    "# Step 206  Val Dice 0.77218, Train Dice 0.163479, Test Dice 0.708648\n",
    "# Step 207  Val Dice 0.76836, Train Dice 0.163065, Test Dice 0.709023\n",
    "# Step 208  Val Dice 0.76302, Train Dice 0.162530, Test Dice 0.707769\n",
    "# Step 209  Val Dice 0.76847, Train Dice 0.162401, Test Dice 0.704979\n",
    "# Step 210  Val Dice 0.77127, Train Dice 0.163182, Test Dice 0.714228\n",
    "# 211\n",
    "# Step 211  Val Dice 0.76861, Train Dice 0.161761, Test Dice 0.710814\n",
    "# Step 212  Val Dice 0.76458, Train Dice 0.164864, Test Dice 0.713815\n",
    "# Step 213  Val Dice 0.76788, Train Dice 0.162088, Test Dice 0.707267\n",
    "# Step 214  Val Dice 0.76808, Train Dice 0.163573, Test Dice 0.709412\n",
    "# Step 215  Val Dice 0.76011, Train Dice 0.166512, Test Dice 0.711068\n",
    "# Step 216  Val Dice 0.76818, Train Dice 0.164674, Test Dice 0.711465\n",
    "# Step 217  Val Dice 0.76767, Train Dice 0.164095, Test Dice 0.709559\n",
    "# Step 218  Val Dice 0.76298, Train Dice 0.162631, Test Dice 0.707575\n",
    "# Step 219  Val Dice 0.78112, Train Dice 0.163564, Test Dice 0.709439\n",
    "# Step 220  Val Dice 0.76833, Train Dice 0.162865, Test Dice 0.704083\n",
    "# 221\n",
    "# Step 221  Val Dice 0.76389, Train Dice 0.166982, Test Dice 0.713952\n",
    "# Step 222  Val Dice 0.76661, Train Dice 0.163067, Test Dice 0.708963\n",
    "# Step 223  Val Dice 0.76916, Train Dice 0.163549, Test Dice 0.709075\n",
    "# Step 224  Val Dice 0.76982, Train Dice 0.163662, Test Dice 0.708377\n",
    "# Step 225  Val Dice 0.76236, Train Dice 0.164643, Test Dice 0.708495\n",
    "# Step 226  Val Dice 0.77153, Train Dice 0.161870, Test Dice 0.709541\n",
    "# Step 227  Val Dice 0.76347, Train Dice 0.164449, Test Dice 0.710228\n",
    "# Step 228  Val Dice 0.77150, Train Dice 0.162375, Test Dice 0.709313\n",
    "# Step 229  Val Dice 0.76641, Train Dice 0.162626, Test Dice 0.709537\n",
    "# Step 230  Val Dice 0.77155, Train Dice 0.162853, Test Dice 0.711351\n",
    "# 231\n",
    "# Step 231  Val Dice 0.76819, Train Dice 0.161493, Test Dice 0.712496\n",
    "# Step 232  Val Dice 0.76796, Train Dice 0.162816, Test Dice 0.709925\n",
    "# Step 233  Val Dice 0.76854, Train Dice 0.162636, Test Dice 0.712805\n",
    "# Step 234  Val Dice 0.76840, Train Dice 0.162582, Test Dice 0.713332\n",
    "# Step 235  Val Dice 0.76937, Train Dice 0.163471, Test Dice 0.712735\n",
    "# Step 236  Val Dice 0.77256, Train Dice 0.162285, Test Dice 0.706924\n",
    "# Step 237  Val Dice 0.76897, Train Dice 0.163140, Test Dice 0.713225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1, 512, 512) (1600, 1, 512, 512) (8, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# With Thresholding SU-Net covid-19\n",
    "\n",
    "# 200\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.72563, Train Dice 0.773776, Test Dice 0.656163\n",
    "# 1\n",
    "# Step 1  Val Dice 0.72861, Train Dice 0.794941, Test Dice 0.696639\n",
    "# Step 2  Val Dice 0.76738, Train Dice 0.849035, Test Dice 0.704728\n",
    "# Step 3  Val Dice 0.77202, Train Dice 0.864231, Test Dice 0.716497\n",
    "# Step 4  Val Dice 0.76835, Train Dice 0.867871, Test Dice 0.707697\n",
    "# Step 5  Val Dice 0.77276, Train Dice 0.840754, Test Dice 0.653481\n",
    "# Step 6  Val Dice 0.76889, Train Dice 0.872018, Test Dice 0.720899\n",
    "# Step 7  Val Dice 0.77192, Train Dice 0.877137, Test Dice 0.693056\n",
    "# Step 8  Val Dice 0.76492, Train Dice 0.892213, Test Dice 0.697804\n",
    "# Step 9  Val Dice 0.75782, Train Dice 0.880913, Test Dice 0.726608\n",
    "# Step 10  Val Dice 0.77472, Train Dice 0.897464, Test Dice 0.701474\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78308, Train Dice 0.892698, Test Dice 0.700447\n",
    "# Step 12  Val Dice 0.78069, Train Dice 0.898531, Test Dice 0.710404\n",
    "# Step 13  Val Dice 0.78007, Train Dice 0.883505, Test Dice 0.704565\n",
    "# Step 14  Val Dice 0.77499, Train Dice 0.900876, Test Dice 0.710840\n",
    "# Step 15  Val Dice 0.77665, Train Dice 0.891204, Test Dice 0.673112\n",
    "# Step 16  Val Dice 0.77950, Train Dice 0.894011, Test Dice 0.691817\n",
    "# Step 17  Val Dice 0.77797, Train Dice 0.901648, Test Dice 0.707655\n",
    "# Step 18  Val Dice 0.76101, Train Dice 0.903182, Test Dice 0.671819\n",
    "# Step 19  Val Dice 0.77964, Train Dice 0.908991, Test Dice 0.716920\n",
    "# Step 20  Val Dice 0.77315, Train Dice 0.918199, Test Dice 0.721126\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78255, Train Dice 0.923788, Test Dice 0.708279\n",
    "# Step 22  Val Dice 0.77373, Train Dice 0.906263, Test Dice 0.706129\n",
    "# Step 23  Val Dice 0.77720, Train Dice 0.920180, Test Dice 0.702497\n",
    "# Step 24  Val Dice 0.78540, Train Dice 0.909301, Test Dice 0.691417\n",
    "# Step 25  Val Dice 0.77850, Train Dice 0.928295, Test Dice 0.711166\n",
    "# Step 26  Val Dice 0.77145, Train Dice 0.928398, Test Dice 0.710261\n",
    "\n",
    "\n",
    "#400\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.00000, Train Dice 0.000000, Test Dice 0.000000\n",
    "# 1\n",
    "# Step 1  Val Dice 0.00000, Train Dice 0.000000, Test Dice 0.000000\n",
    "# Step 2  Val Dice 0.00000, Train Dice 0.000000, Test Dice 0.000000\n",
    "# Step 3  Val Dice 0.74406, Train Dice 0.850948, Test Dice 0.696338\n",
    "# Step 4  Val Dice 0.76966, Train Dice 0.881907, Test Dice 0.699634\n",
    "# Step 5  Val Dice 0.76961, Train Dice 0.880450, Test Dice 0.711422\n",
    "# Step 6  Val Dice 0.76147, Train Dice 0.848786, Test Dice 0.713672\n",
    "# Step 7  Val Dice 0.76897, Train Dice 0.896030, Test Dice 0.720392\n",
    "# Step 8  Val Dice 0.79013, Train Dice 0.889733, Test Dice 0.694083\n",
    "# Step 9  Val Dice 0.78003, Train Dice 0.901803, Test Dice 0.702104\n",
    "# Step 10  Val Dice 0.77908, Train Dice 0.903664, Test Dice 0.710332\n",
    "# 11\n",
    "# Step 11  Val Dice 0.78928, Train Dice 0.914076, Test Dice 0.699742\n",
    "# Step 12  Val Dice 0.78545, Train Dice 0.911098, Test Dice 0.696475\n",
    "# Step 13  Val Dice 0.78917, Train Dice 0.909817, Test Dice 0.707582\n",
    "# Step 14  Val Dice 0.78210, Train Dice 0.921735, Test Dice 0.708620\n",
    "# Step 15  Val Dice 0.79170, Train Dice 0.911085, Test Dice 0.699334\n",
    "# Step 16  Val Dice 0.78258, Train Dice 0.923038, Test Dice 0.718766\n",
    "# Step 17  Val Dice 0.78631, Train Dice 0.898252, Test Dice 0.686872\n",
    "# Step 18  Val Dice 0.78847, Train Dice 0.917823, Test Dice 0.704930\n",
    "# Step 19  Val Dice 0.78284, Train Dice 0.933700, Test Dice 0.714575\n",
    "# Step 20  Val Dice 0.77650, Train Dice 0.928229, Test Dice 0.719729\n",
    "# 21\n",
    "# Step 21  Val Dice 0.78059, Train Dice 0.931972, Test Dice 0.711662\n",
    "# Step 22  Val Dice 0.78605, Train Dice 0.932118, Test Dice 0.697598\n",
    "# Step 23  Val Dice 0.76662, Train Dice 0.923480, Test Dice 0.721776\n",
    "# Step 24  Val Dice 0.78595, Train Dice 0.939531, Test Dice 0.711545\n",
    "# Step 25  Val Dice 0.77505, Train Dice 0.928128, Test Dice 0.722234\n",
    "# Step 26  Val Dice 0.78289, Train Dice 0.942097, Test Dice 0.708556\n",
    "# Step 27  Val Dice 0.77989, Train Dice 0.943632, Test Dice 0.713825\n",
    "# Step 28  Val Dice 0.78289, Train Dice 0.934409, Test Dice 0.699490\n",
    "# Step 29  Val Dice 0.78426, Train Dice 0.944378, Test Dice 0.708945\n",
    "# Step 30  Val Dice 0.78478, Train Dice 0.948386, Test Dice 0.703117\n",
    "# 31\n",
    "# Step 31  Val Dice 0.77081, Train Dice 0.931432, Test Dice 0.715793\n",
    "# Step 32  Val Dice 0.78126, Train Dice 0.945359, Test Dice 0.705895\n",
    "# Step 33  Val Dice 0.77782, Train Dice 0.950768, Test Dice 0.706816\n",
    "# Step 34  Val Dice 0.78079, Train Dice 0.950488, Test Dice 0.708422\n",
    "# Step 35  Val Dice 0.77731, Train Dice 0.940344, Test Dice 0.703868\n",
    "# Step 36  Val Dice 0.78384, Train Dice 0.952781, Test Dice 0.704444\n",
    "# Step 37  Val Dice 0.76736, Train Dice 0.932290, Test Dice 0.713901\n",
    "# Step 38  Val Dice 0.77932, Train Dice 0.947354, Test Dice 0.708133\n",
    "# Step 39  Val Dice 0.78062, Train Dice 0.951312, Test Dice 0.696970\n",
    "# Step 40  Val Dice 0.78079, Train Dice 0.954571, Test Dice 0.706484\n",
    "# 41\n",
    "# Step 41  Val Dice 0.78270, Train Dice 0.924328, Test Dice 0.686933\n",
    "# Step 42  Val Dice 0.77709, Train Dice 0.945364, Test Dice 0.696427\n",
    "# Step 43  Val Dice 0.77763, Train Dice 0.953043, Test Dice 0.704772\n",
    "# Step 44  Val Dice 0.77600, Train Dice 0.952131, Test Dice 0.708901\n",
    "# Step 45  Val Dice 0.77994, Train Dice 0.956884, Test Dice 0.698488\n",
    "# Step 46  Val Dice 0.77371, Train Dice 0.949831, Test Dice 0.711721\n",
    "# Step 47  Val Dice 0.77601, Train Dice 0.958173, Test Dice 0.694420\n",
    "# Step 48  Val Dice 0.77912, Train Dice 0.962436, Test Dice 0.708736\n",
    "# Step 49  Val Dice 0.77490, Train Dice 0.960822, Test Dice 0.709778\n",
    "# Step 50  Val Dice 0.77038, Train Dice 0.961593, Test Dice 0.707440\n",
    "# 51\n",
    "# Step 51  Val Dice 0.77815, Train Dice 0.954134, Test Dice 0.704454\n",
    "# Step 52  Val Dice 0.77873, Train Dice 0.961715, Test Dice 0.701687\n",
    "# Step 53  Val Dice 0.77641, Train Dice 0.961425, Test Dice 0.704464\n",
    "# Step 54  Val Dice 0.77505, Train Dice 0.964257, Test Dice 0.707438\n",
    "# Step 55  Val Dice 0.77191, Train Dice 0.959450, Test Dice 0.703638\n",
    "# Step 56  Val Dice 0.77564, Train Dice 0.960686, Test Dice 0.708042\n",
    "# Step 57  Val Dice 0.77763, Train Dice 0.959366, Test Dice 0.700933\n",
    "# Step 58  Val Dice 0.78065, Train Dice 0.962203, Test Dice 0.693921\n",
    "# Step 59  Val Dice 0.77432, Train Dice 0.964366, Test Dice 0.708313\n",
    "# Step 60  Val Dice 0.77899, Train Dice 0.965857, Test Dice 0.706369\n",
    "# 61\n",
    "# Step 61  Val Dice 0.77740, Train Dice 0.963179, Test Dice 0.703364\n",
    "# Step 62  Val Dice 0.78126, Train Dice 0.964713, Test Dice 0.702171\n",
    "# Step 63  Val Dice 0.77041, Train Dice 0.965562, Test Dice 0.711433\n",
    "# Step 64  Val Dice 0.77510, Train Dice 0.966777, Test Dice 0.703955\n",
    "# Step 65  Val Dice 0.77448, Train Dice 0.965213, Test Dice 0.699973\n",
    "# Step 66  Val Dice 0.77760, Train Dice 0.966955, Test Dice 0.707886\n",
    "# Step 67  Val Dice 0.77252, Train Dice 0.962011, Test Dice 0.703854\n",
    "# Step 68  Val Dice 0.77708, Train Dice 0.967192, Test Dice 0.703519\n",
    "# Step 69  Val Dice 0.77459, Train Dice 0.957463, Test Dice 0.698678\n",
    "# Step 70  Val Dice 0.77659, Train Dice 0.968218, Test Dice 0.697713\n",
    "# 71\n",
    "# Step 71  Val Dice 0.77891, Train Dice 0.968466, Test Dice 0.700330\n",
    "# Step 72  Val Dice 0.77482, Train Dice 0.966835, Test Dice 0.704828\n",
    "# Step 73  Val Dice 0.78371, Train Dice 0.966986, Test Dice 0.699492\n",
    "# Step 74  Val Dice 0.77655, Train Dice 0.968898, Test Dice 0.697062\n",
    "# Step 75  Val Dice 0.77837, Train Dice 0.965367, Test Dice 0.693754\n",
    "# Step 76  Val Dice 0.77838, Train Dice 0.969659, Test Dice 0.699824\n",
    "# Step 77  Val Dice 0.77561, Train Dice 0.967655, Test Dice 0.693390\n",
    "# Step 78  Val Dice 0.77204, Train Dice 0.967260, Test Dice 0.708103\n",
    "# Step 79  Val Dice 0.76958, Train Dice 0.970215, Test Dice 0.701675\n",
    "# Step 80  Val Dice 0.76922, Train Dice 0.970119, Test Dice 0.708312\n",
    "# 81\n",
    "# Step 81  Val Dice 0.77343, Train Dice 0.956356, Test Dice 0.699828\n",
    "# Step 82  Val Dice 0.76716, Train Dice 0.966875, Test Dice 0.709747\n",
    "# Step 83  Val Dice 0.77701, Train Dice 0.970145, Test Dice 0.698617\n",
    "# Step 84  Val Dice 0.77231, Train Dice 0.973004, Test Dice 0.704267\n",
    "# Step 85  Val Dice 0.77673, Train Dice 0.973313, Test Dice 0.699421\n",
    "# Step 86  Val Dice 0.77436, Train Dice 0.968927, Test Dice 0.706243\n",
    "# Step 87  Val Dice 0.77808, Train Dice 0.972582, Test Dice 0.700359\n",
    "# Step 88  Val Dice 0.77623, Train Dice 0.971815, Test Dice 0.700046\n",
    "# Step 89  Val Dice 0.77383, Train Dice 0.973240, Test Dice 0.701528\n",
    "# Step 90  Val Dice 0.76698, Train Dice 0.970857, Test Dice 0.683983\n",
    "# 91\n",
    "# Step 91  Val Dice 0.77249, Train Dice 0.974599, Test Dice 0.700885\n",
    "# Step 92  Val Dice 0.77518, Train Dice 0.973209, Test Dice 0.706056\n",
    "# Step 93  Val Dice 0.77529, Train Dice 0.970107, Test Dice 0.700380\n",
    "# Step 94  Val Dice 0.77476, Train Dice 0.973055, Test Dice 0.705808\n",
    "# Step 95  Val Dice 0.77321, Train Dice 0.972582, Test Dice 0.705959\n",
    "# Step 96  Val Dice 0.77739, Train Dice 0.971145, Test Dice 0.694224\n",
    "# Step 97  Val Dice 0.77671, Train Dice 0.970899, Test Dice 0.696398\n",
    "# Step 98  Val Dice 0.78002, Train Dice 0.967566, Test Dice 0.699359\n",
    "# Step 99  Val Dice 0.76491, Train Dice 0.969949, Test Dice 0.710666\n",
    "# Step 100  Val Dice 0.77568, Train Dice 0.972653, Test Dice 0.690681\n",
    "# 101\n",
    "# Step 101  Val Dice 0.77717, Train Dice 0.974818, Test Dice 0.701565\n",
    "# Step 102  Val Dice 0.77712, Train Dice 0.973716, Test Dice 0.697856\n",
    "# Step 103  Val Dice 0.76584, Train Dice 0.961966, Test Dice 0.694189\n",
    "# Step 104  Val Dice 0.77221, Train Dice 0.975293, Test Dice 0.700422\n",
    "# Step 105  Val Dice 0.77239, Train Dice 0.972333, Test Dice 0.693468\n",
    "# Step 106  Val Dice 0.77656, Train Dice 0.975722, Test Dice 0.700026\n",
    "\n",
    "\n",
    "#800\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.73091, Train Dice 0.827742, Test Dice 0.675811\n",
    "# 1\n",
    "# Step 1  Val Dice 0.75458, Train Dice 0.851927, Test Dice 0.656428\n",
    "# Step 2  Val Dice 0.75896, Train Dice 0.880884, Test Dice 0.695788\n",
    "# Step 3  Val Dice 0.76047, Train Dice 0.871415, Test Dice 0.688328\n",
    "# Step 4  Val Dice 0.77866, Train Dice 0.910171, Test Dice 0.688894\n",
    "# Step 5  Val Dice 0.75435, Train Dice 0.900584, Test Dice 0.711594\n",
    "# Step 6  Val Dice 0.77633, Train Dice 0.921265, Test Dice 0.706498\n",
    "# Step 7  Val Dice 0.75482, Train Dice 0.911750, Test Dice 0.711192\n",
    "# Step 8  Val Dice 0.77480, Train Dice 0.914968, Test Dice 0.711173\n",
    "# Step 9  Val Dice 0.77748, Train Dice 0.899591, Test Dice 0.667740\n",
    "# Step 10  Val Dice 0.78172, Train Dice 0.922193, Test Dice 0.705815\n",
    "# 11\n",
    "# Step 11  Val Dice 0.75972, Train Dice 0.931075, Test Dice 0.707360\n",
    "# Step 12  Val Dice 0.78010, Train Dice 0.917058, Test Dice 0.697258\n",
    "# Step 13  Val Dice 0.74936, Train Dice 0.926610, Test Dice 0.718647\n",
    "# Step 14  Val Dice 0.76931, Train Dice 0.883458, Test Dice 0.688725\n",
    "# Step 15  Val Dice 0.77121, Train Dice 0.935692, Test Dice 0.722723\n",
    "# Step 16  Val Dice 0.76965, Train Dice 0.942014, Test Dice 0.719206\n",
    "# Step 17  Val Dice 0.76825, Train Dice 0.931715, Test Dice 0.708282\n",
    "# Step 18  Val Dice 0.77983, Train Dice 0.934663, Test Dice 0.698830\n",
    "# Step 19  Val Dice 0.76650, Train Dice 0.945058, Test Dice 0.717419\n",
    "# Step 20  Val Dice 0.76621, Train Dice 0.942795, Test Dice 0.719345\n",
    "# 21\n",
    "# Step 21  Val Dice 0.77814, Train Dice 0.948417, Test Dice 0.711418\n",
    "# Step 22  Val Dice 0.77255, Train Dice 0.949944, Test Dice 0.717387\n",
    "# Step 23  Val Dice 0.77788, Train Dice 0.947192, Test Dice 0.700734\n",
    "# Step 24  Val Dice 0.77329, Train Dice 0.945935, Test Dice 0.714093\n",
    "# Step 25  Val Dice 0.77856, Train Dice 0.950019, Test Dice 0.704517\n",
    "# Step 26  Val Dice 0.78049, Train Dice 0.943824, Test Dice 0.689297\n",
    "# Step 27  Val Dice 0.78002, Train Dice 0.949453, Test Dice 0.706993\n",
    "# Step 28  Val Dice 0.78486, Train Dice 0.949991, Test Dice 0.702930\n",
    "# Step 29  Val Dice 0.77572, Train Dice 0.946057, Test Dice 0.696072\n",
    "# Step 30  Val Dice 0.78101, Train Dice 0.957752, Test Dice 0.714156\n",
    "# 31\n",
    "# Step 31  Val Dice 0.78213, Train Dice 0.958884, Test Dice 0.707809\n",
    "# Step 32  Val Dice 0.77395, Train Dice 0.957177, Test Dice 0.703029\n",
    "# Step 33  Val Dice 0.78397, Train Dice 0.958357, Test Dice 0.701840\n",
    "# Step 34  Val Dice 0.78309, Train Dice 0.959815, Test Dice 0.702792\n",
    "# Step 35  Val Dice 0.77795, Train Dice 0.958253, Test Dice 0.713960\n",
    "# Step 36  Val Dice 0.77751, Train Dice 0.962088, Test Dice 0.710959\n",
    "# Step 37  Val Dice 0.76871, Train Dice 0.946656, Test Dice 0.711484\n",
    "# Step 38  Val Dice 0.78603, Train Dice 0.960597, Test Dice 0.699709\n",
    "# Step 39  Val Dice 0.77521, Train Dice 0.961936, Test Dice 0.699656\n",
    "# Step 40  Val Dice 0.78344, Train Dice 0.965457, Test Dice 0.702907\n",
    "# 41\n",
    "# Step 41  Val Dice 0.77415, Train Dice 0.963947, Test Dice 0.714296\n",
    "# Step 42  Val Dice 0.77797, Train Dice 0.961028, Test Dice 0.706370\n",
    "# Step 43  Val Dice 0.77551, Train Dice 0.958387, Test Dice 0.685865\n",
    "# Step 44  Val Dice 0.78139, Train Dice 0.962919, Test Dice 0.705649\n",
    "# Step 45  Val Dice 0.78065, Train Dice 0.963799, Test Dice 0.706166\n",
    "# Step 46  Val Dice 0.77528, Train Dice 0.968069, Test Dice 0.704759\n",
    "# Step 47  Val Dice 0.77639, Train Dice 0.966856, Test Dice 0.711841\n",
    "# Step 48  Val Dice 0.78613, Train Dice 0.957488, Test Dice 0.698837\n",
    "# Step 49  Val Dice 0.78083, Train Dice 0.969965, Test Dice 0.705464\n",
    "# Step 50  Val Dice 0.77295, Train Dice 0.967689, Test Dice 0.706725\n",
    "# 51\n",
    "# Step 51  Val Dice 0.78410, Train Dice 0.967915, Test Dice 0.697115\n",
    "# Step 52  Val Dice 0.77429, Train Dice 0.967570, Test Dice 0.704452\n",
    "# Step 53  Val Dice 0.78735, Train Dice 0.969769, Test Dice 0.707099\n",
    "# Step 54  Val Dice 0.78101, Train Dice 0.968045, Test Dice 0.699390\n",
    "# Step 55  Val Dice 0.76426, Train Dice 0.966585, Test Dice 0.711767\n",
    "# Step 56  Val Dice 0.78093, Train Dice 0.968742, Test Dice 0.707044\n",
    "# Step 57  Val Dice 0.78047, Train Dice 0.966882, Test Dice 0.698734\n",
    "# Step 58  Val Dice 0.78192, Train Dice 0.965775, Test Dice 0.701132\n",
    "# Step 59  Val Dice 0.77735, Train Dice 0.971825, Test Dice 0.713536\n",
    "# Step 60  Val Dice 0.77322, Train Dice 0.964952, Test Dice 0.704809\n",
    "# 61\n",
    "# Step 61  Val Dice 0.77225, Train Dice 0.966066, Test Dice 0.709265\n",
    "# Step 62  Val Dice 0.78161, Train Dice 0.972864, Test Dice 0.702990\n",
    "# Step 63  Val Dice 0.78006, Train Dice 0.971448, Test Dice 0.706698\n",
    "# Step 64  Val Dice 0.77952, Train Dice 0.973341, Test Dice 0.698848\n",
    "# Step 65  Val Dice 0.78012, Train Dice 0.970125, Test Dice 0.711812\n",
    "# Step 66  Val Dice 0.78444, Train Dice 0.974836, Test Dice 0.704518\n",
    "# Step 67  Val Dice 0.78115, Train Dice 0.970648, Test Dice 0.703315\n",
    "# Step 68  Val Dice 0.77942, Train Dice 0.975091, Test Dice 0.708573\n",
    "# Step 69  Val Dice 0.78289, Train Dice 0.974505, Test Dice 0.704365\n",
    "# Step 70  Val Dice 0.77645, Train Dice 0.972549, Test Dice 0.710394\n",
    "# 71\n",
    "# Step 71  Val Dice 0.78080, Train Dice 0.970318, Test Dice 0.707409\n",
    "# Step 72  Val Dice 0.78290, Train Dice 0.974311, Test Dice 0.707755\n",
    "# Step 73  Val Dice 0.78251, Train Dice 0.973593, Test Dice 0.711284\n",
    "# Step 74  Val Dice 0.78356, Train Dice 0.973109, Test Dice 0.701307\n",
    "# Step 75  Val Dice 0.78231, Train Dice 0.972139, Test Dice 0.698903\n",
    "# Step 76  Val Dice 0.77962, Train Dice 0.975859, Test Dice 0.704973\n",
    "# Step 77  Val Dice 0.78282, Train Dice 0.974880, Test Dice 0.703844\n",
    "# Step 78  Val Dice 0.76787, Train Dice 0.970876, Test Dice 0.701505\n",
    "# Step 79  Val Dice 0.77691, Train Dice 0.972742, Test Dice 0.709887\n",
    "# Step 80  Val Dice 0.77662, Train Dice 0.973489, Test Dice 0.709619\n",
    "# 81\n",
    "# Step 81  Val Dice 0.77662, Train Dice 0.974348, Test Dice 0.695068\n",
    "# Step 82  Val Dice 0.77539, Train Dice 0.957314, Test Dice 0.693524\n",
    "# Step 83  Val Dice 0.78321, Train Dice 0.976367, Test Dice 0.705044\n",
    "# Step 84  Val Dice 0.77978, Train Dice 0.976047, Test Dice 0.710361\n",
    "# Step 85  Val Dice 0.77667, Train Dice 0.973451, Test Dice 0.709521\n",
    "# Step 86  Val Dice 0.77855, Train Dice 0.977368, Test Dice 0.707183\n",
    "# Step 87  Val Dice 0.78443, Train Dice 0.972084, Test Dice 0.701598\n",
    "# Step 88  Val Dice 0.77942, Train Dice 0.972833, Test Dice 0.706841\n",
    "# Step 89  Val Dice 0.77638, Train Dice 0.977545, Test Dice 0.704086\n",
    "# Step 90  Val Dice 0.78128, Train Dice 0.972346, Test Dice 0.692691\n",
    "# 91\n",
    "# Step 91  Val Dice 0.77539, Train Dice 0.978994, Test Dice 0.708265\n",
    "# Step 92  Val Dice 0.77090, Train Dice 0.978818, Test Dice 0.707326\n",
    "# Step 93  Val Dice 0.76808, Train Dice 0.973157, Test Dice 0.713167\n",
    "# Step 94  Val Dice 0.78045, Train Dice 0.973318, Test Dice 0.703878\n",
    "# Step 95  Val Dice 0.77783, Train Dice 0.977985, Test Dice 0.707204\n",
    "# Step 96  Val Dice 0.77626, Train Dice 0.977682, Test Dice 0.702651\n",
    "# Step 97  Val Dice 0.78054, Train Dice 0.978920, Test Dice 0.705400\n",
    "# Step 98  Val Dice 0.77705, Train Dice 0.980040, Test Dice 0.708875\n",
    "# Step 99  Val Dice 0.77811, Train Dice 0.979986, Test Dice 0.708073\n",
    "# Step 100  Val Dice 0.77757, Train Dice 0.980376, Test Dice 0.704508\n",
    "# 101\n",
    "# Step 101  Val Dice 0.77453, Train Dice 0.979063, Test Dice 0.708203\n",
    "# Step 102  Val Dice 0.78084, Train Dice 0.977722, Test Dice 0.702010\n",
    "# Step 103  Val Dice 0.77585, Train Dice 0.976746, Test Dice 0.708220\n",
    "# Step 104  Val Dice 0.75535, Train Dice 0.970772, Test Dice 0.713287\n",
    "# Step 105  Val Dice 0.78334, Train Dice 0.979636, Test Dice 0.706798\n",
    "# Step 106  Val Dice 0.77495, Train Dice 0.978636, Test Dice 0.709226\n",
    "# Step 107  Val Dice 0.77871, Train Dice 0.979885, Test Dice 0.703481\n",
    "# Step 108  Val Dice 0.77602, Train Dice 0.978815, Test Dice 0.706814\n",
    "# Step 109  Val Dice 0.77584, Train Dice 0.980911, Test Dice 0.705562\n",
    "# Step 110  Val Dice 0.77848, Train Dice 0.976224, Test Dice 0.708705\n",
    "# 111\n",
    "# Step 111  Val Dice 0.77919, Train Dice 0.980993, Test Dice 0.710360\n",
    "# Step 112  Val Dice 0.77282, Train Dice 0.979937, Test Dice 0.707999\n",
    "# Step 113  Val Dice 0.77792, Train Dice 0.980478, Test Dice 0.708731\n",
    "# Step 114  Val Dice 0.77385, Train Dice 0.981454, Test Dice 0.706859\n",
    "# Step 115  Val Dice 0.77423, Train Dice 0.980080, Test Dice 0.712261\n",
    "# Step 116  Val Dice 0.77899, Train Dice 0.982053, Test Dice 0.704251\n",
    "# Step 117  Val Dice 0.78034, Train Dice 0.979241, Test Dice 0.703263\n",
    "# Step 118  Val Dice 0.77198, Train Dice 0.979630, Test Dice 0.706765\n",
    "# Step 119  Val Dice 0.76976, Train Dice 0.979434, Test Dice 0.714218\n",
    "# Step 120  Val Dice 0.77610, Train Dice 0.979285, Test Dice 0.701461\n",
    "# 121\n",
    "# Step 121  Val Dice 0.77514, Train Dice 0.980785, Test Dice 0.704637\n",
    "# Step 122  Val Dice 0.77798, Train Dice 0.977181, Test Dice 0.703043\n",
    "\n",
    "\n",
    "#1200\n",
    "# (40, 1, 512, 512) (10, 1, 512, 512) (48, 1, 512, 512) (1600, 1, 512, 512)\n",
    "# Step 0  Val Dice 0.63359, Train Dice 0.776540, Test Dice 0.578813\n",
    "# 1\n",
    "# Step 1  Val Dice 0.73227, Train Dice 0.862010, Test Dice 0.673949\n",
    "# Step 2  Val Dice 0.75327, Train Dice 0.882589, Test Dice 0.694834\n",
    "# Step 3  Val Dice 0.74580, Train Dice 0.883099, Test Dice 0.675501\n",
    "# Step 4  Val Dice 0.75355, Train Dice 0.887541, Test Dice 0.661223\n",
    "# Step 5  Val Dice 0.77087, Train Dice 0.903116, Test Dice 0.692245\n",
    "# Step 6  Val Dice 0.76716, Train Dice 0.921735, Test Dice 0.701752\n",
    "# Step 7  Val Dice 0.76162, Train Dice 0.906085, Test Dice 0.707640\n",
    "# Step 8  Val Dice 0.75423, Train Dice 0.922709, Test Dice 0.702703\n",
    "# Step 9  Val Dice 0.70554, Train Dice 0.830005, Test Dice 0.628310\n",
    "# Step 10  Val Dice 0.77410, Train Dice 0.913078, Test Dice 0.692285\n",
    "# 11\n",
    "# Step 11  Val Dice 0.77181, Train Dice 0.924179, Test Dice 0.697056\n",
    "# Step 12  Val Dice 0.74803, Train Dice 0.921618, Test Dice 0.711098\n",
    "# Step 13  Val Dice 0.74355, Train Dice 0.921366, Test Dice 0.711874\n",
    "# Step 14  Val Dice 0.73418, Train Dice 0.897315, Test Dice 0.701417\n",
    "# Step 15  Val Dice 0.77582, Train Dice 0.936175, Test Dice 0.703727\n",
    "# Step 16  Val Dice 0.77148, Train Dice 0.941932, Test Dice 0.711157\n",
    "# Step 17  Val Dice 0.78518, Train Dice 0.930794, Test Dice 0.676058\n",
    "# Step 18  Val Dice 0.78333, Train Dice 0.944664, Test Dice 0.694008\n",
    "# Step 19  Val Dice 0.78355, Train Dice 0.943261, Test Dice 0.701867\n",
    "# Step 20  Val Dice 0.78347, Train Dice 0.943202, Test Dice 0.695082\n",
    "# 21\n",
    "# Step 21  Val Dice 0.77590, Train Dice 0.931265, Test Dice 0.667410\n",
    "# Step 22  Val Dice 0.77047, Train Dice 0.944965, Test Dice 0.705734\n",
    "# Step 23  Val Dice 0.78013, Train Dice 0.954449, Test Dice 0.700570\n",
    "# Step 24  Val Dice 0.76700, Train Dice 0.953176, Test Dice 0.703875\n",
    "# Step 25  Val Dice 0.77069, Train Dice 0.956826, Test Dice 0.704035\n",
    "# Step 26  Val Dice 0.77865, Train Dice 0.954610, Test Dice 0.689712\n",
    "# Step 27  Val Dice 0.76968, Train Dice 0.954367, Test Dice 0.685966\n",
    "# Step 28  Val Dice 0.76929, Train Dice 0.956877, Test Dice 0.706180\n",
    "# Step 29  Val Dice 0.76114, Train Dice 0.955747, Test Dice 0.709238\n",
    "# Step 30  Val Dice 0.76182, Train Dice 0.959346, Test Dice 0.692449\n",
    "# 31\n",
    "# Step 31  Val Dice 0.76735, Train Dice 0.955069, Test Dice 0.693525\n",
    "# Step 32  Val Dice 0.76560, Train Dice 0.961736, Test Dice 0.699738\n",
    "# Step 33  Val Dice 0.76426, Train Dice 0.959374, Test Dice 0.692841\n",
    "# Step 34  Val Dice 0.76399, Train Dice 0.964125, Test Dice 0.695946\n",
    "# Step 35  Val Dice 0.77228, Train Dice 0.960710, Test Dice 0.699292\n",
    "# Step 36  Val Dice 0.76742, Train Dice 0.955165, Test Dice 0.682769\n",
    "# Step 37  Val Dice 0.76764, Train Dice 0.939777, Test Dice 0.711634\n",
    "# Step 38  Val Dice 0.76628, Train Dice 0.953891, Test Dice 0.706652\n",
    "# Step 39  Val Dice 0.77047, Train Dice 0.967173, Test Dice 0.695514\n",
    "# Step 40  Val Dice 0.76977, Train Dice 0.969502, Test Dice 0.697704\n",
    "# 41\n",
    "# Step 41  Val Dice 0.77022, Train Dice 0.970303, Test Dice 0.700268\n",
    "# Step 42  Val Dice 0.76970, Train Dice 0.966802, Test Dice 0.698149\n",
    "# Step 43  Val Dice 0.76115, Train Dice 0.969117, Test Dice 0.691240\n",
    "# Step 44  Val Dice 0.77005, Train Dice 0.966557, Test Dice 0.703900\n",
    "# Step 45  Val Dice 0.76235, Train Dice 0.969729, Test Dice 0.698454\n",
    "# Step 46  Val Dice 0.77197, Train Dice 0.965366, Test Dice 0.698047\n",
    "# Step 47  Val Dice 0.76331, Train Dice 0.971190, Test Dice 0.703908\n",
    "# Step 48  Val Dice 0.76600, Train Dice 0.970159, Test Dice 0.696308\n",
    "# Step 49  Val Dice 0.76359, Train Dice 0.969238, Test Dice 0.703930\n",
    "# Step 50  Val Dice 0.76825, Train Dice 0.963815, Test Dice 0.694247\n",
    "# 51\n",
    "# Step 51  Val Dice 0.76708, Train Dice 0.969483, Test Dice 0.698340\n",
    "# Step 52  Val Dice 0.75212, Train Dice 0.970604, Test Dice 0.690025\n",
    "# Step 53  Val Dice 0.76250, Train Dice 0.970394, Test Dice 0.702614\n",
    "# Step 54  Val Dice 0.75914, Train Dice 0.972191, Test Dice 0.698490\n",
    "# Step 55  Val Dice 0.76763, Train Dice 0.972444, Test Dice 0.699107\n",
    "# Step 56  Val Dice 0.75130, Train Dice 0.967618, Test Dice 0.699443\n",
    "# Step 57  Val Dice 0.75133, Train Dice 0.967015, Test Dice 0.707088\n",
    "# Step 58  Val Dice 0.76042, Train Dice 0.966875, Test Dice 0.689892\n",
    "# Step 59  Val Dice 0.77081, Train Dice 0.971799, Test Dice 0.695811\n",
    "# Step 60  Val Dice 0.75911, Train Dice 0.968470, Test Dice 0.697367\n",
    "# 61\n",
    "# Step 61  Val Dice 0.75387, Train Dice 0.969686, Test Dice 0.689574\n",
    "# Step 62  Val Dice 0.75741, Train Dice 0.969149, Test Dice 0.688727\n",
    "# Step 63  Val Dice 0.76713, Train Dice 0.973280, Test Dice 0.696694\n",
    "# Step 64  Val Dice 0.75212, Train Dice 0.976112, Test Dice 0.699461\n",
    "# Step 65  Val Dice 0.75807, Train Dice 0.972746, Test Dice 0.694473\n",
    "# Step 66  Val Dice 0.76460, Train Dice 0.974965, Test Dice 0.704639\n",
    "# Step 67  Val Dice 0.76268, Train Dice 0.974017, Test Dice 0.701859\n",
    "# Step 68  Val Dice 0.76516, Train Dice 0.974272, Test Dice 0.696131\n",
    "# Step 69  Val Dice 0.75653, Train Dice 0.973761, Test Dice 0.698658\n",
    "# Step 70  Val Dice 0.76347, Train Dice 0.971662, Test Dice 0.688311\n",
    "# 71\n",
    "# Step 71  Val Dice 0.76223, Train Dice 0.975641, Test Dice 0.703012\n",
    "# Step 72  Val Dice 0.75781, Train Dice 0.976026, Test Dice 0.682989\n",
    "# Step 73  Val Dice 0.76153, Train Dice 0.976484, Test Dice 0.705805\n",
    "# Step 74  Val Dice 0.75872, Train Dice 0.972559, Test Dice 0.698913\n",
    "# Step 75  Val Dice 0.75577, Train Dice 0.973283, Test Dice 0.703776\n",
    "# Step 76  Val Dice 0.76094, Train Dice 0.973409, Test Dice 0.695360\n",
    "# Step 77  Val Dice 0.75377, Train Dice 0.976300, Test Dice 0.699502\n",
    "# Step 78  Val Dice 0.76078, Train Dice 0.979076, Test Dice 0.698064\n",
    "# Step 79  Val Dice 0.76206, Train Dice 0.978934, Test Dice 0.701142\n",
    "# Step 80  Val Dice 0.76116, Train Dice 0.976962, Test Dice 0.694985\n",
    "# 81\n",
    "# Step 81  Val Dice 0.76168, Train Dice 0.974400, Test Dice 0.700762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22,
     44,
     51,
     60,
     91,
     115,
     146,
     156,
     180,
     213,
     236,
     264,
     276,
     307,
     373,
     446,
     483,
     501,
     543,
     597
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For training different models for comparison on COVID-19 dataset using SU-Net  Model\n",
    "\n",
    "import skimage\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/'\n",
    "basepath_models  = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/models/'\n",
    "\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = F.sigmoid(pred)\n",
    "    \n",
    "    pred   = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        #output[output > 0.5]= 1\n",
    "        #output[output < 0.5]= 0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_predictions(models, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        models[i].eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(5):\n",
    "            output = models[k].forward(x)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = output.data.cpu().numpy()\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_sum = np.zeros(outputs[0].shape, dtype='float16')\n",
    "        for k in range(5):\n",
    "            output_sum = output_sum+outputs[k]\n",
    "        output_sum = output_sum/5.0\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output_sum[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array)\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def get_filtered(valx, valy):\n",
    "    valxf = []\n",
    "    valyf = []\n",
    "    \n",
    "    for i in range(valx.shape[0]):\n",
    "        if np.count_nonzero(valy[i]) > 0:\n",
    "            valxf.append(valx[i])\n",
    "            valyf.append(valy[i])\n",
    "    return np.array(valxf), np.array(valyf)\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 4\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "    \n",
    "    idx    = np.random.permutation(trainx.shape[0])\n",
    "    trainx = trainx[idx]\n",
    "    trainy = trainy[idx]\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def prepare_batch(batch_size, k_means, trainx_l, trainy_l, h):\n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(int(batch_size/2)):\n",
    "        idx = random.randint(0, trainx_l.shape[0]-1)\n",
    "        c   = k_means.predict(np.reshape(trainx_l[idx].astype('float32'), [1, 512*512]))[0]\n",
    "        \n",
    "        a.append(trainx_l[idx])\n",
    "        b.append(trainy_l[idx])\n",
    "        \n",
    "        idx = random.randint(0, len(h[c])-1)\n",
    "        t1  = np.expand_dims(np.load(h[c][idx]), 0)\n",
    "        t2  = np.expand_dims(np.load(h[c][idx].replace('-x', '-y')), 0)\n",
    "        \n",
    "        a.append(t1)\n",
    "        b.append(t2)\n",
    "   \n",
    "    a1 = np.array(a).astype('float16')\n",
    "    b1 = np.array(b).astype('float16')\n",
    "   \n",
    "    return a1, b1\n",
    "\n",
    "def store_cluster_slices(model_teacher, k_means, version):\n",
    "    epoch_array = np.arange(79)\n",
    "    all_labels  = []\n",
    "    step_size   = 10 \n",
    "    count       = 0\n",
    "    \n",
    "    for epoch in epoch_array:\n",
    "        temp_index               = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "        trainx, trainx_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "        trainy                   = get_prediction(model_teacher, trainx)\n",
    "        \n",
    "        #trainy = np.load('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/PREDICTION-NUMPY/'+str(epoch)+'.npy')\n",
    "        trainy = np.reshape(trainy, [trainy.shape[0], 512*512])\n",
    "        #print(epoch, trainy.shape, trainx.shape)\n",
    "        \n",
    "        l1     = k_means.predict(trainy)\n",
    "        \n",
    "        for jt, t in enumerate(l1):\n",
    "            temp  = np.reshape(trainy[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-y.npy', temp)\n",
    "            \n",
    "            temp  = np.reshape(trainx[jt], [512, 512]).astype('float16')\n",
    "            np.save('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/'+str(t)+'-'+str(count)+'-x.npy', temp)\n",
    "            \n",
    "            count = count+1\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_hash(version):\n",
    "    all_cluster_files = glob.glob('/media/pranjal/BackupPlus/SIEMENS/SIEMENS/CLUSTER-NUMPY-'+str(version)+'/*.npy')\n",
    "    print('Version ', version, 'File name counts ', len(all_cluster_files))\n",
    "    filename_hash = {}\n",
    "    for i in range(50):\n",
    "        filename_hash[i] = []\n",
    "\n",
    "    for t in all_cluster_files:\n",
    "        filename_hash[int(t.split('/')[-1].split('-')[0])].append(t)\n",
    "    \n",
    "    return filename_hash\n",
    "\n",
    "def get_all_covid_lesions(valx, valy, lesion_size):\n",
    "    lesion_shapes_x = []\n",
    "    lesion_shapes_y = []\n",
    "    \n",
    "    for i in range(valy.shape[0]):\n",
    "        tx           = valx[i, 0]\n",
    "        blobs        = valy[i, 0]\n",
    "        blobs_labels = skimage.measure.label(blobs, background=0)\n",
    "        propsa       = skimage.measure.regionprops(blobs_labels)\n",
    "        \n",
    "        for k in range(len(propsa)):\n",
    "            temp = (blobs_labels == propsa[k].label).astype('uint8')\n",
    "            \n",
    "            temp_size = np.count_nonzero(temp.flatten().astype('uint8'))\n",
    "            if temp_size < lesion_size and temp_size > 5:\n",
    "                slice_x, slice_y = ndimage.find_objects(temp == 1)[0]\n",
    "                \n",
    "                roi_y = 1-temp[slice_x, slice_y]\n",
    "                roi_x = tx[slice_x, slice_y]*temp[slice_x, slice_y]\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x)\n",
    "                lesion_shapes_y.append(roi_y)\n",
    "                \n",
    "                lesion_shapes_x.append(roi_x.T)\n",
    "                lesion_shapes_y.append(roi_y.T)\n",
    "                \n",
    "                lesion_shapes_x.append(np.rot90(roi_x, 180))\n",
    "                lesion_shapes_y.append(np.rot90(roi_y, 180))\n",
    "    \n",
    "    return lesion_shapes_x, lesion_shapes_y\n",
    "\n",
    "def get_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            i,j = np.nonzero(mask[t])\n",
    "            \n",
    "            index = random.randint(0, len(i)-1)\n",
    "            \n",
    "            i = i[index]\n",
    "            j = j[index]\n",
    "            \n",
    "            lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "            \n",
    "            lesion_x     = lesion_shapes_x[lesion_index]\n",
    "            lesion_y     = lesion_shapes_y[lesion_index]\n",
    "            \n",
    "            sx     = int(lesion_x.shape[0]/2)\n",
    "            sy     = int(lesion_x.shape[1]/2)\n",
    "            \n",
    "            if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                m1         = m1*mask[t]\n",
    "                m1[m1 > 0] = 1\n",
    "\n",
    "                x_array.append(np.expand_dims(st,          axis=0))\n",
    "                x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "\n",
    "                count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_multiple_augmented_slice(batch_size, read_ids, lesion_shapes_x, lesion_shapes_y):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    index   = random.randint(0, len(read_ids)-1)\n",
    "    #print(read_ids[index])\n",
    "    \n",
    "    p       = read_ids[index].split('_')[0]\n",
    "    types   = 'CT-1'#read_ids[index].split('_')[1]\n",
    "    count   = 0\n",
    "    \n",
    "    name     = basepath+'studies/'+types+'/'\n",
    "    maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "    volname  = name+'study_'+p+'.nii.gz'\n",
    "    \n",
    "    segmentation_mask = basepath+'masks/'\n",
    "    segmentation_mask = segmentation_mask+'study_'+p+'_mask.nii.gz'\n",
    "    \n",
    "    mask     = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "    vol      = (sitk.GetArrayFromImage(sitk.ReadImage(volname))+1024.0)/1024.0\n",
    "    segmentation_mask = sitk.GetArrayFromImage(sitk.ReadImage(segmentation_mask))\n",
    "    \n",
    "    mask[mask > 0] = 1\n",
    "    count          = 0\n",
    "    \n",
    "    while(count < batch_size):\n",
    "        t     = np.random.randint(0, mask.shape[0]-1)\n",
    "        temp  = np.count_nonzero(mask[t].flatten())\n",
    "        \n",
    "        # Check if lung region is present\n",
    "        if temp > 0:\n",
    "            st  = vol[t]\n",
    "            #segmen\n",
    "            ipl, jpl = np.nonzero(mask[t])\n",
    "            \n",
    "            lesion_count = random.randint(0, 5)\n",
    "            temp_count   = 0\n",
    "            \n",
    "            while(temp_count < lesion_count):\n",
    "                index = random.randint(0, len(ipl)-1)\n",
    "\n",
    "                i = ipl[index]\n",
    "                j = jpl[index]\n",
    "\n",
    "                lesion_index = random.randint(0, len(lesion_shapes_x)-1)\n",
    "\n",
    "                lesion_x     = lesion_shapes_x[lesion_index]\n",
    "                lesion_y     = lesion_shapes_y[lesion_index]\n",
    "\n",
    "                sx     = int(lesion_x.shape[0]/2)\n",
    "                sy     = int(lesion_x.shape[1]/2)\n",
    "\n",
    "                if st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy].shape == lesion_x.shape:\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_y*st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "                    st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  =  lesion_x + st[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]\n",
    "\n",
    "                    m1 = segmentation_mask[t]#np.zeros(st.shape)\n",
    "                    m1[i-sx:i+lesion_x.shape[0]-sx, j-sy:j+lesion_x.shape[1]-sy]  += 1-lesion_y\n",
    "                    m1         = m1*mask[t]\n",
    "                    m1[m1 > 0] = 1\n",
    "                    segmentation_mask[t] = m1\n",
    "                    temp_count           = temp_count + 1\n",
    "            \n",
    "            x_array.append(np.expand_dims(st,          axis=0))\n",
    "            x_array_lungmask.append(np.expand_dims(m1, axis=0))\n",
    "            \n",
    "            count = count+1\n",
    "\n",
    "    x_array          = np.array(x_array)\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def plot_figure_slope(model_save_name):\n",
    "    N = 2\n",
    "    a = val_dice_array1#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = train_dice_array1#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = test_dice_array1#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    temp  = 0\n",
    "    slope = 0\n",
    "    #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "    for i in range(1, len(a)):\n",
    "        if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "            temp  = i#np.argmax(a)\n",
    "            slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "            #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "\n",
    "def plot_figure(model_save_name):\n",
    "    a = list(val_dice_array)#np.convolve(val_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    b = list(train_dice_array)#np.convolve(train_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    c = list(test_dice_array)#np.convolve(test_dice_array1, np.ones((N,))/N, mode='valid')\n",
    "    \n",
    "    #a.insert(0, 0)\n",
    "    #b.insert(0, 0)\n",
    "    #c.insert(0, 0)\n",
    "#     temp  = 0\n",
    "#     slope = 0\n",
    "#     #np.abs(np.abs(b[i]-b[i-1])-np.abs(a[i]-a[i-1])) < 0.1 and\n",
    "#     for i in range(1, len(a)):\n",
    "#         if b[i] >= b[i-1] and a[i] >= a[i-1]:\n",
    "#             temp  = i#np.argmax(a)\n",
    "#             slope = b[i]-b[i-1]-(a[i]-a[i-1])\n",
    "#             #print(i, slope, np.abs(b[i]-b[i-1]), np.abs(a[i]-a[i-1]), b[i], b[i-1])\n",
    "    \n",
    "    # Take arg max for semi model\n",
    "    temp = np.argmax(a)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.ylabel('some numbers')\n",
    "    plt.annotate('Index '+str(temp), xy=(0.75, 0.25), xycoords='axes fraction')\n",
    "    plt.annotate('Train '+str(round(b[temp], 3)), xy=(0.75, 0.20), xycoords='axes fraction')\n",
    "    plt.annotate('Val   '+str(round(a[temp], 3)), xy=(0.75, 0.15), xycoords='axes fraction')\n",
    "    plt.annotate('Test  '+str(round(c[temp], 3)), xy=(0.75, 0.10), xycoords='axes fraction')\n",
    "    #plt.annotate('Slope '+str(round(slope, 3)),   xy=(0.75, 0.05), xycoords='axes fraction')\n",
    "    #plt.text(6, 0, )\n",
    "    #plt.text(6, 0.1, 'Val   '+str(round(a[temp], 3)))\n",
    "    #plt.text(6, 0.2, 'Train '+str(round(b[temp], 3)))\n",
    "    #plt.text(6, 0.3, 'Test  '+str(round(c[temp], 3)))\n",
    "    \n",
    "    plt.savefig(model_save_name+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return\n",
    "\n",
    "def train_model1(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "        #x2 = model.forward(x)        \n",
    "        #print(x2.shape)\n",
    "        \n",
    "#         lstm = nn.LSTM(512*512,512*512,batchfirst=True)\n",
    "#         hidden = (torch.randn(1, 512, 512), torch.randn(1, 512, 512))\n",
    "#         outlstm = lstm(x, hidden)\n",
    "#         n = np.asarray(outlstm)\n",
    "  \n",
    "        print(i, x.shape[0])\n",
    "        \n",
    "        if(x.shape[0]!= 4):\n",
    "            break\n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        y = np.expand_dims(y, 1)\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def train_model2(model, batch_size, optimizer, criterion, trainx, trainy, augment=False):\n",
    "    #batch_size = 4\n",
    "    loss_array = []\n",
    "   \n",
    "    model.train()\n",
    "    #print(len(trainx)//batch_size)\n",
    "   \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, 0, :, :]\n",
    "        \n",
    "                \n",
    "        if augment:\n",
    "            for k in range(x.shape[0]):\n",
    "                rotv = random.randint(0, 3)\n",
    "                x[k, 0, :, :] = np.rot90(x[k, 0, :, :], rotv)\n",
    "                y[k, 0, :, :] = np.rot90(y[k, 0, :, :], rotv)\n",
    "       \n",
    "  \n",
    "        if(x.shape[0]!=4):\n",
    "            break\n",
    "            \n",
    "    \n",
    "        x = np.expand_dims(x, 1)\n",
    "        \n",
    "\n",
    "        y = np.expand_dims(y, 1)\n",
    "\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_attn_w.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        #print(i,attn_weights[1])\n",
    "        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "       \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "       # torch.nn.utils.clip_grad_norm(attn_decoder1.parameters(),0.7)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer_attn_w.step()\n",
    "   \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "device         = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "# train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "# val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "# test_ids       = np.load(basepath+'TEST.npy')\n",
    "# unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "# nocovid_ids    = np.load(basepath+'NOCOVID.npy')\n",
    "\n",
    "\n",
    "# unlabelled_ids     = unlabelled_ids\n",
    "# train_ids          = train_ids[:4]\n",
    "# val_ids            = val_ids\n",
    "# test_ids           = test_ids\n",
    "\n",
    "trainx_l = np.load(basepath+'train_x.npy')/255.0\n",
    "trainy_l = np.load(basepath+'train_y.npy')\n",
    "trainy_l[trainy_l > 0] = 1\n",
    "\n",
    "train_size    = 40\n",
    "valx = trainx_l[train_size:]\n",
    "valy = trainy_l[train_size:]\n",
    "\n",
    "trainx_l = trainx_l[:train_size]\n",
    "trainy_l = trainy_l[:train_size]\n",
    "\n",
    "testx = np.load(basepath+'test_x.npy')/255.0\n",
    "testy = np.load(basepath+'test_y.npy')\n",
    "testy[testy > 0] = 1\n",
    "\n",
    "\n",
    "trainx_l1 = np.zeros([trainx_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valx1     = np.zeros([valx.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testx1    = np.zeros([testx.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "trainy_l1 = np.zeros([trainy_l.shape[0], 1, 512, 512], dtype='float16')\n",
    "valy1     = np.zeros([valy.shape[0], 1, 512, 512],     dtype='float16')\n",
    "testy1    = np.zeros([testy.shape[0], 1, 512, 512],    dtype='float16')\n",
    "\n",
    "\n",
    "for i in range(trainx_l.shape[0]):\n",
    "    trainx_l1[i, 0] = scipy.ndimage.zoom(trainx_l[i], 2, order=3)\n",
    "    trainy_l1[i, 0] = scipy.ndimage.zoom(trainy_l[i], 2, order=0)\n",
    "\n",
    "for i in range(valx.shape[0]):\n",
    "    valx1[i, 0] = scipy.ndimage.zoom(valx[i], 2, order=3)\n",
    "    valy1[i, 0] = scipy.ndimage.zoom(valy[i], 2, order=0)\n",
    "\n",
    "for i in range(testx.shape[0]):\n",
    "    testx1[i, 0] = scipy.ndimage.zoom(testx[i], 2, order=3)\n",
    "    testy1[i, 0] = scipy.ndimage.zoom(testy[i], 2, order=0)\n",
    "\n",
    "\n",
    "trainx_l = trainx_l1\n",
    "trainy_l = trainy_l1\n",
    "valx = valx1\n",
    "valy = valy1\n",
    "testx = testx1\n",
    "testy = testy1\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "prev_max        = -1000\n",
    "model_student   = UNetDoubleSmallWithoutGN(1, 1)\n",
    "model_student.cuda()\n",
    "\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0001)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "\n",
    "val_dice_array   = []\n",
    "train_dice_array = []\n",
    "test_dice_array  = []\n",
    "\n",
    "trainx, trainy   = sort_data(trainx_l, trainy_l)\n",
    "total_epochs = 1000\n",
    "\n",
    "\n",
    "# trainx = np.expand_dims(trainx, axis=1)\n",
    "# trainy = np.expand_dims(trainy, axis=1)\n",
    "\n",
    "# valx   = np.expand_dims(valx, axis=1)\n",
    "# valy   = np.expand_dims(valy, axis=1)\n",
    "\n",
    "# testx  = np.expand_dims(testx, axis=1)\n",
    "# testy  = np.expand_dims(testy, axis=1)\n",
    "\n",
    "teacher_dice_array = []\n",
    "test_dice_array    = []\n",
    "\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    if epoch%10 ==1:\n",
    "        print(epoch)\n",
    "    #train_model1(model, optimizer, criterion, trainx, trainy, augment=False)\n",
    "    train_loss    = train_model(model_student, 4, optimizer_student, criterion, trainx, trainy, False)\n",
    "    #train_loss    = train_model(model_student, 2, optimizer_student, criterion, trainx, trainy, False)\n",
    "    \n",
    "    val_dice      = evaluate_result(model_student, valx,   valy)\n",
    "    student_dice1 = evaluate_result(model_student, trainx, trainy)\n",
    "    student_dice2 = evaluate_result(model_student, testx,  testy)\n",
    "    \n",
    "    \n",
    "    train_dice_array.append(np.mean(student_dice1))\n",
    "    val_dice_array.append(np.mean(val_dice))\n",
    "    test_dice_array.append(np.mean(student_dice2))\n",
    "\n",
    "    model_save_name = \"tmi-compare-unet-covid19\"\n",
    "    \n",
    "    #if np.mean(val_dice) > prev_max:\n",
    "    print(\"Step %d  Val Dice %.5f, Train Dice %f, Test Dice %f\" % (epoch, np.mean(val_dice), np.mean(student_dice1), np.mean(student_dice2)))\n",
    "    prev_max     = np.mean(val_dice)\n",
    "    torch.save(model_student.state_dict(), basepath_models+model_save_name+'-'+str(epoch)+\".pt\")\n",
    "\n",
    "    #np.save(model_save_name+'_train.npy',      train_dice_array)\n",
    "    #np.save(model_save_name+'_validation.npy', val_dice_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('trainx_sai.npy', trainx)\n",
    "# np.save('trainy_sai.npy', trainy)\n",
    "# np.save('valx_sai.npy', valx)\n",
    "# np.save('valy_sai.npy', valy)\n",
    "# np.save('testx_sai.npy', testx)\n",
    "# np.save('testy_sai.npy', testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([258784.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,   3360.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainy[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1640, 1, 512, 512) (1640, 1, 512, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainy[index].flatten())\n",
    "print(trainy.shape, trainx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd40c10fa90>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 10)#1000, trainx.shape[0]-1)\n",
    "index  = 0\n",
    "#print(index, trainx.shape)\n",
    "plt.imshow(trainx[index, 0].astype('float32'), cmap='gray')\n",
    "plt.imshow(trainy[index, 0].astype('float32'), cmap='jet', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     21,
     43,
     50,
     81,
     103,
     127,
     151
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For training the Group Norm using un-labelled data\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "basepath         = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID_MOSCOW/COVID_MOSCOW/COVID19_1110/'\n",
    "basepath_models  = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID_MOSCOW/COVID_MOSCOW/COVID19_1110/models/single_models/'\n",
    "\n",
    "\n",
    "def read_training_data(read_ids):\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for p in read_ids:\n",
    "        name = basepath+'masks/'\n",
    "        name = name+'study_'+p+'_mask.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(name))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(name.replace('_mask.nii.gz', '.nii.gz').replace('masks', 'studies/CT-1')))\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            temp  = np.count_nonzero(mask[t].flatten())\n",
    "            if temp > 0:\n",
    "                x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                y_array.append(np.expand_dims(mask[t], axis=0))\n",
    "\n",
    "    x_array = (np.array(x_array)+1024.0)/1024.0\n",
    "    y_array = np.array(y_array)\n",
    "    \n",
    "    return x_array, y_array\n",
    "\n",
    "def dice(im1, im2):\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum()+0.00001)\n",
    "\n",
    "def read_training_data_unlabelled(read_ids):\n",
    "    x_array          = []\n",
    "    x_array_lungmask = []\n",
    "    \n",
    "    names   = [x.split('_')[0] for x in read_ids]\n",
    "    types   = [x.split('_')[1] for x in read_ids]\n",
    "    count   = 0\n",
    "    \n",
    "    for p in names:\n",
    "        name     = basepath+'studies/'+types[count]+'/'\n",
    "        maskname = name+'study_'+p+'_mask.nii.gz'\n",
    "        volname  = name+'study_'+p+'.nii.gz'\n",
    "        \n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(maskname))\n",
    "        vol  = sitk.GetArrayFromImage(sitk.ReadImage(volname))\n",
    "        mask[mask > 0] = 1\n",
    "        \n",
    "        for t in range(mask.shape[0]):\n",
    "            if True:#t % 1 == 0:\n",
    "                temp  = np.count_nonzero(mask[t].flatten())\n",
    "                if temp > 0: # Check if lung region is present\n",
    "                    x_array.append(np.expand_dims(vol[t], axis=0))\n",
    "                    x_array_lungmask.append(np.expand_dims(mask[t], axis=0))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "    x_array          = (np.array(x_array)+1024.0)/1024.0\n",
    "    x_array_lungmask = np.array(x_array_lungmask)\n",
    "    \n",
    "    return x_array, x_array_lungmask\n",
    "\n",
    "def get_prediction(model, valx):\n",
    "    output_array   = []\n",
    "    batch_size     = 1\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        \n",
    "        for k in range(output.shape[0]):\n",
    "            output_array.append(output[k, 0])\n",
    "    \n",
    "    output_array = np.array(output_array).astype('float16')\n",
    "    output_array = np.expand_dims(output_array, 1)\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "def evaluate_result(model, valx, valy):\n",
    "    model.eval()\n",
    "    \n",
    "    val_dice       = []\n",
    "    batch_size     = 1\n",
    "    for ik in range(len(valx)//batch_size):\n",
    "        x = valx[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "        y = valy[ik*batch_size:(ik+1)*batch_size, :, :, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "\n",
    "        output = model.forward(x)\n",
    "\n",
    "        output = torch.sigmoid(output)        \n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        output[output < 0.5] = 0\n",
    "        output[output > 0.5] = 1\n",
    "        \n",
    "        for pk in range(output.shape[0]):\n",
    "            dt = dice(y[pk, 0, :, :], output[pk, 0, :, :])\n",
    "            val_dice.append(dt)\n",
    "    return val_dice\n",
    "\n",
    "def train_model(model, optimizer, criterion, trainx, trainy):\n",
    "    batch_size = 2\n",
    "    loss_array = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i in range(len(trainx)//batch_size):\n",
    "        x = trainx[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = trainy[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)        \n",
    "        loss   = criterion(output , y)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_array = np.mean(loss_array)\n",
    "    return loss_array\n",
    "\n",
    "def sort_data(trainx1, trainy1):\n",
    "    # Sort the data\n",
    "    X = trainx1\n",
    "    Y = trainy1\n",
    "    r = [t for t in sorted(zip(Y,X), key=lambda pair: np.sum(pair[0].flatten()))]\n",
    "    \n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        trainy.append(r[i][0])\n",
    "        trainx.append(r[i][1])\n",
    "    \n",
    "    trainx = np.array(trainx)\n",
    "    trainy = np.array(trainy)\n",
    "    \n",
    "    return trainx, trainy\n",
    "        \n",
    "train_ids      = np.load(basepath+'TRAIN.npy')\n",
    "val_ids        = np.load(basepath+'VALIDATION.npy')\n",
    "test_ids       = np.load(basepath+'TEST.npy')\n",
    "unlabelled_ids = np.load(basepath+'NOTLABELLED.npy')\n",
    "\n",
    "train_ids           = train_ids\n",
    "\n",
    "trainx_l, trainy_l = read_training_data(train_ids)\n",
    "valx, valy         = read_training_data(val_ids)\n",
    "testx, testy       = read_training_data(test_ids)\n",
    "\n",
    "print(trainx_l.shape, valx.shape, testx.shape)\n",
    "\n",
    "valx_img = sitk.GetImageFromArray(valx.astype('float32')[:, 0, :, :])\n",
    "sitk.WriteImage(valx_img, basepath+'CT-img.nii.gz')\n",
    "\n",
    "\n",
    "model_teacher = SUNet(1,1)#UNetDoubleSmall(1,1)\n",
    "model_teacher.cuda()\n",
    "\n",
    "\n",
    "p1         = torch.load(basepath_models+\"tmi-f-3-93.pt\")\n",
    "model_teacher.load_state_dict(p1)\n",
    "\n",
    "\n",
    "device             = torch.device(\"cuda:0\")\n",
    "optimizer_student  = optim.Adam(model_student.parameters(), lr=0.0005)\n",
    "criterion          = nn.BCEWithLogitsLoss(torch.ones([1]).cuda())\n",
    "\n",
    "val_loss_array   = []\n",
    "train_loss_array = []\n",
    "\n",
    "prev_max_teacher = -1000\n",
    "prev_max    = -1000\n",
    "model_count = 0\n",
    "step_size   = 20\n",
    "beta        = 0.9\n",
    "\n",
    "val_dice_t   = evaluate_result(model_teacher, valx, valy)\n",
    "print(\"Dice in the beginning \", np.mean(val_dice_t))\n",
    "\n",
    "val_dice_t = np.mean(val_dice_t)\n",
    "prev_max   = val_dice_t\n",
    "\n",
    "teacher_dice_array = []\n",
    "\n",
    "train_dice_array = []\n",
    "val_dice_array   = []\n",
    "test_dice_array  = []\n",
    "\n",
    "model_save_name = \"tmi-f-semi-sunet\"\n",
    "\n",
    "first_time = True\n",
    "\n",
    "for epoch in range(300):\n",
    "    temp_index                 = epoch%(int(len(unlabelled_ids)/step_size))\n",
    "    trainx1, trainx1_lungmask  = read_training_data_unlabelled(unlabelled_ids[temp_index*step_size:temp_index*step_size+step_size])\n",
    "    trainy1                    = get_prediction(model_teacher, trainx1)\n",
    "    \n",
    "    trainx, trainy = sort_data(trainx1, trainy1)\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch, trainx.shape, trainy.shape)\n",
    "    \n",
    "    train_loss = train_model(model_student, optimizer_student, criterion, trainx, trainy)\n",
    "    \n",
    "    train_dice = evaluate_result(model_student, trainx_l, trainy_l)\n",
    "    val_dice   = evaluate_result(model_student, valx, valy)\n",
    "    \n",
    "    # Update teacher weights\n",
    "    if np.mean(val_dice) > val_dice_t:\n",
    "        print(epoch, ' Updating Teacher Weights')\n",
    "        torch.save(model_student.state_dict(), \"temp.pt\")\n",
    "        torch.save(model_student.state_dict(), basepath_models+model_save_name+\".pt\")\n",
    "        p1         = torch.load('temp.pt')\n",
    "        \n",
    "        model_teacher.load_state_dict(p1)\n",
    "        val_dice_t = np.mean(val_dice)\n",
    "    \n",
    "    train_dice_array.append(np.mean(train_dice))\n",
    "    val_dice_array.append(np.mean(val_dice))\n",
    "    \n",
    "    print(\"Step %d  Train Dice %.5f  Val Dice %.5f \" % (epoch, np.mean(train_dice), np.mean(val_dice)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "# [STAR] For selecting the most reliable weights\n",
    "\n",
    "s  = 300\n",
    "a1 = np.zeros([s, 236])\n",
    "b1 = np.zeros([s, 126])\n",
    "\n",
    "count = 0\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "\n",
    "model_save_name = 'tmi-f-single-semi'\n",
    "\n",
    "def scoring_function(val_array, test_array, epoch):\n",
    "    score_array = []\n",
    "    step_size   = 5\n",
    "    alpha       = 10\n",
    "    \n",
    "    temp_array     = val_array[epoch-step_size:epoch]\n",
    "    sum_array      = 1-np.mean(temp_array, axis=0)\n",
    "    var_array      = np.std(temp_array, axis=0)\n",
    "\n",
    "    score_temp     = sum_array + alpha*var_array\n",
    "    final_score    = score_temp*val_array[epoch]\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "for epoch in range(s):\n",
    "    a = np.load('/home/yu-hao/AttentionDeepMIL/val_dice_array-'+model_save_name+'--'+str(epoch)+'.npy')\n",
    "    a1[epoch] = a\n",
    "\n",
    "score_array = []\n",
    "for epoch in range(100, 300):\n",
    "    final_score = scoring_function(a1, b1, epoch)\n",
    "    score_array.append(np.mean(final_score))\n",
    "\n",
    "index = np.argmax(score_array) \n",
    "print('Most reliable Weights Index ', index, score_array[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# For creating the dataset for COVID-19\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "arr_x = []\n",
    "arr_y = []\n",
    "\n",
    "#train = glob.glob('/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/TestingSet/LungInfection-Test/Imgs/*.jpg')\n",
    "train = glob.glob('/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/UnlabelledSet/Imgs/*.jpg')\n",
    "\n",
    "for t in train:\n",
    "    img = imageio.imread(t)\n",
    "    res = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "    arr_x.append(res.T)\n",
    "    \n",
    "    #img = imageio.imread(t.replace('Imgs', 'GT').replace('jpg', 'png'))\n",
    "    #res = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "    #arr_y.append(res.T)\n",
    "    \n",
    "    #print(img.shape, res.shape, t.split('/')[-1])\n",
    "\n",
    "\n",
    "arr_x = np.array(arr_x)\n",
    "arr_y = np.array(arr_y)\n",
    "\n",
    "print(arr_x.shape, arr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f587b7c5048>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#np.save('/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/unlabelled_x.npy', arr_x)\n",
    "#np.save('/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/test_y.npy', arr_y)\n",
    "\n",
    "\n",
    "basepath         = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/'\n",
    "basepath_models  = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/COVID19/COVID-SemiSeg/Dataset/models/'\n",
    "\n",
    "\n",
    "trainx_l = np.load(basepath+'train_x.npy')\n",
    "trainy_l = np.load(basepath+'train_y.npy')\n",
    "\n",
    "valx = trainx_l[40:]\n",
    "valy = trainy_l[40:]\n",
    "\n",
    "trainx_l = trainx_l[:40]\n",
    "trainy_l = trainy_l[:40]\n",
    "\n",
    "testx = np.load(basepath+'test_x.npy')\n",
    "testy = np.load(basepath+'test_y.npy')\n",
    "\n",
    "index = random.randint(0, trainx_l.shape[0]-1)\n",
    "plt.imshow(trainx_l[index], cmap='gray')\n",
    "plt.imshow(trainy_l[index], cmap='jet', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
